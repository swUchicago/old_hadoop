2017-01-25 12:53:07,196 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-01-25 12:53:07,429 ERROR org.apache.hadoop.dfs.DataNode: java.lang.NullPointerException
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:120)
	at org.apache.hadoop.dfs.DataNode.startDataNode(DataNode.java:220)
	at org.apache.hadoop.dfs.DataNode.<init>(DataNode.java:190)
	at org.apache.hadoop.dfs.DataNode.makeInstance(DataNode.java:2987)
	at org.apache.hadoop.dfs.DataNode.instantiateDataNode(DataNode.java:2942)
	at org.apache.hadoop.dfs.DataNode.createDataNode(DataNode.java:2950)
	at org.apache.hadoop.dfs.DataNode.main(DataNode.java:3072)

2017-01-25 12:53:07,431 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-01-25 12:57:00,330 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-01-25 12:57:00,424 ERROR org.apache.hadoop.dfs.DataNode: java.lang.NullPointerException
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:120)
	at org.apache.hadoop.dfs.DataNode.startDataNode(DataNode.java:220)
	at org.apache.hadoop.dfs.DataNode.<init>(DataNode.java:190)
	at org.apache.hadoop.dfs.DataNode.makeInstance(DataNode.java:2987)
	at org.apache.hadoop.dfs.DataNode.instantiateDataNode(DataNode.java:2942)
	at org.apache.hadoop.dfs.DataNode.createDataNode(DataNode.java:2950)
	at org.apache.hadoop.dfs.DataNode.main(DataNode.java:3072)

2017-01-25 12:57:00,426 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-01-25 13:02:30,018 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-01-25 13:02:30,116 ERROR org.apache.hadoop.dfs.DataNode: java.lang.NullPointerException
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:120)
	at org.apache.hadoop.dfs.DataNode.startDataNode(DataNode.java:220)
	at org.apache.hadoop.dfs.DataNode.<init>(DataNode.java:190)
	at org.apache.hadoop.dfs.DataNode.makeInstance(DataNode.java:2987)
	at org.apache.hadoop.dfs.DataNode.instantiateDataNode(DataNode.java:2942)
	at org.apache.hadoop.dfs.DataNode.createDataNode(DataNode.java:2950)
	at org.apache.hadoop.dfs.DataNode.main(DataNode.java:3072)

2017-01-25 13:02:30,117 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-01-25 13:13:14,995 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-01-25 13:13:15,075 ERROR org.apache.hadoop.dfs.DataNode: java.lang.NullPointerException
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:120)
	at org.apache.hadoop.dfs.DataNode.startDataNode(DataNode.java:220)
	at org.apache.hadoop.dfs.DataNode.<init>(DataNode.java:190)
	at org.apache.hadoop.dfs.DataNode.makeInstance(DataNode.java:2987)
	at org.apache.hadoop.dfs.DataNode.instantiateDataNode(DataNode.java:2942)
	at org.apache.hadoop.dfs.DataNode.createDataNode(DataNode.java:2950)
	at org.apache.hadoop.dfs.DataNode.main(DataNode.java:3072)

2017-01-25 13:13:15,076 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-01-25 13:19:18,162 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-01-25 13:19:18,258 ERROR org.apache.hadoop.dfs.DataNode: java.lang.NullPointerException
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:120)
	at org.apache.hadoop.dfs.DataNode.startDataNode(DataNode.java:220)
	at org.apache.hadoop.dfs.DataNode.<init>(DataNode.java:190)
	at org.apache.hadoop.dfs.DataNode.makeInstance(DataNode.java:2987)
	at org.apache.hadoop.dfs.DataNode.instantiateDataNode(DataNode.java:2942)
	at org.apache.hadoop.dfs.DataNode.createDataNode(DataNode.java:2950)
	at org.apache.hadoop.dfs.DataNode.main(DataNode.java:3072)

2017-01-25 13:19:18,258 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-01-25 13:31:25,547 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-01-25 13:31:25,640 ERROR org.apache.hadoop.dfs.DataNode: java.lang.NullPointerException
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:120)
	at org.apache.hadoop.dfs.DataNode.startDataNode(DataNode.java:220)
	at org.apache.hadoop.dfs.DataNode.<init>(DataNode.java:190)
	at org.apache.hadoop.dfs.DataNode.makeInstance(DataNode.java:2987)
	at org.apache.hadoop.dfs.DataNode.instantiateDataNode(DataNode.java:2942)
	at org.apache.hadoop.dfs.DataNode.createDataNode(DataNode.java:2950)
	at org.apache.hadoop.dfs.DataNode.main(DataNode.java:3072)

2017-01-25 13:31:25,642 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-01-25 13:33:25,922 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-01-25 13:33:26,004 ERROR org.apache.hadoop.dfs.DataNode: java.lang.NullPointerException
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:120)
	at org.apache.hadoop.dfs.DataNode.startDataNode(DataNode.java:220)
	at org.apache.hadoop.dfs.DataNode.<init>(DataNode.java:190)
	at org.apache.hadoop.dfs.DataNode.makeInstance(DataNode.java:2987)
	at org.apache.hadoop.dfs.DataNode.instantiateDataNode(DataNode.java:2942)
	at org.apache.hadoop.dfs.DataNode.createDataNode(DataNode.java:2950)
	at org.apache.hadoop.dfs.DataNode.main(DataNode.java:3072)

2017-01-25 13:33:26,005 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-01-25 13:37:04,223 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-01-25 13:37:04,313 ERROR org.apache.hadoop.dfs.DataNode: java.lang.NullPointerException
	at org.apache.hadoop.net.NetUtils.createSocketAddr(NetUtils.java:130)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:116)
	at org.apache.hadoop.dfs.NameNode.getAddress(NameNode.java:120)
	at org.apache.hadoop.dfs.DataNode.startDataNode(DataNode.java:220)
	at org.apache.hadoop.dfs.DataNode.<init>(DataNode.java:190)
	at org.apache.hadoop.dfs.DataNode.makeInstance(DataNode.java:2987)
	at org.apache.hadoop.dfs.DataNode.instantiateDataNode(DataNode.java:2942)
	at org.apache.hadoop.dfs.DataNode.createDataNode(DataNode.java:2950)
	at org.apache.hadoop.dfs.DataNode.main(DataNode.java:3072)

2017-01-25 13:37:04,314 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-01-25 13:38:48,222 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-01-25 13:38:48,419 INFO org.apache.hadoop.dfs.Storage: Storage directory /tmp/hadoop-ubuntu/dfs/data is not formatted.
2017-01-25 13:38:48,419 INFO org.apache.hadoop.dfs.Storage: Formatting ...
2017-01-25 13:38:48,498 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-01-25 13:38:48,500 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-01-25 13:38:48,502 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-01-25 13:38:48,566 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-01-25 13:38:48,623 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-01-25 13:38:48,624 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-01-25 13:38:48,624 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-01-25 13:38:48,973 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@3e4203
2017-01-25 13:38:49,003 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-01-25 13:38:49,005 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-01-25 13:38:49,005 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1428b92
2017-01-25 13:38:49,009 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-01-25 13:38:49,028 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-01-25 13:38:49,034 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-01-25 13:38:49,035 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-01-25 13:38:49,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-01-25 13:38:49,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-01-25 13:38:49,036 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=, infoPort=50075, ipcPort=50020)
2017-01-25 13:38:49,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-01-25 13:38:49,051 INFO org.apache.hadoop.dfs.DataNode: New storage id DS-824238571-192.168.1.153-50010-1485347929046 is assigned to data-node 192.168.1.153:50010
2017-01-25 13:38:49,051 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-824238571-192.168.1.153-50010-1485347929046, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/tmp/hadoop-ubuntu/dfs/data/current'}
2017-01-25 13:38:49,052 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-01-25 13:38:49,079 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-01-25 13:38:52,057 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 0 blocks got processed in 5 msecs
2017-01-25 13:40:28,809 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2790146584740114245_1001 src: /192.168.1.150:39591 dest: /192.168.1.150:50010
2017-01-25 13:40:31,432 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2790146584740114245_1001 of size 67108864 from /192.168.1.150
2017-01-25 13:40:31,433 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_2790146584740114245_1001 terminating
2017-01-25 13:40:31,444 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7483195498917248287_1001 src: /192.168.1.149:45007 dest: /192.168.1.149:50010
2017-01-25 13:40:34,155 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7483195498917248287_1001 of size 67108864 from /192.168.1.149
2017-01-25 13:40:34,156 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 3 for block blk_7483195498917248287_1001 terminating
2017-01-25 13:40:34,163 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_400271960667239907_1001 src: /192.168.1.149:45008 dest: /192.168.1.149:50010
2017-01-25 13:40:36,710 INFO org.apache.hadoop.dfs.DataNode: Received block blk_400271960667239907_1001 of size 67108864 from /192.168.1.149
2017-01-25 13:40:36,710 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 3 for block blk_400271960667239907_1001 terminating
2017-01-25 13:40:36,717 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1563805579239834675_1001 src: /192.168.1.149:45009 dest: /192.168.1.149:50010
2017-01-25 13:40:39,667 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1563805579239834675_1001 of size 67108864 from /192.168.1.149
2017-01-25 13:40:39,668 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 3 for block blk_-1563805579239834675_1001 terminating
2017-01-25 13:40:39,685 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7071485614296096692_1001 src: /192.168.1.149:45010 dest: /192.168.1.149:50010
2017-01-25 13:40:42,134 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7071485614296096692_1001 of size 67108864 from /192.168.1.149
2017-01-25 13:40:42,135 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 3 for block blk_7071485614296096692_1001 terminating
2017-01-25 13:40:42,143 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8199783887394004628_1001 src: /192.168.1.149:45011 dest: /192.168.1.149:50010
2017-01-25 13:40:44,708 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8199783887394004628_1001 of size 67108864 from /192.168.1.149
2017-01-25 13:40:44,709 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 3 for block blk_-8199783887394004628_1001 terminating
2017-01-25 13:40:44,722 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2620284790544624968_1001 src: /192.168.1.152:52091 dest: /192.168.1.152:50010
2017-01-25 13:40:47,386 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2620284790544624968_1001 of size 67108864 from /192.168.1.152
2017-01-25 13:40:47,387 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_2620284790544624968_1001 terminating
2017-01-25 13:40:47,397 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2810230500076811144_1001 src: /192.168.1.149:45013 dest: /192.168.1.149:50010
2017-01-25 13:40:49,886 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2810230500076811144_1001 of size 67108864 from /192.168.1.149
2017-01-25 13:40:49,887 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 3 for block blk_-2810230500076811144_1001 terminating
2017-01-25 13:40:49,908 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1413298075455969439_1001 src: /192.168.1.151:48765 dest: /192.168.1.151:50010
2017-01-25 13:40:52,458 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1413298075455969439_1001 of size 67108864 from /192.168.1.151
2017-01-25 13:40:52,458 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-1413298075455969439_1001 terminating
2017-01-25 13:40:52,474 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2258330095751324702_1001 src: /192.168.1.152:52094 dest: /192.168.1.152:50010
2017-01-25 13:40:55,518 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2258330095751324702_1001 of size 67108864 from /192.168.1.152
2017-01-25 13:40:55,519 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_2258330095751324702_1001 terminating
2017-01-25 13:40:55,535 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2384965920294131514_1001 src: /192.168.1.150:39599 dest: /192.168.1.150:50010
2017-01-25 13:40:57,958 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2384965920294131514_1001 of size 67108864 from /192.168.1.150
2017-01-25 13:40:57,959 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_-2384965920294131514_1001 terminating
2017-01-25 13:40:57,969 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5702801935970232371_1001 src: /192.168.1.150:39600 dest: /192.168.1.150:50010
2017-01-25 13:40:59,345 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5702801935970232371_1001 of size 37345947 from /192.168.1.150
2017-01-25 13:40:59,345 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_5702801935970232371_1001 terminating
2017-01-25 13:47:10,043 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_2790146584740114245_1001
2017-01-25 13:48:14,642 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_400271960667239907_1001
2017-01-25 13:49:19,242 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_7483195498917248287_1001
2017-01-25 13:51:07,269 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-01-25 13:51:32,957 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-01-25 13:51:33,213 ERROR org.apache.hadoop.dfs.DataNode: java.io.IOException: Incompatible namespaceIDs in /tmp/hadoop-ubuntu/dfs/data: namenode namespaceID = 1649181079; datanode namespaceID = 1482718088
	at org.apache.hadoop.dfs.DataStorage.doTransition(DataStorage.java:226)
	at org.apache.hadoop.dfs.DataStorage.recoverTransitionRead(DataStorage.java:141)
	at org.apache.hadoop.dfs.DataNode.startDataNode(DataNode.java:273)
	at org.apache.hadoop.dfs.DataNode.<init>(DataNode.java:190)
	at org.apache.hadoop.dfs.DataNode.makeInstance(DataNode.java:2987)
	at org.apache.hadoop.dfs.DataNode.instantiateDataNode(DataNode.java:2942)
	at org.apache.hadoop.dfs.DataNode.createDataNode(DataNode.java:2950)
	at org.apache.hadoop.dfs.DataNode.main(DataNode.java:3072)

2017-01-25 13:51:33,215 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-01-25 13:55:33,768 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-01-25 13:55:34,037 ERROR org.apache.hadoop.dfs.DataNode: java.io.IOException: Incompatible namespaceIDs in /tmp/hadoop-ubuntu/dfs/data: namenode namespaceID = 1649181079; datanode namespaceID = 1482718088
	at org.apache.hadoop.dfs.DataStorage.doTransition(DataStorage.java:226)
	at org.apache.hadoop.dfs.DataStorage.recoverTransitionRead(DataStorage.java:141)
	at org.apache.hadoop.dfs.DataNode.startDataNode(DataNode.java:273)
	at org.apache.hadoop.dfs.DataNode.<init>(DataNode.java:190)
	at org.apache.hadoop.dfs.DataNode.makeInstance(DataNode.java:2987)
	at org.apache.hadoop.dfs.DataNode.instantiateDataNode(DataNode.java:2942)
	at org.apache.hadoop.dfs.DataNode.createDataNode(DataNode.java:2950)
	at org.apache.hadoop.dfs.DataNode.main(DataNode.java:3072)

2017-01-25 13:55:34,039 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-01-25 13:59:49,604 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-01-25 13:59:49,867 ERROR org.apache.hadoop.dfs.DataNode: java.io.IOException: Incompatible namespaceIDs in /tmp/hadoop-ubuntu/dfs/data: namenode namespaceID = 651906; datanode namespaceID = 1482718088
	at org.apache.hadoop.dfs.DataStorage.doTransition(DataStorage.java:226)
	at org.apache.hadoop.dfs.DataStorage.recoverTransitionRead(DataStorage.java:141)
	at org.apache.hadoop.dfs.DataNode.startDataNode(DataNode.java:273)
	at org.apache.hadoop.dfs.DataNode.<init>(DataNode.java:190)
	at org.apache.hadoop.dfs.DataNode.makeInstance(DataNode.java:2987)
	at org.apache.hadoop.dfs.DataNode.instantiateDataNode(DataNode.java:2942)
	at org.apache.hadoop.dfs.DataNode.createDataNode(DataNode.java:2950)
	at org.apache.hadoop.dfs.DataNode.main(DataNode.java:3072)

2017-01-25 13:59:49,868 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-01-25 14:04:19,758 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-01-25 14:04:20,015 ERROR org.apache.hadoop.dfs.DataNode: java.io.IOException: Incompatible namespaceIDs in /tmp/hadoop-ubuntu/dfs/data: namenode namespaceID = 1862473998; datanode namespaceID = 1482718088
	at org.apache.hadoop.dfs.DataStorage.doTransition(DataStorage.java:226)
	at org.apache.hadoop.dfs.DataStorage.recoverTransitionRead(DataStorage.java:141)
	at org.apache.hadoop.dfs.DataNode.startDataNode(DataNode.java:273)
	at org.apache.hadoop.dfs.DataNode.<init>(DataNode.java:190)
	at org.apache.hadoop.dfs.DataNode.makeInstance(DataNode.java:2987)
	at org.apache.hadoop.dfs.DataNode.instantiateDataNode(DataNode.java:2942)
	at org.apache.hadoop.dfs.DataNode.createDataNode(DataNode.java:2950)
	at org.apache.hadoop.dfs.DataNode.main(DataNode.java:3072)

2017-01-25 14:04:20,017 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
