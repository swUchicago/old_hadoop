2017-06-12 00:41:34,550 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-06-12 01:41:34,890 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-06-12 02:41:35,156 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-06-12 03:41:37,882 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-06-12 04:41:38,676 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-06-12 05:41:39,185 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-06-12 06:41:41,901 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-06-12 07:41:42,754 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 2 msecs
2017-06-12 08:41:43,012 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-06-12 09:41:43,558 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 2 msecs
2017-06-12 10:41:44,242 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-06-12 11:41:44,807 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-06-12 12:41:45,800 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-06-12 13:41:46,474 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-06-12 13:53:17,139 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 13:53:27,927 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 13:53:28,137 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 13:53:28,138 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 13:53:28,140 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 13:53:28,212 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 13:53:28,272 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 13:53:28,273 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 13:53:28,273 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 13:53:28,516 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-06-12 13:53:28,554 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 13:53:28,557 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 13:53:28,557 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 13:53:28,562 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 13:53:28,581 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 13:53:28,586 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 13:53:28,586 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 13:53:28,588 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 13:53:28,588 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 13:53:28,589 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 13:53:28,589 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 13:53:28,591 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 13:53:28,592 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 13:53:28,602 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 13:53:31,600 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-06-12 13:54:28,625 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8398867088423654570_3280 src: /192.168.1.157:56588 dest: /192.168.1.157:50010
2017-06-12 13:54:28,651 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8398867088423654570_3280 src: /192.168.1.157:56588 dest: /192.168.1.157:50010 of size 91176
2017-06-12 13:54:28,702 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3864908518966715244_3282 src: /192.168.1.158:39818 dest: /192.168.1.158:50010
2017-06-12 13:54:28,704 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3864908518966715244_3282 src: /192.168.1.158:39818 dest: /192.168.1.158:50010 of size 13560
2017-06-12 13:54:28,991 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 13:54:31,603 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7187081691974326397_3281 src: /192.168.1.157:56596 dest: /192.168.1.157:50010
2017-06-12 13:54:31,610 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7187081691974326397_3281 src: /192.168.1.157:56596 dest: /192.168.1.157:50010 of size 2165
2017-06-12 13:54:34,603 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1807378698007185883_3284 src: /192.168.1.157:56599 dest: /192.168.1.157:50010
2017-06-12 13:54:34,604 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1807378698007185883_3284 src: /192.168.1.157:56599 dest: /192.168.1.157:50010 of size 13545
2017-06-12 13:54:46,414 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 13:54:50,754 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-06-12 13:54:51,802 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-06-12 13:54:57,762 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 13:55:08,223 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 13:55:12,603 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 13:55:28,503 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-06-12 13:56:16,709 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1807378698007185883_3284 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1807378698007185883
2017-06-12 13:56:16,709 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3864908518966715244_3282 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3864908518966715244
2017-06-12 13:56:16,710 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7187081691974326397_3281 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7187081691974326397
2017-06-12 13:56:16,710 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8398867088423654570_3280 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8398867088423654570
2017-06-12 13:56:22,706 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 13:56:33,419 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 13:56:33,603 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 13:56:33,605 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 13:56:33,606 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 13:56:33,673 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 13:56:33,729 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 13:56:33,730 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 13:56:33,730 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 13:56:33,965 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-06-12 13:56:34,004 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 13:56:34,006 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 13:56:34,006 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 13:56:34,011 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 13:56:34,030 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 13:56:34,035 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 13:56:34,035 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 13:56:34,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 13:56:34,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 13:56:34,037 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 13:56:34,037 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 13:56:34,057 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 13:56:34,058 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 13:56:34,071 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 13:56:37,075 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-06-12 13:57:39,459 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 13:57:40,183 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2879779314407707132_3290 src: /192.168.1.158:39870 dest: /192.168.1.158:50010
2017-06-12 13:57:40,194 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2879779314407707132_3290 src: /192.168.1.158:39870 dest: /192.168.1.158:50010 of size 2165
2017-06-12 13:57:40,207 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7869541685308795209_3289 src: /192.168.1.156:41120 dest: /192.168.1.156:50010
2017-06-12 13:57:40,212 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7869541685308795209_3289 src: /192.168.1.156:41120 dest: /192.168.1.156:50010 of size 91176
2017-06-12 13:57:43,199 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9080898050475780168_3293 src: /192.168.1.156:41121 dest: /192.168.1.156:50010
2017-06-12 13:57:43,200 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9080898050475780168_3293 src: /192.168.1.156:41121 dest: /192.168.1.156:50010 of size 13545
2017-06-12 13:57:46,134 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8513922124554039631_3291 src: /192.168.1.158:39873 dest: /192.168.1.158:50010
2017-06-12 13:57:46,135 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8513922124554039631_3291 src: /192.168.1.158:39873 dest: /192.168.1.158:50010 of size 13560
2017-06-12 13:57:56,182 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 13:57:59,574 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-06-12 13:58:02,303 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-06-12 13:58:07,184 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 13:58:18,260 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-06-12 13:58:22,218 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-06-12 13:58:23,043 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 13:59:37,169 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1498413300591572_3298 src: /192.168.1.158:39916 dest: /192.168.1.158:50010
2017-06-12 13:59:37,172 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1498413300591572_3298 src: /192.168.1.158:39916 dest: /192.168.1.158:50010 of size 26940
2017-06-12 13:59:37,257 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-253457559538255652_3294 src: /192.168.1.156:41163 dest: /192.168.1.156:50010
2017-06-12 13:59:37,845 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-253457559538255652_3294 src: /192.168.1.156:41163 dest: /192.168.1.156:50010 of size 41550601
2017-06-12 13:59:40,183 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9080898050475780168_3293 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9080898050475780168
2017-06-12 13:59:40,183 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7869541685308795209_3289 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7869541685308795209
2017-06-12 13:59:40,184 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2879779314407707132_3290 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2879779314407707132
2017-06-12 13:59:40,184 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8513922124554039631_3291 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8513922124554039631
2017-06-12 13:59:45,374 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 13:59:56,234 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 13:59:56,425 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 13:59:56,427 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 13:59:56,429 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 13:59:56,495 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 13:59:56,552 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 13:59:56,553 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 13:59:56,553 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 13:59:56,793 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-06-12 13:59:56,828 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 13:59:56,831 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 13:59:56,831 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-06-12 13:59:56,836 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 13:59:56,853 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 13:59:56,858 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 13:59:56,859 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 13:59:56,860 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 13:59:56,861 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 13:59:56,861 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 13:59:56,861 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 13:59:56,872 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 13:59:56,873 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 13:59:56,887 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 13:59:59,890 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 26 blocks got processed in 14 msecs
2017-06-12 14:00:32,892 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-253457559538255652_3294 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-253457559538255652
2017-06-12 14:00:32,893 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1498413300591572_3298 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1498413300591572
2017-06-12 14:00:34,850 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-253457559538255652_3294
2017-06-12 14:01:02,251 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-06-12 14:01:02,334 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 14:01:02,945 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7073630916140705650_3300 src: /192.168.1.158:39930 dest: /192.168.1.158:50010
2017-06-12 14:01:02,957 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7073630916140705650_3300 src: /192.168.1.158:39930 dest: /192.168.1.158:50010 of size 2165
2017-06-12 14:01:03,006 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2566162366766345983_3299 src: /192.168.1.158:39931 dest: /192.168.1.158:50010
2017-06-12 14:01:03,021 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2566162366766345983_3299 src: /192.168.1.158:39931 dest: /192.168.1.158:50010 of size 91176
2017-06-12 14:01:06,005 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8069648128039448758_3301 src: /192.168.1.156:41182 dest: /192.168.1.156:50010
2017-06-12 14:01:06,007 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8069648128039448758_3301 src: /192.168.1.156:41182 dest: /192.168.1.156:50010 of size 13560
2017-06-12 14:01:08,925 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6569068534147500114_3303 src: /192.168.1.158:39934 dest: /192.168.1.158:50010
2017-06-12 14:01:08,926 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6569068534147500114_3303 src: /192.168.1.158:39934 dest: /192.168.1.158:50010 of size 13545
2017-06-12 14:01:18,998 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 14:01:19,609 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-06-12 14:01:25,138 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-06-12 14:01:25,177 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 14:01:41,839 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-06-12 14:01:41,948 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-06-12 14:01:45,245 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-06-12 14:01:45,248 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 14:03:05,981 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8069648128039448758_3301 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8069648128039448758
2017-06-12 14:03:05,981 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7073630916140705650_3300 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7073630916140705650
2017-06-12 14:03:05,982 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2566162366766345983_3299 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2566162366766345983
2017-06-12 14:03:08,986 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6569068534147500114_3303 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6569068534147500114
2017-06-12 14:03:15,783 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 14:03:26,688 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 14:03:26,880 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 14:03:26,882 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 14:03:26,884 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 14:03:26,953 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 14:03:27,013 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 14:03:27,014 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 14:03:27,014 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 14:03:27,251 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-06-12 14:03:27,291 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 14:03:27,294 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 14:03:27,294 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 14:03:27,299 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 14:03:27,323 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 14:03:27,328 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 14:03:27,328 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 14:03:27,330 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 14:03:27,330 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 14:03:27,331 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 14:03:27,331 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 14:03:27,350 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 14:03:27,350 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 14:03:27,362 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 14:03:30,365 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-06-12 14:04:27,457 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1058670541508968738_3309 src: /192.168.1.158:39976 dest: /192.168.1.158:50010
2017-06-12 14:04:27,468 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3267137701346166748_3313 src: /192.168.1.158:39977 dest: /192.168.1.158:50010
2017-06-12 14:04:27,482 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1058670541508968738_3309 src: /192.168.1.158:39976 dest: /192.168.1.158:50010 of size 91176
2017-06-12 14:04:27,483 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3267137701346166748_3313 src: /192.168.1.158:39977 dest: /192.168.1.158:50010 of size 13545
2017-06-12 14:04:27,714 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-06-12 14:04:27,722 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 14:04:30,389 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4516319862248541661_3310 src: /192.168.1.156:41252 dest: /192.168.1.156:50010
2017-06-12 14:04:30,391 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-803569156549562686_3311 src: /192.168.1.156:41253 dest: /192.168.1.156:50010
2017-06-12 14:04:30,392 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4516319862248541661_3310 src: /192.168.1.156:41252 dest: /192.168.1.156:50010 of size 2165
2017-06-12 14:04:30,393 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-803569156549562686_3311 src: /192.168.1.156:41253 dest: /192.168.1.156:50010 of size 13560
2017-06-12 14:04:32,819 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 14:04:45,313 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 14:04:46,028 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 14:04:50,184 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 14:04:53,020 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 14:04:53,041 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-06-12 14:05:10,228 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 14:06:21,442 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_473710692241621861_3317 src: /192.168.1.158:40012 dest: /192.168.1.158:50010
2017-06-12 14:06:21,444 INFO org.apache.hadoop.dfs.DataNode: Received block blk_473710692241621861_3317 src: /192.168.1.158:40012 dest: /192.168.1.158:50010 of size 27439
2017-06-12 14:06:24,543 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4516319862248541661_3310 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4516319862248541661
2017-06-12 14:06:24,543 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3267137701346166748_3313 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3267137701346166748
2017-06-12 14:06:24,544 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1058670541508968738_3309 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1058670541508968738
2017-06-12 14:06:24,544 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-803569156549562686_3311 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-803569156549562686
2017-06-12 14:06:24,544 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_473710692241621861_3317 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_473710692241621861
2017-06-12 14:06:31,527 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 14:06:42,380 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 14:06:42,597 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 14:06:42,599 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 14:06:42,601 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 14:06:42,668 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 14:06:42,725 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 14:06:42,726 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 14:06:42,726 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 14:06:42,979 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-06-12 14:06:43,018 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 14:06:43,021 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 14:06:43,022 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-06-12 14:06:43,027 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 14:06:43,046 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 14:06:43,054 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 14:06:43,054 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 14:06:43,055 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 14:06:43,055 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 14:06:43,055 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 14:06:43,056 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 14:06:43,058 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 14:06:43,059 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 14:06:43,070 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 14:06:46,070 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-06-12 14:07:48,425 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-06-12 14:07:48,487 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 14:07:49,067 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_692837836862001395_3318 src: /192.168.1.156:41315 dest: /192.168.1.156:50010
2017-06-12 14:07:49,084 INFO org.apache.hadoop.dfs.DataNode: Received block blk_692837836862001395_3318 src: /192.168.1.156:41315 dest: /192.168.1.156:50010 of size 91176
2017-06-12 14:07:49,101 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2404321471702871780_3319 src: /192.168.1.158:40025 dest: /192.168.1.158:50010
2017-06-12 14:07:49,101 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2404321471702871780_3319 src: /192.168.1.158:40025 dest: /192.168.1.158:50010 of size 2165
2017-06-12 14:07:52,065 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8613692471678278504_3322 src: /192.168.1.156:41316 dest: /192.168.1.156:50010
2017-06-12 14:07:52,066 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8613692471678278504_3322 src: /192.168.1.156:41316 dest: /192.168.1.156:50010 of size 13545
2017-06-12 14:07:52,072 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4466499245546960759_3320 src: /192.168.1.156:41317 dest: /192.168.1.156:50010
2017-06-12 14:07:52,073 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4466499245546960759_3320 src: /192.168.1.156:41317 dest: /192.168.1.156:50010 of size 13560
2017-06-12 14:07:52,099 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4466499245546960759_3320 src: /192.168.1.157:56859 dest: /192.168.1.157:50010
2017-06-12 14:07:52,099 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8613692471678278504_3322 src: /192.168.1.157:56860 dest: /192.168.1.157:50010
2017-06-12 14:07:52,099 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4466499245546960759_3320 received exception java.io.IOException: Block blk_4466499245546960759_3320 is valid, and cannot be written to.
2017-06-12 14:07:52,099 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8613692471678278504_3322 received exception java.io.IOException: Block blk_8613692471678278504_3322 is valid, and cannot be written to.
2017-06-12 14:07:52,101 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_4466499245546960759_3320 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 14:07:52,101 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8613692471678278504_3322 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 14:07:53,619 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 14:07:55,124 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4466499245546960759_3320 to 192.168.1.158:50010
2017-06-12 14:07:55,128 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_4466499245546960759_3320 to /192.168.1.158:50010
2017-06-12 14:08:06,496 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 14:08:06,819 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 14:08:13,502 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 14:08:14,608 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-06-12 14:08:30,458 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 14:08:31,181 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 14:09:43,124 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1360853692564451566_3326 src: /192.168.1.158:40052 dest: /192.168.1.158:50010
2017-06-12 14:09:43,126 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1360853692564451566_3326 src: /192.168.1.158:40052 dest: /192.168.1.158:50010 of size 27896
2017-06-12 14:09:46,204 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_692837836862001395_3318 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_692837836862001395
2017-06-12 14:09:46,205 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2404321471702871780_3319 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2404321471702871780
2017-06-12 14:09:46,205 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4466499245546960759_3320 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4466499245546960759
2017-06-12 14:09:46,205 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8613692471678278504_3322 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8613692471678278504
2017-06-12 14:09:52,218 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 14:10:03,034 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 14:10:03,224 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 14:10:03,226 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 14:10:03,228 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 14:10:03,298 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 14:10:03,354 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 14:10:03,355 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 14:10:03,355 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 14:10:03,590 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-06-12 14:10:03,638 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 14:10:03,640 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 14:10:03,640 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-06-12 14:10:03,646 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 14:10:03,665 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 14:10:03,670 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 14:10:03,670 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 14:10:03,671 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 14:10:03,672 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 14:10:03,672 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 14:10:03,672 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 14:10:03,687 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 14:10:03,687 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 14:10:03,698 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 14:10:03,753 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_1360853692564451566_3326
2017-06-12 14:10:06,696 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 5 msecs
2017-06-12 14:10:39,752 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1360853692564451566_3326 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1360853692564451566
2017-06-12 14:11:08,980 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-06-12 14:11:08,996 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 14:11:09,716 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6688277368444185467_3327 src: /192.168.1.158:40065 dest: /192.168.1.158:50010
2017-06-12 14:11:09,726 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6688277368444185467_3327 src: /192.168.1.158:40065 dest: /192.168.1.158:50010 of size 91176
2017-06-12 14:11:09,766 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6273474858246904636_3331 src: /192.168.1.156:41382 dest: /192.168.1.156:50010
2017-06-12 14:11:09,769 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6273474858246904636_3331 src: /192.168.1.156:41382 dest: /192.168.1.156:50010 of size 13545
2017-06-12 14:11:12,703 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3538642204101686696_3328 src: /192.168.1.157:56928 dest: /192.168.1.157:50010
2017-06-12 14:11:12,705 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3538642204101686696_3328 src: /192.168.1.157:56928 dest: /192.168.1.157:50010 of size 2165
2017-06-12 14:11:12,774 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5354999683186626562_3329 src: /192.168.1.156:41383 dest: /192.168.1.156:50010
2017-06-12 14:11:12,775 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5354999683186626562_3329 src: /192.168.1.156:41383 dest: /192.168.1.156:50010 of size 13560
2017-06-12 14:11:12,775 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3538642204101686696_3328 src: /192.168.1.156:41384 dest: /192.168.1.156:50010
2017-06-12 14:11:12,776 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3538642204101686696_3328 received exception java.io.IOException: Block blk_-3538642204101686696_3328 is valid, and cannot be written to.
2017-06-12 14:11:12,777 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-3538642204101686696_3328 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 14:11:14,138 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 14:11:15,769 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-3538642204101686696_3328 to 192.168.1.158:50010
2017-06-12 14:11:15,772 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-3538642204101686696_3328 to /192.168.1.158:50010
2017-06-12 14:11:26,361 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 14:11:27,524 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-06-12 14:11:31,803 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 14:11:34,083 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 14:11:50,420 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 14:11:52,936 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 14:12:08,209 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-06-12 14:12:36,813 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6979691953186148274_3335 src: /192.168.1.158:40093 dest: /192.168.1.158:50010
2017-06-12 14:12:36,815 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6979691953186148274_3335 src: /192.168.1.158:40093 dest: /192.168.1.158:50010 of size 26580
2017-06-12 14:12:39,800 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6273474858246904636_3331 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6273474858246904636
2017-06-12 14:12:39,800 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3538642204101686696_3328 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3538642204101686696
2017-06-12 14:12:39,801 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5354999683186626562_3329 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5354999683186626562
2017-06-12 14:12:39,801 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6688277368444185467_3327 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6688277368444185467
2017-06-12 14:12:47,640 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 14:12:58,462 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 14:12:58,668 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 14:12:58,670 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 14:12:58,672 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 14:12:58,732 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 14:12:58,781 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 14:12:58,782 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 14:12:58,782 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 14:12:59,007 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-06-12 14:12:59,043 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 14:12:59,046 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 14:12:59,046 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 14:12:59,051 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 14:12:59,069 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 14:12:59,077 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 14:12:59,078 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 14:12:59,078 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 14:12:59,078 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 14:12:59,079 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 14:12:59,079 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 14:12:59,081 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 14:12:59,081 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 14:12:59,088 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 14:12:59,144 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_6979691953186148274_3335
2017-06-12 14:13:02,089 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 8 msecs
2017-06-12 14:13:35,167 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6979691953186148274_3335 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6979691953186148274
2017-06-12 14:13:59,007 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4179468569981995132_3336 src: /192.168.1.156:41431 dest: /192.168.1.156:50010
2017-06-12 14:13:59,023 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4179468569981995132_3336 src: /192.168.1.156:41431 dest: /192.168.1.156:50010 of size 91176
2017-06-12 14:13:59,149 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2361220582291360079_3340 src: /192.168.1.157:56984 dest: /192.168.1.157:50010
2017-06-12 14:13:59,161 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2361220582291360079_3340 src: /192.168.1.157:56984 dest: /192.168.1.157:50010 of size 13553
2017-06-12 14:13:59,490 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-06-12 14:13:59,557 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 14:14:01,993 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4620310610743847592_3338 src: /192.168.1.156:41439 dest: /192.168.1.156:50010
2017-06-12 14:14:01,994 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1297227484697028191_3337 src: /192.168.1.156:41440 dest: /192.168.1.156:50010
2017-06-12 14:14:02,001 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1297227484697028191_3337 src: /192.168.1.156:41440 dest: /192.168.1.156:50010 of size 2165
2017-06-12 14:14:02,010 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4620310610743847592_3338 src: /192.168.1.156:41439 dest: /192.168.1.156:50010 of size 13568
2017-06-12 14:14:02,136 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1297227484697028191_3337 src: /192.168.1.157:56991 dest: /192.168.1.157:50010
2017-06-12 14:14:02,136 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1297227484697028191_3337 received exception java.io.IOException: Block blk_1297227484697028191_3337 is valid, and cannot be written to.
2017-06-12 14:14:02,138 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_1297227484697028191_3337 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 14:14:15,684 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 14:14:17,244 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 14:15:41,173 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1418921021461937557_3344 src: /192.168.1.157:57059 dest: /192.168.1.157:50010
2017-06-12 14:15:41,178 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1418921021461937557_3344 src: /192.168.1.157:57059 dest: /192.168.1.157:50010 of size 23950
2017-06-12 14:15:44,349 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4179468569981995132_3336 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4179468569981995132
2017-06-12 14:15:44,350 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1297227484697028191_3337 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1297227484697028191
2017-06-12 14:15:44,350 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4620310610743847592_3338 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4620310610743847592
2017-06-12 14:15:47,350 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2361220582291360079_3340 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2361220582291360079
2017-06-12 14:15:47,350 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1418921021461937557_3344 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1418921021461937557
2017-06-12 14:15:52,345 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 14:16:03,194 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 14:16:03,384 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 14:16:03,386 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 14:16:03,388 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 14:16:03,443 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 14:16:03,490 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 14:16:03,491 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 14:16:03,491 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 14:16:03,706 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-06-12 14:16:03,741 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 14:16:03,744 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 14:16:03,744 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-06-12 14:16:03,749 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 14:16:03,765 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 14:16:03,770 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 14:16:03,770 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 14:16:03,772 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 14:16:03,782 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 14:16:03,782 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 14:16:03,782 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 14:16:03,792 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 14:16:03,793 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 14:16:03,807 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 14:16:06,807 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-06-12 14:17:09,209 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 14:17:09,880 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1805513420882118386_3346 src: /192.168.1.157:57076 dest: /192.168.1.157:50010
2017-06-12 14:17:09,896 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1805513420882118386_3346 src: /192.168.1.157:57076 dest: /192.168.1.157:50010 of size 2165
2017-06-12 14:17:09,976 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1689727599398973873_3345 src: /192.168.1.158:40122 dest: /192.168.1.158:50010
2017-06-12 14:17:09,984 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1689727599398973873_3345 src: /192.168.1.158:40122 dest: /192.168.1.158:50010 of size 91176
2017-06-12 14:17:12,893 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3949367044627823970_3349 src: /192.168.1.157:57078 dest: /192.168.1.157:50010
2017-06-12 14:17:12,895 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3949367044627823970_3349 src: /192.168.1.157:57078 dest: /192.168.1.157:50010 of size 13553
2017-06-12 14:17:14,296 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 14:17:15,858 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1505782389106449692_3347 src: /192.168.1.158:40129 dest: /192.168.1.158:50010
2017-06-12 14:17:15,859 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1505782389106449692_3347 src: /192.168.1.158:40129 dest: /192.168.1.158:50010 of size 13568
2017-06-12 14:17:27,461 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 14:17:30,913 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-06-12 14:17:32,256 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-06-12 14:17:34,323 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 14:17:50,423 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 14:18:57,953 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1689727599398973873_3345 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1689727599398973873
2017-06-12 14:18:57,953 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1505782389106449692_3347 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1505782389106449692
2017-06-12 14:18:57,954 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1805513420882118386_3346 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1805513420882118386
2017-06-12 14:19:00,951 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3949367044627823970_3349 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3949367044627823970
2017-06-12 14:19:07,002 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-06-12 14:19:07,140 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 14:19:17,988 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 14:19:18,173 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 14:19:18,175 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 14:19:18,176 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 14:19:18,241 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 14:19:18,297 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 14:19:18,298 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 14:19:18,298 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 14:19:18,533 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-06-12 14:19:18,568 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 14:19:18,570 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 14:19:18,570 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-06-12 14:19:18,575 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 14:19:18,592 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 14:19:18,597 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 14:19:18,597 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 14:19:18,599 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 14:19:18,599 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 14:19:18,600 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 14:19:18,600 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 14:19:18,610 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 14:19:18,610 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 14:19:18,624 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 14:19:21,624 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-06-12 14:20:24,102 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-06-12 14:20:24,148 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 14:20:24,653 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5444516244696152322_3354 src: /192.168.1.157:57141 dest: /192.168.1.157:50010
2017-06-12 14:20:24,669 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5444516244696152322_3354 src: /192.168.1.157:57141 dest: /192.168.1.157:50010 of size 91176
2017-06-12 14:20:24,750 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2763638533350293260_3358 src: /192.168.1.156:41572 dest: /192.168.1.156:50010
2017-06-12 14:20:24,751 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2763638533350293260_3358 src: /192.168.1.156:41572 dest: /192.168.1.156:50010 of size 13553
2017-06-12 14:20:27,658 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8910712322187498470_3355 src: /192.168.1.157:57142 dest: /192.168.1.157:50010
2017-06-12 14:20:27,659 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8910712322187498470_3355 src: /192.168.1.157:57142 dest: /192.168.1.157:50010 of size 2165
2017-06-12 14:20:27,661 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8910712322187498470_3355 src: /192.168.1.157:57143 dest: /192.168.1.157:50010
2017-06-12 14:20:27,662 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8910712322187498470_3355 received exception java.io.IOException: Block blk_-8910712322187498470_3355 is valid, and cannot be written to.
2017-06-12 14:20:27,664 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-8910712322187498470_3355 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 14:20:27,747 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6847864212504505573_3356 src: /192.168.1.156:41574 dest: /192.168.1.156:50010
2017-06-12 14:20:27,748 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6847864212504505573_3356 src: /192.168.1.156:41573 dest: /192.168.1.156:50010
2017-06-12 14:20:27,748 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6847864212504505573_3356 received exception java.io.IOException: Block blk_6847864212504505573_3356 has already been started (though not completed), and thus cannot be created.
2017-06-12 14:20:27,749 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_6847864212504505573_3356 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 14:20:27,750 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6847864212504505573_3356 src: /192.168.1.156:41574 dest: /192.168.1.156:50010 of size 13568
2017-06-12 14:20:29,200 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 14:20:30,726 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8910712322187498470_3355 to 192.168.1.158:50010
2017-06-12 14:20:30,727 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_6847864212504505573_3356 to 192.168.1.158:50010
2017-06-12 14:20:30,730 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_6847864212504505573_3356 to /192.168.1.158:50010
2017-06-12 14:20:30,730 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-8910712322187498470_3355 to /192.168.1.158:50010
2017-06-12 14:20:41,883 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 14:20:41,995 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 14:20:49,108 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 14:20:49,257 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-06-12 14:20:50,295 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 14:21:06,380 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 14:21:06,749 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-06-12 14:21:07,911 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-06-12 14:21:22,989 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-06-12 14:22:09,699 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2862811591047225913_3362 src: /192.168.1.158:40202 dest: /192.168.1.158:50010
2017-06-12 14:22:09,701 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2862811591047225913_3362 src: /192.168.1.158:40202 dest: /192.168.1.158:50010 of size 28352
2017-06-12 14:22:12,810 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8910712322187498470_3355 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8910712322187498470
2017-06-12 14:22:12,811 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5444516244696152322_3354 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5444516244696152322
2017-06-12 14:22:12,811 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6847864212504505573_3356 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6847864212504505573
2017-06-12 14:22:15,823 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2862811591047225913_3362 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2862811591047225913
2017-06-12 14:22:15,823 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2763638533350293260_3358 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2763638533350293260
2017-06-12 14:55:29,552 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-06-12 15:07:20,924 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-06-12 15:07:21,068 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 15:07:31,905 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 15:07:32,090 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 15:07:32,092 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 15:07:32,094 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 15:07:32,154 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 15:07:32,203 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 15:07:32,204 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 15:07:32,204 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 15:07:32,420 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-06-12 15:07:32,459 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 15:07:32,462 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 15:07:32,462 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 15:07:32,467 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 15:07:32,489 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 15:07:32,493 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 15:07:32,494 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 15:07:32,494 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 15:07:32,495 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 15:07:32,495 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 15:07:32,495 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 15:07:32,505 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 15:07:32,506 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 15:07:32,517 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 15:07:35,520 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-06-12 15:08:32,619 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4537593188357700512_3367 src: /192.168.1.158:40211 dest: /192.168.1.158:50010
2017-06-12 15:08:32,638 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4537593188357700512_3367 src: /192.168.1.158:40211 dest: /192.168.1.158:50010 of size 13545
2017-06-12 15:08:32,700 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7749007778266342426_3363 src: /192.168.1.158:40213 dest: /192.168.1.158:50010
2017-06-12 15:08:32,705 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7749007778266342426_3363 src: /192.168.1.158:40213 dest: /192.168.1.158:50010 of size 91176
2017-06-12 15:08:32,895 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 15:08:35,554 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7921430445421712433_3364 src: /192.168.1.157:57210 dest: /192.168.1.157:50010
2017-06-12 15:08:35,564 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7921430445421712433_3364 src: /192.168.1.157:57210 dest: /192.168.1.157:50010 of size 2165
2017-06-12 15:08:35,683 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7921430445421712433_3364 src: /192.168.1.156:41634 dest: /192.168.1.156:50010
2017-06-12 15:08:35,683 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7921430445421712433_3364 received exception java.io.IOException: Block blk_-7921430445421712433_3364 is valid, and cannot be written to.
2017-06-12 15:08:35,685 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-7921430445421712433_3364 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 15:08:38,615 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5057323800156580992_3365 src: /192.168.1.158:40220 dest: /192.168.1.158:50010
2017-06-12 15:08:38,616 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5057323800156580992_3365 src: /192.168.1.158:40220 dest: /192.168.1.158:50010 of size 13560
2017-06-12 15:08:49,219 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 15:08:53,409 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-06-12 15:08:55,692 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-06-12 15:09:00,610 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 15:09:13,394 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-06-12 15:09:13,497 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 15:09:34,188 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-06-12 15:10:35,601 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3956546736697310136_3372 src: /192.168.1.158:40260 dest: /192.168.1.158:50010
2017-06-12 15:10:35,602 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3956546736697310136_3372 src: /192.168.1.158:40260 dest: /192.168.1.158:50010 of size 28673
2017-06-12 15:10:38,690 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7921430445421712433_3364 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7921430445421712433
2017-06-12 15:10:38,690 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7749007778266342426_3363 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7749007778266342426
2017-06-12 15:10:38,703 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3956546736697310136_3372 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3956546736697310136
2017-06-12 15:10:38,704 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4537593188357700512_3367 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4537593188357700512
2017-06-12 15:10:38,705 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5057323800156580992_3365 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5057323800156580992
2017-06-12 15:10:45,773 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 15:10:56,580 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 15:10:56,770 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 15:10:56,772 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 15:10:56,773 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 15:10:56,840 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 15:10:56,897 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 15:10:56,898 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 15:10:56,898 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 15:10:57,134 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-06-12 15:10:57,171 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 15:10:57,174 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 15:10:57,174 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-06-12 15:10:57,179 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 15:10:57,199 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 15:10:57,204 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 15:10:57,204 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 15:10:57,207 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 15:10:57,207 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 15:10:57,207 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 15:10:57,208 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 15:10:57,231 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 15:10:57,232 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 15:10:57,254 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 15:11:00,248 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 16 msecs
2017-06-12 15:12:02,521 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-06-12 15:12:02,562 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 15:12:03,279 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5522635114484686021_3377 src: /192.168.1.157:57277 dest: /192.168.1.157:50010
2017-06-12 15:12:03,299 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5522635114484686021_3377 src: /192.168.1.157:57277 dest: /192.168.1.157:50010 of size 13545
2017-06-12 15:12:03,308 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2879927414621442900_3373 src: /192.168.1.156:41708 dest: /192.168.1.156:50010
2017-06-12 15:12:03,315 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2879927414621442900_3373 src: /192.168.1.156:41708 dest: /192.168.1.156:50010 of size 91176
2017-06-12 15:12:06,308 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6385704347477312454_3374 src: /192.168.1.156:41709 dest: /192.168.1.156:50010
2017-06-12 15:12:06,310 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6385704347477312454_3374 src: /192.168.1.156:41709 dest: /192.168.1.156:50010 of size 2165
2017-06-12 15:12:09,278 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1579430972574873353_3375 src: /192.168.1.158:40276 dest: /192.168.1.158:50010
2017-06-12 15:12:09,280 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1579430972574873353_3375 src: /192.168.1.158:40276 dest: /192.168.1.158:50010 of size 13560
2017-06-12 15:12:19,661 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 15:12:19,861 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-06-12 15:12:25,381 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-06-12 15:12:25,420 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 15:12:42,216 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-06-12 15:12:42,270 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 15:13:03,953 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-06-12 15:13:54,396 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5522635114484686021_3377 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5522635114484686021
2017-06-12 15:13:54,397 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1579430972574873353_3375 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1579430972574873353
2017-06-12 15:13:54,398 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2879927414621442900_3373 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2879927414621442900
2017-06-12 15:13:54,398 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6385704347477312454_3374 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6385704347477312454
2017-06-12 15:14:00,396 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-06-12 15:14:00,479 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 15:14:11,288 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 15:14:11,494 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 15:14:11,497 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 15:14:11,499 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 15:14:11,562 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 15:14:11,616 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 15:14:11,618 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 15:14:11,618 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 15:14:11,849 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-06-12 15:14:11,887 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 15:14:11,889 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 15:14:11,889 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 15:14:11,894 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 15:14:11,911 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 15:14:11,915 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 15:14:11,916 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 15:14:11,917 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 15:14:11,918 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 15:14:11,918 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 15:14:11,918 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 15:14:11,930 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 15:14:11,930 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 15:14:11,945 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 15:14:14,947 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 17 msecs
2017-06-12 15:15:17,305 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 15:15:17,985 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7385091374844219473_3384 src: /192.168.1.157:57338 dest: /192.168.1.157:50010
2017-06-12 15:15:18,000 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7385091374844219473_3384 src: /192.168.1.157:57338 dest: /192.168.1.157:50010 of size 13560
2017-06-12 15:15:18,038 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7001465032027451478_3382 src: /192.168.1.156:41778 dest: /192.168.1.156:50010
2017-06-12 15:15:18,055 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7001465032027451478_3382 src: /192.168.1.156:41778 dest: /192.168.1.156:50010 of size 91176
2017-06-12 15:15:21,040 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4249259733912319163_3383 src: /192.168.1.156:41779 dest: /192.168.1.156:50010
2017-06-12 15:15:21,041 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4249259733912319163_3383 src: /192.168.1.156:41779 dest: /192.168.1.156:50010 of size 2165
2017-06-12 15:15:23,977 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2560359199335196949_3386 src: /192.168.1.158:40322 dest: /192.168.1.158:50010
2017-06-12 15:15:23,979 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2560359199335196949_3386 src: /192.168.1.158:40322 dest: /192.168.1.158:50010 of size 13545
2017-06-12 15:15:33,900 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 15:15:38,250 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-06-12 15:15:40,136 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 15:15:45,231 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 15:15:57,125 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-06-12 15:16:01,788 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 15:16:01,897 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 15:16:06,069 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-06-12 15:16:17,646 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-06-12 15:17:27,085 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7385091374844219473_3384 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7385091374844219473
2017-06-12 15:17:27,087 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4249259733912319163_3383 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4249259733912319163
2017-06-12 15:17:27,088 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7001465032027451478_3382 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7001465032027451478
2017-06-12 15:17:30,083 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2560359199335196949_3386 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2560359199335196949
2017-06-12 15:17:36,838 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 15:17:47,638 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 15:17:47,836 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 15:17:47,838 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 15:17:47,840 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 15:17:47,905 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 15:17:47,952 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 15:17:47,953 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 15:17:47,953 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 15:17:48,174 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-06-12 15:17:48,211 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 15:17:48,215 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 15:17:48,216 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 15:17:48,225 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 15:17:48,245 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 15:17:48,250 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 15:17:48,250 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 15:17:48,252 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 15:17:48,252 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 15:17:48,253 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 15:17:48,253 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 15:17:48,261 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 15:17:48,262 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 15:17:48,274 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 15:17:51,277 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-06-12 15:18:48,410 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4747641486272308780_3395 src: /192.168.1.156:41839 dest: /192.168.1.156:50010
2017-06-12 15:18:48,423 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8686362307958231663_3391 src: /192.168.1.158:40359 dest: /192.168.1.158:50010
2017-06-12 15:18:48,429 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4747641486272308780_3395 src: /192.168.1.156:41839 dest: /192.168.1.156:50010 of size 13545
2017-06-12 15:18:48,431 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8686362307958231663_3391 src: /192.168.1.158:40359 dest: /192.168.1.158:50010 of size 91176
2017-06-12 15:18:48,820 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 15:18:48,829 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-06-12 15:18:51,375 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9215817662821364946_3392 src: /192.168.1.156:41848 dest: /192.168.1.156:50010
2017-06-12 15:18:51,375 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4393336948616441866_3393 src: /192.168.1.156:41847 dest: /192.168.1.156:50010
2017-06-12 15:18:51,376 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9215817662821364946_3392 src: /192.168.1.156:41848 dest: /192.168.1.156:50010 of size 2165
2017-06-12 15:18:51,379 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4393336948616441866_3393 src: /192.168.1.156:41847 dest: /192.168.1.156:50010 of size 13560
2017-06-12 15:18:51,387 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9215817662821364946_3392 src: /192.168.1.157:57409 dest: /192.168.1.157:50010
2017-06-12 15:18:51,387 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-9215817662821364946_3392 received exception java.io.IOException: Block blk_-9215817662821364946_3392 is valid, and cannot be written to.
2017-06-12 15:18:51,388 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-9215817662821364946_3392 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 15:18:53,942 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 15:19:06,734 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 15:19:07,039 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 15:19:11,220 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 15:19:14,008 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 15:19:16,722 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 15:19:30,197 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-06-12 15:19:34,067 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 15:20:36,420 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5943534852305921994_3399 src: /192.168.1.157:57456 dest: /192.168.1.157:50010
2017-06-12 15:20:36,425 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5943534852305921994_3399 src: /192.168.1.157:57456 dest: /192.168.1.157:50010 of size 27896
2017-06-12 15:20:39,391 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9215817662821364946_3392 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9215817662821364946
2017-06-12 15:20:39,392 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8686362307958231663_3391 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8686362307958231663
2017-06-12 15:20:39,392 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4393336948616441866_3393 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4393336948616441866
2017-06-12 15:20:42,397 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5943534852305921994_3399 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5943534852305921994
2017-06-12 15:20:42,398 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4747641486272308780_3395 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4747641486272308780
2017-06-12 15:20:47,585 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 15:20:58,435 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 15:20:58,624 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 15:20:58,626 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 15:20:58,628 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 15:20:58,693 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 15:20:58,751 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 15:20:58,751 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 15:20:58,752 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 15:20:58,993 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-06-12 15:20:59,031 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 15:20:59,034 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 15:20:59,034 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 15:20:59,039 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 15:20:59,058 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 15:20:59,063 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 15:20:59,064 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 15:20:59,065 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 15:20:59,066 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 15:20:59,066 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 15:20:59,066 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 15:20:59,099 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 15:20:59,099 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 15:20:59,108 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 15:21:02,112 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-06-12 15:22:04,475 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-06-12 15:22:04,520 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 15:22:05,158 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8498294310264546823_3402 src: /192.168.1.158:40415 dest: /192.168.1.158:50010
2017-06-12 15:22:05,176 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8498294310264546823_3402 src: /192.168.1.158:40415 dest: /192.168.1.158:50010 of size 13560
2017-06-12 15:22:05,209 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6949985340728492862_3400 src: /192.168.1.156:41914 dest: /192.168.1.156:50010
2017-06-12 15:22:05,230 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6949985340728492862_3400 src: /192.168.1.156:41914 dest: /192.168.1.156:50010 of size 91176
2017-06-12 15:22:08,209 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8458281682995379544_3401 src: /192.168.1.156:41915 dest: /192.168.1.156:50010
2017-06-12 15:22:08,209 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8458281682995379544_3401 src: /192.168.1.156:41915 dest: /192.168.1.156:50010 of size 2165
2017-06-12 15:22:09,558 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 15:22:11,187 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6229266862390794095_3404 src: /192.168.1.158:40422 dest: /192.168.1.158:50010
2017-06-12 15:22:11,189 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6229266862390794095_3404 src: /192.168.1.158:40422 dest: /192.168.1.158:50010 of size 13545
2017-06-12 15:22:23,208 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 15:22:24,246 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-06-12 15:22:27,431 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-06-12 15:22:29,562 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 15:24:02,259 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_528514784455608860_3409 src: /192.168.1.156:41969 dest: /192.168.1.156:50010
2017-06-12 15:24:02,265 INFO org.apache.hadoop.dfs.DataNode: Received block blk_528514784455608860_3409 src: /192.168.1.156:41969 dest: /192.168.1.156:50010 of size 29133
2017-06-12 15:24:05,264 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8498294310264546823_3402 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8498294310264546823
2017-06-12 15:24:05,265 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8458281682995379544_3401 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8458281682995379544
2017-06-12 15:24:05,265 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6949985340728492862_3400 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6949985340728492862
2017-06-12 15:24:05,266 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6229266862390794095_3404 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6229266862390794095
2017-06-12 15:24:11,266 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-06-12 15:24:11,357 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 15:24:22,153 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 15:24:22,342 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 15:24:22,344 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 15:24:22,345 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 15:24:22,408 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 15:24:22,457 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 15:24:22,458 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 15:24:22,458 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 15:24:22,671 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-06-12 15:24:22,704 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 15:24:22,707 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 15:24:22,707 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-06-12 15:24:22,711 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 15:24:22,728 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 15:24:22,733 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 15:24:22,733 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 15:24:22,734 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 15:24:22,735 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 15:24:22,735 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 15:24:22,735 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 15:24:22,761 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 15:24:22,761 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 15:24:22,774 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 15:24:22,834 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_528514784455608860_3409
2017-06-12 15:24:25,777 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 15 msecs
2017-06-12 15:24:58,852 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_528514784455608860_3409 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_528514784455608860
2017-06-12 15:25:28,189 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-06-12 15:25:28,211 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 15:25:28,883 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8585469204882675978_3410 src: /192.168.1.157:57539 dest: /192.168.1.157:50010
2017-06-12 15:25:28,901 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8585469204882675978_3410 src: /192.168.1.157:57539 dest: /192.168.1.157:50010 of size 91176
2017-06-12 15:25:28,962 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_780364549270920390_3412 src: /192.168.1.158:40455 dest: /192.168.1.158:50010
2017-06-12 15:25:28,971 INFO org.apache.hadoop.dfs.DataNode: Received block blk_780364549270920390_3412 src: /192.168.1.158:40455 dest: /192.168.1.158:50010 of size 13560
2017-06-12 15:25:31,884 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1178101097609582045_3414 src: /192.168.1.157:57540 dest: /192.168.1.157:50010
2017-06-12 15:25:31,885 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1178101097609582045_3414 src: /192.168.1.157:57540 dest: /192.168.1.157:50010 of size 13545
2017-06-12 15:25:31,962 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8607280812733689742_3411 src: /192.168.1.156:41986 dest: /192.168.1.156:50010
2017-06-12 15:25:31,963 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8607280812733689742_3411 src: /192.168.1.156:41986 dest: /192.168.1.156:50010 of size 2165
2017-06-12 15:25:33,238 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-06-12 15:25:45,729 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 15:25:45,988 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 15:25:50,101 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 15:25:53,351 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-06-12 15:25:53,429 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-06-12 15:25:56,265 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 15:27:22,957 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8585469204882675978_3410 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8585469204882675978
2017-06-12 15:27:22,958 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_780364549270920390_3412 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_780364549270920390
2017-06-12 15:27:22,958 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8607280812733689742_3411 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8607280812733689742
2017-06-12 15:27:25,948 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1178101097609582045_3414 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1178101097609582045
2017-06-12 15:27:32,617 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 15:27:43,495 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 15:27:43,691 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 15:27:43,693 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 15:27:43,695 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 15:27:43,766 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 15:27:43,822 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 15:27:43,823 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 15:27:43,823 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 15:27:44,060 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-06-12 15:27:44,096 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 15:27:44,098 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 15:27:44,099 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 15:27:44,104 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 15:27:44,121 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 15:27:44,126 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 15:27:44,127 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 15:27:44,128 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 15:27:44,129 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 15:27:44,129 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 15:27:44,129 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 15:27:44,131 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 15:27:44,132 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 15:27:44,140 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 15:27:47,143 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-06-12 15:28:44,190 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4442203892447891757_3419 src: /192.168.1.157:57601 dest: /192.168.1.157:50010
2017-06-12 15:28:44,208 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7868874643826297503_3421 src: /192.168.1.156:42043 dest: /192.168.1.156:50010
2017-06-12 15:28:44,218 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7868874643826297503_3421 src: /192.168.1.156:42043 dest: /192.168.1.156:50010 of size 13568
2017-06-12 15:28:44,224 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4442203892447891757_3419 src: /192.168.1.157:57601 dest: /192.168.1.157:50010 of size 91176
2017-06-12 15:28:47,201 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-469147702429451268_3420 src: /192.168.1.156:42050 dest: /192.168.1.156:50010
2017-06-12 15:28:47,210 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-469147702429451268_3420 src: /192.168.1.156:42050 dest: /192.168.1.156:50010 of size 2165
2017-06-12 15:28:47,211 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6014354438661280265_3423 src: /192.168.1.156:42051 dest: /192.168.1.156:50010
2017-06-12 15:28:47,213 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6014354438661280265_3423 src: /192.168.1.156:42051 dest: /192.168.1.156:50010 of size 13553
2017-06-12 15:30:59,198 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2049669097083798060_3427 src: /192.168.1.157:57677 dest: /192.168.1.157:50010
2017-06-12 15:30:59,201 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2049669097083798060_3427 src: /192.168.1.157:57677 dest: /192.168.1.157:50010 of size 23950
2017-06-12 15:31:02,368 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7868874643826297503_3421 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7868874643826297503
2017-06-12 15:31:02,369 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6014354438661280265_3423 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6014354438661280265
2017-06-12 15:31:02,369 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4442203892447891757_3419 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4442203892447891757
2017-06-12 15:31:02,369 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2049669097083798060_3427 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2049669097083798060
2017-06-12 15:31:02,370 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-469147702429451268_3420 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-469147702429451268
2017-06-12 15:31:09,344 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 15:31:20,257 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 15:31:20,457 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 15:31:20,458 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 15:31:20,459 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 15:31:20,528 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 15:31:20,586 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 15:31:20,587 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 15:31:20,587 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 15:31:20,825 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-06-12 15:31:20,861 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 15:31:20,864 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 15:31:20,864 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 15:31:20,870 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 15:31:20,888 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 15:31:20,893 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 15:31:20,894 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 15:31:20,895 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 15:31:20,896 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 15:31:20,896 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 15:31:20,896 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 15:31:20,899 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 15:31:20,899 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 15:31:20,908 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 15:31:23,909 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-06-12 15:32:26,844 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6432353274336695036_3430 src: /192.168.1.157:57692 dest: /192.168.1.157:50010
2017-06-12 15:32:26,860 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6432353274336695036_3430 src: /192.168.1.157:57692 dest: /192.168.1.157:50010 of size 13568
2017-06-12 15:32:26,889 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8591260530737927038_3428 src: /192.168.1.156:42121 dest: /192.168.1.156:50010
2017-06-12 15:32:26,897 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8591260530737927038_3428 src: /192.168.1.156:42121 dest: /192.168.1.156:50010 of size 91176
2017-06-12 15:32:29,825 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3792857528249049715_3429 src: /192.168.1.157:57693 dest: /192.168.1.157:50010
2017-06-12 15:32:29,827 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_543792645892697710_3432 src: /192.168.1.157:57694 dest: /192.168.1.157:50010
2017-06-12 15:32:29,828 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3792857528249049715_3429 src: /192.168.1.157:57693 dest: /192.168.1.157:50010 of size 2165
2017-06-12 15:32:29,830 INFO org.apache.hadoop.dfs.DataNode: Received block blk_543792645892697710_3432 src: /192.168.1.157:57694 dest: /192.168.1.157:50010 of size 13553
2017-06-12 15:34:38,870 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4050995253297593709_3436 src: /192.168.1.157:57757 dest: /192.168.1.157:50010
2017-06-12 15:34:38,874 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4050995253297593709_3436 src: /192.168.1.157:57757 dest: /192.168.1.157:50010 of size 23946
2017-06-12 15:34:42,102 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6432353274336695036_3430 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6432353274336695036
2017-06-12 15:34:42,102 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3792857528249049715_3429 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3792857528249049715
2017-06-12 15:34:42,103 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_543792645892697710_3432 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_543792645892697710
2017-06-12 15:34:42,103 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4050995253297593709_3436 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4050995253297593709
2017-06-12 15:34:42,104 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8591260530737927038_3428 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8591260530737927038
2017-06-12 15:34:49,021 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 15:34:59,869 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 15:35:00,059 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 15:35:00,061 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 15:35:00,062 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 15:35:00,133 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 15:35:00,191 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 15:35:00,192 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 15:35:00,192 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 15:35:00,444 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-06-12 15:35:00,481 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 15:35:00,483 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 15:35:00,483 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 15:35:00,488 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 15:35:00,506 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 15:35:00,510 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 15:35:00,511 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 15:35:00,512 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 15:35:00,513 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 15:35:00,513 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 15:35:00,513 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 15:35:00,516 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 15:35:00,516 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 15:35:00,525 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 15:35:03,528 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-06-12 15:36:06,532 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-294220375712076000_3438 src: /192.168.1.157:57774 dest: /192.168.1.157:50010
2017-06-12 15:36:06,545 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-294220375712076000_3438 src: /192.168.1.157:57774 dest: /192.168.1.157:50010 of size 2165
2017-06-12 15:36:06,602 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-636349731141435890_3437 src: /192.168.1.158:40508 dest: /192.168.1.158:50010
2017-06-12 15:36:06,604 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-636349731141435890_3437 src: /192.168.1.158:40508 dest: /192.168.1.158:50010 of size 91176
2017-06-12 15:36:09,505 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6698346615973737331_3439 src: /192.168.1.157:57775 dest: /192.168.1.157:50010
2017-06-12 15:36:09,508 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6698346615973737331_3439 src: /192.168.1.157:57775 dest: /192.168.1.157:50010 of size 13568
2017-06-12 15:36:12,612 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3968797114867784288_3441 src: /192.168.1.158:40509 dest: /192.168.1.158:50010
2017-06-12 15:36:12,615 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3968797114867784288_3441 src: /192.168.1.158:40509 dest: /192.168.1.158:50010 of size 13553
2017-06-12 15:38:18,605 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-636349731141435890_3437 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-636349731141435890
2017-06-12 15:38:18,606 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-294220375712076000_3438 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-294220375712076000
2017-06-12 15:38:18,606 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6698346615973737331_3439 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6698346615973737331
2017-06-12 15:38:21,554 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8656693011936640432_3445 src: /192.168.1.157:57840 dest: /192.168.1.157:50010
2017-06-12 15:38:21,560 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8656693011936640432_3445 src: /192.168.1.157:57840 dest: /192.168.1.157:50010 of size 23949
2017-06-12 15:38:24,604 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3968797114867784288_3441 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3968797114867784288
2017-06-12 15:47:15,984 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 6 msecs
2017-06-12 16:07:15,893 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 16:07:26,719 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 16:07:26,907 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 16:07:26,908 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 16:07:26,910 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 16:07:26,976 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 16:07:27,033 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 16:07:27,034 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 16:07:27,034 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 16:07:27,274 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-06-12 16:07:27,310 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 16:07:27,314 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 16:07:27,314 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 16:07:27,318 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 16:07:27,336 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 16:07:27,341 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 16:07:27,342 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 16:07:27,343 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 16:07:27,344 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 16:07:27,344 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 16:07:27,344 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 16:07:27,347 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 16:07:27,347 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 16:07:27,355 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 16:07:27,413 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-8656693011936640432_3445
2017-06-12 16:07:30,355 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 8 msecs
2017-06-12 16:08:03,392 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8656693011936640432_3445 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8656693011936640432
2017-06-12 16:08:27,441 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7314275304494816348_3446 src: /192.168.1.158:40512 dest: /192.168.1.158:50010
2017-06-12 16:08:27,457 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7314275304494816348_3446 src: /192.168.1.158:40512 dest: /192.168.1.158:50010 of size 91176
2017-06-12 16:08:27,471 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_96755853645383546_3447 src: /192.168.1.158:40513 dest: /192.168.1.158:50010
2017-06-12 16:08:27,472 INFO org.apache.hadoop.dfs.DataNode: Received block blk_96755853645383546_3447 src: /192.168.1.158:40513 dest: /192.168.1.158:50010 of size 2165
2017-06-12 16:08:30,392 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2271683067002388461_3450 src: /192.168.1.156:42270 dest: /192.168.1.156:50010
2017-06-12 16:08:30,396 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2271683067002388461_3450 src: /192.168.1.156:42270 dest: /192.168.1.156:50010 of size 13553
2017-06-12 16:08:33,459 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7264800113096351978_3448 src: /192.168.1.157:57860 dest: /192.168.1.157:50010
2017-06-12 16:08:33,461 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7264800113096351978_3448 src: /192.168.1.157:57860 dest: /192.168.1.157:50010 of size 13568
2017-06-12 16:10:51,450 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6856894205719611699_3454 src: /192.168.1.156:42335 dest: /192.168.1.156:50010
2017-06-12 16:10:51,456 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6856894205719611699_3454 src: /192.168.1.156:42335 dest: /192.168.1.156:50010 of size 23950
2017-06-12 16:10:54,580 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7314275304494816348_3446 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7314275304494816348
2017-06-12 16:10:54,580 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_96755853645383546_3447 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_96755853645383546
2017-06-12 16:10:54,581 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2271683067002388461_3450 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2271683067002388461
2017-06-12 16:10:54,581 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7264800113096351978_3448 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7264800113096351978
2017-06-12 16:10:59,586 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 16:11:10,341 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 16:11:10,527 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 16:11:10,529 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 16:11:10,531 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 16:11:10,592 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 16:11:10,640 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 16:11:10,640 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 16:11:10,641 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 16:11:10,861 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-06-12 16:11:10,899 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 16:11:10,901 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 16:11:10,901 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 16:11:10,907 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 16:11:10,928 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 16:11:10,934 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 16:11:10,935 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 16:11:10,935 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 16:11:10,936 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 16:11:10,936 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 16:11:10,936 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 16:11:10,945 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 16:11:10,946 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 16:11:10,966 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 16:11:11,022 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-6856894205719611699_3454
2017-06-12 16:11:13,962 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 16 msecs
2017-06-12 16:11:46,997 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6856894205719611699_3454 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6856894205719611699
2017-06-12 16:12:17,090 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5706438192550668237_3459 src: /192.168.1.157:57929 dest: /192.168.1.157:50010
2017-06-12 16:12:17,109 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5706438192550668237_3459 src: /192.168.1.157:57929 dest: /192.168.1.157:50010 of size 13553
2017-06-12 16:12:17,117 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9188997088655263796_3455 src: /192.168.1.158:40516 dest: /192.168.1.158:50010
2017-06-12 16:12:17,121 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9188997088655263796_3455 src: /192.168.1.158:40516 dest: /192.168.1.158:50010 of size 91176
2017-06-12 16:12:20,092 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1909723909557387724_3456 src: /192.168.1.156:42353 dest: /192.168.1.156:50010
2017-06-12 16:12:20,097 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1909723909557387724_3456 src: /192.168.1.156:42354 dest: /192.168.1.156:50010
2017-06-12 16:12:20,098 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-1909723909557387724_3456 received exception java.io.IOException: Block blk_-1909723909557387724_3456 has already been started (though not completed), and thus cannot be created.
2017-06-12 16:12:20,098 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1909723909557387724_3456 src: /192.168.1.156:42353 dest: /192.168.1.156:50010 of size 2165
2017-06-12 16:12:20,100 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2338819476201735006_3457 src: /192.168.1.157:57930 dest: /192.168.1.157:50010
2017-06-12 16:12:20,101 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-1909723909557387724_3456 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 16:12:20,101 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2338819476201735006_3457 src: /192.168.1.157:57930 dest: /192.168.1.157:50010 of size 13568
2017-06-12 16:12:23,034 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1909723909557387724_3456 to 192.168.1.158:50010
2017-06-12 16:12:23,044 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-1909723909557387724_3456 to /192.168.1.158:50010
2017-06-12 16:14:38,194 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1909723909557387724_3456 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1909723909557387724
2017-06-12 16:14:38,194 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2338819476201735006_3457 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2338819476201735006
2017-06-12 16:14:38,195 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9188997088655263796_3455 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9188997088655263796
2017-06-12 16:14:41,145 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7415487953707868217_3463 src: /192.168.1.157:57989 dest: /192.168.1.157:50010
2017-06-12 16:14:41,150 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7415487953707868217_3463 src: /192.168.1.157:57989 dest: /192.168.1.157:50010 of size 23950
2017-06-12 16:14:44,196 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5706438192550668237_3459 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5706438192550668237
2017-06-12 16:14:49,295 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 16:15:00,128 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 16:15:00,334 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 16:15:00,335 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 16:15:00,337 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 16:15:00,402 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 16:15:00,459 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 16:15:00,460 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 16:15:00,460 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 16:15:00,710 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-06-12 16:15:00,746 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 16:15:00,748 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 16:15:00,749 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-06-12 16:15:00,754 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 16:15:00,771 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 16:15:00,776 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 16:15:00,776 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 16:15:00,778 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 16:15:00,778 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 16:15:00,779 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 16:15:00,779 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 16:15:00,782 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 16:15:00,782 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 16:15:00,791 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 16:15:00,847 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-7415487953707868217_3463
2017-06-12 16:15:03,793 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 8 msecs
2017-06-12 16:15:36,823 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7415487953707868217_3463 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7415487953707868217
2017-06-12 16:16:06,788 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3134194569800310617_3464 src: /192.168.1.158:40520 dest: /192.168.1.158:50010
2017-06-12 16:16:06,788 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1106971106747997603_3465 src: /192.168.1.158:40519 dest: /192.168.1.158:50010
2017-06-12 16:16:06,808 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1106971106747997603_3465 src: /192.168.1.158:40519 dest: /192.168.1.158:50010 of size 2165
2017-06-12 16:16:06,808 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3134194569800310617_3464 src: /192.168.1.158:40520 dest: /192.168.1.158:50010 of size 91176
2017-06-12 16:16:09,760 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_25383694311747150_3466 src: /192.168.1.157:58007 dest: /192.168.1.157:50010
2017-06-12 16:16:09,762 INFO org.apache.hadoop.dfs.DataNode: Received block blk_25383694311747150_3466 src: /192.168.1.157:58007 dest: /192.168.1.157:50010 of size 13568
2017-06-12 16:16:09,781 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5687770036907083253_3468 src: /192.168.1.156:42435 dest: /192.168.1.156:50010
2017-06-12 16:16:09,782 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5687770036907083253_3468 src: /192.168.1.156:42435 dest: /192.168.1.156:50010 of size 13553
2017-06-12 16:16:09,784 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_25383694311747150_3466 src: /192.168.1.156:42436 dest: /192.168.1.156:50010
2017-06-12 16:16:09,785 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_25383694311747150_3466 received exception java.io.IOException: Block blk_25383694311747150_3466 is valid, and cannot be written to.
2017-06-12 16:16:09,786 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_25383694311747150_3466 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 16:16:12,835 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_25383694311747150_3466 to 192.168.1.158:50010
2017-06-12 16:16:12,842 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_25383694311747150_3466 to /192.168.1.158:50010
2017-06-12 16:18:33,840 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2010422324405602132_3472 src: /192.168.1.158:40521 dest: /192.168.1.158:50010
2017-06-12 16:18:33,841 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2010422324405602132_3472 src: /192.168.1.158:40521 dest: /192.168.1.158:50010 of size 23950
2017-06-12 16:18:36,966 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3134194569800310617_3464 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3134194569800310617
2017-06-12 16:18:36,966 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1106971106747997603_3465 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1106971106747997603
2017-06-12 16:18:36,967 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_25383694311747150_3466 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_25383694311747150
2017-06-12 16:18:39,967 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5687770036907083253_3468 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5687770036907083253
2017-06-12 16:18:39,967 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2010422324405602132_3472 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2010422324405602132
2017-06-12 16:26:13,867 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 16:26:24,735 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 16:26:24,915 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 16:26:24,916 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 16:26:24,918 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 16:26:24,987 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 16:26:25,044 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 16:26:25,044 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 16:26:25,044 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 16:26:25,283 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-06-12 16:26:25,321 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 16:26:25,325 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 16:26:25,325 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 16:26:25,330 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 16:26:25,347 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 16:26:25,353 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 16:26:25,353 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 16:26:25,355 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 16:26:25,355 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 16:26:25,356 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 16:26:25,356 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 16:26:25,367 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 16:26:25,367 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 16:26:25,382 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 16:26:28,385 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-06-12 16:27:25,476 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3308216774925152601_3475 src: /192.168.1.157:58081 dest: /192.168.1.157:50010
2017-06-12 16:27:25,490 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3308216774925152601_3475 src: /192.168.1.157:58081 dest: /192.168.1.157:50010 of size 13560
2017-06-12 16:27:25,506 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7831666377624240260_3473 src: /192.168.1.158:40531 dest: /192.168.1.158:50010
2017-06-12 16:27:25,511 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7831666377624240260_3473 src: /192.168.1.158:40531 dest: /192.168.1.158:50010 of size 91176
2017-06-12 16:27:25,665 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-06-12 16:27:28,463 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2860570260235380022_3477 src: /192.168.1.157:58086 dest: /192.168.1.157:50010
2017-06-12 16:27:28,465 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7605130768125435868_3474 src: /192.168.1.157:58087 dest: /192.168.1.157:50010
2017-06-12 16:27:28,467 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7605130768125435868_3474 src: /192.168.1.157:58087 dest: /192.168.1.157:50010 of size 4325
2017-06-12 16:27:28,468 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7605130768125435868_3474 src: /192.168.1.156:42511 dest: /192.168.1.156:50010
2017-06-12 16:27:28,469 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7605130768125435868_3474 received exception java.io.IOException: Block blk_7605130768125435868_3474 is valid, and cannot be written to.
2017-06-12 16:27:28,470 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7605130768125435868_3474 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 16:27:28,471 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2860570260235380022_3477 src: /192.168.1.157:58086 dest: /192.168.1.157:50010 of size 13545
2017-06-12 16:27:31,433 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7605130768125435868_3474 to 192.168.1.158:50010
2017-06-12 16:27:31,436 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_7605130768125435868_3474 to /192.168.1.158:50010
2017-06-12 16:27:33,957 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 16:27:37,485 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 16:27:47,239 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 16:27:58,378 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-06-12 16:27:59,798 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 16:28:01,320 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-06-12 16:28:03,017 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-06-12 16:28:12,843 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 16:28:18,196 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 16:29:31,509 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7708409133194617799_3481 src: /192.168.1.157:58166 dest: /192.168.1.157:50010
2017-06-12 16:29:31,526 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Exception writing block blk_-7708409133194617799_3481 to mirror 192.168.1.158:50010
java.io.IOException: Broken pipe
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:94)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:450)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)
	at java.io.DataOutputStream.flush(DataOutputStream.java:123)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2704)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 16:29:31,527 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7708409133194617799_3481 src: /192.168.1.157:58166 dest: /192.168.1.157:50010 of size 47386
2017-06-12 16:29:34,512 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7831666377624240260_3473 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7831666377624240260
2017-06-12 16:29:34,514 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7708409133194617799_3481 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7708409133194617799
2017-06-12 16:29:34,514 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3308216774925152601_3475 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3308216774925152601
2017-06-12 16:29:34,514 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2860570260235380022_3477 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2860570260235380022
2017-06-12 16:29:34,515 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7605130768125435868_3474 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7605130768125435868
2017-06-12 16:29:41,513 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 16:29:52,337 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 16:29:52,532 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 16:29:52,534 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 16:29:52,536 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 16:29:52,610 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 16:29:52,672 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 16:29:52,673 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 16:29:52,673 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 16:29:52,907 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-06-12 16:29:52,945 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 16:29:52,948 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 16:29:52,948 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 16:29:52,953 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 16:29:52,971 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 16:29:52,976 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 16:29:52,977 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 16:29:52,978 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 16:29:52,979 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 16:29:52,979 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 16:29:52,980 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 16:29:52,983 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 16:29:52,984 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 16:29:52,991 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 16:29:55,994 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-06-12 16:30:58,954 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1328373976658846055_3484 src: /192.168.1.158:40590 dest: /192.168.1.158:50010
2017-06-12 16:30:58,970 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1328373976658846055_3484 src: /192.168.1.158:40590 dest: /192.168.1.158:50010 of size 13560
2017-06-12 16:30:59,035 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-440007795860558113_3482 src: /192.168.1.158:40591 dest: /192.168.1.158:50010
2017-06-12 16:30:59,046 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-440007795860558113_3482 src: /192.168.1.158:40591 dest: /192.168.1.158:50010 of size 91176
2017-06-12 16:31:01,938 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1597081022613519089_3486 src: /192.168.1.157:58181 dest: /192.168.1.157:50010
2017-06-12 16:31:01,938 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1597081022613519089_3486 src: /192.168.1.157:58181 dest: /192.168.1.157:50010 of size 13545
2017-06-12 16:31:02,034 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6190647260929304814_3483 src: /192.168.1.156:42606 dest: /192.168.1.156:50010
2017-06-12 16:31:02,044 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6190647260929304814_3483 src: /192.168.1.156:42606 dest: /192.168.1.156:50010 of size 4325
2017-06-12 16:31:06,766 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 16:31:07,369 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-06-12 16:31:10,238 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 16:31:19,610 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 16:31:23,058 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-06-12 16:31:30,837 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 16:31:34,950 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-06-12 16:31:42,622 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-06-12 16:31:55,521 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 16:32:47,081 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1114666345217907659_3490 src: /192.168.1.156:42680 dest: /192.168.1.156:50010
2017-06-12 16:32:47,083 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1114666345217907659_3490 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-06-12 16:32:47,085 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 16:32:50,059 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6190647260929304814_3483 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6190647260929304814
2017-06-12 16:32:50,059 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-440007795860558113_3482 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-440007795860558113
2017-06-12 16:32:50,060 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1328373976658846055_3484 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1328373976658846055
2017-06-12 16:32:50,060 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1597081022613519089_3486 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1597081022613519089
2017-06-12 16:32:56,153 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-06-12 16:32:56,209 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 16:33:06,952 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 16:33:07,141 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 16:33:07,143 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 16:33:07,144 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 16:33:07,215 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 16:33:07,273 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 16:33:07,274 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 16:33:07,274 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 16:33:07,518 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-06-12 16:33:07,558 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 16:33:07,560 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 16:33:07,561 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-06-12 16:33:07,565 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 16:33:07,583 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 16:33:07,589 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 16:33:07,590 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 16:33:07,591 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 16:33:07,592 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 16:33:07,593 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 16:33:07,593 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 16:33:07,595 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 16:33:07,596 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 16:33:07,605 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 16:33:10,608 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 9 msecs
2017-06-12 16:34:13,644 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6519593746396324076_3492 src: /192.168.1.157:58267 dest: /192.168.1.157:50010
2017-06-12 16:34:13,658 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6519593746396324076_3492 src: /192.168.1.157:58267 dest: /192.168.1.157:50010 of size 4325
2017-06-12 16:34:13,753 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2816929534455843173_3491 src: /192.168.1.158:40657 dest: /192.168.1.158:50010
2017-06-12 16:34:13,760 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2816929534455843173_3491 src: /192.168.1.158:40657 dest: /192.168.1.158:50010 of size 91176
2017-06-12 16:34:16,638 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6668381797522619945_3493 src: /192.168.1.157:58268 dest: /192.168.1.157:50010
2017-06-12 16:34:16,638 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6668381797522619945_3493 src: /192.168.1.157:58269 dest: /192.168.1.157:50010
2017-06-12 16:34:16,639 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6668381797522619945_3493 received exception java.io.IOException: Block blk_6668381797522619945_3493 has already been started (though not completed), and thus cannot be created.
2017-06-12 16:34:16,639 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6668381797522619945_3493 src: /192.168.1.157:58268 dest: /192.168.1.157:50010 of size 13560
2017-06-12 16:34:16,648 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_6668381797522619945_3493 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 16:34:16,752 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7692661718118550414_3495 src: /192.168.1.156:42697 dest: /192.168.1.156:50010
2017-06-12 16:34:16,754 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7692661718118550414_3495 src: /192.168.1.156:42697 dest: /192.168.1.156:50010 of size 13545
2017-06-12 16:34:21,312 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 16:34:21,648 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-06-12 16:34:24,724 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 16:34:34,210 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 16:34:37,515 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-06-12 16:34:40,647 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 28 blocks got processed in 5 msecs
2017-06-12 16:34:46,891 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 16:34:50,360 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-06-12 16:34:58,863 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 16:35:08,504 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-06-12 16:35:12,828 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-06-12 16:36:16,691 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2816929534455843173_3491 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2816929534455843173
2017-06-12 16:36:16,692 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6519593746396324076_3492 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6519593746396324076
2017-06-12 16:36:16,692 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6668381797522619945_3493 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6668381797522619945
2017-06-12 16:36:19,806 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5548958216107346143_3499 src: /192.168.1.158:40703 dest: /192.168.1.158:50010
2017-06-12 16:36:19,807 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5548958216107346143_3499 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-06-12 16:36:19,807 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 16:36:22,690 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7692661718118550414_3495 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7692661718118550414
2017-06-12 16:36:29,658 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 16:36:40,466 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 16:36:40,656 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 16:36:40,658 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 16:36:40,660 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 16:36:40,725 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 16:36:40,782 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 16:36:40,783 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 16:36:40,783 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 16:36:41,011 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-06-12 16:36:41,047 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 16:36:41,050 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 16:36:41,050 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-06-12 16:36:41,054 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 16:36:41,071 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 16:36:41,076 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 16:36:41,076 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 16:36:41,077 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 16:36:41,078 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 16:36:41,078 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 16:36:41,078 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 16:36:41,089 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 16:36:41,089 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 16:36:41,100 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 16:36:44,103 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-06-12 16:37:41,195 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1594322054956405982_3502 src: /192.168.1.158:40711 dest: /192.168.1.158:50010
2017-06-12 16:37:41,210 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1594322054956405982_3502 src: /192.168.1.158:40711 dest: /192.168.1.158:50010 of size 13560
2017-06-12 16:37:41,218 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6600705513883740368_3500 src: /192.168.1.158:40712 dest: /192.168.1.158:50010
2017-06-12 16:37:41,223 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6600705513883740368_3500 src: /192.168.1.158:40712 dest: /192.168.1.158:50010 of size 91176
2017-06-12 16:37:44,192 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6480266486607427722_3501 src: /192.168.1.156:42800 dest: /192.168.1.156:50010
2017-06-12 16:37:44,196 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6480266486607427722_3501 src: /192.168.1.156:42800 dest: /192.168.1.156:50010 of size 4325
2017-06-12 16:37:46,573 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 16:37:47,219 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5452293416581381710_3504 src: /192.168.1.158:40725 dest: /192.168.1.158:50010
2017-06-12 16:37:47,221 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5452293416581381710_3504 src: /192.168.1.158:40725 dest: /192.168.1.158:50010 of size 13545
2017-06-12 16:37:50,555 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 16:37:53,334 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-06-12 16:37:58,113 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 16:38:01,171 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-06-12 16:38:03,134 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 16:38:06,838 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 16:39:23,237 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6600705513883740368_3500 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6600705513883740368
2017-06-12 16:39:23,238 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6480266486607427722_3501 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6480266486607427722
2017-06-12 16:39:23,238 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1594322054956405982_3502 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1594322054956405982
2017-06-12 16:39:26,240 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5452293416581381710_3504 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5452293416581381710
2017-06-12 16:39:33,410 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 16:39:44,327 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 16:39:44,532 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 16:39:44,534 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 16:39:44,536 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 16:39:44,602 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 16:39:44,660 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 16:39:44,661 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 16:39:44,661 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 16:39:44,878 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-06-12 16:39:44,910 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 16:39:44,913 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 16:39:44,913 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 16:39:44,918 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 16:39:44,935 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 16:39:44,940 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 16:39:44,941 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 16:39:44,942 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 16:39:44,942 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 16:39:44,943 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 16:39:44,943 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 16:39:44,945 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 16:39:44,945 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 16:39:44,952 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 16:39:47,954 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 9 msecs
2017-06-12 16:40:50,369 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-06-12 16:40:50,419 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-06-12 16:40:50,973 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6246053736891084899_3509 src: /192.168.1.158:40770 dest: /192.168.1.158:50010
2017-06-12 16:40:50,993 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6246053736891084899_3509 src: /192.168.1.158:40770 dest: /192.168.1.158:50010 of size 91176
2017-06-12 16:40:51,025 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-946394529502459536_3511 src: /192.168.1.156:42883 dest: /192.168.1.156:50010
2017-06-12 16:40:51,046 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-946394529502459536_3511 src: /192.168.1.156:42883 dest: /192.168.1.156:50010 of size 13560
2017-06-12 16:40:54,025 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7723451954483656089_3513 src: /192.168.1.156:42884 dest: /192.168.1.156:50010
2017-06-12 16:40:54,026 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7723451954483656089_3513 src: /192.168.1.156:42884 dest: /192.168.1.156:50010 of size 13545
2017-06-12 16:40:55,622 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 16:40:57,024 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6324083289564135403_3510 src: /192.168.1.156:42894 dest: /192.168.1.156:50010
2017-06-12 16:40:57,025 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6324083289564135403_3510 src: /192.168.1.156:42894 dest: /192.168.1.156:50010 of size 4325
2017-06-12 16:41:04,716 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-06-12 16:41:06,585 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 16:41:06,647 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 16:41:21,299 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 16:41:29,286 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-06-12 16:42:29,996 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4911097888207155081_3517 src: /192.168.1.157:58515 dest: /192.168.1.157:50010
2017-06-12 16:42:30,001 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4911097888207155081_3517 src: /192.168.1.157:58515 dest: /192.168.1.157:50010 of size 45720
2017-06-12 16:42:33,083 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6324083289564135403_3510 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6324083289564135403
2017-06-12 16:42:33,083 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-946394529502459536_3511 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-946394529502459536
2017-06-12 16:42:33,084 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6246053736891084899_3509 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6246053736891084899
2017-06-12 16:42:36,082 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4911097888207155081_3517 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4911097888207155081
2017-06-12 16:42:36,083 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7723451954483656089_3513 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7723451954483656089
2017-06-12 16:42:42,086 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-06-12 16:42:42,114 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 16:42:52,942 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 16:42:53,153 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 16:42:53,155 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 16:42:53,157 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 16:42:53,223 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 16:42:53,280 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 16:42:53,281 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 16:42:53,281 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 16:42:53,511 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-06-12 16:42:53,547 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 16:42:53,550 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 16:42:53,550 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 16:42:53,555 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 16:42:53,576 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 16:42:53,580 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 16:42:53,581 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 16:42:53,581 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 16:42:53,581 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 16:42:53,582 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 16:42:53,582 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 16:42:53,583 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 16:42:53,584 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 16:42:53,594 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 16:42:56,600 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 12 msecs
2017-06-12 16:43:59,644 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7750357450804328955_3518 src: /192.168.1.158:40829 dest: /192.168.1.158:50010
2017-06-12 16:43:59,660 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7750357450804328955_3518 src: /192.168.1.158:40829 dest: /192.168.1.158:50010 of size 91176
2017-06-12 16:43:59,702 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5724254119255878759_3520 src: /192.168.1.158:40830 dest: /192.168.1.158:50010
2017-06-12 16:43:59,705 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5724254119255878759_3520 src: /192.168.1.158:40830 dest: /192.168.1.158:50010 of size 13560
2017-06-12 16:44:02,626 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7045187037338948922_3519 src: /192.168.1.157:58531 dest: /192.168.1.157:50010
2017-06-12 16:44:02,627 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7045187037338948922_3519 src: /192.168.1.157:58531 dest: /192.168.1.157:50010 of size 4325
2017-06-12 16:44:02,699 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3746353291406510504_3522 src: /192.168.1.156:42964 dest: /192.168.1.156:50010
2017-06-12 16:44:02,700 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3746353291406510504_3522 src: /192.168.1.156:42964 dest: /192.168.1.156:50010 of size 13545
2017-06-12 16:44:08,207 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 16:44:08,937 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-06-12 16:44:14,187 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 16:44:14,486 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 16:44:14,541 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 16:44:19,014 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-06-12 16:44:24,761 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 16:44:29,873 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 16:44:29,911 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-06-12 16:45:59,762 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1228582000364812478_3526 src: /192.168.1.158:40876 dest: /192.168.1.158:50010
2017-06-12 16:45:59,765 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1228582000364812478_3526 src: /192.168.1.158:40876 dest: /192.168.1.158:50010 of size 47545
2017-06-12 16:46:02,799 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7750357450804328955_3518 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7750357450804328955
2017-06-12 16:46:02,799 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7045187037338948922_3519 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7045187037338948922
2017-06-12 16:46:02,800 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5724254119255878759_3520 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5724254119255878759
2017-06-12 16:46:02,800 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3746353291406510504_3522 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3746353291406510504
2017-06-12 16:46:10,407 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 16:46:21,354 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 16:46:21,545 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 16:46:21,547 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 16:46:21,548 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 16:46:21,609 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 16:46:21,658 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 16:46:21,658 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 16:46:21,658 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 16:46:21,878 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-06-12 16:46:21,910 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 16:46:21,916 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 16:46:21,916 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-06-12 16:46:21,925 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 16:46:21,949 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 16:46:21,955 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 16:46:21,956 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 16:46:21,956 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 16:46:21,956 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 16:46:21,956 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 16:46:21,957 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 16:46:21,988 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 16:46:21,988 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 16:46:22,007 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 16:46:22,063 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-1228582000364812478_3526
2017-06-12 16:46:25,002 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 14 msecs
2017-06-12 16:46:58,030 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1228582000364812478_3526 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1228582000364812478
2017-06-12 16:47:22,071 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6434099635524125500_3529 src: /192.168.1.158:40884 dest: /192.168.1.158:50010
2017-06-12 16:47:22,082 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6434099635524125500_3529 src: /192.168.1.158:40884 dest: /192.168.1.158:50010 of size 13560
2017-06-12 16:47:22,099 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2021357847438336043_3527 src: /192.168.1.156:43055 dest: /192.168.1.156:50010
2017-06-12 16:47:22,125 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2021357847438336043_3527 src: /192.168.1.156:43055 dest: /192.168.1.156:50010 of size 91176
2017-06-12 16:47:25,030 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8409471691370350754_3531 src: /192.168.1.157:58623 dest: /192.168.1.157:50010
2017-06-12 16:47:25,035 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8454240387406583709_3528 src: /192.168.1.157:58624 dest: /192.168.1.157:50010
2017-06-12 16:47:25,036 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8454240387406583709_3528 src: /192.168.1.157:58624 dest: /192.168.1.157:50010 of size 4325
2017-06-12 16:47:25,037 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8409471691370350754_3531 src: /192.168.1.157:58623 dest: /192.168.1.157:50010 of size 13545
2017-06-12 16:47:25,086 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8409471691370350754_3531 src: /192.168.1.156:43062 dest: /192.168.1.156:50010
2017-06-12 16:47:25,087 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8409471691370350754_3531 received exception java.io.IOException: Block blk_8409471691370350754_3531 is valid, and cannot be written to.
2017-06-12 16:47:25,088 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8409471691370350754_3531 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 16:47:31,539 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-06-12 16:47:34,920 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-06-12 16:47:37,809 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 16:47:40,053 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-06-12 16:47:40,391 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 16:47:41,829 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-06-12 16:47:45,563 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-06-12 16:49:10,115 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2021357847438336043_3527 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2021357847438336043
2017-06-12 16:49:10,115 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6434099635524125500_3529 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6434099635524125500
2017-06-12 16:49:10,116 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8409471691370350754_3531 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8409471691370350754
2017-06-12 16:49:10,116 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8454240387406583709_3528 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8454240387406583709
2017-06-12 16:49:16,118 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-06-12 16:49:16,185 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 16:49:26,999 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 16:49:27,210 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 16:49:27,212 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 16:49:27,213 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 16:49:27,287 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 16:49:27,347 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 16:49:27,348 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 16:49:27,348 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 16:49:27,591 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-06-12 16:49:27,633 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 16:49:27,635 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 16:49:27,635 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-06-12 16:49:27,640 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 16:49:27,658 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 16:49:27,663 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 16:49:27,664 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 16:49:27,665 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 16:49:27,666 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 16:49:27,666 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 16:49:27,666 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 16:49:27,669 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 16:49:27,669 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 16:49:27,679 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 16:49:30,680 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-06-12 16:50:33,736 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1510175705540023054_3540 src: /192.168.1.158:40942 dest: /192.168.1.158:50010
2017-06-12 16:50:33,746 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1510175705540023054_3540 src: /192.168.1.158:40942 dest: /192.168.1.158:50010 of size 13545
2017-06-12 16:50:33,760 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9209224309816128781_3536 src: /192.168.1.156:43140 dest: /192.168.1.156:50010
2017-06-12 16:50:33,772 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9209224309816128781_3536 src: /192.168.1.156:43140 dest: /192.168.1.156:50010 of size 91176
2017-06-12 16:50:36,722 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3663364373473787515_3537 src: /192.168.1.157:58712 dest: /192.168.1.157:50010
2017-06-12 16:50:36,723 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3663364373473787515_3537 src: /192.168.1.157:58712 dest: /192.168.1.157:50010 of size 4325
2017-06-12 16:50:36,762 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3663364373473787515_3537 src: /192.168.1.156:43142 dest: /192.168.1.156:50010
2017-06-12 16:50:36,763 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3663364373473787515_3537 received exception java.io.IOException: Block blk_3663364373473787515_3537 is valid, and cannot be written to.
2017-06-12 16:50:36,764 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_3663364373473787515_3537 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 16:50:39,722 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7618360020621923569_3538 src: /192.168.1.157:58722 dest: /192.168.1.157:50010
2017-06-12 16:50:39,724 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7618360020621923569_3538 src: /192.168.1.157:58722 dest: /192.168.1.157:50010 of size 13560
2017-06-12 16:50:39,786 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_3663364373473787515_3537 to 192.168.1.158:50010
2017-06-12 16:50:39,789 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_3663364373473787515_3537 to /192.168.1.158:50010
2017-06-12 16:50:42,098 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-06-12 16:50:43,226 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-06-12 16:50:48,515 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 16:50:49,434 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-06-12 16:50:49,699 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 16:50:50,495 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-06-12 16:50:55,393 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-06-12 16:50:56,152 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 16:50:56,537 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-06-12 16:52:00,797 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4853163517827606483_3544 src: /192.168.1.156:43203 dest: /192.168.1.156:50010
2017-06-12 16:52:00,798 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-4853163517827606483_3544 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-06-12 16:52:00,799 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 16:52:03,817 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9209224309816128781_3536 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9209224309816128781
2017-06-12 16:52:03,818 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1510175705540023054_3540 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1510175705540023054
2017-06-12 16:52:03,818 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3663364373473787515_3537 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3663364373473787515
2017-06-12 16:52:03,819 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7618360020621923569_3538 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7618360020621923569
2017-06-12 16:52:10,817 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-06-12 16:52:21,634 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-12 16:52:21,844 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-06-12 16:52:21,845 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-06-12 16:52:21,847 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-06-12 16:52:21,916 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-12 16:52:21,975 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-12 16:52:21,976 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-12 16:52:21,976 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-12 16:52:22,212 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-06-12 16:52:22,247 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-12 16:52:22,249 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-06-12 16:52:22,249 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-06-12 16:52:22,254 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-06-12 16:52:22,275 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-06-12 16:52:22,281 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-12 16:52:22,282 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-06-12 16:52:22,282 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-06-12 16:52:22,282 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-06-12 16:52:22,283 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-06-12 16:52:22,283 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-06-12 16:52:22,288 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-06-12 16:52:22,289 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-06-12 16:52:22,304 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-06-12 16:52:25,301 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 9 msecs
2017-06-12 16:53:27,709 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-06-12 16:53:28,333 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5834700216748775968_3549 src: /192.168.1.157:58791 dest: /192.168.1.157:50010
2017-06-12 16:53:28,355 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3914451514159617909_3545 src: /192.168.1.156:43218 dest: /192.168.1.156:50010
2017-06-12 16:53:28,371 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5834700216748775968_3549 src: /192.168.1.157:58791 dest: /192.168.1.157:50010 of size 13545
2017-06-12 16:53:28,376 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3914451514159617909_3545 src: /192.168.1.156:43218 dest: /192.168.1.156:50010 of size 91176
2017-06-12 16:53:31,332 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7124773739801080042_3546 src: /192.168.1.157:58792 dest: /192.168.1.157:50010
2017-06-12 16:53:31,333 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7124773739801080042_3546 src: /192.168.1.157:58793 dest: /192.168.1.157:50010
2017-06-12 16:53:31,333 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7124773739801080042_3546 received exception java.io.IOException: Block blk_7124773739801080042_3546 has already been started (though not completed), and thus cannot be created.
2017-06-12 16:53:31,333 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7124773739801080042_3546 src: /192.168.1.157:58792 dest: /192.168.1.157:50010 of size 4325
2017-06-12 16:53:31,343 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7124773739801080042_3546 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-06-12 16:53:32,824 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-06-12 16:53:34,319 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5041995107041225091_3547 src: /192.168.1.158:41002 dest: /192.168.1.158:50010
2017-06-12 16:53:34,320 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5041995107041225091_3547 src: /192.168.1.158:41002 dest: /192.168.1.158:50010 of size 13560
2017-06-12 16:53:38,163 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-06-12 16:53:43,056 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-06-12 16:53:43,889 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-06-12 16:53:45,431 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-06-12 16:53:51,107 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-06-12 16:53:59,013 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-06-12 16:55:28,424 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5834700216748775968_3549 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5834700216748775968
2017-06-12 16:55:28,425 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5041995107041225091_3547 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5041995107041225091
2017-06-12 16:55:28,425 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3914451514159617909_3545 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3914451514159617909
2017-06-12 16:55:28,425 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7124773739801080042_3546 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7124773739801080042
2017-06-12 17:09:01,935 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 5 msecs
2017-06-12 18:09:04,538 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-06-12 19:09:05,119 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-06-12 20:09:05,326 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-06-12 21:09:05,478 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-06-12 22:09:06,331 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-06-12 23:09:06,761 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
