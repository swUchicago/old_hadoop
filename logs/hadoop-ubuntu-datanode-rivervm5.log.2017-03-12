2017-03-12 07:39:38,662 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 07:39:38,836 INFO org.apache.hadoop.dfs.Storage: Storage directory /home/ubuntu/old_hadoop_temp/dfs/data is not formatted.
2017-03-12 07:39:38,836 INFO org.apache.hadoop.dfs.Storage: Formatting ...
2017-03-12 07:39:38,893 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 07:39:38,895 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 07:39:38,897 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 07:39:38,963 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 07:39:39,022 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 07:39:39,023 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 07:39:39,023 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 07:39:39,266 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@169d193
2017-03-12 07:39:39,312 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 07:39:39,315 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 07:39:39,315 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1428b92
2017-03-12 07:39:39,321 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 07:39:39,338 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 07:39:39,344 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 07:39:39,344 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 07:39:39,346 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 07:39:39,347 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 07:39:39,347 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=, infoPort=50075, ipcPort=50020)
2017-03-12 07:39:39,347 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 07:40:20,142 INFO org.apache.hadoop.dfs.DataNode: New storage id DS-1789512078-192.168.1.153-50010-1489300820131 is assigned to data-node 192.168.1.153:50010
2017-03-12 07:40:20,143 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-1789512078-192.168.1.153-50010-1489300820131, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 07:40:20,144 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 07:40:20,161 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 07:40:23,149 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 0 blocks got processed in 4 msecs
2017-03-12 07:46:32,435 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-03-12 07:46:32,572 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 08:18:08,429 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 08:18:08,603 INFO org.apache.hadoop.dfs.Storage: Storage directory /home/ubuntu/old_hadoop_temp/dfs/data is not formatted.
2017-03-12 08:18:08,603 INFO org.apache.hadoop.dfs.Storage: Formatting ...
2017-03-12 08:18:08,659 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 08:18:08,661 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 08:18:08,662 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 08:18:08,725 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 08:18:08,776 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 08:18:08,777 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 08:18:08,777 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 08:18:08,997 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@15ff2e1
2017-03-12 08:18:09,036 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 08:18:09,039 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 08:18:09,039 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1428b92
2017-03-12 08:18:09,044 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 08:18:09,068 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 08:18:09,076 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 08:18:09,079 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 08:18:09,079 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 08:18:09,079 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 08:18:09,080 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=, infoPort=50075, ipcPort=50020)
2017-03-12 08:18:09,080 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 08:18:09,094 INFO org.apache.hadoop.dfs.DataNode: New storage id DS-177065084-192.168.1.153-50010-1489303089088 is assigned to data-node 192.168.1.153:50010
2017-03-12 08:18:09,095 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 08:18:09,096 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 08:18:09,106 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 08:18:12,103 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 0 blocks got processed in 4 msecs
2017-03-12 08:19:05,740 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 08:19:11,793 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 08:19:11,983 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 08:19:11,985 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 08:19:11,987 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 08:19:12,047 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 08:19:12,094 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 08:19:12,095 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 08:19:12,095 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 08:19:12,316 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@169d193
2017-03-12 08:19:12,363 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 08:19:12,366 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 08:19:12,366 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1428b92
2017-03-12 08:19:12,372 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 08:19:12,393 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 08:19:12,397 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 08:19:12,398 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 08:19:12,399 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 08:19:12,399 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 08:19:12,400 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 08:19:12,400 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 08:19:12,402 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 08:19:12,402 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 08:19:12,410 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 08:19:15,410 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 0 blocks got processed in 5 msecs
2017-03-12 08:19:48,251 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7701193938081024283_1001 src: /192.168.1.152:33062 dest: /192.168.1.152:50010
2017-03-12 08:19:50,541 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7701193938081024283_1001 of size 67108864 from /192.168.1.152
2017-03-12 08:19:50,541 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_-7701193938081024283_1001 terminating
2017-03-12 08:19:50,559 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9165782496790827072_1001 src: /192.168.1.152:33063 dest: /192.168.1.152:50010
2017-03-12 08:19:53,133 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9165782496790827072_1001 of size 67108864 from /192.168.1.152
2017-03-12 08:19:53,133 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_-9165782496790827072_1001 terminating
2017-03-12 08:19:53,154 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1397883976202270799_1001 src: /192.168.1.152:33064 dest: /192.168.1.152:50010
2017-03-12 08:19:55,678 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1397883976202270799_1001 of size 67108864 from /192.168.1.152
2017-03-12 08:19:55,679 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_1397883976202270799_1001 terminating
2017-03-12 08:19:55,691 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4893380956617376253_1001 src: /192.168.1.152:33065 dest: /192.168.1.152:50010
2017-03-12 08:19:58,079 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4893380956617376253_1001 of size 67108864 from /192.168.1.152
2017-03-12 08:19:58,079 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_-4893380956617376253_1001 terminating
2017-03-12 08:19:58,088 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7033895350336583192_1001 src: /192.168.1.149:35433 dest: /192.168.1.149:50010
2017-03-12 08:20:00,371 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7033895350336583192_1001 of size 67108864 from /192.168.1.149
2017-03-12 08:20:00,372 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 3 for block blk_7033895350336583192_1001 terminating
2017-03-12 08:20:00,392 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4733740065594982407_1001 src: /192.168.1.151:50640 dest: /192.168.1.151:50010
2017-03-12 08:20:02,702 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4733740065594982407_1001 of size 67108864 from /192.168.1.151
2017-03-12 08:20:02,702 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-4733740065594982407_1001 terminating
2017-03-12 08:20:02,723 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2414267635078914264_1001 src: /192.168.1.152:33067 dest: /192.168.1.152:50010
2017-03-12 08:20:05,235 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2414267635078914264_1001 of size 67108864 from /192.168.1.152
2017-03-12 08:20:05,235 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-2414267635078914264_1001 terminating
2017-03-12 08:20:05,255 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2469247396937600182_1001 src: /192.168.1.151:50642 dest: /192.168.1.151:50010
2017-03-12 08:20:07,635 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2469247396937600182_1001 of size 67103998 from /192.168.1.151
2017-03-12 08:20:07,635 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_2469247396937600182_1001 terminating
2017-03-12 08:24:00,333 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_1397883976202270799_1001
2017-03-12 08:25:04,933 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_7033895350336583192_1001
2017-03-12 08:25:07,177 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 08:25:12,810 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 08:25:13,006 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 08:25:13,008 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 08:25:13,010 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 08:25:13,078 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 08:25:13,136 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 08:25:13,137 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 08:25:13,137 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 08:25:13,375 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-03-12 08:25:13,412 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 08:25:13,414 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 08:25:13,414 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@cd1a1f
2017-03-12 08:25:13,425 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 08:25:13,448 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 08:25:13,453 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 08:25:13,453 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 08:25:13,455 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 08:25:13,455 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 08:25:13,455 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 08:25:13,456 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 08:25:13,459 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 08:25:13,459 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 08:25:13,469 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 08:25:16,466 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 7 msecs
2017-03-12 08:26:16,016 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-9165782496790827072_1001
2017-03-12 08:32:16,631 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-03-12 08:33:20,083 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7824668893822863501_1002 src: /192.168.1.149:35474 dest: /192.168.1.149:50010
2017-03-12 08:33:20,196 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7824668893822863501_1002 of size 91176 from /192.168.1.149
2017-03-12 08:33:20,197 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 3 for block blk_-7824668893822863501_1002 terminating
2017-03-12 08:33:20,298 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7490624228308848690_1003 src: /192.168.1.151:50646 dest: /192.168.1.151:50010
2017-03-12 08:33:20,324 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7490624228308848690_1003 of size 1045 from /192.168.1.151
2017-03-12 08:33:20,327 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_7490624228308848690_1003 terminating
2017-03-12 08:33:20,424 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1846226504520978894_1004 src: /192.168.1.152:33073 dest: /192.168.1.152:50010
2017-03-12 08:33:20,441 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1846226504520978894_1004 of size 13560 from /192.168.1.152
2017-03-12 08:33:20,441 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_1846226504520978894_1004 terminating
2017-03-12 08:33:20,697 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4106476569456553450_1006 src: /192.168.1.151:50647 dest: /192.168.1.151:50010
2017-03-12 08:33:20,708 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4106476569456553450_1006 of size 13546 from /192.168.1.151
2017-03-12 08:33:20,709 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-4106476569456553450_1006 terminating
2017-03-12 08:33:20,751 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7490624228308848690_1003 to /192.168.1.149
2017-03-12 08:33:23,246 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1846226504520978894_1004 to /192.168.1.153
2017-03-12 08:33:23,287 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7824668893822863501_1002 to /192.168.1.153
2017-03-12 08:33:24,276 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 08:33:42,705 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 08:33:49,043 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 08:34:05,205 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2469247396937600182_1001 to /192.168.1.153
2017-03-12 08:34:14,539 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4816434573626117508_1007 src: /192.168.1.150:41823 dest: /192.168.1.150:50010
2017-03-12 08:34:14,988 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8639692712667183202_1008 src: /192.168.1.150:41824 dest: /192.168.1.150:50010
2017-03-12 08:34:15,138 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1690120014765923853_1009 src: /192.168.1.153:53942 dest: /192.168.1.153:50010
2017-03-12 08:34:19,402 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6420364453653906964_1010 src: /192.168.1.150:41830 dest: /192.168.1.150:50010
2017-03-12 08:34:19,649 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4816434573626117508_1007 of size 31964396 from /192.168.1.150
2017-03-12 08:34:19,649 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_4816434573626117508_1007 terminating
2017-03-12 08:34:20,261 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1690120014765923853_1009 of size 31976695 from /192.168.1.153
2017-03-12 08:34:20,262 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 3 for block blk_1690120014765923853_1009 terminating
2017-03-12 08:34:20,282 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8639692712667183202_1008 of size 31980463 from /192.168.1.150
2017-03-12 08:34:20,282 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-8639692712667183202_1008 terminating
2017-03-12 08:34:23,889 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6420364453653906964_1010 of size 31981189 from /192.168.1.150
2017-03-12 08:34:23,890 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_-6420364453653906964_1010 terminating
2017-03-12 08:34:24,646 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4760310202880407001_1010 src: /192.168.1.150:41831 dest: /192.168.1.150:50010
2017-03-12 08:34:24,662 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4760310202880407001_1010 of size 14460 from /192.168.1.150
2017-03-12 08:34:24,664 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_-4760310202880407001_1010 terminating
2017-03-12 08:34:34,702 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8639692712667183202_1008 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8639692712667183202
2017-03-12 08:34:34,702 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7824668893822863501_1002 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7824668893822863501
2017-03-12 08:34:34,711 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6420364453653906964_1010 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6420364453653906964
2017-03-12 08:34:34,711 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4760310202880407001_1010 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4760310202880407001
2017-03-12 08:34:34,712 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4106476569456553450_1006 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4106476569456553450
2017-03-12 08:34:34,718 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1690120014765923853_1009 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1690120014765923853
2017-03-12 08:34:34,718 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1846226504520978894_1004 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1846226504520978894
2017-03-12 08:34:34,724 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4816434573626117508_1007 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4816434573626117508
2017-03-12 08:34:34,724 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7490624228308848690_1003 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7490624228308848690
2017-03-12 08:46:17,913 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-2414267635078914264_1001
2017-03-12 08:56:18,523 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-4733740065594982407_1001
2017-03-12 09:06:18,192 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-7701193938081024283_1001
2017-03-12 09:16:17,905 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-4893380956617376253_1001
2017-03-12 09:32:17,917 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-03-12 09:53:56,793 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 09:54:04,827 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 09:54:05,024 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 09:54:05,025 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 09:54:05,027 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 09:54:05,086 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 09:54:05,136 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 09:54:05,137 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 09:54:05,137 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 09:54:05,355 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-03-12 09:54:05,392 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 09:54:05,395 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 09:54:05,395 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@d9558d
2017-03-12 09:54:05,401 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 09:54:05,421 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 09:54:05,426 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 09:54:05,426 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 09:54:05,428 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 09:54:05,428 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 09:54:05,429 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 09:54:05,429 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 09:54:05,431 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 09:54:05,432 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 09:54:05,439 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 09:54:08,437 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-03-12 09:54:18,120 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 09:54:45,876 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 09:54:46,066 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 09:54:46,069 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 09:54:46,072 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 09:54:46,146 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 09:54:46,206 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 09:54:46,207 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 09:54:46,207 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 09:54:46,444 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-03-12 09:54:46,484 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 09:54:46,486 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 09:54:46,486 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 09:54:46,491 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 09:54:46,510 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 09:54:46,518 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 09:54:46,519 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 09:54:46,521 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 09:54:46,521 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 09:54:46,521 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 09:54:46,521 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 09:54:46,525 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 09:54:46,525 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 09:54:46,533 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 09:54:49,534 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-03-12 09:58:43,105 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4512992147626574891_1011 src: /192.168.1.149:35564 dest: /192.168.1.149:50010
2017-03-12 09:58:43,262 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4512992147626574891_1011 of size 91176 from /192.168.1.149
2017-03-12 09:58:43,264 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 3 for block blk_-4512992147626574891_1011 terminating
2017-03-12 09:58:43,374 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2902861315266458775_1012 src: /192.168.1.150:41844 dest: /192.168.1.150:50010
2017-03-12 09:58:43,391 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2902861315266458775_1012 of size 1045 from /192.168.1.150
2017-03-12 09:58:43,395 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_-2902861315266458775_1012 terminating
2017-03-12 09:58:43,479 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8416370400495315803_1013 src: /192.168.1.151:50680 dest: /192.168.1.151:50010
2017-03-12 09:58:43,498 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8416370400495315803_1013 of size 13552 from /192.168.1.151
2017-03-12 09:58:43,499 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_-8416370400495315803_1013 terminating
2017-03-12 09:58:43,574 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-8416370400495315803_1013 to /192.168.1.149
2017-03-12 09:58:43,818 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5856126218604842116_1015 src: /192.168.1.150:41846 dest: /192.168.1.150:50010
2017-03-12 09:58:43,828 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5856126218604842116_1015 of size 13538 from /192.168.1.150
2017-03-12 09:58:43,829 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-5856126218604842116_1015 terminating
2017-03-12 09:58:46,006 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-8416370400495315803_1013 to /192.168.1.153
2017-03-12 09:58:46,045 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4512992147626574891_1011 to /192.168.1.153
2017-03-12 09:58:47,068 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 09:59:05,045 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 09:59:10,906 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 09:59:27,393 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 09:59:42,758 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8769040527514266702_1016 src: /192.168.1.152:33135 dest: /192.168.1.152:50010
2017-03-12 09:59:43,562 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3150110953900637239_1018 src: /192.168.1.150:41871 dest: /192.168.1.150:50010
2017-03-12 09:59:43,575 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8578796567783577188_1018 src: /192.168.1.153:53984 dest: /192.168.1.153:50010
2017-03-12 09:59:43,793 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7785975542043177339_1019 src: /192.168.1.150:41872 dest: /192.168.1.150:50010
2017-03-12 09:59:48,024 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8769040527514266702_1016 of size 31981189 from /192.168.1.152
2017-03-12 09:59:48,025 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-8769040527514266702_1016 terminating
2017-03-12 09:59:48,869 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8578796567783577188_1018 of size 31976695 from /192.168.1.153
2017-03-12 09:59:48,869 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 3 for block blk_8578796567783577188_1018 terminating
2017-03-12 09:59:49,139 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3150110953900637239_1018 of size 31964396 from /192.168.1.150
2017-03-12 09:59:49,140 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_3150110953900637239_1018 terminating
2017-03-12 09:59:49,483 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7785975542043177339_1019 of size 31980463 from /192.168.1.150
2017-03-12 09:59:49,484 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_-7785975542043177339_1019 terminating
2017-03-12 09:59:50,158 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5398761292640883378_1019 src: /192.168.1.150:41873 dest: /192.168.1.150:50010
2017-03-12 09:59:50,183 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5398761292640883378_1019 of size 14460 from /192.168.1.150
2017-03-12 09:59:50,185 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_-5398761292640883378_1019 terminating
2017-03-12 09:59:58,646 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8769040527514266702_1016 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8769040527514266702
2017-03-12 09:59:58,646 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8416370400495315803_1013 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8416370400495315803
2017-03-12 09:59:58,654 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7785975542043177339_1019 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7785975542043177339
2017-03-12 09:59:58,654 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5856126218604842116_1015 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5856126218604842116
2017-03-12 09:59:58,654 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5398761292640883378_1019 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5398761292640883378
2017-03-12 09:59:58,654 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4512992147626574891_1011 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4512992147626574891
2017-03-12 09:59:58,655 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2902861315266458775_1012 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2902861315266458775
2017-03-12 09:59:58,661 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3150110953900637239_1018 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3150110953900637239
2017-03-12 09:59:58,667 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8578796567783577188_1018 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8578796567783577188
2017-03-12 10:24:46,213 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 10:24:54,335 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 10:24:54,569 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 10:24:54,571 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 10:24:54,573 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 10:24:54,645 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 10:24:54,706 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 10:24:54,707 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 10:24:54,707 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 10:24:54,928 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-03-12 10:24:54,961 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 10:24:54,964 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 10:24:54,964 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 10:24:54,969 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 10:24:54,986 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 10:24:54,990 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 10:24:54,991 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 10:24:54,992 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 10:24:54,993 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 10:24:54,993 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 10:24:54,993 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 10:24:54,996 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 10:24:54,996 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 10:24:55,005 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 10:24:58,005 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-03-12 10:26:09,899 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5717309899466217875_1021 src: /192.168.1.150:41883 dest: /192.168.1.150:50010
2017-03-12 10:26:09,913 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5717309899466217875_1021 src: /192.168.1.150:41883 dest: /192.168.1.150:50010 of size 1045
2017-03-12 10:26:10,308 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 10:26:15,873 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-709652179173783031_1022 src: /192.168.1.151:50721 dest: /192.168.1.151:50010
2017-03-12 10:26:15,875 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-709652179173783031_1022 src: /192.168.1.151:50721 dest: /192.168.1.151:50010 of size 13560
2017-03-12 10:26:16,065 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1141863208364196006_1020 src: /192.168.1.152:33153 dest: /192.168.1.152:50010
2017-03-12 10:26:16,069 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1141863208364196006_1020 src: /192.168.1.152:33153 dest: /192.168.1.152:50010 of size 91176
2017-03-12 10:26:18,880 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5815105841034326273_1024 src: /192.168.1.150:41889 dest: /192.168.1.150:50010
2017-03-12 10:26:18,881 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5815105841034326273_1024 src: /192.168.1.150:41889 dest: /192.168.1.150:50010 of size 13546
2017-03-12 10:26:22,032 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_5815105841034326273_1024 to 192.168.1.151:50010
2017-03-12 10:26:22,037 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_5815105841034326273_1024 to /192.168.1.151:50010
2017-03-12 10:26:27,573 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 10:26:33,028 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 10:26:48,404 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 10:26:52,830 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 10:27:08,303 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 10:28:28,029 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9116007423481270701_1028 src: /192.168.1.152:33174 dest: /192.168.1.152:50010
2017-03-12 10:28:28,030 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9116007423481270701_1028 src: /192.168.1.152:33174 dest: /192.168.1.152:50010 of size 16868
2017-03-12 10:28:34,084 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5717309899466217875_1021 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5717309899466217875
2017-03-12 10:28:34,084 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1141863208364196006_1020 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1141863208364196006
2017-03-12 10:28:34,084 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-709652179173783031_1022 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-709652179173783031
2017-03-12 10:28:34,085 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5815105841034326273_1024 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5815105841034326273
2017-03-12 10:29:34,236 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-03-12 10:29:34,337 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 10:29:41,079 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 10:29:41,269 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 10:29:41,271 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 10:29:41,273 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 10:29:41,342 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 10:29:41,401 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 10:29:41,402 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 10:29:41,402 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 10:29:41,643 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-03-12 10:29:41,683 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 10:29:41,686 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 10:29:41,686 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@cd1a1f
2017-03-12 10:29:41,690 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 10:29:41,708 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 10:29:41,713 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 10:29:41,714 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 10:29:41,715 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 10:29:41,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 10:29:41,719 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 10:29:41,719 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 10:29:41,722 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 10:29:41,723 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 10:29:41,731 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 10:29:41,761 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_9116007423481270701_1028
2017-03-12 10:29:44,729 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 6 msecs
2017-03-12 10:30:17,745 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9116007423481270701_1028 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9116007423481270701
2017-03-12 10:33:17,130 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 10:33:17,840 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7819948142583574146_1031 src: /192.168.1.151:50756 dest: /192.168.1.151:50010
2017-03-12 10:33:17,853 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7819948142583574146_1031 src: /192.168.1.151:50756 dest: /192.168.1.151:50010 of size 13560
2017-03-12 10:33:20,737 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6566360756994261882_1033 src: /192.168.1.152:33186 dest: /192.168.1.152:50010
2017-03-12 10:33:20,739 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6566360756994261882_1033 src: /192.168.1.152:33186 dest: /192.168.1.152:50010 of size 13546
2017-03-12 10:33:20,768 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4448192495319699544_1029 src: /192.168.1.150:41942 dest: /192.168.1.150:50010
2017-03-12 10:33:20,771 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4448192495319699544_1029 src: /192.168.1.150:41942 dest: /192.168.1.150:50010 of size 91176
2017-03-12 10:33:26,773 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4425214108023462688_1030 src: /192.168.1.152:33188 dest: /192.168.1.152:50010
2017-03-12 10:33:26,773 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4425214108023462688_1030 src: /192.168.1.152:33188 dest: /192.168.1.152:50010 of size 1045
2017-03-12 10:33:35,184 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 10:33:40,876 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 10:33:56,748 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 10:35:26,850 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7819948142583574146_1031 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7819948142583574146
2017-03-12 10:35:26,851 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6566360756994261882_1033 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6566360756994261882
2017-03-12 10:35:26,851 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4448192495319699544_1029 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4448192495319699544
2017-03-12 10:35:26,852 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4425214108023462688_1030 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4425214108023462688
2017-03-12 10:38:02,004 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 10:38:03,084 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7995121845629062522_1040 src: /192.168.1.150:42007 dest: /192.168.1.150:50010
2017-03-12 10:38:03,088 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7995121845629062522_1040 src: /192.168.1.150:42007 dest: /192.168.1.150:50010 of size 13560
2017-03-12 10:38:06,089 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-718048119678993888_1038 src: /192.168.1.150:42009 dest: /192.168.1.150:50010
2017-03-12 10:38:06,094 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-718048119678993888_1038 src: /192.168.1.150:42009 dest: /192.168.1.150:50010 of size 91176
2017-03-12 10:38:09,096 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5373459152520368464_1042 src: /192.168.1.152:33214 dest: /192.168.1.152:50010
2017-03-12 10:38:09,098 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5373459152520368464_1042 src: /192.168.1.152:33214 dest: /192.168.1.152:50010 of size 13546
2017-03-12 10:38:12,096 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6497900378754560744_1039 src: /192.168.1.150:42011 dest: /192.168.1.150:50010
2017-03-12 10:38:12,097 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6497900378754560744_1039 src: /192.168.1.150:42011 dest: /192.168.1.150:50010 of size 1045
2017-03-12 10:38:17,291 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 10:38:22,775 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 10:38:38,037 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 10:38:47,228 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 10:39:02,817 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 10:40:24,249 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3402276274213593753_1046 src: /192.168.1.150:42053 dest: /192.168.1.150:50010
2017-03-12 10:40:24,250 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3402276274213593753_1046 src: /192.168.1.150:42053 dest: /192.168.1.150:50010 of size 19823
2017-03-12 10:40:29,954 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7995121845629062522_1040 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7995121845629062522
2017-03-12 10:40:29,954 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-718048119678993888_1038 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-718048119678993888
2017-03-12 10:40:29,955 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6497900378754560744_1039 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6497900378754560744
2017-03-12 10:40:45,286 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5907773941187743335_1045 src: /192.168.1.151:50804 dest: /192.168.1.151:50010
2017-03-12 10:40:46,045 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5907773941187743335_1045 src: /192.168.1.151:50804 dest: /192.168.1.151:50010 of size 31976695
2017-03-12 10:40:51,283 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3771796375680625336_1045 src: /192.168.1.150:42057 dest: /192.168.1.150:50010
2017-03-12 10:40:51,932 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3771796375680625336_1045 src: /192.168.1.150:42057 dest: /192.168.1.150:50010 of size 31980463
2017-03-12 10:40:54,289 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_131589558712514503_1046 src: /192.168.1.150:42058 dest: /192.168.1.150:50010
2017-03-12 10:40:54,779 INFO org.apache.hadoop.dfs.DataNode: Received block blk_131589558712514503_1046 src: /192.168.1.150:42058 dest: /192.168.1.150:50010 of size 31964396
2017-03-12 10:40:57,293 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5004199963531788692_1043 src: /192.168.1.150:42060 dest: /192.168.1.150:50010
2017-03-12 10:40:58,118 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5004199963531788692_1043 src: /192.168.1.150:42060 dest: /192.168.1.150:50010 of size 31981189
2017-03-12 10:41:00,302 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5004199963531788692_1043 src: /192.168.1.152:33236 dest: /192.168.1.152:50010
2017-03-12 10:41:00,302 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5004199963531788692_1043 received exception java.io.IOException: Block blk_5004199963531788692_1043 is valid, and cannot be written to.
2017-03-12 10:41:00,304 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_5004199963531788692_1043 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 10:41:02,966 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_131589558712514503_1046 to 192.168.1.151:50010
2017-03-12 10:41:03,476 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_131589558712514503_1046 to /192.168.1.151:50010
2017-03-12 10:46:28,278 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-3771796375680625336_1045
2017-03-12 10:51:02,989 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_131589558712514503_1046
2017-03-12 11:00:56,270 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_3402276274213593753_1046
2017-03-12 11:06:53,113 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 11:07:51,293 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 11:07:51,483 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 11:07:51,485 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 11:07:51,487 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 11:07:51,552 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 11:07:51,610 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 11:07:51,611 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 11:07:51,611 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 11:07:51,845 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-03-12 11:07:51,877 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 11:07:51,879 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 11:07:51,879 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 11:07:51,884 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 11:07:51,898 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 11:07:51,903 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 11:07:51,911 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 11:07:51,912 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 11:07:51,912 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 11:07:51,912 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 11:07:51,913 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 11:07:51,915 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 11:07:51,916 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 11:07:51,926 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 11:07:51,956 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_5373459152520368464_1042
2017-03-12 11:07:54,927 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 14 blocks got processed in 8 msecs
2017-03-12 11:09:03,957 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5907773941187743335_1045 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5907773941187743335
2017-03-12 11:09:03,963 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3771796375680625336_1045 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3771796375680625336
2017-03-12 11:09:03,969 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_131589558712514503_1046 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_131589558712514503
2017-03-12 11:09:03,970 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3402276274213593753_1046 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3402276274213593753
2017-03-12 11:09:03,976 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5004199963531788692_1043 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5004199963531788692
2017-03-12 11:09:03,976 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5373459152520368464_1042 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5373459152520368464
2017-03-12 11:09:47,376 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 11:09:48,945 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8894415104481402114_1047 src: /192.168.1.151:50817 dest: /192.168.1.151:50010
2017-03-12 11:09:48,961 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8894415104481402114_1047 src: /192.168.1.151:50817 dest: /192.168.1.151:50010 of size 91176
2017-03-12 11:09:51,939 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8077702603377468186_1048 src: /192.168.1.150:42087 dest: /192.168.1.150:50010
2017-03-12 11:09:51,940 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8077702603377468186_1048 src: /192.168.1.150:42087 dest: /192.168.1.150:50010 of size 1045
2017-03-12 11:09:51,969 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8894415104481402114_1047 to 192.168.1.152:50010
2017-03-12 11:09:51,979 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-8894415104481402114_1047 to /192.168.1.152:50010
2017-03-12 11:09:54,961 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8077702603377468186_1048 to 192.168.1.152:50010
2017-03-12 11:09:54,963 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-8077702603377468186_1048 to /192.168.1.152:50010
2017-03-12 11:09:57,920 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4212748225311102313_1049 src: /192.168.1.150:42089 dest: /192.168.1.150:50010
2017-03-12 11:09:57,921 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4212748225311102313_1049 src: /192.168.1.150:42089 dest: /192.168.1.150:50010 of size 13552
2017-03-12 11:09:57,923 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4212748225311102313_1049 src: /192.168.1.150:42090 dest: /192.168.1.150:50010
2017-03-12 11:09:57,923 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-4212748225311102313_1049 received exception java.io.IOException: Block blk_-4212748225311102313_1049 is valid, and cannot be written to.
2017-03-12 11:09:57,925 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-4212748225311102313_1049 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 11:09:57,989 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4865735626707721462_1051 src: /192.168.1.152:33249 dest: /192.168.1.152:50010
2017-03-12 11:09:57,999 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4865735626707721462_1051 src: /192.168.1.152:33249 dest: /192.168.1.152:50010 of size 13538
2017-03-12 11:10:03,430 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 11:10:09,185 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 11:10:25,241 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 11:10:29,935 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 11:10:45,310 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 11:10:54,201 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 11:11:09,044 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 11:11:18,996 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8894415104481402114_1047 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8894415104481402114
2017-03-12 11:11:18,997 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8077702603377468186_1048 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8077702603377468186
2017-03-12 11:11:18,997 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4865735626707721462_1051 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4865735626707721462
2017-03-12 11:11:18,998 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4212748225311102313_1049 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4212748225311102313
2017-03-12 11:18:34,348 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-03-12 11:18:34,418 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 11:18:40,547 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 11:18:40,729 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 11:18:40,730 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 11:18:40,731 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 11:18:40,799 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 11:18:40,857 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 11:18:40,857 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 11:18:40,858 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 11:18:41,100 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-03-12 11:18:41,137 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 11:18:41,140 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 11:18:41,140 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 11:18:41,146 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 11:18:41,163 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 11:18:41,167 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 11:18:41,168 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 11:18:41,169 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 11:18:41,170 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 11:18:41,170 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 11:18:41,171 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 11:18:41,173 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 11:18:41,173 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 11:18:41,183 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 11:18:44,179 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-03-12 11:19:59,127 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6171001725525337407_1056 src: /192.168.1.151:50843 dest: /192.168.1.151:50010
2017-03-12 11:19:59,141 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6171001725525337407_1056 src: /192.168.1.151:50843 dest: /192.168.1.151:50010 of size 13538
2017-03-12 11:20:01,462 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 11:20:01,547 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 11:20:02,062 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5093326381441190210_1054 src: /192.168.1.150:42124 dest: /192.168.1.150:50010
2017-03-12 11:20:02,072 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5093326381441190210_1054 src: /192.168.1.150:42124 dest: /192.168.1.150:50010 of size 13552
2017-03-12 11:20:05,073 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2316366240670996885_1052 src: /192.168.1.150:42126 dest: /192.168.1.150:50010
2017-03-12 11:20:05,076 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2316366240670996885_1052 src: /192.168.1.150:42126 dest: /192.168.1.150:50010 of size 91176
2017-03-12 11:20:05,209 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-5093326381441190210_1054 to 192.168.1.152:50010
2017-03-12 11:20:05,213 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-5093326381441190210_1054 to /192.168.1.152:50010
2017-03-12 11:20:08,066 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6443491922847077950_1053 src: /192.168.1.150:42130 dest: /192.168.1.150:50010
2017-03-12 11:20:08,067 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6443491922847077950_1053 src: /192.168.1.150:42130 dest: /192.168.1.150:50010 of size 1045
2017-03-12 11:20:17,865 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 11:20:19,558 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 11:20:51,525 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 11:21:07,524 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 11:21:17,235 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6171001725525337407_1056 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6171001725525337407
2017-03-12 11:21:17,236 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5093326381441190210_1054 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5093326381441190210
2017-03-12 11:21:17,236 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2316366240670996885_1052 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2316366240670996885
2017-03-12 11:21:17,236 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6443491922847077950_1053 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6443491922847077950
2017-03-12 11:22:17,218 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5598253871722103900_1058 src: /192.168.1.151:50879 dest: /192.168.1.151:50010
2017-03-12 11:22:17,219 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5598253871722103900_1058 src: /192.168.1.151:50879 dest: /192.168.1.151:50010 of size 1045
2017-03-12 11:22:17,386 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 11:22:20,258 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-5598253871722103900_1058 to 192.168.1.152:50010
2017-03-12 11:22:20,260 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-5598253871722103900_1058 to /192.168.1.152:50010
2017-03-12 11:22:23,222 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7316298314326357011_1059 src: /192.168.1.150:42169 dest: /192.168.1.150:50010
2017-03-12 11:22:23,224 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7316298314326357011_1059 src: /192.168.1.150:42169 dest: /192.168.1.150:50010 of size 13552
2017-03-12 11:22:23,322 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1937335795818171184_1061 src: /192.168.1.151:50886 dest: /192.168.1.151:50010
2017-03-12 11:22:23,326 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1937335795818171184_1061 src: /192.168.1.151:50886 dest: /192.168.1.151:50010 of size 13538
2017-03-12 11:22:26,225 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7738547658767822365_1057 src: /192.168.1.150:42170 dest: /192.168.1.150:50010
2017-03-12 11:22:26,229 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7738547658767822365_1057 src: /192.168.1.150:42170 dest: /192.168.1.150:50010 of size 91176
2017-03-12 11:22:34,067 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 11:22:36,875 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 11:22:42,475 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 11:22:58,259 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 11:23:07,477 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 11:23:22,946 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 11:23:35,285 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5598253871722103900_1058 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5598253871722103900
2017-03-12 11:23:35,286 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1937335795818171184_1061 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1937335795818171184
2017-03-12 11:23:35,286 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7316298314326357011_1059 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7316298314326357011
2017-03-12 11:23:35,287 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7738547658767822365_1057 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7738547658767822365
2017-03-12 11:24:08,339 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2574293532565192501_1064 src: /192.168.1.150:42194 dest: /192.168.1.150:50010
2017-03-12 11:24:08,341 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2574293532565192501_1064 src: /192.168.1.150:42194 dest: /192.168.1.150:50010 of size 13552
2017-03-12 11:24:08,372 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 11:24:09,403 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2574293532565192501_1064 to /192.168.1.152
2017-03-12 11:24:11,297 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_2574293532565192501_1064 to 192.168.1.152:50010
2017-03-12 11:24:11,298 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_2574293532565192501_1064 to /192.168.1.152:50010
2017-03-12 11:24:11,348 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3441923046168994267_1066 src: /192.168.1.150:42207 dest: /192.168.1.150:50010
2017-03-12 11:24:11,349 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3441923046168994267_1066 src: /192.168.1.150:42207 dest: /192.168.1.150:50010 of size 13538
2017-03-12 11:24:14,298 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-3441923046168994267_1066 to 192.168.1.151:50010, 192.168.1.152:50010
2017-03-12 11:24:14,300 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-3441923046168994267_1066 to /192.168.1.151:50010
2017-03-12 11:24:14,346 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8907677947236818740_1063 src: /192.168.1.150:42208 dest: /192.168.1.150:50010
2017-03-12 11:24:14,347 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8907677947236818740_1063 src: /192.168.1.150:42208 dest: /192.168.1.150:50010 of size 1045
2017-03-12 11:24:17,300 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8907677947236818740_1063 to 192.168.1.151:50010
2017-03-12 11:24:17,302 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_8907677947236818740_1063 to /192.168.1.151:50010
2017-03-12 11:24:20,262 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3125132164474958510_1062 src: /192.168.1.151:50912 dest: /192.168.1.151:50010
2017-03-12 11:24:20,275 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3125132164474958510_1062 src: /192.168.1.151:50912 dest: /192.168.1.151:50010 of size 91176
2017-03-12 11:24:26,405 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 11:24:26,729 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 11:24:32,522 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 11:24:47,946 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 11:25:26,323 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3441923046168994267_1066 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3441923046168994267
2017-03-12 11:25:26,324 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2574293532565192501_1064 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2574293532565192501
2017-03-12 11:25:26,324 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3125132164474958510_1062 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3125132164474958510
2017-03-12 11:25:26,325 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8907677947236818740_1063 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8907677947236818740
2017-03-12 11:27:42,362 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 11:27:49,358 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 11:27:49,553 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 11:27:49,555 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 11:27:49,557 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 11:27:49,627 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 11:27:49,686 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 11:27:49,687 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 11:27:49,687 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 11:27:49,921 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-03-12 11:27:49,959 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 11:27:49,961 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 11:27:49,961 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 11:27:49,967 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 11:27:49,995 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 11:27:50,003 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 11:27:50,004 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 11:27:50,005 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 11:27:50,005 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 11:27:50,005 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 11:27:50,006 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 11:27:50,008 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 11:27:50,009 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 11:27:50,017 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 11:27:53,015 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-03-12 11:29:16,954 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8686071531042893597_1071 src: /192.168.1.150:42234 dest: /192.168.1.150:50010
2017-03-12 11:29:16,971 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8686071531042893597_1071 src: /192.168.1.150:42234 dest: /192.168.1.150:50010 of size 13538
2017-03-12 11:29:19,924 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1407144719992033517_1067 src: /192.168.1.150:42242 dest: /192.168.1.150:50010
2017-03-12 11:29:19,933 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1407144719992033517_1067 src: /192.168.1.150:42242 dest: /192.168.1.150:50010 of size 91176
2017-03-12 11:29:20,363 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 11:29:22,929 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8443796294827455570_1068 src: /192.168.1.150:42245 dest: /192.168.1.150:50010
2017-03-12 11:29:22,933 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8443796294827455570_1068 src: /192.168.1.150:42245 dest: /192.168.1.150:50010 of size 1045
2017-03-12 11:29:25,932 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8500702563875665231_1069 src: /192.168.1.150:42246 dest: /192.168.1.150:50010
2017-03-12 11:29:25,934 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8500702563875665231_1069 src: /192.168.1.150:42246 dest: /192.168.1.150:50010 of size 13552
2017-03-12 11:29:25,935 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8500702563875665231_1069 src: /192.168.1.150:42247 dest: /192.168.1.150:50010
2017-03-12 11:29:25,935 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8500702563875665231_1069 received exception java.io.IOException: Block blk_8500702563875665231_1069 is valid, and cannot be written to.
2017-03-12 11:29:25,937 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8500702563875665231_1069 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 11:29:29,052 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8500702563875665231_1069 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 11:29:29,058 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_8500702563875665231_1069 to /192.168.1.152:50010
2017-03-12 11:29:37,235 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 11:29:43,129 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 11:29:57,823 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 11:30:05,510 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 11:30:20,937 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 11:30:25,302 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 11:30:40,123 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 11:30:53,079 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8686071531042893597_1071 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8686071531042893597
2017-03-12 11:30:53,080 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1407144719992033517_1067 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1407144719992033517
2017-03-12 11:30:53,080 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8443796294827455570_1068 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8443796294827455570
2017-03-12 11:30:53,080 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8500702563875665231_1069 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8500702563875665231
2017-03-12 11:33:47,808 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 11:33:53,601 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 11:33:53,799 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 11:33:53,800 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 11:33:53,802 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 11:33:53,867 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 11:33:53,925 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 11:33:53,925 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 11:33:53,926 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 11:33:54,148 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-03-12 11:33:54,187 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 11:33:54,190 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 11:33:54,190 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 11:33:54,194 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 11:33:54,212 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 11:33:54,216 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 11:33:54,217 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 11:33:54,218 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 11:33:54,219 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 11:33:54,219 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 11:33:54,220 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 11:33:54,222 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 11:33:54,223 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 11:33:54,231 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 11:33:57,229 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-03-12 11:34:54,158 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8185230575824634648_1072 src: /192.168.1.150:42279 dest: /192.168.1.150:50010
2017-03-12 11:34:54,173 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8185230575824634648_1072 src: /192.168.1.150:42279 dest: /192.168.1.150:50010 of size 91176
2017-03-12 11:34:54,629 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 11:34:54,691 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 11:35:00,142 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7780223603206692840_1073 src: /192.168.1.151:50975 dest: /192.168.1.151:50010
2017-03-12 11:35:00,147 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7780223603206692840_1073 src: /192.168.1.151:50975 dest: /192.168.1.151:50010 of size 1045
2017-03-12 11:35:00,240 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8169091740299917299_1076 src: /192.168.1.151:50976 dest: /192.168.1.151:50010
2017-03-12 11:35:00,241 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8169091740299917299_1076 src: /192.168.1.151:50976 dest: /192.168.1.151:50010 of size 13546
2017-03-12 11:35:03,137 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4699788908162814109_1074 src: /192.168.1.150:42290 dest: /192.168.1.150:50010
2017-03-12 11:35:03,139 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4699788908162814109_1074 src: /192.168.1.150:42290 dest: /192.168.1.150:50010 of size 13560
2017-03-12 11:35:03,263 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7780223603206692840_1073 to 192.168.1.152:50010
2017-03-12 11:35:03,272 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-7780223603206692840_1073 to /192.168.1.152:50010
2017-03-12 11:35:10,920 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 11:35:12,588 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 11:35:21,301 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-8169091740299917299_1076
2017-03-12 11:35:44,596 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 11:35:59,315 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 11:36:12,283 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8185230575824634648_1072 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8185230575824634648
2017-03-12 11:36:12,284 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8169091740299917299_1076 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8169091740299917299
2017-03-12 11:36:12,284 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7780223603206692840_1073 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7780223603206692840
2017-03-12 11:36:12,284 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4699788908162814109_1074 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4699788908162814109
2017-03-12 11:38:26,215 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 11:38:32,482 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 11:38:32,677 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 11:38:32,679 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 11:38:32,681 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 11:38:32,750 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 11:38:32,802 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 11:38:32,803 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 11:38:32,803 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 11:38:33,015 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-03-12 11:38:33,055 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 11:38:33,058 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 11:38:33,058 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 11:38:33,062 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 11:38:33,080 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 11:38:33,085 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 11:38:33,086 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 11:38:33,087 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 11:38:33,088 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 11:38:33,088 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 11:38:33,088 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 11:38:33,091 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 11:38:33,091 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 11:38:33,100 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 11:38:36,099 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 4 msecs
2017-03-12 11:39:33,083 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7446887228344807076_1079 src: /192.168.1.150:42320 dest: /192.168.1.150:50010
2017-03-12 11:39:33,098 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7446887228344807076_1079 src: /192.168.1.150:42320 dest: /192.168.1.150:50010 of size 13560
2017-03-12 11:39:33,427 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 11:39:36,013 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4780928926620352488_1081 src: /192.168.1.150:42322 dest: /192.168.1.150:50010
2017-03-12 11:39:36,015 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4780928926620352488_1081 src: /192.168.1.150:42322 dest: /192.168.1.150:50010 of size 13546
2017-03-12 11:39:36,117 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7446887228344807076_1079 to 192.168.1.152:50010
2017-03-12 11:39:36,122 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-7446887228344807076_1079 to /192.168.1.152:50010
2017-03-12 11:39:39,022 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6531558117140414518_1077 src: /192.168.1.150:42323 dest: /192.168.1.150:50010
2017-03-12 11:39:39,027 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6531558117140414518_1077 src: /192.168.1.150:42323 dest: /192.168.1.150:50010 of size 91176
2017-03-12 11:39:42,025 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6794815545749799113_1078 src: /192.168.1.150:42325 dest: /192.168.1.150:50010
2017-03-12 11:39:42,026 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6794815545749799113_1078 src: /192.168.1.150:42325 dest: /192.168.1.150:50010 of size 1045
2017-03-12 11:39:42,118 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_6531558117140414518_1077 to 192.168.1.151:50010
2017-03-12 11:39:42,121 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_6531558117140414518_1077 to /192.168.1.151:50010
2017-03-12 11:39:49,487 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 11:39:55,166 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 11:40:10,703 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 11:40:18,509 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 11:40:34,270 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 11:40:38,353 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 11:40:53,364 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 11:41:03,145 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7446887228344807076_1079 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7446887228344807076
2017-03-12 11:41:03,147 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4780928926620352488_1081 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4780928926620352488
2017-03-12 11:41:03,147 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6531558117140414518_1077 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6531558117140414518
2017-03-12 11:41:03,148 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6794815545749799113_1078 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6794815545749799113
2017-03-12 11:45:03,418 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-03-12 11:45:03,596 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 11:45:10,174 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 11:45:10,367 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 11:45:10,369 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 11:45:10,371 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 11:45:10,433 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 11:45:10,481 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 11:45:10,482 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 11:45:10,482 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 11:45:10,695 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-03-12 11:45:10,726 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 11:45:10,729 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 11:45:10,729 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 11:45:10,735 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 11:45:10,752 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 11:45:10,757 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 11:45:10,758 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 11:45:10,760 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 11:45:10,761 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 11:45:10,761 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 11:45:10,761 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 11:45:10,765 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 11:45:10,765 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 11:45:10,775 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 11:45:13,775 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-03-12 11:47:01,303 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 11:47:01,799 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8212458008908069029_1084 src: /192.168.1.150:42355 dest: /192.168.1.150:50010
2017-03-12 11:47:01,821 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8212458008908069029_1084 src: /192.168.1.150:42355 dest: /192.168.1.150:50010 of size 13560
2017-03-12 11:47:01,905 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8923632630727570656_1083 src: /192.168.1.151:51035 dest: /192.168.1.151:50010
2017-03-12 11:47:01,907 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8923632630727570656_1083 src: /192.168.1.151:51035 dest: /192.168.1.151:50010 of size 1045
2017-03-12 11:47:04,807 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2271405666657905262_1082 src: /192.168.1.152:33461 dest: /192.168.1.152:50010
2017-03-12 11:47:04,809 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2271405666657905262_1082 src: /192.168.1.152:33461 dest: /192.168.1.152:50010 of size 91176
2017-03-12 11:47:07,801 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2142786376529512516_1086 src: /192.168.1.150:42357 dest: /192.168.1.150:50010
2017-03-12 11:47:07,802 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2142786376529512516_1086 src: /192.168.1.150:42357 dest: /192.168.1.150:50010 of size 13546
2017-03-12 11:47:07,812 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2271405666657905262_1082 to 192.168.1.151:50010
2017-03-12 11:47:07,817 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-2271405666657905262_1082 to /192.168.1.151:50010
2017-03-12 11:47:16,745 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 11:49:10,871 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8923632630727570656_1083 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8923632630727570656
2017-03-12 11:49:10,871 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8212458008908069029_1084 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8212458008908069029
2017-03-12 11:49:10,872 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2271405666657905262_1082 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2271405666657905262
2017-03-12 11:49:10,872 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2142786376529512516_1086 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2142786376529512516
2017-03-12 11:49:35,580 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 11:49:41,514 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 11:49:41,713 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 11:49:41,715 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 11:49:41,716 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 11:49:41,791 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 11:49:41,853 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 11:49:41,854 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 11:49:41,854 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 11:49:42,081 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-03-12 11:49:42,114 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 11:49:42,116 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 11:49:42,116 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 11:49:42,120 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 11:49:42,134 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 11:49:42,138 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 11:49:42,139 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 11:49:42,140 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 11:49:42,141 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 11:49:42,141 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 11:49:42,141 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 11:49:42,144 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 11:49:42,144 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 11:49:42,152 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 11:49:45,152 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-03-12 11:50:37,060 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 11:51:19,004 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 11:51:19,190 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 11:51:19,192 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 11:51:19,194 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 11:51:19,257 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 11:51:19,304 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 11:51:19,305 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 11:51:19,305 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 11:51:19,512 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-03-12 11:51:19,544 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 11:51:19,547 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 11:51:19,547 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 11:51:19,552 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 11:51:19,568 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 11:51:19,572 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 11:51:19,573 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 11:51:19,574 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 11:51:19,574 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 11:51:19,575 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 11:51:19,575 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 11:51:19,578 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 11:51:19,578 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 11:51:19,587 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 11:51:22,585 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 7 msecs
2017-03-12 11:52:22,563 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4659885774520268040_1092 src: /192.168.1.150:42399 dest: /192.168.1.150:50010
2017-03-12 11:52:22,581 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4659885774520268040_1092 src: /192.168.1.150:42399 dest: /192.168.1.150:50010 of size 1045
2017-03-12 11:52:24,943 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 11:52:25,089 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 11:52:28,542 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8636693649092990999_1095 src: /192.168.1.150:42412 dest: /192.168.1.150:50010
2017-03-12 11:52:28,547 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8636693649092990999_1095 src: /192.168.1.150:42412 dest: /192.168.1.150:50010 of size 13546
2017-03-12 11:52:28,747 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3627834285483078676_1091 src: /192.168.1.151:51062 dest: /192.168.1.151:50010
2017-03-12 11:52:28,756 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3627834285483078676_1091 src: /192.168.1.151:51062 dest: /192.168.1.151:50010 of size 91176
2017-03-12 11:52:31,544 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4619349378466304594_1093 src: /192.168.1.150:42416 dest: /192.168.1.150:50010
2017-03-12 11:52:31,546 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4619349378466304594_1093 src: /192.168.1.150:42416 dest: /192.168.1.150:50010 of size 13560
2017-03-12 11:52:31,612 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8636693649092990999_1095 to 192.168.1.152:50010
2017-03-12 11:52:31,616 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-8636693649092990999_1095 to /192.168.1.152:50010
2017-03-12 11:52:41,115 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 11:52:42,496 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 11:52:50,128 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 11:52:50,195 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 11:53:06,264 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 11:53:06,828 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2469247396937600182_1001 to /192.168.1.153
2017-03-12 11:53:40,640 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8636693649092990999_1095 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8636693649092990999
2017-03-12 11:53:40,640 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4659885774520268040_1092 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4659885774520268040
2017-03-12 11:53:40,641 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3627834285483078676_1091 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3627834285483078676
2017-03-12 11:53:40,641 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4619349378466304594_1093 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4619349378466304594
2017-03-12 11:54:25,687 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3810268235846896692_1096 src: /192.168.1.151:51085 dest: /192.168.1.151:50010
2017-03-12 11:54:25,689 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3810268235846896692_1096 src: /192.168.1.151:51085 dest: /192.168.1.151:50010 of size 91176
2017-03-12 11:54:26,174 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_3810268235846896692_1096 to /192.168.1.152
2017-03-12 11:54:26,177 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 11:54:26,232 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 11:54:28,680 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5833874750945642109_1100 src: /192.168.1.150:42446 dest: /192.168.1.150:50010
2017-03-12 11:54:28,682 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5833874750945642109_1100 src: /192.168.1.150:42446 dest: /192.168.1.150:50010 of size 13546
2017-03-12 11:54:34,685 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7437394555209150452_1098 src: /192.168.1.151:51090 dest: /192.168.1.151:50010
2017-03-12 11:54:34,685 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7437394555209150452_1098 src: /192.168.1.151:51090 dest: /192.168.1.151:50010 of size 13560
2017-03-12 11:54:34,786 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2878167576028234231_1097 src: /192.168.1.152:33514 dest: /192.168.1.152:50010
2017-03-12 11:54:34,788 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2878167576028234231_1097 src: /192.168.1.152:33514 dest: /192.168.1.152:50010 of size 1045
2017-03-12 11:54:37,658 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7437394555209150452_1098 to 192.168.1.152:50010
2017-03-12 11:54:37,659 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-7437394555209150452_1098 to /192.168.1.152:50010
2017-03-12 11:54:42,650 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 11:54:43,117 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 11:54:51,214 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 11:55:43,682 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7437394555209150452_1098 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7437394555209150452
2017-03-12 11:55:43,683 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5833874750945642109_1100 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5833874750945642109
2017-03-12 11:55:43,683 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2878167576028234231_1097 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2878167576028234231
2017-03-12 11:55:43,684 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3810268235846896692_1096 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3810268235846896692
2017-03-12 11:55:52,824 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7246094886136305722_1101 src: /192.168.1.151:51101 dest: /192.168.1.151:50010
2017-03-12 11:55:52,826 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7246094886136305722_1101 src: /192.168.1.151:51101 dest: /192.168.1.151:50010 of size 91176
2017-03-12 11:55:55,817 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4399148341773292834_1103 src: /192.168.1.152:33531 dest: /192.168.1.152:50010
2017-03-12 11:55:55,819 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4399148341773292834_1103 src: /192.168.1.152:33531 dest: /192.168.1.152:50010 of size 13560
2017-03-12 11:55:58,780 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1116615322044546455_1102 src: /192.168.1.150:42488 dest: /192.168.1.150:50010
2017-03-12 11:55:58,784 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1116615322044546455_1102 src: /192.168.1.150:42488 dest: /192.168.1.150:50010 of size 1045
2017-03-12 11:55:58,821 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4253645977570740398_1105 src: /192.168.1.151:51102 dest: /192.168.1.151:50010
2017-03-12 11:55:58,822 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4253645977570740398_1105 src: /192.168.1.151:51102 dest: /192.168.1.151:50010 of size 13546
2017-03-12 11:56:01,689 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1116615322044546455_1102 to 192.168.1.151:50010
2017-03-12 11:56:01,691 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-1116615322044546455_1102 to /192.168.1.151:50010
2017-03-12 11:56:27,269 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4399148341773292834_1103 to /192.168.1.153
2017-03-12 11:56:27,501 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7246094886136305722_1101 to /192.168.1.153
2017-03-12 11:56:48,378 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 11:57:04,083 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2469247396937600182_1001 to /192.168.1.153
2017-03-12 11:57:08,197 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 11:57:24,000 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 11:57:37,723 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7246094886136305722_1101 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7246094886136305722
2017-03-12 11:57:37,724 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4399148341773292834_1103 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4399148341773292834
2017-03-12 11:57:37,724 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4253645977570740398_1105 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4253645977570740398
2017-03-12 11:57:37,724 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1116615322044546455_1102 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1116615322044546455
2017-03-12 11:58:19,750 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-03-12 11:58:34,743 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 11:59:12,065 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 11:59:12,269 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 11:59:12,272 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 11:59:12,274 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 11:59:12,348 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 11:59:12,411 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 11:59:12,412 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 11:59:12,412 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 11:59:12,664 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-03-12 11:59:12,701 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 11:59:12,704 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 11:59:12,704 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 11:59:12,709 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 11:59:12,726 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 11:59:12,731 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 11:59:12,731 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 11:59:12,733 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 11:59:12,733 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 11:59:12,734 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 11:59:12,734 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 11:59:12,741 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 11:59:12,742 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 11:59:12,750 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 11:59:15,748 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-03-12 12:00:06,591 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2617524871078667802_1108 src: /192.168.1.150:42521 dest: /192.168.1.150:50010
2017-03-12 12:00:06,609 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2617524871078667802_1108 src: /192.168.1.150:42521 dest: /192.168.1.150:50010 of size 13560
2017-03-12 12:00:06,891 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2617524871078667802_1108 to /192.168.1.153
2017-03-12 12:00:07,893 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 12:00:09,588 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2090566101322294282_1110 src: /192.168.1.150:42531 dest: /192.168.1.150:50010
2017-03-12 12:00:09,590 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2090566101322294282_1110 src: /192.168.1.150:42531 dest: /192.168.1.150:50010 of size 13546
2017-03-12 12:00:12,589 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-347712809673236186_1107 src: /192.168.1.151:51143 dest: /192.168.1.151:50010
2017-03-12 12:00:12,591 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-347712809673236186_1107 src: /192.168.1.151:51143 dest: /192.168.1.151:50010 of size 1045
2017-03-12 12:00:12,786 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2090566101322294282_1110 to 192.168.1.152:50010
2017-03-12 12:00:12,791 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-2090566101322294282_1110 to /192.168.1.152:50010
2017-03-12 12:00:15,584 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3783867780428493152_1106 src: /192.168.1.150:42533 dest: /192.168.1.150:50010
2017-03-12 12:00:15,586 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3783867780428493152_1106 src: /192.168.1.150:42533 dest: /192.168.1.150:50010 of size 91176
2017-03-12 12:00:15,774 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-347712809673236186_1107 to 192.168.1.152:50010
2017-03-12 12:00:15,777 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-347712809673236186_1107 to /192.168.1.152:50010
2017-03-12 12:00:23,351 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 12:02:09,712 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-487214114948600484_1114 src: /192.168.1.150:42569 dest: /192.168.1.150:50010
2017-03-12 12:02:10,187 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-487214114948600484_1114 src: /192.168.1.150:42569 dest: /192.168.1.150:50010 of size 31976695
2017-03-12 12:02:12,725 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5849343332435927139_1111 src: /192.168.1.150:42570 dest: /192.168.1.150:50010
2017-03-12 12:02:13,186 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5849343332435927139_1111 src: /192.168.1.150:42570 dest: /192.168.1.150:50010 of size 31981189
2017-03-12 12:02:18,720 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5997065165224269889_1117 src: /192.168.1.150:42578 dest: /192.168.1.150:50010
2017-03-12 12:02:18,724 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5997065165224269889_1117 src: /192.168.1.150:42578 dest: /192.168.1.150:50010 of size 13560
2017-03-12 12:02:21,820 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-5997065165224269889_1117 to 192.168.1.151:50010
2017-03-12 12:02:21,824 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-5997065165224269889_1117 to /192.168.1.151:50010
2017-03-12 12:02:24,798 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1384769432347459788_1119 src: /192.168.1.152:33584 dest: /192.168.1.152:50010
2017-03-12 12:02:24,800 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1384769432347459788_1119 src: /192.168.1.152:33584 dest: /192.168.1.152:50010 of size 13546
2017-03-12 12:02:27,836 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-789690445014374873_1116 src: /192.168.1.151:51163 dest: /192.168.1.151:50010
2017-03-12 12:02:27,837 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-789690445014374873_1116 src: /192.168.1.151:51163 dest: /192.168.1.151:50010 of size 1045
2017-03-12 12:02:30,804 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8615070458774935724_1115 src: /192.168.1.152:33585 dest: /192.168.1.152:50010
2017-03-12 12:02:30,811 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8615070458774935724_1115 src: /192.168.1.152:33585 dest: /192.168.1.152:50010 of size 91176
2017-03-12 12:02:33,825 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2617524871078667802_1108 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2617524871078667802
2017-03-12 12:02:33,826 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2090566101322294282_1110 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2090566101322294282
2017-03-12 12:02:33,837 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-487214114948600484_1114 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-487214114948600484
2017-03-12 12:02:33,837 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-347712809673236186_1107 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-347712809673236186
2017-03-12 12:02:33,837 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3783867780428493152_1106 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3783867780428493152
2017-03-12 12:04:36,880 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_660695991139742172_1120 src: /192.168.1.150:42631 dest: /192.168.1.150:50010
2017-03-12 12:04:37,341 INFO org.apache.hadoop.dfs.DataNode: Received block blk_660695991139742172_1120 src: /192.168.1.150:42631 dest: /192.168.1.150:50010 of size 31980463
2017-03-12 12:04:39,880 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4876864490607027949_1122 src: /192.168.1.150:42633 dest: /192.168.1.150:50010
2017-03-12 12:04:40,386 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4876864490607027949_1122 src: /192.168.1.150:42633 dest: /192.168.1.150:50010 of size 31976695
2017-03-12 12:04:42,891 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-697111329237717668_1121 src: /192.168.1.150:42634 dest: /192.168.1.150:50010
2017-03-12 12:04:43,421 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-697111329237717668_1121 src: /192.168.1.150:42634 dest: /192.168.1.150:50010 of size 31981189
2017-03-12 12:04:51,897 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2682166303200314929_1123 src: /192.168.1.150:42636 dest: /192.168.1.150:50010
2017-03-12 12:04:52,385 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2682166303200314929_1123 src: /192.168.1.150:42636 dest: /192.168.1.150:50010 of size 31964396
2017-03-12 12:04:57,904 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5864427427408966532_1128 src: /192.168.1.150:42637 dest: /192.168.1.150:50010
2017-03-12 12:04:57,908 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5864427427408966532_1128 src: /192.168.1.150:42637 dest: /192.168.1.150:50010 of size 13546
2017-03-12 12:05:00,879 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-5864427427408966532_1128 to 192.168.1.152:50010
2017-03-12 12:05:00,883 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-5864427427408966532_1128 to /192.168.1.152:50010
2017-03-12 12:05:03,850 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1649380903313077676_1125 src: /192.168.1.152:33606 dest: /192.168.1.152:50010
2017-03-12 12:05:03,851 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1649380903313077676_1125 src: /192.168.1.152:33606 dest: /192.168.1.152:50010 of size 1045
2017-03-12 12:05:03,924 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6019287739234401352_1124 src: /192.168.1.151:51184 dest: /192.168.1.151:50010
2017-03-12 12:05:03,926 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6019287739234401352_1124 src: /192.168.1.151:51184 dest: /192.168.1.151:50010 of size 91176
2017-03-12 12:05:09,913 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8062519935314325633_1126 src: /192.168.1.150:42651 dest: /192.168.1.150:50010
2017-03-12 12:05:09,916 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8062519935314325633_1126 src: /192.168.1.150:42651 dest: /192.168.1.150:50010 of size 13560
2017-03-12 12:05:12,892 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5997065165224269889_1117 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5997065165224269889
2017-03-12 12:05:12,893 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1384769432347459788_1119 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1384769432347459788
2017-03-12 12:05:12,893 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-789690445014374873_1116 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-789690445014374873
2017-03-12 12:05:12,903 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-697111329237717668_1121 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-697111329237717668
2017-03-12 12:05:12,911 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_660695991139742172_1120 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_660695991139742172
2017-03-12 12:05:12,916 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4876864490607027949_1122 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4876864490607027949
2017-03-12 12:05:12,917 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8615070458774935724_1115 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8615070458774935724
2017-03-12 12:07:45,935 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5864427427408966532_1128 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5864427427408966532
2017-03-12 12:07:45,935 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1649380903313077676_1125 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1649380903313077676
2017-03-12 12:07:45,936 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6019287739234401352_1124 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6019287739234401352
2017-03-12 12:07:45,936 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8062519935314325633_1126 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8062519935314325633
2017-03-12 12:52:26,120 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-2682166303200314929_1123
2017-03-12 12:53:04,880 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 10 blocks got processed in 5 msecs
2017-03-12 12:53:07,893 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2682166303200314929_1123 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2682166303200314929
2017-03-12 12:53:07,899 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5849343332435927139_1111 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5849343332435927139
2017-03-12 13:53:06,151 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-03-12 14:53:07,425 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 4 msecs
2017-03-12 15:36:57,874 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 15:37:03,676 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 15:37:03,881 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 15:37:03,883 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 15:37:03,885 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 15:37:03,956 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 15:37:04,016 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 15:37:04,016 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 15:37:04,017 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 15:37:04,258 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-03-12 15:37:04,296 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 15:37:04,299 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 15:37:04,299 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 15:37:04,305 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 15:37:04,323 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 15:37:04,327 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 15:37:04,328 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 15:37:04,329 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 15:37:04,330 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 15:37:04,330 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 15:37:04,330 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 15:37:04,333 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 15:37:04,333 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 15:37:04,342 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 15:37:07,339 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-03-12 15:38:16,224 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-818977082110453354_1134 src: /192.168.1.150:42701 dest: /192.168.1.150:50010
2017-03-12 15:38:16,242 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-818977082110453354_1134 src: /192.168.1.150:42701 dest: /192.168.1.150:50010 of size 1045
2017-03-12 15:38:19,635 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 15:38:22,201 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3385177144890088805_1135 src: /192.168.1.150:42712 dest: /192.168.1.150:50010
2017-03-12 15:38:22,205 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3385177144890088805_1135 src: /192.168.1.150:42712 dest: /192.168.1.150:50010 of size 13552
2017-03-12 15:38:28,216 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2037119846062963426_1137 src: /192.168.1.151:51226 dest: /192.168.1.151:50010
2017-03-12 15:38:28,217 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2037119846062963426_1137 src: /192.168.1.151:51226 dest: /192.168.1.151:50010 of size 13538
2017-03-12 15:38:31,210 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4724353119596005233_1133 src: /192.168.1.150:42716 dest: /192.168.1.150:50010
2017-03-12 15:38:31,215 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4724353119596005233_1133 src: /192.168.1.150:42716 dest: /192.168.1.150:50010 of size 91176
2017-03-12 15:38:36,727 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 15:38:42,436 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 15:38:58,087 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 15:39:02,293 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 15:39:17,836 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 15:39:22,109 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 15:39:37,704 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 15:39:49,307 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8075672509846877352_1138 src: /192.168.1.150:42739 dest: /192.168.1.150:50010
2017-03-12 15:39:49,315 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8075672509846877352_1138 src: /192.168.1.150:42739 dest: /192.168.1.150:50010 of size 91176
2017-03-12 15:39:49,658 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-8075672509846877352_1138 to /192.168.1.152
2017-03-12 15:39:49,910 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 15:39:52,304 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7725337711515398659_1142 src: /192.168.1.150:42750 dest: /192.168.1.150:50010
2017-03-12 15:39:52,305 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7725337711515398659_1142 src: /192.168.1.150:42750 dest: /192.168.1.150:50010 of size 13538
2017-03-12 15:39:52,403 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8075672509846877352_1138 to 192.168.1.152:50010
2017-03-12 15:39:52,410 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-8075672509846877352_1138 to /192.168.1.152:50010
2017-03-12 15:39:55,402 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7725337711515398659_1142 to 192.168.1.152:50010
2017-03-12 15:39:55,405 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-7725337711515398659_1142 to /192.168.1.152:50010
2017-03-12 15:39:58,317 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3693856340015439763_1140 src: /192.168.1.150:42752 dest: /192.168.1.150:50010
2017-03-12 15:39:58,318 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3693856340015439763_1140 src: /192.168.1.150:42752 dest: /192.168.1.150:50010 of size 13552
2017-03-12 15:39:58,459 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5929755403288087580_1139 src: /192.168.1.151:51257 dest: /192.168.1.151:50010
2017-03-12 15:39:58,461 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5929755403288087580_1139 src: /192.168.1.151:51257 dest: /192.168.1.151:50010 of size 1045
2017-03-12 15:40:04,411 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2037119846062963426_1137 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2037119846062963426
2017-03-12 15:40:04,411 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-818977082110453354_1134 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-818977082110453354
2017-03-12 15:40:04,412 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3385177144890088805_1135 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3385177144890088805
2017-03-12 15:40:04,412 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4724353119596005233_1133 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4724353119596005233
2017-03-12 15:40:07,483 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 15:40:12,708 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 15:40:28,942 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 15:40:37,759 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 15:40:53,874 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2469247396937600182_1001 to /192.168.1.153
2017-03-12 15:41:23,691 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 15:41:28,450 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7636549551253538064_1144 src: /192.168.1.152:33709 dest: /192.168.1.152:50010
2017-03-12 15:41:28,453 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7636549551253538064_1144 src: /192.168.1.152:33709 dest: /192.168.1.152:50010 of size 1045
2017-03-12 15:41:31,450 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4780997859754301593_1147 src: /192.168.1.152:33711 dest: /192.168.1.152:50010
2017-03-12 15:41:31,451 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4780997859754301593_1147 src: /192.168.1.152:33711 dest: /192.168.1.152:50010 of size 13538
2017-03-12 15:41:34,425 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9124069643811194999_1145 src: /192.168.1.150:42796 dest: /192.168.1.150:50010
2017-03-12 15:41:34,426 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9124069643811194999_1145 src: /192.168.1.150:42796 dest: /192.168.1.150:50010 of size 13552
2017-03-12 15:41:34,428 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9124069643811194999_1145 src: /192.168.1.150:42797 dest: /192.168.1.150:50010
2017-03-12 15:41:34,428 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_9124069643811194999_1145 received exception java.io.IOException: Block blk_9124069643811194999_1145 is valid, and cannot be written to.
2017-03-12 15:41:34,429 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_9124069643811194999_1145 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 15:41:34,451 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5629691866458740807_1143 src: /192.168.1.152:33712 dest: /192.168.1.152:50010
2017-03-12 15:41:34,456 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5629691866458740807_1143 src: /192.168.1.152:33712 dest: /192.168.1.152:50010 of size 91176
2017-03-12 15:41:37,442 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_9124069643811194999_1145 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 15:41:37,446 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_9124069643811194999_1145 to /192.168.1.152:50010
2017-03-12 15:41:39,300 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 15:41:40,444 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8075672509846877352_1138 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8075672509846877352
2017-03-12 15:41:40,444 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7725337711515398659_1142 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7725337711515398659
2017-03-12 15:41:40,444 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5929755403288087580_1139 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5929755403288087580
2017-03-12 15:41:40,445 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3693856340015439763_1140 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3693856340015439763
2017-03-12 15:41:44,534 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 15:41:59,854 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 15:42:09,345 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 15:42:24,367 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2469247396937600182_1001 to /192.168.1.153
2017-03-12 15:42:29,152 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 15:42:52,472 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7636549551253538064_1144 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7636549551253538064
2017-03-12 15:42:52,473 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4780997859754301593_1147 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4780997859754301593
2017-03-12 15:42:52,473 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5629691866458740807_1143 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5629691866458740807
2017-03-12 15:42:52,473 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9124069643811194999_1145 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9124069643811194999
2017-03-12 15:47:19,107 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 15:47:25,290 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 15:47:25,486 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 15:47:25,488 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 15:47:25,490 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 15:47:25,560 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 15:47:25,619 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 15:47:25,620 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 15:47:25,620 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 15:47:25,866 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-03-12 15:47:25,905 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 15:47:25,908 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 15:47:25,908 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 15:47:25,913 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 15:47:25,937 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 15:47:25,943 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 15:47:25,943 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 15:47:25,945 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 15:47:25,946 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 15:47:25,946 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 15:47:25,946 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 15:47:25,957 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 15:47:25,958 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 15:47:25,968 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 15:47:28,964 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-03-12 15:49:16,875 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5563250114605756750_1148 src: /192.168.1.152:33734 dest: /192.168.1.152:50010
2017-03-12 15:49:16,889 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5563250114605756750_1148 src: /192.168.1.152:33734 dest: /192.168.1.152:50010 of size 91176
2017-03-12 15:49:20,005 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_5563250114605756750_1148 to 192.168.1.151:50010
2017-03-12 15:49:20,020 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_5563250114605756750_1148 to /192.168.1.151:50010
2017-03-12 15:49:22,811 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6300572384793835013_1149 src: /192.168.1.150:42835 dest: /192.168.1.150:50010
2017-03-12 15:49:22,813 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6300572384793835013_1149 src: /192.168.1.150:42835 dest: /192.168.1.150:50010 of size 1045
2017-03-12 15:49:23,062 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_291347956339127485_1152 src: /192.168.1.152:33735 dest: /192.168.1.152:50010
2017-03-12 15:49:23,064 INFO org.apache.hadoop.dfs.DataNode: Received block blk_291347956339127485_1152 src: /192.168.1.152:33735 dest: /192.168.1.152:50010 of size 13546
2017-03-12 15:49:25,825 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-452241843070355072_1150 src: /192.168.1.151:51309 dest: /192.168.1.151:50010
2017-03-12 15:49:25,827 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-452241843070355072_1150 src: /192.168.1.151:51309 dest: /192.168.1.151:50010 of size 13560
2017-03-12 15:52:26,125 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6250694205498662529_1153 src: /192.168.1.152:33737 dest: /192.168.1.152:50010
2017-03-12 15:52:26,820 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6250694205498662529_1153 src: /192.168.1.152:33737 dest: /192.168.1.152:50010 of size 31981189
2017-03-12 15:52:47,059 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_489574326102637195_1154 src: /192.168.1.151:51312 dest: /192.168.1.151:50010
2017-03-12 15:52:47,791 INFO org.apache.hadoop.dfs.DataNode: Received block blk_489574326102637195_1154 src: /192.168.1.151:51312 dest: /192.168.1.151:50010 of size 31976695
2017-03-12 15:53:05,066 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-98209125140692379_1155 src: /192.168.1.151:51313 dest: /192.168.1.151:50010
2017-03-12 15:53:05,745 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-98209125140692379_1155 src: /192.168.1.151:51313 dest: /192.168.1.151:50010 of size 31980463
2017-03-12 15:53:23,081 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1521209256746814613_1156 src: /192.168.1.150:42908 dest: /192.168.1.150:50010
2017-03-12 15:53:23,087 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1521209256746814613_1156 src: /192.168.1.150:42908 dest: /192.168.1.150:50010 of size 14460
2017-03-12 15:53:29,086 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5548339540942433040_1158 src: /192.168.1.150:42909 dest: /192.168.1.150:50010
2017-03-12 15:53:29,089 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5548339540942433040_1158 src: /192.168.1.150:42909 dest: /192.168.1.150:50010 of size 1045
2017-03-12 15:53:32,088 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_5548339540942433040_1158 to 192.168.1.152:50010
2017-03-12 15:53:32,091 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_5548339540942433040_1158 to /192.168.1.152:50010
2017-03-12 15:53:35,095 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7422841834231233651_1157 src: /192.168.1.150:42920 dest: /192.168.1.150:50010
2017-03-12 15:53:35,101 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7422841834231233651_1157 src: /192.168.1.150:42920 dest: /192.168.1.150:50010 of size 91176
2017-03-12 15:53:35,139 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7381610729618393095_1161 src: /192.168.1.152:33740 dest: /192.168.1.152:50010
2017-03-12 15:53:35,142 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7381610729618393095_1161 src: /192.168.1.152:33740 dest: /192.168.1.152:50010 of size 13546
2017-03-12 15:53:41,141 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7966516245473318499_1159 src: /192.168.1.152:33741 dest: /192.168.1.152:50010
2017-03-12 15:53:41,144 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7966516245473318499_1159 src: /192.168.1.152:33741 dest: /192.168.1.152:50010 of size 13560
2017-03-12 15:53:44,103 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6250694205498662529_1153 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6250694205498662529
2017-03-12 15:53:44,104 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-452241843070355072_1150 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-452241843070355072
2017-03-12 15:53:44,111 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-98209125140692379_1155 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-98209125140692379
2017-03-12 15:53:44,111 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_291347956339127485_1152 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_291347956339127485
2017-03-12 15:53:44,117 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_489574326102637195_1154 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_489574326102637195
2017-03-12 15:53:44,117 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5563250114605756750_1148 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5563250114605756750
2017-03-12 15:53:44,117 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6300572384793835013_1149 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6300572384793835013
2017-03-12 15:56:35,305 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5844599444690886972_1162 src: /192.168.1.150:42978 dest: /192.168.1.150:50010
2017-03-12 15:56:36,012 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5844599444690886972_1162 src: /192.168.1.150:42978 dest: /192.168.1.150:50010 of size 31981189
2017-03-12 15:56:53,326 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4406914518532376240_1163 src: /192.168.1.150:42985 dest: /192.168.1.150:50010
2017-03-12 15:56:54,095 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4406914518532376240_1163 src: /192.168.1.150:42985 dest: /192.168.1.150:50010 of size 31976695
2017-03-12 15:57:14,357 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6908807829972979005_1164 src: /192.168.1.151:51315 dest: /192.168.1.151:50010
2017-03-12 15:57:15,021 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6908807829972979005_1164 src: /192.168.1.151:51315 dest: /192.168.1.151:50010 of size 31980463
2017-03-12 15:57:35,372 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8828913811395593112_1165 src: /192.168.1.150:42995 dest: /192.168.1.150:50010
2017-03-12 15:57:35,376 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8828913811395593112_1165 src: /192.168.1.150:42995 dest: /192.168.1.150:50010 of size 14460
2017-03-12 15:57:44,229 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5169741703477811788_1168 src: /192.168.1.152:33743 dest: /192.168.1.152:50010
2017-03-12 15:57:44,230 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5169741703477811788_1168 src: /192.168.1.152:33743 dest: /192.168.1.152:50010 of size 13560
2017-03-12 15:57:47,165 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3274352231640635923_1170 src: /192.168.1.152:33744 dest: /192.168.1.152:50010
2017-03-12 15:57:47,167 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3274352231640635923_1170 src: /192.168.1.152:33744 dest: /192.168.1.152:50010 of size 13546
2017-03-12 15:57:47,381 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1989399898526316970_1167 src: /192.168.1.150:43007 dest: /192.168.1.150:50010
2017-03-12 15:57:47,384 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1989399898526316970_1167 src: /192.168.1.150:43007 dest: /192.168.1.150:50010 of size 1045
2017-03-12 15:57:50,393 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3048014554258801353_1166 src: /192.168.1.150:43008 dest: /192.168.1.150:50010
2017-03-12 15:57:50,396 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3048014554258801353_1166 src: /192.168.1.150:43009 dest: /192.168.1.150:50010
2017-03-12 15:57:50,397 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3048014554258801353_1166 src: /192.168.1.150:43008 dest: /192.168.1.150:50010 of size 91176
2017-03-12 15:57:50,397 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3048014554258801353_1166 received exception java.io.IOException: Block blk_3048014554258801353_1166 is valid, and cannot be written to.
2017-03-12 15:57:50,399 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_3048014554258801353_1166 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 15:57:56,196 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6908807829972979005_1164 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6908807829972979005
2017-03-12 15:57:56,202 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4406914518532376240_1163 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4406914518532376240
2017-03-12 15:57:56,202 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5548339540942433040_1158 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5548339540942433040
2017-03-12 15:57:56,209 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5844599444690886972_1162 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5844599444690886972
2017-03-12 15:57:56,209 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7381610729618393095_1161 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7381610729618393095
2017-03-12 15:57:56,210 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7422841834231233651_1157 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7422841834231233651
2017-03-12 15:57:56,210 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7966516245473318499_1159 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7966516245473318499
2017-03-12 16:00:44,584 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2940769295687213645_1171 src: /192.168.1.150:43066 dest: /192.168.1.150:50010
2017-03-12 16:00:45,261 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2940769295687213645_1171 src: /192.168.1.150:43066 dest: /192.168.1.150:50010 of size 31981189
2017-03-12 16:01:05,614 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3778766078343309642_1172 src: /192.168.1.150:43073 dest: /192.168.1.150:50010
2017-03-12 16:01:06,347 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3778766078343309642_1172 src: /192.168.1.150:43073 dest: /192.168.1.150:50010 of size 31976695
2017-03-12 16:01:26,650 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2967360102657831360_1173 src: /192.168.1.151:51317 dest: /192.168.1.151:50010
2017-03-12 16:01:27,416 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2967360102657831360_1173 src: /192.168.1.151:51317 dest: /192.168.1.151:50010 of size 31980463
2017-03-12 16:01:50,281 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5169741703477811788_1168 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5169741703477811788
2017-03-12 16:01:50,282 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3274352231640635923_1170 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3274352231640635923
2017-03-12 16:01:50,293 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2967360102657831360_1173 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2967360102657831360
2017-03-12 16:01:50,300 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2940769295687213645_1171 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2940769295687213645
2017-03-12 16:01:50,301 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1989399898526316970_1167 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1989399898526316970
2017-03-12 16:01:50,301 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3048014554258801353_1166 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3048014554258801353
2017-03-12 16:01:50,307 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3778766078343309642_1172 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3778766078343309642
2017-03-12 16:06:50,867 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 16:06:56,968 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 16:06:57,173 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 16:06:57,175 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 16:06:57,177 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 16:06:57,250 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 16:06:57,310 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 16:06:57,311 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 16:06:57,311 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 16:06:57,557 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-03-12 16:06:57,595 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 16:06:57,599 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 16:06:57,599 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 16:06:57,604 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 16:06:57,627 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 16:06:57,633 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 16:06:57,634 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 16:06:57,635 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 16:06:57,635 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 16:06:57,635 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 16:06:57,636 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 16:06:57,637 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 16:06:57,638 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 16:06:57,647 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 16:06:57,680 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_8828913811395593112_1165
2017-03-12 16:07:00,647 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 10 blocks got processed in 6 msecs
2017-03-12 16:07:09,649 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 10 blocks got processed in 4 msecs
2017-03-12 16:07:33,659 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1521209256746814613_1156 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1521209256746814613
2017-03-12 16:07:33,659 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8828913811395593112_1165 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8828913811395593112
2017-03-12 16:08:39,627 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6708591014476683054_1175 src: /192.168.1.152:33749 dest: /192.168.1.152:50010
2017-03-12 16:08:39,640 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6708591014476683054_1175 src: /192.168.1.152:33749 dest: /192.168.1.152:50010 of size 91176
2017-03-12 16:08:42,591 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3131503513643343706_1179 src: /192.168.1.150:43100 dest: /192.168.1.150:50010
2017-03-12 16:08:42,612 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3131503513643343706_1179 src: /192.168.1.150:43100 dest: /192.168.1.150:50010 of size 13546
2017-03-12 16:08:48,586 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9161309369147525216_1176 src: /192.168.1.150:43103 dest: /192.168.1.150:50010
2017-03-12 16:08:48,587 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9161309369147525216_1176 src: /192.168.1.150:43103 dest: /192.168.1.150:50010 of size 1045
2017-03-12 16:08:48,590 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-237904374656179744_1177 src: /192.168.1.152:33753 dest: /192.168.1.152:50010
2017-03-12 16:08:48,591 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-237904374656179744_1177 src: /192.168.1.152:33753 dest: /192.168.1.152:50010 of size 13560
2017-03-12 16:08:51,681 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_9161309369147525216_1176 to 192.168.1.152:50010
2017-03-12 16:08:51,688 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_9161309369147525216_1176 to /192.168.1.152:50010
2017-03-12 16:11:00,755 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6522104291560356541_1180 src: /192.168.1.152:33754 dest: /192.168.1.152:50010
2017-03-12 16:11:02,168 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6522104291560356541_1180 src: /192.168.1.152:33754 dest: /192.168.1.152:50010 of size 31981189
2017-03-12 16:11:21,771 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2054216394901627213_1181 src: /192.168.1.151:51321 dest: /192.168.1.151:50010
2017-03-12 16:11:22,609 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2054216394901627213_1181 src: /192.168.1.151:51321 dest: /192.168.1.151:50010 of size 31976695
2017-03-12 16:11:24,734 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2054216394901627213_1181 to 192.168.1.152:50010
2017-03-12 16:11:25,292 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-2054216394901627213_1181 to /192.168.1.152:50010
2017-03-12 16:11:39,797 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3681692452997619620_1182 src: /192.168.1.152:33755 dest: /192.168.1.152:50010
2017-03-12 16:11:40,553 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3681692452997619620_1182 src: /192.168.1.152:33755 dest: /192.168.1.152:50010 of size 31980463
2017-03-12 16:12:06,819 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8419060891752255093_1186 src: /192.168.1.151:51322 dest: /192.168.1.151:50010
2017-03-12 16:12:06,820 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8419060891752255093_1186 src: /192.168.1.151:51322 dest: /192.168.1.151:50010 of size 13560
2017-03-12 16:12:09,754 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8419060891752255093_1186 to 192.168.1.152:50010
2017-03-12 16:12:09,757 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-8419060891752255093_1186 to /192.168.1.152:50010
2017-03-12 16:12:09,818 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1179878290349824573_1188 src: /192.168.1.150:43182 dest: /192.168.1.150:50010
2017-03-12 16:12:09,823 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1179878290349824573_1188 src: /192.168.1.150:43183 dest: /192.168.1.150:50010
2017-03-12 16:12:09,823 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-1179878290349824573_1188 received exception java.io.IOException: Block blk_-1179878290349824573_1188 has already been started (though not completed), and thus cannot be created.
2017-03-12 16:12:09,824 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1179878290349824573_1188 src: /192.168.1.150:43182 dest: /192.168.1.150:50010 of size 13546
2017-03-12 16:12:09,826 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-1179878290349824573_1188 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:12:12,756 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1179878290349824573_1188 to 192.168.1.151:50010, 192.168.1.152:50010
2017-03-12 16:12:12,760 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-1179878290349824573_1188 to /192.168.1.151:50010
2017-03-12 16:12:12,823 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-687231809670304157_1184 src: /192.168.1.150:43186 dest: /192.168.1.150:50010
2017-03-12 16:12:12,826 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-687231809670304157_1184 src: /192.168.1.150:43186 dest: /192.168.1.150:50010 of size 91176
2017-03-12 16:12:15,756 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-687231809670304157_1184 to 192.168.1.151:50010
2017-03-12 16:12:15,763 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-687231809670304157_1184 to /192.168.1.151:50010
2017-03-12 16:12:18,831 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1710939855277306937_1185 src: /192.168.1.150:43189 dest: /192.168.1.150:50010
2017-03-12 16:12:18,834 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1710939855277306937_1185 src: /192.168.1.150:43189 dest: /192.168.1.150:50010 of size 1045
2017-03-12 16:12:21,758 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6708591014476683054_1175 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6708591014476683054
2017-03-12 16:12:21,765 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6522104291560356541_1180 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6522104291560356541
2017-03-12 16:12:21,770 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3681692452997619620_1182 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3681692452997619620
2017-03-12 16:12:21,770 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3131503513643343706_1179 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3131503513643343706
2017-03-12 16:12:21,775 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2054216394901627213_1181 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2054216394901627213
2017-03-12 16:12:21,775 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-237904374656179744_1177 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-237904374656179744
2017-03-12 16:12:21,775 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9161309369147525216_1176 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9161309369147525216
2017-03-12 16:14:24,981 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3386578541102456277_1189 src: /192.168.1.150:43237 dest: /192.168.1.150:50010
2017-03-12 16:14:25,826 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3386578541102456277_1189 src: /192.168.1.150:43237 dest: /192.168.1.150:50010 of size 31981189
2017-03-12 16:14:46,010 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2121816494649845389_1190 src: /192.168.1.151:51324 dest: /192.168.1.151:50010
2017-03-12 16:14:46,778 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2121816494649845389_1190 src: /192.168.1.151:51324 dest: /192.168.1.151:50010 of size 31976695
2017-03-12 16:15:33,842 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6636657163346401372_1197 src: /192.168.1.151:51326 dest: /192.168.1.151:50010
2017-03-12 16:15:33,844 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6636657163346401372_1197 src: /192.168.1.151:51326 dest: /192.168.1.151:50010 of size 13546
2017-03-12 16:15:36,738 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3209879546996903751_1195 src: /192.168.1.152:33756 dest: /192.168.1.152:50010
2017-03-12 16:15:36,740 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3209879546996903751_1195 src: /192.168.1.152:33756 dest: /192.168.1.152:50010 of size 13560
2017-03-12 16:15:39,740 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6159065216009368983_1193 src: /192.168.1.152:33757 dest: /192.168.1.152:50010
2017-03-12 16:15:39,744 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6159065216009368983_1193 src: /192.168.1.152:33757 dest: /192.168.1.152:50010 of size 91176
2017-03-12 16:15:42,842 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8913300546410018431_1194 src: /192.168.1.152:33758 dest: /192.168.1.152:50010
2017-03-12 16:15:42,843 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8913300546410018431_1194 src: /192.168.1.152:33758 dest: /192.168.1.152:50010 of size 1045
2017-03-12 16:15:45,831 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8419060891752255093_1186 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8419060891752255093
2017-03-12 16:15:45,843 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3386578541102456277_1189 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3386578541102456277
2017-03-12 16:15:45,851 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2121816494649845389_1190 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2121816494649845389
2017-03-12 16:15:45,851 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1179878290349824573_1188 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1179878290349824573
2017-03-12 16:15:45,851 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-687231809670304157_1184 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-687231809670304157
2017-03-12 16:15:45,851 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1710939855277306937_1185 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1710939855277306937
2017-03-12 16:17:55,218 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5720652885878491578_1198 src: /192.168.1.150:43318 dest: /192.168.1.150:50010
2017-03-12 16:17:55,647 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5720652885878491578_1198 src: /192.168.1.150:43318 dest: /192.168.1.150:50010 of size 31981189
2017-03-12 16:19:00,900 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6636657163346401372_1197 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6636657163346401372
2017-03-12 16:19:00,909 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5720652885878491578_1198 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5720652885878491578
2017-03-12 16:19:00,910 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3209879546996903751_1195 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3209879546996903751
2017-03-12 16:19:00,910 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6159065216009368983_1193 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6159065216009368983
2017-03-12 16:19:00,910 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8913300546410018431_1194 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8913300546410018431
2017-03-12 16:25:02,458 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 16:25:10,344 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 16:25:10,543 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 16:25:10,544 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 16:25:10,546 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 16:25:10,616 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 16:25:10,675 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 16:25:10,676 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 16:25:10,676 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 16:25:10,919 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-03-12 16:25:10,958 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 16:25:10,960 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 16:25:10,960 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 16:25:10,965 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 16:25:10,987 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 16:25:10,992 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 16:25:10,992 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 16:25:10,994 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 16:25:10,995 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 16:25:10,995 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 16:25:10,994 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 16:25:10,997 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 16:25:10,998 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 16:25:11,007 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 16:25:14,007 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-03-12 16:27:10,880 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5768288927820086192_1203 src: /192.168.1.150:43351 dest: /192.168.1.150:50010
2017-03-12 16:27:10,893 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5768288927820086192_1203 src: /192.168.1.150:43351 dest: /192.168.1.150:50010 of size 2085
2017-03-12 16:27:13,871 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1291077424117035196_1204 src: /192.168.1.152:33771 dest: /192.168.1.152:50010
2017-03-12 16:27:13,873 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1291077424117035196_1204 src: /192.168.1.152:33771 dest: /192.168.1.152:50010 of size 13560
2017-03-12 16:27:16,870 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-543972320334669220_1206 src: /192.168.1.150:43354 dest: /192.168.1.150:50010
2017-03-12 16:27:16,872 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-543972320334669220_1206 src: /192.168.1.150:43354 dest: /192.168.1.150:50010 of size 13546
2017-03-12 16:27:16,874 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3514170462678962186_1202 src: /192.168.1.150:43355 dest: /192.168.1.150:50010
2017-03-12 16:27:16,876 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3514170462678962186_1202 src: /192.168.1.150:43355 dest: /192.168.1.150:50010 of size 91176
2017-03-12 16:27:20,049 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-543972320334669220_1206 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 16:27:20,056 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-543972320334669220_1206 to /192.168.1.152:50010
2017-03-12 16:27:21,147 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 16:27:23,049 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_3514170462678962186_1202 to 192.168.1.151:50010, 192.168.1.152:50010
2017-03-12 16:27:23,054 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_3514170462678962186_1202 to /192.168.1.151:50010
2017-03-12 16:27:24,988 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 16:27:44,443 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 16:27:48,120 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 16:28:16,936 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-285720866624223956_1210 src: /192.168.1.150:43389 dest: /192.168.1.150:50010
2017-03-12 16:28:16,947 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-285720866624223956_1210 src: /192.168.1.150:43389 dest: /192.168.1.150:50010 of size 23376
2017-03-12 16:28:22,938 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6398064203118061007_1213 src: /192.168.1.150:43393 dest: /192.168.1.150:50010
2017-03-12 16:28:22,943 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6398064203118061007_1213 src: /192.168.1.150:43393 dest: /192.168.1.150:50010 of size 13560
2017-03-12 16:28:23,576 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-6398064203118061007_1213 to /192.168.1.151
2017-03-12 16:28:24,163 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-6398064203118061007_1213 to /192.168.1.153
2017-03-12 16:28:24,231 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-6398064203118061007_1213 to /192.168.1.152
2017-03-12 16:28:25,062 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 16:28:26,073 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6398064203118061007_1213 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 16:28:26,076 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Failed to transfer blk_-6398064203118061007_1213 to 192.168.1.152:50010 got java.net.SocketException: Original Exception : java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:420)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:552)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:199)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1873)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataNode$DataTransfer.run(DataNode.java:2855)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	... 8 more

2017-03-12 16:28:28,946 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1726209248250254272_1215 src: /192.168.1.150:43401 dest: /192.168.1.150:50010
2017-03-12 16:28:28,950 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1726209248250254272_1215 src: /192.168.1.150:43401 dest: /192.168.1.150:50010 of size 13546
2017-03-12 16:28:32,075 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1726209248250254272_1215 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 16:28:32,078 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-1726209248250254272_1215 to /192.168.1.152:50010
2017-03-12 16:28:34,954 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2360928662310686138_1212 src: /192.168.1.150:43404 dest: /192.168.1.150:50010
2017-03-12 16:28:34,957 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2360928662310686138_1212 src: /192.168.1.150:43404 dest: /192.168.1.150:50010 of size 2085
2017-03-12 16:28:37,857 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 16:28:38,076 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_2360928662310686138_1212 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 16:28:38,078 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_2360928662310686138_1212 to /192.168.1.152:50010
2017-03-12 16:28:40,959 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4876523803694041254_1211 src: /192.168.1.150:43411 dest: /192.168.1.150:50010
2017-03-12 16:28:40,962 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4876523803694041254_1211 src: /192.168.1.150:43411 dest: /192.168.1.150:50010 of size 91176
2017-03-12 16:28:47,080 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4876523803694041254_1211 to 192.168.1.151:50010, 192.168.1.152:50010
2017-03-12 16:28:47,086 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Failed to transfer blk_4876523803694041254_1211 to 192.168.1.151:50010 got java.net.SocketException: Original Exception : java.io.IOException: Broken pipe
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:420)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:552)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:199)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1873)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataNode$DataTransfer.run(DataNode.java:2855)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Broken pipe
	... 8 more

2017-03-12 16:28:49,549 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 16:28:56,085 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4876523803694041254_1211 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 16:28:56,090 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_4876523803694041254_1211 to /192.168.1.152:50010
2017-03-12 16:28:59,087 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4876523803694041254_1211 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 16:28:59,093 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Failed to transfer blk_4876523803694041254_1211 to 192.168.1.152:50010 got java.net.SocketException: Original Exception : java.io.IOException: Broken pipe
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:420)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:552)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:199)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1873)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataNode$DataTransfer.run(DataNode.java:2855)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Broken pipe
	... 8 more

2017-03-12 16:29:01,406 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 16:29:02,086 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4876523803694041254_1211 to 192.168.1.151:50010, 192.168.1.152:50010
2017-03-12 16:29:02,091 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_4876523803694041254_1211 to /192.168.1.151:50010
2017-03-12 16:29:08,089 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4876523803694041254_1211 to 192.168.1.151:50010, 192.168.1.152:50010
2017-03-12 16:29:08,094 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Failed to transfer blk_4876523803694041254_1211 to 192.168.1.151:50010 got java.net.SocketException: Original Exception : java.io.IOException: Broken pipe
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:420)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:552)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:199)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1873)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataNode$DataTransfer.run(DataNode.java:2855)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Broken pipe
	... 8 more

2017-03-12 16:29:11,101 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4876523803694041254_1211 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 16:29:11,109 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_4876523803694041254_1211 to /192.168.1.152:50010
2017-03-12 16:29:14,094 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4876523803694041254_1211 to 192.168.1.151:50010
2017-03-12 16:29:14,102 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Failed to transfer blk_4876523803694041254_1211 to 192.168.1.151:50010 got java.net.SocketException: Original Exception : java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:94)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:450)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1870)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataNode$DataTransfer.run(DataNode.java:2855)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	... 13 more

2017-03-12 16:29:26,101 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4876523803694041254_1211 to 192.168.1.151:50010
2017-03-12 16:29:26,107 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_4876523803694041254_1211 to /192.168.1.151:50010
2017-03-12 16:29:32,103 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4876523803694041254_1211 to 192.168.1.151:50010
2017-03-12 16:29:32,111 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Failed to transfer blk_4876523803694041254_1211 to 192.168.1.151:50010 got java.net.SocketException: Original Exception : java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:420)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:552)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:199)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1873)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataNode$DataTransfer.run(DataNode.java:2855)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	... 8 more

2017-03-12 16:29:38,104 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4876523803694041254_1211 to 192.168.1.151:50010
2017-03-12 16:29:38,108 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_4876523803694041254_1211 to /192.168.1.151:50010
2017-03-12 16:29:47,108 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6398064203118061007_1213 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6398064203118061007
2017-03-12 16:29:47,109 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5768288927820086192_1203 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5768288927820086192
2017-03-12 16:29:47,110 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1726209248250254272_1215 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1726209248250254272
2017-03-12 16:29:47,110 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1291077424117035196_1204 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1291077424117035196
2017-03-12 16:29:47,111 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-543972320334669220_1206 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-543972320334669220
2017-03-12 16:29:47,111 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2360928662310686138_1212 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2360928662310686138
2017-03-12 16:29:47,112 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3514170462678962186_1202 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3514170462678962186
2017-03-12 16:29:47,112 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4876523803694041254_1211 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4876523803694041254
2017-03-12 16:29:53,043 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8968644918249929665_1223 src: /192.168.1.150:43471 dest: /192.168.1.150:50010
2017-03-12 16:29:53,043 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8968644918249929665_1223 src: /192.168.1.150:43471 dest: /192.168.1.150:50010 of size 13560
2017-03-12 16:29:56,110 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8968644918249929665_1223 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 16:29:56,115 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-8968644918249929665_1223 to /192.168.1.152:50010
2017-03-12 16:29:59,046 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4244725863418961331_1225 src: /192.168.1.150:43473 dest: /192.168.1.150:50010
2017-03-12 16:29:59,047 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4244725863418961331_1225 src: /192.168.1.150:43473 dest: /192.168.1.150:50010 of size 13546
2017-03-12 16:29:59,152 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 16:30:02,048 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1582153603561009456_1222 src: /192.168.1.150:43480 dest: /192.168.1.150:50010
2017-03-12 16:30:02,050 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1582153603561009456_1222 src: /192.168.1.150:43480 dest: /192.168.1.150:50010 of size 2085
2017-03-12 16:30:02,086 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5876290751059256751_1221 src: /192.168.1.152:33851 dest: /192.168.1.152:50010
2017-03-12 16:30:02,090 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5876290751059256751_1221 src: /192.168.1.152:33851 dest: /192.168.1.152:50010 of size 91176
2017-03-12 16:30:02,112 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-4244725863418961331_1225 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 16:30:02,115 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-4244725863418961331_1225 to /192.168.1.152:50010
2017-03-12 16:30:05,113 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-5876290751059256751_1221 to 192.168.1.151:50010
2017-03-12 16:30:05,117 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-5876290751059256751_1221 to /192.168.1.151:50010
2017-03-12 16:30:10,855 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 16:30:22,657 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 16:30:34,771 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 16:30:46,448 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 16:30:58,028 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2469247396937600182_1001 to /192.168.1.153
2017-03-12 16:31:35,144 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8968644918249929665_1223 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8968644918249929665
2017-03-12 16:31:35,145 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5876290751059256751_1221 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5876290751059256751
2017-03-12 16:31:35,145 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4244725863418961331_1225 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4244725863418961331
2017-03-12 16:31:35,146 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1582153603561009456_1222 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1582153603561009456
2017-03-12 16:37:56,724 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 16:38:02,427 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 16:38:02,627 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 16:38:02,629 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 16:38:02,630 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 16:38:02,702 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 16:38:02,771 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 16:38:02,772 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 16:38:02,772 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 16:38:02,999 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-03-12 16:38:03,033 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 16:38:03,036 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 16:38:03,036 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@cd1a1f
2017-03-12 16:38:03,041 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 16:38:03,062 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 16:38:03,066 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 16:38:03,066 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 16:38:03,068 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 16:38:03,069 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 16:38:03,070 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 16:38:03,070 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 16:38:03,072 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 16:38:03,073 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 16:38:03,081 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 16:38:03,114 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-285720866624223956_1210
2017-03-12 16:38:06,079 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 6 msecs
2017-03-12 16:38:39,095 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-285720866624223956_1210 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-285720866624223956
2017-03-12 16:40:21,040 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8270637891897539047_1235 src: /192.168.1.150:43523 dest: /192.168.1.150:50010
2017-03-12 16:40:21,056 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8270637891897539047_1235 src: /192.168.1.150:43523 dest: /192.168.1.150:50010 of size 13547
2017-03-12 16:40:24,037 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1872669002743203334_1232 src: /192.168.1.150:43532 dest: /192.168.1.150:50010
2017-03-12 16:40:24,039 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1872669002743203334_1232 src: /192.168.1.150:43532 dest: /192.168.1.150:50010 of size 2085
2017-03-12 16:40:30,035 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6455345861275209896_1233 src: /192.168.1.150:43536 dest: /192.168.1.150:50010
2017-03-12 16:40:30,036 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6455345861275209896_1233 src: /192.168.1.150:43536 dest: /192.168.1.150:50010 of size 13561
2017-03-12 16:40:30,179 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5678415830610672467_1231 src: /192.168.1.151:51469 dest: /192.168.1.151:50010
2017-03-12 16:40:30,180 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5678415830610672467_1231 src: /192.168.1.151:51469 dest: /192.168.1.151:50010 of size 91176
2017-03-12 16:40:33,582 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7701193938081024283_1001 to /192.168.1.153
2017-03-12 16:40:37,329 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 16:40:48,466 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 16:41:00,248 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 16:41:27,154 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 12 blocks got processed in 4 msecs
2017-03-12 16:41:33,158 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8270637891897539047_1235 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8270637891897539047
2017-03-12 16:41:33,159 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1872669002743203334_1232 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1872669002743203334
2017-03-12 16:41:33,159 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5678415830610672467_1231 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5678415830610672467
2017-03-12 16:41:33,160 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6455345861275209896_1233 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6455345861275209896
2017-03-12 16:41:36,116 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3457497363530266123_1242 src: /192.168.1.150:43573 dest: /192.168.1.150:50010
2017-03-12 16:41:36,122 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3457497363530266123_1242 src: /192.168.1.150:43573 dest: /192.168.1.150:50010 of size 13561
2017-03-12 16:41:39,117 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6583392820966837760_1240 src: /192.168.1.150:43578 dest: /192.168.1.150:50010
2017-03-12 16:41:39,119 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6583392820966837760_1240 src: /192.168.1.150:43578 dest: /192.168.1.150:50010 of size 91176
2017-03-12 16:41:39,160 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_3457497363530266123_1242 to 192.168.1.151:50010
2017-03-12 16:41:39,165 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_3457497363530266123_1242 to /192.168.1.151:50010
2017-03-12 16:41:42,119 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6876260366365266094_1244 src: /192.168.1.150:43579 dest: /192.168.1.150:50010
2017-03-12 16:41:42,122 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6876260366365266094_1244 src: /192.168.1.150:43579 dest: /192.168.1.150:50010 of size 13547
2017-03-12 16:41:45,164 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_6876260366365266094_1244 to 192.168.1.151:50010
2017-03-12 16:41:45,168 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_6876260366365266094_1244 to /192.168.1.151:50010
2017-03-12 16:41:48,212 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6906701525058985124_1241 src: /192.168.1.151:51503 dest: /192.168.1.151:50010
2017-03-12 16:41:48,213 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6906701525058985124_1241 src: /192.168.1.151:51503 dest: /192.168.1.151:50010 of size 2085
2017-03-12 16:42:11,288 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_3457497363530266123_1242 to /192.168.1.153
2017-03-12 16:42:11,315 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6583392820966837760_1240 to /192.168.1.153
2017-03-12 16:42:20,351 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 16:42:32,003 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 16:42:43,650 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 16:42:55,828 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2469247396937600182_1001 to /192.168.1.153
2017-03-12 16:43:18,230 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5227992124916519344_1248 src: /192.168.1.150:43622 dest: /192.168.1.150:50010
2017-03-12 16:43:18,235 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5227992124916519344_1248 src: /192.168.1.150:43622 dest: /192.168.1.150:50010 of size 24178
2017-03-12 16:43:24,239 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6315045916916930936_1251 src: /192.168.1.151:51541 dest: /192.168.1.151:50010
2017-03-12 16:43:24,240 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6315045916916930936_1251 src: /192.168.1.151:51541 dest: /192.168.1.151:50010 of size 13561
2017-03-12 16:43:27,243 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4518936858927803746_1250 src: /192.168.1.150:43632 dest: /192.168.1.150:50010
2017-03-12 16:43:27,243 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4518936858927803746_1250 src: /192.168.1.150:43633 dest: /192.168.1.150:50010
2017-03-12 16:43:27,243 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-4518936858927803746_1250 received exception java.io.IOException: Block blk_-4518936858927803746_1250 has already been started (though not completed), and thus cannot be created.
2017-03-12 16:43:27,244 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4518936858927803746_1250 src: /192.168.1.150:43632 dest: /192.168.1.150:50010 of size 2085
2017-03-12 16:43:27,246 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-4518936858927803746_1250 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:43:30,206 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-4518936858927803746_1250 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 16:43:30,209 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-4518936858927803746_1250 to /192.168.1.152:50010
2017-03-12 16:43:30,244 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3297058281152576620_1253 src: /192.168.1.152:33984 dest: /192.168.1.152:50010
2017-03-12 16:43:30,259 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3297058281152576620_1253 src: /192.168.1.152:33984 dest: /192.168.1.152:50010 of size 13547
2017-03-12 16:43:33,207 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_3297058281152576620_1253 to 192.168.1.151:50010
2017-03-12 16:43:33,210 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_3297058281152576620_1253 to /192.168.1.151:50010
2017-03-12 16:43:36,257 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3495118466755576265_1249 src: /192.168.1.151:51543 dest: /192.168.1.151:50010
2017-03-12 16:43:36,262 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3495118466755576265_1249 src: /192.168.1.151:51543 dest: /192.168.1.151:50010 of size 91176
2017-03-12 16:43:39,210 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3457497363530266123_1242 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3457497363530266123
2017-03-12 16:43:39,210 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6583392820966837760_1240 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6583392820966837760
2017-03-12 16:43:39,210 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6876260366365266094_1244 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6876260366365266094
2017-03-12 16:43:39,211 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6906701525058985124_1241 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6906701525058985124
2017-03-12 16:44:11,845 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-6315045916916930936_1251 to /192.168.1.153
2017-03-12 16:44:11,870 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_3495118466755576265_1249 to /192.168.1.153
2017-03-12 16:44:12,770 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 16:44:32,719 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 16:44:43,993 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 16:45:18,304 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6822059446970476921_1258 src: /192.168.1.151:51586 dest: /192.168.1.151:50010
2017-03-12 16:45:18,312 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6822059446970476921_1258 src: /192.168.1.151:51586 dest: /192.168.1.151:50010 of size 91176
2017-03-12 16:45:21,207 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_65506842683212604_1262 src: /192.168.1.152:34032 dest: /192.168.1.152:50010
2017-03-12 16:45:21,210 INFO org.apache.hadoop.dfs.DataNode: Received block blk_65506842683212604_1262 src: /192.168.1.152:34032 dest: /192.168.1.152:50010 of size 13547
2017-03-12 16:45:21,368 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1473316218981862703_1260 src: /192.168.1.152:34033 dest: /192.168.1.152:50010
2017-03-12 16:45:21,369 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1473316218981862703_1260 src: /192.168.1.152:34033 dest: /192.168.1.152:50010 of size 13561
2017-03-12 16:45:24,246 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_1473316218981862703_1260 to 192.168.1.151:50010
2017-03-12 16:45:24,249 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_1473316218981862703_1260 to /192.168.1.151:50010
2017-03-12 16:45:27,368 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1804015394223897797_1259 src: /192.168.1.150:43703 dest: /192.168.1.150:50010
2017-03-12 16:45:27,369 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1804015394223897797_1259 src: /192.168.1.150:43703 dest: /192.168.1.150:50010 of size 2085
2017-03-12 16:45:30,248 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6315045916916930936_1251 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6315045916916930936
2017-03-12 16:45:30,249 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4518936858927803746_1250 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4518936858927803746
2017-03-12 16:45:30,249 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3297058281152576620_1253 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3297058281152576620
2017-03-12 16:45:30,249 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3495118466755576265_1249 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3495118466755576265
2017-03-12 16:45:35,957 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 16:45:39,224 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 16:45:51,016 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 16:46:30,271 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6822059446970476921_1258 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6822059446970476921
2017-03-12 16:46:30,271 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_65506842683212604_1262 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_65506842683212604
2017-03-12 16:46:30,272 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1473316218981862703_1260 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1473316218981862703
2017-03-12 16:46:30,272 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1804015394223897797_1259 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1804015394223897797
2017-03-12 16:46:33,461 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8457408884696464670_1267 src: /192.168.1.151:51620 dest: /192.168.1.151:50010
2017-03-12 16:46:33,461 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8457408884696464670_1267 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:46:33,462 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:46:36,339 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8457408884696464670_1267 src: /192.168.1.151:51621 dest: /192.168.1.151:50010
2017-03-12 16:46:36,339 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8457408884696464670_1267 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:46:36,340 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:46:39,240 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-347861074215085824_1269 src: /192.168.1.151:51622 dest: /192.168.1.151:50010
2017-03-12 16:46:39,240 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-347861074215085824_1269 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:46:39,240 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:46:39,337 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8457408884696464670_1267 src: /192.168.1.152:34066 dest: /192.168.1.152:50010
2017-03-12 16:46:39,338 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8457408884696464670_1267 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:46:39,338 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:46:42,236 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8457408884696464670_1267 src: /192.168.1.152:34068 dest: /192.168.1.152:50010
2017-03-12 16:46:42,237 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8457408884696464670_1267 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:46:42,237 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:46:42,335 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2525080674269471354_1271 src: /192.168.1.151:51624 dest: /192.168.1.151:50010
2017-03-12 16:46:42,335 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_2525080674269471354_1271 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:46:42,336 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:46:45,338 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8457408884696464670_1267 src: /192.168.1.151:51625 dest: /192.168.1.151:50010
2017-03-12 16:46:45,338 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8457408884696464670_1267 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:46:45,338 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:46:45,461 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3595745564687844412_1268 src: /192.168.1.150:43757 dest: /192.168.1.150:50010
2017-03-12 16:46:45,462 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3595745564687844412_1268 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:46:45,462 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:46:48,237 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8457408884696464670_1267 src: /192.168.1.152:34069 dest: /192.168.1.152:50010
2017-03-12 16:46:48,237 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8457408884696464670_1267 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:46:48,237 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:46:51,467 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8457408884696464670_1267 src: /192.168.1.150:43760 dest: /192.168.1.150:50010
2017-03-12 16:46:51,468 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8457408884696464670_1267 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:46:51,468 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:46:54,472 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8457408884696464670_1267 src: /192.168.1.150:43762 dest: /192.168.1.150:50010
2017-03-12 16:46:54,473 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8457408884696464670_1267 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:46:54,473 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:46:57,246 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8457408884696464670_1267 src: /192.168.1.152:34070 dest: /192.168.1.152:50010
2017-03-12 16:46:57,247 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8457408884696464670_1267 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:46:57,247 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:47:00,342 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8457408884696464670_1267 src: /192.168.1.151:51626 dest: /192.168.1.151:50010
2017-03-12 16:47:00,343 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8457408884696464670_1267 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:47:00,343 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:47:03,252 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8457408884696464670_1267 src: /192.168.1.152:34071 dest: /192.168.1.152:50010
2017-03-12 16:47:03,252 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8457408884696464670_1267 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 16:47:03,253 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:47:06,483 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8457408884696464670_1267 src: /192.168.1.150:43770 dest: /192.168.1.150:50010
2017-03-12 16:47:06,487 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8457408884696464670_1267 src: /192.168.1.150:43770 dest: /192.168.1.150:50010 of size 91176
2017-03-12 16:47:15,338 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-8457408884696464670_1267 to /192.168.1.153
2017-03-12 16:47:16,247 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 16:47:36,618 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 16:47:48,753 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 16:48:18,574 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6772841782870442397_1275 src: /192.168.1.151:51659 dest: /192.168.1.151:50010
2017-03-12 16:48:18,576 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6772841782870442397_1275 src: /192.168.1.151:51659 dest: /192.168.1.151:50010 of size 24190
2017-03-12 16:48:27,274 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3076170128939143943_1278 src: /192.168.1.152:34117 dest: /192.168.1.152:50010
2017-03-12 16:48:27,276 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3076170128939143943_1278 src: /192.168.1.152:34117 dest: /192.168.1.152:50010 of size 13561
2017-03-12 16:48:27,575 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3082245345375863652_1277 src: /192.168.1.150:43816 dest: /192.168.1.150:50010
2017-03-12 16:48:27,576 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3082245345375863652_1277 src: /192.168.1.150:43816 dest: /192.168.1.150:50010 of size 2085
2017-03-12 16:48:30,313 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_3082245345375863652_1277 to 192.168.1.152:50010
2017-03-12 16:48:30,316 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_3082245345375863652_1277 to /192.168.1.152:50010
2017-03-12 16:48:30,594 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5032471574514571544_1276 src: /192.168.1.151:51660 dest: /192.168.1.151:50010
2017-03-12 16:48:30,596 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5032471574514571544_1276 src: /192.168.1.151:51660 dest: /192.168.1.151:50010 of size 91176
2017-03-12 16:48:36,590 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6028157015865501320_1280 src: /192.168.1.150:43824 dest: /192.168.1.150:50010
2017-03-12 16:48:36,593 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6028157015865501320_1280 src: /192.168.1.150:43824 dest: /192.168.1.150:50010 of size 13547
2017-03-12 16:48:39,316 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8457408884696464670_1267 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8457408884696464670
2017-03-12 16:49:16,789 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_3076170128939143943_1278 to /192.168.1.153
2017-03-12 16:49:16,812 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_5032471574514571544_1276 to /192.168.1.153
2017-03-12 16:49:17,649 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 16:49:28,430 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7033895350336583192_1001 to /192.168.1.153
2017-03-12 16:49:40,208 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-2414267635078914264_1001 to /192.168.1.153
2017-03-12 16:50:15,699 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4796914021661151607_1284 src: /192.168.1.150:43880 dest: /192.168.1.150:50010
2017-03-12 16:50:15,703 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4796914021661151607_1284 src: /192.168.1.150:43880 dest: /192.168.1.150:50010 of size 23777
2017-03-12 16:50:21,707 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7202218032651094222_1285 src: /192.168.1.150:43888 dest: /192.168.1.150:50010
2017-03-12 16:50:21,720 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7202218032651094222_1285 src: /192.168.1.150:43888 dest: /192.168.1.150:50010 of size 91176
2017-03-12 16:50:27,319 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5109113630534635941_1289 src: /192.168.1.151:51700 dest: /192.168.1.151:50010
2017-03-12 16:50:27,320 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5109113630534635941_1289 src: /192.168.1.151:51700 dest: /192.168.1.151:50010 of size 13547
2017-03-12 16:50:30,318 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2758254547122918995_1287 src: /192.168.1.152:34161 dest: /192.168.1.152:50010
2017-03-12 16:50:30,319 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2758254547122918995_1287 src: /192.168.1.152:34161 dest: /192.168.1.152:50010 of size 13561
2017-03-12 16:50:30,712 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_997748688962131068_1286 src: /192.168.1.150:43894 dest: /192.168.1.150:50010
2017-03-12 16:50:30,712 INFO org.apache.hadoop.dfs.DataNode: Received block blk_997748688962131068_1286 src: /192.168.1.150:43894 dest: /192.168.1.150:50010 of size 2085
2017-03-12 16:50:33,357 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_997748688962131068_1286 to 192.168.1.152:50010
2017-03-12 16:50:33,360 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_997748688962131068_1286 to /192.168.1.152:50010
2017-03-12 16:50:35,104 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 16:50:36,358 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3076170128939143943_1278 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3076170128939143943
2017-03-12 16:50:36,358 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3082245345375863652_1277 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3082245345375863652
2017-03-12 16:50:36,358 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5032471574514571544_1276 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5032471574514571544
2017-03-12 16:50:36,358 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6028157015865501320_1280 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6028157015865501320
2017-03-12 16:50:54,555 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 16:51:06,930 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2469247396937600182_1001 to /192.168.1.153
2017-03-12 16:51:36,462 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6307690217534619603_1294 src: /192.168.1.151:51736 dest: /192.168.1.151:50010
2017-03-12 16:51:36,464 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6307690217534619603_1294 src: /192.168.1.151:51736 dest: /192.168.1.151:50010 of size 91176
2017-03-12 16:51:39,349 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4241167505022961570_1298 src: /192.168.1.152:34194 dest: /192.168.1.152:50010
2017-03-12 16:51:39,353 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4241167505022961570_1298 src: /192.168.1.152:34194 dest: /192.168.1.152:50010 of size 13547
2017-03-12 16:51:42,458 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_477259401075482304_1295 src: /192.168.1.151:51738 dest: /192.168.1.151:50010
2017-03-12 16:51:42,459 INFO org.apache.hadoop.dfs.DataNode: Received block blk_477259401075482304_1295 src: /192.168.1.151:51738 dest: /192.168.1.151:50010 of size 2085
2017-03-12 16:51:42,799 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6014565433374588760_1296 src: /192.168.1.150:43940 dest: /192.168.1.150:50010
2017-03-12 16:51:42,801 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6014565433374588760_1296 src: /192.168.1.150:43940 dest: /192.168.1.150:50010 of size 13561
2017-03-12 16:51:42,802 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6014565433374588760_1296 src: /192.168.1.150:43941 dest: /192.168.1.150:50010
2017-03-12 16:51:42,803 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6014565433374588760_1296 received exception java.io.IOException: Block blk_6014565433374588760_1296 is valid, and cannot be written to.
2017-03-12 16:51:42,803 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_6014565433374588760_1296 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:51:48,386 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7202218032651094222_1285 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7202218032651094222
2017-03-12 16:51:48,386 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5109113630534635941_1289 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5109113630534635941
2017-03-12 16:51:48,386 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2758254547122918995_1287 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2758254547122918995
2017-03-12 16:51:48,387 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_997748688962131068_1286 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_997748688962131068
2017-03-12 16:52:19,685 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6014565433374588760_1296 to /192.168.1.153
2017-03-12 16:52:19,709 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-6307690217534619603_1294 to /192.168.1.153
2017-03-12 16:52:28,178 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 16:52:31,332 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 16:52:43,113 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 16:53:24,921 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8875831968590155889_1305 src: /192.168.1.152:34240 dest: /192.168.1.152:50010
2017-03-12 16:53:24,922 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8875831968590155889_1305 src: /192.168.1.152:34240 dest: /192.168.1.152:50010 of size 13561
2017-03-12 16:53:27,427 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8875831968590155889_1305 to 192.168.1.151:50010
2017-03-12 16:53:27,435 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-8875831968590155889_1305 to /192.168.1.151:50010
2017-03-12 16:53:27,915 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1017080529311710706_1304 src: /192.168.1.150:43999 dest: /192.168.1.150:50010
2017-03-12 16:53:27,916 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1017080529311710706_1304 src: /192.168.1.150:43999 dest: /192.168.1.150:50010 of size 2085
2017-03-12 16:53:27,918 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1017080529311710706_1304 src: /192.168.1.150:43998 dest: /192.168.1.150:50010
2017-03-12 16:53:27,918 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-1017080529311710706_1304 received exception java.io.IOException: Block blk_-1017080529311710706_1304 is valid, and cannot be written to.
2017-03-12 16:53:27,918 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-1017080529311710706_1304 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:53:33,678 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 16:53:36,502 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7076941753914429738_1307 src: /192.168.1.152:34244 dest: /192.168.1.152:50010
2017-03-12 16:53:36,503 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7076941753914429738_1307 src: /192.168.1.152:34244 dest: /192.168.1.152:50010 of size 13547
2017-03-12 16:53:37,710 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_1397883976202270799_1001 to /192.168.1.153
2017-03-12 16:53:39,499 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_571876563905506526_1303 src: /192.168.1.151:51787 dest: /192.168.1.151:50010
2017-03-12 16:53:39,507 INFO org.apache.hadoop.dfs.DataNode: Received block blk_571876563905506526_1303 src: /192.168.1.151:51787 dest: /192.168.1.151:50010 of size 91176
2017-03-12 16:53:42,433 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6307690217534619603_1294 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6307690217534619603
2017-03-12 16:53:42,433 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4241167505022961570_1298 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4241167505022961570
2017-03-12 16:53:42,434 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_477259401075482304_1295 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_477259401075482304
2017-03-12 16:53:42,434 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6014565433374588760_1296 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6014565433374588760
2017-03-12 16:53:57,248 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 16:54:09,266 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2469247396937600182_1001 to /192.168.1.153
2017-03-12 16:54:33,461 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8875831968590155889_1305 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8875831968590155889
2017-03-12 16:54:33,461 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1017080529311710706_1304 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1017080529311710706
2017-03-12 16:54:33,461 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_571876563905506526_1303 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_571876563905506526
2017-03-12 16:54:33,462 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7076941753914429738_1307 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7076941753914429738
2017-03-12 16:54:36,998 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7986052243781437872_1313 src: /192.168.1.151:51815 dest: /192.168.1.151:50010
2017-03-12 16:54:37,000 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7986052243781437872_1313 src: /192.168.1.151:51815 dest: /192.168.1.151:50010 of size 2085
2017-03-12 16:54:42,522 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7409552694244719150_1316 src: /192.168.1.151:51817 dest: /192.168.1.151:50010
2017-03-12 16:54:42,523 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7409552694244719150_1316 src: /192.168.1.151:51817 dest: /192.168.1.151:50010 of size 13547
2017-03-12 16:54:43,004 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5685332948813032133_1314 src: /192.168.1.150:44046 dest: /192.168.1.150:50010
2017-03-12 16:54:43,007 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5685332948813032133_1314 src: /192.168.1.150:44046 dest: /192.168.1.150:50010 of size 13561
2017-03-12 16:54:45,466 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-5685332948813032133_1314 to 192.168.1.151:50010
2017-03-12 16:54:45,469 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-5685332948813032133_1314 to /192.168.1.151:50010
2017-03-12 16:54:46,020 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1692087288872245598_1312 src: /192.168.1.150:44047 dest: /192.168.1.150:50010
2017-03-12 16:54:46,020 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1692087288872245598_1312 src: /192.168.1.150:44048 dest: /192.168.1.150:50010
2017-03-12 16:54:46,020 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-1692087288872245598_1312 received exception java.io.IOException: Block blk_-1692087288872245598_1312 has already been started (though not completed), and thus cannot be created.
2017-03-12 16:54:46,021 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-1692087288872245598_1312 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 16:54:46,022 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1692087288872245598_1312 src: /192.168.1.150:44047 dest: /192.168.1.150:50010 of size 91176
2017-03-12 16:55:21,444 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-5685332948813032133_1314 to /192.168.1.153
2017-03-12 16:55:21,467 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-1692087288872245598_1312 to /192.168.1.153
2017-03-12 16:55:22,274 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-9165782496790827072_1001 to /192.168.1.153
2017-03-12 16:55:35,108 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4893380956617376253_1001 to /192.168.1.153
2017-03-12 16:55:46,883 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4733740065594982407_1001 to /192.168.1.153
2017-03-12 16:56:22,125 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4024049859630329977_1320 src: /192.168.1.152:34309 dest: /192.168.1.152:50010
2017-03-12 16:56:22,126 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4024049859630329977_1320 src: /192.168.1.152:34309 dest: /192.168.1.152:50010 of size 23777
2017-03-12 16:56:27,507 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7986052243781437872_1313 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7986052243781437872
2017-03-12 16:56:27,508 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7409552694244719150_1316 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7409552694244719150
2017-03-12 16:56:27,508 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5685332948813032133_1314 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5685332948813032133
2017-03-12 16:56:27,509 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1692087288872245598_1312 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1692087288872245598
2017-03-12 17:00:54,312 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 17:01:00,285 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 17:01:00,476 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 17:01:00,478 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 17:01:00,480 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 17:01:00,549 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 17:01:00,608 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 17:01:00,609 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 17:01:00,609 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 17:01:00,839 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@14a8af0
2017-03-12 17:01:00,880 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 17:01:00,885 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 17:01:00,885 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 17:01:00,891 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 17:01:00,912 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 17:01:00,920 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 17:01:00,922 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 17:01:00,922 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 17:01:00,922 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 17:01:00,922 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 17:01:00,922 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 17:01:00,925 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 17:01:00,926 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 17:01:00,934 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 17:01:00,965 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_5227992124916519344_1248
2017-03-12 17:01:03,934 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 12 blocks got processed in 8 msecs
2017-03-12 17:01:39,952 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4796914021661151607_1284 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4796914021661151607
2017-03-12 17:01:39,952 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4024049859630329977_1320 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4024049859630329977
2017-03-12 17:01:39,953 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5227992124916519344_1248 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5227992124916519344
2017-03-12 17:01:39,953 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6772841782870442397_1275 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6772841782870442397
2017-03-12 17:03:25,015 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9165782496790827072_1001 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9165782496790827072
2017-03-12 17:03:25,028 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7701193938081024283_1001 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7701193938081024283
2017-03-12 17:03:25,041 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4893380956617376253_1001 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4893380956617376253
2017-03-12 17:03:25,053 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4733740065594982407_1001 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4733740065594982407
2017-03-12 17:03:25,065 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2414267635078914264_1001 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2414267635078914264
2017-03-12 17:03:25,077 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1397883976202270799_1001 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1397883976202270799
2017-03-12 17:03:25,089 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2469247396937600182_1001 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2469247396937600182
2017-03-12 17:03:25,100 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7033895350336583192_1001 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7033895350336583192
2017-03-12 17:03:58,011 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 0 blocks got processed in 2 msecs
2017-03-12 17:04:03,840 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5846398419858363523_1321 src: /192.168.1.150:44099 dest: /192.168.1.150:50010
2017-03-12 17:04:05,440 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5846398419858363523_1321 src: /192.168.1.150:44099 dest: /192.168.1.150:50010 of size 67108864
2017-03-12 17:04:06,837 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1579000667075903073_1321 src: /192.168.1.150:44100 dest: /192.168.1.150:50010
2017-03-12 17:04:06,839 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5846398419858363523_1321 src: /192.168.1.150:44101 dest: /192.168.1.150:50010
2017-03-12 17:04:06,847 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-5846398419858363523_1321 received exception java.io.IOException: Block blk_-5846398419858363523_1321 is valid, and cannot be written to.
2017-03-12 17:04:06,849 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-5846398419858363523_1321 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:04:08,269 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1579000667075903073_1321 src: /192.168.1.150:44100 dest: /192.168.1.150:50010 of size 67108864
2017-03-12 17:04:09,844 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1579000667075903073_1321 src: /192.168.1.152:34312 dest: /192.168.1.152:50010
2017-03-12 17:04:09,845 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-1579000667075903073_1321 received exception java.io.IOException: Block blk_-1579000667075903073_1321 is valid, and cannot be written to.
2017-03-12 17:04:09,845 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-1579000667075903073_1321 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:04:13,015 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1579000667075903073_1321 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 17:04:13,024 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Failed to transfer blk_-1579000667075903073_1321 to 192.168.1.152:50010 got java.net.SocketException: Original Exception : java.io.IOException: Broken pipe
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:420)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:552)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:199)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1873)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataNode$DataTransfer.run(DataNode.java:2855)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Broken pipe
	... 8 more

2017-03-12 17:04:18,848 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_779910154838770954_1321 src: /192.168.1.150:44106 dest: /192.168.1.150:50010
2017-03-12 17:04:19,075 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_775897233445821566_1321 src: /192.168.1.151:51862 dest: /192.168.1.151:50010
2017-03-12 17:04:20,480 INFO org.apache.hadoop.dfs.DataNode: Received block blk_779910154838770954_1321 src: /192.168.1.150:44106 dest: /192.168.1.150:50010 of size 67108864
2017-03-12 17:04:21,229 INFO org.apache.hadoop.dfs.DataNode: Received block blk_775897233445821566_1321 src: /192.168.1.151:51862 dest: /192.168.1.151:50010 of size 67108864
2017-03-12 17:04:22,063 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_779910154838770954_1321 src: /192.168.1.152:34314 dest: /192.168.1.152:50010
2017-03-12 17:04:22,063 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_779910154838770954_1321 received exception java.io.IOException: Block blk_779910154838770954_1321 is valid, and cannot be written to.
2017-03-12 17:04:22,064 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_779910154838770954_1321 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:04:24,849 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1737711120405196135_1321 src: /192.168.1.150:44110 dest: /192.168.1.150:50010
2017-03-12 17:04:25,789 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1737711120405196135_1321 src: /192.168.1.150:44110 dest: /192.168.1.150:50010 of size 67108864
2017-03-12 17:04:30,858 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7574575955316690399_1321 src: /192.168.1.150:44112 dest: /192.168.1.150:50010
2017-03-12 17:04:31,088 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5140029763330577131_1321 src: /192.168.1.152:34315 dest: /192.168.1.152:50010
2017-03-12 17:04:32,253 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7574575955316690399_1321 src: /192.168.1.150:44112 dest: /192.168.1.150:50010 of size 67108864
2017-03-12 17:04:33,124 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5140029763330577131_1321 src: /192.168.1.152:34315 dest: /192.168.1.152:50010 of size 67108864
2017-03-12 17:04:33,865 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7574575955316690399_1321 src: /192.168.1.150:44114 dest: /192.168.1.150:50010
2017-03-12 17:04:33,866 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7574575955316690399_1321 received exception java.io.IOException: Block blk_7574575955316690399_1321 is valid, and cannot be written to.
2017-03-12 17:04:33,866 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7574575955316690399_1321 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:04:36,863 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9131080977903790873_1321 src: /192.168.1.150:44116 dest: /192.168.1.150:50010
2017-03-12 17:04:38,055 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9131080977903790873_1321 src: /192.168.1.150:44116 dest: /192.168.1.150:50010 of size 67103998
2017-03-12 17:04:40,023 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_9131080977903790873_1321 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 17:04:41,032 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_9131080977903790873_1321 to /192.168.1.152:50010
2017-03-12 17:05:28,058 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5846398419858363523_1321 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5846398419858363523
2017-03-12 17:05:28,070 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1579000667075903073_1321 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1579000667075903073
2017-03-12 17:05:28,083 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_775897233445821566_1321 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_775897233445821566
2017-03-12 17:05:28,095 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_779910154838770954_1321 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_779910154838770954
2017-03-12 17:05:28,107 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1737711120405196135_1321 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1737711120405196135
2017-03-12 17:05:28,118 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5140029763330577131_1321 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5140029763330577131
2017-03-12 17:05:28,130 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7574575955316690399_1321 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7574575955316690399
2017-03-12 17:05:28,142 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9131080977903790873_1321 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9131080977903790873
2017-03-12 17:06:01,126 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6991344143272659216_1322 src: /192.168.1.151:51866 dest: /192.168.1.151:50010
2017-03-12 17:06:03,497 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6991344143272659216_1322 of size 67108864 from /192.168.1.151
2017-03-12 17:06:03,498 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_6991344143272659216_1322 terminating
2017-03-12 17:06:03,517 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6953776988626442917_1322 src: /192.168.1.150:44118 dest: /192.168.1.150:50010
2017-03-12 17:06:05,975 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6953776988626442917_1322 of size 67108864 from /192.168.1.150
2017-03-12 17:06:05,975 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_6953776988626442917_1322 terminating
2017-03-12 17:06:05,988 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1023911497645659605_1322 src: /192.168.1.149:37037 dest: /192.168.1.149:50010
2017-03-12 17:06:08,333 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1023911497645659605_1322 of size 67103998 from /192.168.1.149
2017-03-12 17:06:08,334 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 3 for block blk_-1023911497645659605_1322 terminating
2017-03-12 17:06:12,987 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_190219405230331044_1322 src: /192.168.1.151:51869 dest: /192.168.1.151:50010
2017-03-12 17:06:14,420 INFO org.apache.hadoop.dfs.DataNode: Received block blk_190219405230331044_1322 src: /192.168.1.151:51869 dest: /192.168.1.151:50010 of size 67108864
2017-03-12 17:06:15,972 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2597118070594322412_1322 src: /192.168.1.150:44120 dest: /192.168.1.150:50010
2017-03-12 17:06:16,934 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2597118070594322412_1322 src: /192.168.1.150:44120 dest: /192.168.1.150:50010 of size 67108864
2017-03-12 17:06:19,056 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_2597118070594322412_1322 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 17:06:21,578 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_2597118070594322412_1322 to /192.168.1.152:50010
2017-03-12 17:06:24,985 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8323398072542634072_1322 src: /192.168.1.150:44125 dest: /192.168.1.150:50010
2017-03-12 17:06:25,055 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5635846406904869563_1322 src: /192.168.1.152:34322 dest: /192.168.1.152:50010
2017-03-12 17:06:26,484 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5635846406904869563_1322 src: /192.168.1.152:34322 dest: /192.168.1.152:50010 of size 67108864
2017-03-12 17:06:27,294 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8323398072542634072_1322 src: /192.168.1.150:44125 dest: /192.168.1.150:50010 of size 67108864
2017-03-12 17:06:27,997 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7925426400168019642_1322 src: /192.168.1.150:44126 dest: /192.168.1.150:50010
2017-03-12 17:06:27,997 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8323398072542634072_1322 src: /192.168.1.150:44127 dest: /192.168.1.150:50010
2017-03-12 17:06:27,999 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8323398072542634072_1322 received exception java.io.IOException: Block blk_8323398072542634072_1322 is valid, and cannot be written to.
2017-03-12 17:06:27,999 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8323398072542634072_1322 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:06:28,101 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7925426400168019642_1322 src: /192.168.1.152:34323 dest: /192.168.1.152:50010
2017-03-12 17:06:28,102 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7925426400168019642_1322 received exception java.io.IOException: Block blk_7925426400168019642_1322 has already been started (though not completed), and thus cannot be created.
2017-03-12 17:06:28,102 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7925426400168019642_1322 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:06:28,903 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7925426400168019642_1322 src: /192.168.1.150:44126 dest: /192.168.1.150:50010 of size 67108864
2017-03-12 17:08:16,095 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8353831394120071426_1325 src: /192.168.1.152:34334 dest: /192.168.1.152:50010
2017-03-12 17:08:16,099 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8353831394120071426_1325 src: /192.168.1.152:34334 dest: /192.168.1.152:50010 of size 13560
2017-03-12 17:08:16,108 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3864548397600400282_1327 src: /192.168.1.150:44137 dest: /192.168.1.150:50010
2017-03-12 17:08:16,109 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3864548397600400282_1327 src: /192.168.1.150:44137 dest: /192.168.1.150:50010 of size 13546
2017-03-12 17:08:19,101 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-3864548397600400282_1327 to 192.168.1.151:50010
2017-03-12 17:08:19,106 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-3864548397600400282_1327 to /192.168.1.151:50010
2017-03-12 17:08:21,109 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_190219405230331044_1322 to /192.168.1.153
2017-03-12 17:08:22,117 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5852049118049620737_1324 src: /192.168.1.150:44140 dest: /192.168.1.150:50010
2017-03-12 17:08:22,118 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5852049118049620737_1324 src: /192.168.1.150:44140 dest: /192.168.1.150:50010 of size 2085
2017-03-12 17:08:22,138 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1816339325743863335_1323 src: /192.168.1.151:51880 dest: /192.168.1.151:50010
2017-03-12 17:08:22,144 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1816339325743863335_1323 src: /192.168.1.151:51880 dest: /192.168.1.151:50010 of size 91176
2017-03-12 17:08:33,114 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7925426400168019642_1322 to /192.168.1.153
2017-03-12 17:08:44,457 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6991344143272659216_1322 to /192.168.1.153
2017-03-12 17:08:56,934 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-1023911497645659605_1322 to /192.168.1.153
2017-03-12 17:09:11,056 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-1023911497645659605_1322
2017-03-12 17:09:25,125 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8623340220897493447_1333 src: /192.168.1.152:34370 dest: /192.168.1.152:50010
2017-03-12 17:09:25,125 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8623340220897493447_1333 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:25,126 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:25,190 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2856568433006583030_1336 src: /192.168.1.150:44185 dest: /192.168.1.150:50010
2017-03-12 17:09:25,191 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2856568433006583030_1336 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:25,191 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:28,132 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-998653210526658789_1332 src: /192.168.1.152:34371 dest: /192.168.1.152:50010
2017-03-12 17:09:28,133 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-998653210526658789_1332 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:28,133 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:28,196 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2856568433006583030_1336 src: /192.168.1.151:51915 dest: /192.168.1.151:50010
2017-03-12 17:09:28,196 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2856568433006583030_1336 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:28,196 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:31,140 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-998653210526658789_1332 src: /192.168.1.152:34372 dest: /192.168.1.152:50010
2017-03-12 17:09:31,141 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-998653210526658789_1332 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:31,143 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:31,200 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8048100959070590671_1334 src: /192.168.1.150:44187 dest: /192.168.1.150:50010
2017-03-12 17:09:31,200 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2856568433006583030_1336 src: /192.168.1.150:44188 dest: /192.168.1.150:50010
2017-03-12 17:09:31,200 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8048100959070590671_1334 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:31,201 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2856568433006583030_1336 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:31,201 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:31,202 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:34,179 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2856568433006583030_1336 src: /192.168.1.152:34373 dest: /192.168.1.152:50010
2017-03-12 17:09:34,180 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2856568433006583030_1336 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:34,181 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:34,201 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8048100959070590671_1334 src: /192.168.1.151:51917 dest: /192.168.1.151:50010
2017-03-12 17:09:34,201 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8048100959070590671_1334 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:34,202 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:37,206 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8048100959070590671_1334 src: /192.168.1.152:34374 dest: /192.168.1.152:50010
2017-03-12 17:09:37,206 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8048100959070590671_1334 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:37,207 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:40,134 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-998653210526658789_1332 src: /192.168.1.151:51918 dest: /192.168.1.151:50010
2017-03-12 17:09:40,135 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-998653210526658789_1332 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:40,140 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:43,212 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-998653210526658789_1332 src: /192.168.1.150:44195 dest: /192.168.1.150:50010
2017-03-12 17:09:43,212 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-998653210526658789_1332 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:43,212 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:46,180 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-998653210526658789_1332 src: /192.168.1.151:51919 dest: /192.168.1.151:50010
2017-03-12 17:09:46,180 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-998653210526658789_1332 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:46,181 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:49,137 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-998653210526658789_1332 src: /192.168.1.152:34376 dest: /192.168.1.152:50010
2017-03-12 17:09:49,137 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-998653210526658789_1332 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:49,137 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:52,180 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-998653210526658789_1332 src: /192.168.1.151:51920 dest: /192.168.1.151:50010
2017-03-12 17:09:52,181 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-998653210526658789_1332 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:52,181 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:55,224 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-998653210526658789_1332 src: /192.168.1.150:44203 dest: /192.168.1.150:50010
2017-03-12 17:09:55,224 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-998653210526658789_1332 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:55,224 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:09:58,183 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-998653210526658789_1332 src: /192.168.1.151:51921 dest: /192.168.1.151:50010
2017-03-12 17:09:58,183 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-998653210526658789_1332 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:09:58,184 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:10:01,150 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-998653210526658789_1332 src: /192.168.1.152:34377 dest: /192.168.1.152:50010
2017-03-12 17:10:01,155 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-998653210526658789_1332 src: /192.168.1.152:34377 dest: /192.168.1.152:50010 of size 91176
2017-03-12 17:10:04,143 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8353831394120071426_1325 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8353831394120071426
2017-03-12 17:10:04,145 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3864548397600400282_1327 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3864548397600400282
2017-03-12 17:10:04,145 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1816339325743863335_1323 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1816339325743863335
2017-03-12 17:10:04,145 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5852049118049620737_1324 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5852049118049620737
2017-03-12 17:10:07,722 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-998653210526658789_1332 to /192.168.1.153
2017-03-12 17:10:08,576 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_5635846406904869563_1322 to /192.168.1.153
2017-03-12 17:10:15,655 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_6991344143272659216_1322
2017-03-12 17:10:21,315 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7925426400168019642_1322 to /192.168.1.153
2017-03-12 17:10:40,749 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6953776988626442917_1322 to /192.168.1.153
2017-03-12 17:11:07,304 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4328958666823930789_1340 src: /192.168.1.150:44238 dest: /192.168.1.150:50010
2017-03-12 17:11:07,308 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4328958666823930789_1340 src: /192.168.1.150:44238 dest: /192.168.1.150:50010 of size 23777
2017-03-12 17:11:13,310 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-118862996158075038_1342 src: /192.168.1.150:44243 dest: /192.168.1.150:50010
2017-03-12 17:11:13,312 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-118862996158075038_1342 src: /192.168.1.150:44243 dest: /192.168.1.150:50010 of size 2085
2017-03-12 17:11:16,173 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-118862996158075038_1342 to 192.168.1.151:50010
2017-03-12 17:11:16,176 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-118862996158075038_1342 to /192.168.1.151:50010
2017-03-12 17:11:16,314 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2693295636938269336_1343 src: /192.168.1.150:44249 dest: /192.168.1.150:50010
2017-03-12 17:11:16,316 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2693295636938269336_1343 src: /192.168.1.150:44249 dest: /192.168.1.150:50010 of size 13560
2017-03-12 17:11:19,323 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4773507099149800452_1341 src: /192.168.1.152:34424 dest: /192.168.1.152:50010
2017-03-12 17:11:19,324 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4773507099149800452_1341 src: /192.168.1.152:34424 dest: /192.168.1.152:50010 of size 91176
2017-03-12 17:11:22,320 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8189509593587321069_1345 src: /192.168.1.150:44252 dest: /192.168.1.150:50010
2017-03-12 17:11:22,321 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8189509593587321069_1345 src: /192.168.1.150:44252 dest: /192.168.1.150:50010 of size 13546
2017-03-12 17:11:28,180 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-998653210526658789_1332 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-998653210526658789
2017-03-12 17:11:33,687 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7925426400168019642_1322 to /192.168.1.153
2017-03-12 17:11:45,356 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_8323398072542634072_1322 to /192.168.1.153
2017-03-12 17:11:48,686 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6953776988626442917_1322 to /192.168.1.153
2017-03-12 17:12:37,421 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7640434145665807068_1351 src: /192.168.1.151:52020 dest: /192.168.1.151:50010
2017-03-12 17:12:37,422 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7640434145665807068_1351 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:37,422 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:40,247 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7640434145665807068_1351 src: /192.168.1.152:34467 dest: /192.168.1.152:50010
2017-03-12 17:12:40,247 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7640434145665807068_1351 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:40,248 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:40,408 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3774233039220515996_1352 src: /192.168.1.150:44306 dest: /192.168.1.150:50010
2017-03-12 17:12:40,408 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3774233039220515996_1352 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:40,409 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3774233039220515996_1352 src: /192.168.1.150:44307 dest: /192.168.1.150:50010
2017-03-12 17:12:40,409 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:40,410 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3774233039220515996_1352 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:40,410 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:43,213 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7640434145665807068_1351 src: /192.168.1.152:34468 dest: /192.168.1.152:50010
2017-03-12 17:12:43,214 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7640434145665807068_1351 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:43,214 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:43,414 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3774233039220515996_1352 src: /192.168.1.151:52024 dest: /192.168.1.151:50010
2017-03-12 17:12:43,415 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3774233039220515996_1352 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:43,415 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:46,246 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7640434145665807068_1351 src: /192.168.1.151:52025 dest: /192.168.1.151:50010
2017-03-12 17:12:46,247 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7640434145665807068_1351 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:46,247 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:49,216 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7640434145665807068_1351 src: /192.168.1.152:34469 dest: /192.168.1.152:50010
2017-03-12 17:12:49,216 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7640434145665807068_1351 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:49,216 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:49,246 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3774233039220515996_1352 src: /192.168.1.151:52027 dest: /192.168.1.151:50010
2017-03-12 17:12:49,246 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3774233039220515996_1352 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:49,247 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:49,422 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6558765831836030631_1355 src: /192.168.1.151:52028 dest: /192.168.1.151:50010
2017-03-12 17:12:49,422 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6558765831836030631_1355 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:49,422 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:52,217 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7640434145665807068_1351 src: /192.168.1.152:34471 dest: /192.168.1.152:50010
2017-03-12 17:12:52,218 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7640434145665807068_1351 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:52,218 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:52,427 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-961973499043522708_1353 src: /192.168.1.150:44314 dest: /192.168.1.150:50010
2017-03-12 17:12:52,427 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6558765831836030631_1355 src: /192.168.1.150:44315 dest: /192.168.1.150:50010
2017-03-12 17:12:52,427 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-961973499043522708_1353 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:52,428 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6558765831836030631_1355 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:52,428 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:52,428 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:55,214 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7640434145665807068_1351 src: /192.168.1.152:34475 dest: /192.168.1.152:50010
2017-03-12 17:12:55,216 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7640434145665807068_1351 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:55,216 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:55,249 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6558765831836030631_1355 src: /192.168.1.151:52033 dest: /192.168.1.151:50010
2017-03-12 17:12:55,250 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6558765831836030631_1355 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:55,250 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:12:58,255 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7640434145665807068_1351 src: /192.168.1.151:52034 dest: /192.168.1.151:50010
2017-03-12 17:12:58,255 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7640434145665807068_1351 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:12:58,255 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:13:01,446 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7640434145665807068_1351 src: /192.168.1.150:44323 dest: /192.168.1.150:50010
2017-03-12 17:13:01,448 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7640434145665807068_1351 src: /192.168.1.150:44323 dest: /192.168.1.150:50010 of size 91176
2017-03-12 17:13:02,114 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_6953776988626442917_1322
2017-03-12 17:13:04,220 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-118862996158075038_1342 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-118862996158075038
2017-03-12 17:13:04,221 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2693295636938269336_1343 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2693295636938269336
2017-03-12 17:13:04,221 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4773507099149800452_1341 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4773507099149800452
2017-03-12 17:13:04,221 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8189509593587321069_1345 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8189509593587321069
2017-03-12 17:13:09,735 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7640434145665807068_1351 to /192.168.1.153
2017-03-12 17:13:19,299 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_8323398072542634072_1322 to /192.168.1.153
2017-03-12 17:13:31,712 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6953776988626442917_1322 to /192.168.1.153
2017-03-12 17:14:06,713 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_5635846406904869563_1322
2017-03-12 17:14:16,244 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7640434145665807068_1351 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7640434145665807068
2017-03-12 17:14:19,525 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5543353535614142156_1362 src: /192.168.1.150:44370 dest: /192.168.1.150:50010
2017-03-12 17:14:19,527 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5543353535614142156_1362 src: /192.168.1.150:44370 dest: /192.168.1.150:50010 of size 2085
2017-03-12 17:14:25,288 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2789132407903227190_1361 src: /192.168.1.151:52078 dest: /192.168.1.151:50010
2017-03-12 17:14:25,290 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2789132407903227190_1361 src: /192.168.1.151:52078 dest: /192.168.1.151:50010 of size 91176
2017-03-12 17:14:25,535 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2668930375805868852_1365 src: /192.168.1.151:52079 dest: /192.168.1.151:50010
2017-03-12 17:14:25,536 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2668930375805868852_1365 src: /192.168.1.151:52079 dest: /192.168.1.151:50010 of size 13546
2017-03-12 17:14:31,538 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5921389236535378710_1363 src: /192.168.1.150:44380 dest: /192.168.1.150:50010
2017-03-12 17:14:31,541 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5921389236535378710_1363 src: /192.168.1.150:44380 dest: /192.168.1.150:50010 of size 13560
2017-03-12 17:14:41,533 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2597118070594322412_1322 to /192.168.1.153
2017-03-12 17:14:45,638 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7925426400168019642_1322 to /192.168.1.153
2017-03-12 17:14:56,337 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6991344143272659216_1322 to /192.168.1.153
2017-03-12 17:15:28,611 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3300570134526529103_1369 src: /192.168.1.152:34550 dest: /192.168.1.152:50010
2017-03-12 17:15:28,613 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3300570134526529103_1369 src: /192.168.1.152:34550 dest: /192.168.1.152:50010 of size 23376
2017-03-12 17:15:34,617 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_27786906479562244_1371 src: /192.168.1.151:52112 dest: /192.168.1.151:50010
2017-03-12 17:15:34,618 INFO org.apache.hadoop.dfs.DataNode: Received block blk_27786906479562244_1371 src: /192.168.1.151:52112 dest: /192.168.1.151:50010 of size 2085
2017-03-12 17:15:37,276 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_27786906479562244_1371 to 192.168.1.152:50010
2017-03-12 17:15:37,279 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_27786906479562244_1371 to /192.168.1.152:50010
2017-03-12 17:15:40,315 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2927508199139558209_1370 src: /192.168.1.151:52113 dest: /192.168.1.151:50010
2017-03-12 17:15:40,320 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2927508199139558209_1370 src: /192.168.1.151:52113 dest: /192.168.1.151:50010 of size 91176
2017-03-12 17:15:40,617 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3748860581634727528_1374 src: /192.168.1.150:44425 dest: /192.168.1.150:50010
2017-03-12 17:15:40,620 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3748860581634727528_1374 src: /192.168.1.150:44425 dest: /192.168.1.150:50010 of size 13546
2017-03-12 17:15:43,620 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9154868226959299132_1372 src: /192.168.1.150:44427 dest: /192.168.1.150:50010
2017-03-12 17:15:43,621 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9154868226959299132_1372 src: /192.168.1.150:44427 dest: /192.168.1.150:50010 of size 13560
2017-03-12 17:15:49,280 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5543353535614142156_1362 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5543353535614142156
2017-03-12 17:15:49,281 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2789132407903227190_1361 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2789132407903227190
2017-03-12 17:15:49,281 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2668930375805868852_1365 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2668930375805868852
2017-03-12 17:15:49,281 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5921389236535378710_1363 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5921389236535378710
2017-03-12 17:16:12,343 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_9154868226959299132_1372 to /192.168.1.153
2017-03-12 17:16:12,572 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2927508199139558209_1370 to /192.168.1.153
2017-03-12 17:16:21,972 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_5635846406904869563_1322 to /192.168.1.153
2017-03-12 17:16:26,279 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7925426400168019642_1322 to /192.168.1.153
2017-03-12 17:16:38,037 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6991344143272659216_1322 to /192.168.1.153
2017-03-12 17:17:25,745 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8829792206296410524_1379 src: /192.168.1.152:34601 dest: /192.168.1.152:50010
2017-03-12 17:17:25,757 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8829792206296410524_1379 src: /192.168.1.152:34601 dest: /192.168.1.152:50010 of size 91176
2017-03-12 17:17:28,314 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8829792206296410524_1379 to 192.168.1.151:50010
2017-03-12 17:17:28,319 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-8829792206296410524_1379 to /192.168.1.151:50010
2017-03-12 17:17:28,745 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6662527040853629422_1380 src: /192.168.1.152:34604 dest: /192.168.1.152:50010
2017-03-12 17:17:28,745 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6662527040853629422_1380 src: /192.168.1.152:34604 dest: /192.168.1.152:50010 of size 2085
2017-03-12 17:17:34,751 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_139255897200002729_1381 src: /192.168.1.150:44487 dest: /192.168.1.150:50010
2017-03-12 17:17:34,753 INFO org.apache.hadoop.dfs.DataNode: Received block blk_139255897200002729_1381 src: /192.168.1.150:44487 dest: /192.168.1.150:50010 of size 13560
2017-03-12 17:17:37,760 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9061176956072417311_1383 src: /192.168.1.150:44488 dest: /192.168.1.150:50010
2017-03-12 17:17:37,760 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9061176956072417311_1383 src: /192.168.1.150:44489 dest: /192.168.1.150:50010
2017-03-12 17:17:37,761 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_9061176956072417311_1383 received exception java.io.IOException: Block blk_9061176956072417311_1383 has already been started (though not completed), and thus cannot be created.
2017-03-12 17:17:37,761 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_9061176956072417311_1383 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:17:37,761 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9061176956072417311_1383 src: /192.168.1.150:44488 dest: /192.168.1.150:50010 of size 13546
2017-03-12 17:17:40,318 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_9061176956072417311_1383 to 192.168.1.151:50010
2017-03-12 17:17:40,321 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_9061176956072417311_1383 to /192.168.1.151:50010
2017-03-12 17:17:43,320 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_27786906479562244_1371 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_27786906479562244
2017-03-12 17:17:43,320 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2927508199139558209_1370 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2927508199139558209
2017-03-12 17:17:43,320 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3748860581634727528_1374 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3748860581634727528
2017-03-12 17:17:43,321 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9154868226959299132_1372 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9154868226959299132
2017-03-12 17:18:14,153 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_139255897200002729_1381 to /192.168.1.153
2017-03-12 17:18:14,176 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-8829792206296410524_1379 to /192.168.1.153
2017-03-12 17:18:22,967 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-1023911497645659605_1322 to /192.168.1.153
2017-03-12 17:19:04,856 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-336718865058515496_1391 src: /192.168.1.152:34640 dest: /192.168.1.152:50010
2017-03-12 17:19:04,857 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-336718865058515496_1391 src: /192.168.1.152:34640 dest: /192.168.1.152:50010 of size 13560
2017-03-12 17:19:07,351 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-336718865058515496_1391 to 192.168.1.151:50010
2017-03-12 17:19:07,356 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-336718865058515496_1391 to /192.168.1.151:50010
2017-03-12 17:19:07,859 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_319442905033516251_1393 src: /192.168.1.150:44545 dest: /192.168.1.150:50010
2017-03-12 17:19:07,860 INFO org.apache.hadoop.dfs.DataNode: Received block blk_319442905033516251_1393 src: /192.168.1.150:44545 dest: /192.168.1.150:50010 of size 13546
2017-03-12 17:19:10,352 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_319442905033516251_1393 to 192.168.1.151:50010
2017-03-12 17:19:10,355 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_319442905033516251_1393 to /192.168.1.151:50010
2017-03-12 17:19:10,863 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2745568033995841951_1390 src: /192.168.1.152:34641 dest: /192.168.1.152:50010
2017-03-12 17:19:10,864 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2745568033995841951_1390 src: /192.168.1.152:34641 dest: /192.168.1.152:50010 of size 2085
2017-03-12 17:19:16,353 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5128343246509111318_1389 src: /192.168.1.152:34643 dest: /192.168.1.152:50010
2017-03-12 17:19:16,358 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5128343246509111318_1389 src: /192.168.1.152:34643 dest: /192.168.1.152:50010 of size 91176
2017-03-12 17:19:19,355 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8829792206296410524_1379 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8829792206296410524
2017-03-12 17:19:19,355 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_139255897200002729_1381 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_139255897200002729
2017-03-12 17:19:19,355 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6662527040853629422_1380 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6662527040853629422
2017-03-12 17:19:19,355 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9061176956072417311_1383 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9061176956072417311
2017-03-12 17:19:26,832 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_5635846406904869563_1322 to /192.168.1.153
2017-03-12 17:19:39,144 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7925426400168019642_1322 to /192.168.1.153
2017-03-12 17:19:50,936 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6991344143272659216_1322 to /192.168.1.153
2017-03-12 17:20:03,020 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-1023911497645659605_1322 to /192.168.1.153
2017-03-12 17:20:31,379 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-336718865058515496_1391 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-336718865058515496
2017-03-12 17:20:31,380 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_319442905033516251_1393 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_319442905033516251
2017-03-12 17:20:31,380 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2745568033995841951_1390 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2745568033995841951
2017-03-12 17:20:31,380 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5128343246509111318_1389 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5128343246509111318
2017-03-12 17:20:34,957 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7801355125145637307_1398 src: /192.168.1.150:44596 dest: /192.168.1.150:50010
2017-03-12 17:20:34,957 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7801355125145637307_1398 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:34,957 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:20:37,964 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7801355125145637307_1398 src: /192.168.1.150:44598 dest: /192.168.1.150:50010
2017-03-12 17:20:37,965 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7801355125145637307_1398 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:37,965 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:20:40,421 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4416949303704714292_1400 src: /192.168.1.151:52253 dest: /192.168.1.151:50010
2017-03-12 17:20:40,422 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-4416949303704714292_1400 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:40,422 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:20:43,395 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7801355125145637307_1398 src: /192.168.1.152:34693 dest: /192.168.1.152:50010
2017-03-12 17:20:43,396 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7801355125145637307_1398 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:43,396 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:20:43,965 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4997999015900695161_1399 src: /192.168.1.150:44601 dest: /192.168.1.150:50010
2017-03-12 17:20:43,966 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4997999015900695161_1399 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:43,966 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:20:46,430 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7801355125145637307_1398 src: /192.168.1.151:52255 dest: /192.168.1.151:50010
2017-03-12 17:20:46,430 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7801355125145637307_1398 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:46,430 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:20:46,970 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7385216182114997699_1402 src: /192.168.1.150:44607 dest: /192.168.1.150:50010
2017-03-12 17:20:46,970 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7385216182114997699_1402 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:46,970 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:20:49,393 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7801355125145637307_1398 src: /192.168.1.152:34698 dest: /192.168.1.152:50010
2017-03-12 17:20:49,394 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7801355125145637307_1398 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:49,394 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:20:49,424 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4997999015900695161_1399 src: /192.168.1.151:52260 dest: /192.168.1.151:50010
2017-03-12 17:20:49,424 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4997999015900695161_1399 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:49,424 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:20:49,973 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4997999015900695161_1399 src: /192.168.1.150:44608 dest: /192.168.1.150:50010
2017-03-12 17:20:49,973 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4997999015900695161_1399 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:49,974 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:20:52,399 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7801355125145637307_1398 src: /192.168.1.152:34699 dest: /192.168.1.152:50010
2017-03-12 17:20:52,399 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7801355125145637307_1398 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:52,399 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:20:52,978 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7385216182114997699_1402 src: /192.168.1.150:44610 dest: /192.168.1.150:50010
2017-03-12 17:20:52,978 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7385216182114997699_1402 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:52,978 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:20:55,431 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7801355125145637307_1398 src: /192.168.1.151:52265 dest: /192.168.1.151:50010
2017-03-12 17:20:55,431 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7801355125145637307_1398 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:55,432 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:20:58,400 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7801355125145637307_1398 src: /192.168.1.152:34704 dest: /192.168.1.152:50010
2017-03-12 17:20:58,400 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7801355125145637307_1398 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-03-12 17:20:58,400 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:21:01,396 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7801355125145637307_1398 src: /192.168.1.152:34710 dest: /192.168.1.152:50010
2017-03-12 17:21:01,404 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7801355125145637307_1398 src: /192.168.1.152:34710 dest: /192.168.1.152:50010 of size 91176
2017-03-12 17:21:21,028 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-7801355125145637307_1398 to /192.168.1.153
2017-03-12 17:21:30,249 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6953776988626442917_1322 to /192.168.1.153
2017-03-12 17:21:36,933 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6953776988626442917_1322 to /192.168.1.153
2017-03-12 17:22:22,421 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7801355125145637307_1398 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7801355125145637307
2017-03-12 17:22:26,089 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7229230791135722338_1409 src: /192.168.1.152:34743 dest: /192.168.1.152:50010
2017-03-12 17:22:26,090 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7229230791135722338_1409 src: /192.168.1.152:34743 dest: /192.168.1.152:50010 of size 2085
2017-03-12 17:22:31,425 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4453042558203563347_1412 src: /192.168.1.152:34754 dest: /192.168.1.152:50010
2017-03-12 17:22:31,428 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4453042558203563347_1412 src: /192.168.1.152:34754 dest: /192.168.1.152:50010 of size 13546
2017-03-12 17:22:32,097 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2821451300930578467_1408 src: /192.168.1.151:52296 dest: /192.168.1.151:50010
2017-03-12 17:22:32,100 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2821451300930578467_1408 src: /192.168.1.151:52296 dest: /192.168.1.151:50010 of size 91176
2017-03-12 17:22:38,099 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8698544987529364608_1410 src: /192.168.1.152:34755 dest: /192.168.1.152:50010
2017-03-12 17:22:38,100 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8698544987529364608_1410 src: /192.168.1.152:34755 dest: /192.168.1.152:50010 of size 13560
2017-03-12 17:22:38,557 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_190219405230331044_1322 to /192.168.1.153
2017-03-12 17:22:51,078 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7925426400168019642_1322 to /192.168.1.153
2017-03-12 17:23:01,902 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6991344143272659216_1322 to /192.168.1.153
2017-03-12 17:23:14,069 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-1023911497645659605_1322 to /192.168.1.153
2017-03-12 17:23:40,453 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7229230791135722338_1409 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7229230791135722338
2017-03-12 17:23:40,453 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4453042558203563347_1412 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4453042558203563347
2017-03-12 17:23:40,454 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2821451300930578467_1408 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2821451300930578467
2017-03-12 17:23:40,454 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8698544987529364608_1410 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8698544987529364608
2017-03-12 17:25:12,434 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_2597118070594322412_1322
2017-03-12 17:31:19,189 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 17:31:25,135 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 17:31:25,333 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 17:31:25,335 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 17:31:25,337 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 17:31:25,395 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 17:31:25,443 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 17:31:25,445 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 17:31:25,445 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 17:31:25,658 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-03-12 17:31:25,697 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 17:31:25,699 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 17:31:25,700 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 17:31:25,704 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 17:31:25,722 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 17:31:25,727 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 17:31:25,727 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 17:31:25,729 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 17:31:25,729 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 17:31:25,729 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 17:31:25,729 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 17:31:25,732 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 17:31:25,732 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 17:31:25,739 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 17:31:28,738 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 10 blocks got processed in 6 msecs
2017-03-12 17:32:04,756 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3300570134526529103_1369 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3300570134526529103
2017-03-12 17:32:04,757 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4328958666823930789_1340 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4328958666823930789
2017-03-12 17:32:28,343 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_8323398072542634072_1322
2017-03-12 17:34:04,833 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3610755291559011639_1419 src: /192.168.1.152:34794 dest: /192.168.1.152:50010
2017-03-12 17:34:04,849 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3610755291559011639_1419 src: /192.168.1.152:34794 dest: /192.168.1.152:50010 of size 13561
2017-03-12 17:34:07,812 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3738838926907846512_1418 src: /192.168.1.150:44719 dest: /192.168.1.150:50010
2017-03-12 17:34:07,814 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3738838926907846512_1418 src: /192.168.1.150:44719 dest: /192.168.1.150:50010 of size 2085
2017-03-12 17:34:10,807 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5143799351748743802_1421 src: /192.168.1.150:44720 dest: /192.168.1.150:50010
2017-03-12 17:34:10,809 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5143799351748743802_1421 src: /192.168.1.150:44720 dest: /192.168.1.150:50010 of size 13547
2017-03-12 17:34:13,813 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8010218450358307586_1417 src: /192.168.1.150:44721 dest: /192.168.1.150:50010
2017-03-12 17:34:13,815 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8010218450358307586_1417 src: /192.168.1.150:44721 dest: /192.168.1.150:50010 of size 91176
2017-03-12 17:37:35,053 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1343615270656689825_1422 src: /192.168.1.151:52337 dest: /192.168.1.151:50010
2017-03-12 17:37:35,762 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1343615270656689825_1422 src: /192.168.1.151:52337 dest: /192.168.1.151:50010 of size 31981189
2017-03-12 17:38:14,089 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-190521777790620688_1423 src: /192.168.1.150:44829 dest: /192.168.1.150:50010
2017-03-12 17:38:14,577 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-190521777790620688_1423 src: /192.168.1.150:44829 dest: /192.168.1.150:50010 of size 31976695
2017-03-12 17:39:32,175 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7639092063869339481_1427 src: /192.168.1.150:44849 dest: /192.168.1.150:50010
2017-03-12 17:39:32,178 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7639092063869339481_1427 src: /192.168.1.150:44849 dest: /192.168.1.150:50010 of size 2085
2017-03-12 17:39:34,935 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7639092063869339481_1427 to 192.168.1.152:50010
2017-03-12 17:39:34,942 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-7639092063869339481_1427 to /192.168.1.152:50010
2017-03-12 17:39:37,869 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5647071848633535160_1430 src: /192.168.1.152:34797 dest: /192.168.1.152:50010
2017-03-12 17:39:37,873 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5647071848633535160_1430 src: /192.168.1.152:34797 dest: /192.168.1.152:50010 of size 13547
2017-03-12 17:39:38,184 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5960531312898380881_1426 src: /192.168.1.151:52340 dest: /192.168.1.151:50010
2017-03-12 17:39:38,189 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5960531312898380881_1426 src: /192.168.1.151:52340 dest: /192.168.1.151:50010 of size 91176
2017-03-12 17:39:40,937 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_5960531312898380881_1426 to 192.168.1.152:50010
2017-03-12 17:39:40,944 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_5960531312898380881_1426 to /192.168.1.152:50010
2017-03-12 17:39:41,184 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9023341507115263768_1428 src: /192.168.1.150:44855 dest: /192.168.1.150:50010
2017-03-12 17:39:41,185 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9023341507115263768_1428 src: /192.168.1.150:44855 dest: /192.168.1.150:50010 of size 13561
2017-03-12 17:39:46,940 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3610755291559011639_1419 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3610755291559011639
2017-03-12 17:39:46,950 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1343615270656689825_1422 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1343615270656689825
2017-03-12 17:39:46,957 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-190521777790620688_1423 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-190521777790620688
2017-03-12 17:39:46,957 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3738838926907846512_1418 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3738838926907846512
2017-03-12 17:39:46,957 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5143799351748743802_1421 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5143799351748743802
2017-03-12 17:39:46,957 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8010218450358307586_1417 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8010218450358307586
2017-03-12 17:42:31,096 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_190219405230331044_1322
2017-03-12 17:42:56,411 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_126810271039512527_1431 src: /192.168.1.150:44952 dest: /192.168.1.150:50010
2017-03-12 17:42:57,179 INFO org.apache.hadoop.dfs.DataNode: Received block blk_126810271039512527_1431 src: /192.168.1.150:44952 dest: /192.168.1.150:50010 of size 31981189
2017-03-12 17:43:32,457 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-319391993588455395_1432 src: /192.168.1.150:44963 dest: /192.168.1.150:50010
2017-03-12 17:43:32,952 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-319391993588455395_1432 src: /192.168.1.150:44963 dest: /192.168.1.150:50010 of size 31976695
2017-03-12 17:44:11,495 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1096291341667763431_1433 src: /192.168.1.150:44973 dest: /192.168.1.150:50010
2017-03-12 17:44:11,929 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1096291341667763431_1433 src: /192.168.1.150:44973 dest: /192.168.1.150:50010 of size 31980463
2017-03-12 17:44:24,150 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_9023341507115263768_1428
2017-03-12 17:44:47,541 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6195806170796557356_1434 src: /192.168.1.152:34799 dest: /192.168.1.152:50010
2017-03-12 17:44:47,542 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6195806170796557356_1434 src: /192.168.1.152:34799 dest: /192.168.1.152:50010 of size 23376
2017-03-12 17:44:53,559 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8921862918631694892_1435 src: /192.168.1.151:52341 dest: /192.168.1.151:50010
2017-03-12 17:44:53,563 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8921862918631694892_1435 src: /192.168.1.151:52341 dest: /192.168.1.151:50010 of size 91176
2017-03-12 17:44:58,979 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8670251992254937863_1437 src: /192.168.1.152:34800 dest: /192.168.1.152:50010
2017-03-12 17:44:58,981 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8670251992254937863_1437 src: /192.168.1.152:34800 dest: /192.168.1.152:50010 of size 13561
2017-03-12 17:44:59,549 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5021396651306713644_1439 src: /192.168.1.150:44990 dest: /192.168.1.150:50010
2017-03-12 17:44:59,553 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5021396651306713644_1439 src: /192.168.1.150:44990 dest: /192.168.1.150:50010 of size 13547
2017-03-12 17:45:05,166 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6635006587271398801_1436 src: /192.168.1.151:52344 dest: /192.168.1.151:50010
2017-03-12 17:45:05,169 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6635006587271398801_1436 src: /192.168.1.151:52344 dest: /192.168.1.151:50010 of size 2085
2017-03-12 17:45:08,047 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7639092063869339481_1427 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7639092063869339481
2017-03-12 17:45:08,047 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5647071848633535160_1430 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5647071848633535160
2017-03-12 17:45:08,058 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1096291341667763431_1433 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1096291341667763431
2017-03-12 17:45:08,064 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-319391993588455395_1432 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-319391993588455395
2017-03-12 17:45:08,070 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_126810271039512527_1431 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_126810271039512527
2017-03-12 17:45:08,070 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5960531312898380881_1426 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5960531312898380881
2017-03-12 17:45:08,070 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9023341507115263768_1428 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9023341507115263768
2017-03-12 17:48:17,775 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5218849250083069413_1440 src: /192.168.1.150:45087 dest: /192.168.1.150:50010
2017-03-12 17:48:18,303 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5218849250083069413_1440 src: /192.168.1.150:45087 dest: /192.168.1.150:50010 of size 31981189
2017-03-12 17:48:20,780 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5218849250083069413_1440 src: /192.168.1.150:45090 dest: /192.168.1.150:50010
2017-03-12 17:48:20,781 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5218849250083069413_1440 received exception java.io.IOException: Block blk_5218849250083069413_1440 is valid, and cannot be written to.
2017-03-12 17:48:20,783 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_5218849250083069413_1440 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:50:14,150 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8921862918631694892_1435 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8921862918631694892
2017-03-12 17:50:14,151 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8670251992254937863_1437 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8670251992254937863
2017-03-12 17:50:14,151 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5021396651306713644_1439 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5021396651306713644
2017-03-12 17:50:14,158 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5218849250083069413_1440 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5218849250083069413
2017-03-12 17:50:14,159 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6635006587271398801_1436 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6635006587271398801
2017-03-12 17:53:26,227 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 17:53:31,995 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 17:53:32,191 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 17:53:32,193 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 17:53:32,194 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 17:53:32,256 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 17:53:32,306 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 17:53:32,307 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 17:53:32,307 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 17:53:32,530 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@12e8099
2017-03-12 17:53:32,567 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 17:53:32,569 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 17:53:32,569 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 17:53:32,575 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 17:53:32,592 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 17:53:32,596 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 17:53:32,597 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 17:53:32,598 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 17:53:32,599 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 17:53:32,599 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 17:53:32,599 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 17:53:32,601 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 17:53:32,602 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 17:53:32,609 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 17:53:35,609 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 7 msecs
2017-03-12 17:54:11,627 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6195806170796557356_1434 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6195806170796557356
2017-03-12 17:54:26,297 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 17:55:23,687 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 17:55:23,889 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 17:55:23,892 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 17:55:23,893 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 17:55:23,963 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 17:55:24,022 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 17:55:24,023 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 17:55:24,023 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 17:55:24,253 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@12e8099
2017-03-12 17:55:24,288 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 17:55:24,290 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 17:55:24,290 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@cd1a1f
2017-03-12 17:55:24,295 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 17:55:24,312 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 17:55:24,316 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 17:55:24,317 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 17:55:24,331 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 17:55:24,332 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 17:55:24,332 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 17:55:24,332 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 17:55:24,336 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 17:55:24,336 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 17:55:24,345 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 17:55:27,342 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-03-12 17:56:26,898 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_7925426400168019642_1322
2017-03-12 17:56:57,250 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8583740378030345477_1446 src: /192.168.1.151:52350 dest: /192.168.1.151:50010
2017-03-12 17:56:57,266 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8583740378030345477_1446 src: /192.168.1.151:52350 dest: /192.168.1.151:50010 of size 13559
2017-03-12 17:56:58,486 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-8583740378030345477_1446 to /192.168.1.153
2017-03-12 17:56:59,500 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_190219405230331044_1322 to /192.168.1.153
2017-03-12 17:57:00,227 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5217500022149124785_1444 src: /192.168.1.150:45126 dest: /192.168.1.150:50010
2017-03-12 17:57:00,231 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5217500022149124785_1444 src: /192.168.1.150:45126 dest: /192.168.1.150:50010 of size 91176
2017-03-12 17:57:03,218 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6533824262816083767_1448 src: /192.168.1.150:45127 dest: /192.168.1.150:50010
2017-03-12 17:57:03,221 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6533824262816083767_1448 src: /192.168.1.150:45127 dest: /192.168.1.150:50010 of size 13545
2017-03-12 17:57:03,378 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-5217500022149124785_1444 to 192.168.1.152:50010
2017-03-12 17:57:03,384 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-5217500022149124785_1444 to /192.168.1.152:50010
2017-03-12 17:57:06,223 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8939510781798274331_1445 src: /192.168.1.150:45129 dest: /192.168.1.150:50010
2017-03-12 17:57:06,224 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8939510781798274331_1445 src: /192.168.1.150:45129 dest: /192.168.1.150:50010 of size 1045
2017-03-12 17:57:17,150 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_5635846406904869563_1322 to /192.168.1.153
2017-03-12 17:57:23,258 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6991344143272659216_1322 to /192.168.1.153
2017-03-12 17:57:39,215 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6953776988626442917_1322 to /192.168.1.153
2017-03-12 17:57:44,057 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_8323398072542634072_1322 to /192.168.1.153
2017-03-12 17:58:00,072 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6991344143272659216_1322 to /192.168.1.153
2017-03-12 17:58:04,853 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7925426400168019642_1322 to /192.168.1.153
2017-03-12 17:58:21,203 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_8323398072542634072_1322 to /192.168.1.153
2017-03-12 17:58:30,427 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8583740378030345477_1446 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8583740378030345477
2017-03-12 17:58:30,428 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5217500022149124785_1444 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5217500022149124785
2017-03-12 17:58:30,428 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6533824262816083767_1448 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6533824262816083767
2017-03-12 17:58:30,428 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8939510781798274331_1445 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8939510781798274331
2017-03-12 17:58:30,721 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_5635846406904869563_1322 to /192.168.1.153
2017-03-12 17:58:33,321 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3788892995941694757_1453 src: /192.168.1.151:52391 dest: /192.168.1.151:50010
2017-03-12 17:58:33,322 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3788892995941694757_1453 src: /192.168.1.151:52391 dest: /192.168.1.151:50010 of size 13545
2017-03-12 17:58:36,328 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3218568153723620629_1449 src: /192.168.1.150:45165 dest: /192.168.1.150:50010
2017-03-12 17:58:36,329 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3218568153723620629_1449 src: /192.168.1.150:45165 dest: /192.168.1.150:50010 of size 91176
2017-03-12 17:58:39,430 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_3218568153723620629_1449 to 192.168.1.152:50010
2017-03-12 17:58:39,437 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_3218568153723620629_1449 to /192.168.1.152:50010
2017-03-12 17:58:42,327 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3645844314607823310_1450 src: /192.168.1.152:34838 dest: /192.168.1.152:50010
2017-03-12 17:58:42,328 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3645844314607823310_1450 src: /192.168.1.152:34838 dest: /192.168.1.152:50010 of size 1045
2017-03-12 17:58:42,332 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7028025949438617111_1451 src: /192.168.1.150:45167 dest: /192.168.1.150:50010
2017-03-12 17:58:42,333 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7028025949438617111_1451 src: /192.168.1.150:45167 dest: /192.168.1.150:50010 of size 13559
2017-03-12 17:58:42,335 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7028025949438617111_1451 src: /192.168.1.150:45168 dest: /192.168.1.150:50010
2017-03-12 17:58:42,336 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7028025949438617111_1451 received exception java.io.IOException: Block blk_7028025949438617111_1451 is valid, and cannot be written to.
2017-03-12 17:58:42,337 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7028025949438617111_1451 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 17:58:45,432 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7028025949438617111_1451 to 192.168.1.151:50010, 192.168.1.152:50010
2017-03-12 17:58:45,435 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_7028025949438617111_1451 to /192.168.1.151:50010
2017-03-12 17:58:46,664 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2597118070594322412_1322 to /192.168.1.153
2017-03-12 17:58:51,483 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7925426400168019642_1322 to /192.168.1.153
2017-03-12 17:59:07,167 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_8323398072542634072_1322 to /192.168.1.153
2017-03-12 17:59:11,376 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_8323398072542634072_1322 to /192.168.1.153
2017-03-12 17:59:26,369 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6991344143272659216_1322 to /192.168.1.153
2017-03-12 17:59:31,203 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6953776988626442917_1322 to /192.168.1.153
2017-03-12 18:00:00,945 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_5635846406904869563_1322 to /192.168.1.153
2017-03-12 18:00:03,380 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6947548195006547338_1455 src: /192.168.1.151:52424 dest: /192.168.1.151:50010
2017-03-12 18:00:03,382 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6947548195006547338_1455 src: /192.168.1.151:52424 dest: /192.168.1.151:50010 of size 1045
2017-03-12 18:00:03,424 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6225540910075272792_1456 src: /192.168.1.150:45202 dest: /192.168.1.150:50010
2017-03-12 18:00:03,425 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6225540910075272792_1456 src: /192.168.1.150:45202 dest: /192.168.1.150:50010 of size 13559
2017-03-12 18:00:06,432 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3578749477758466902_1454 src: /192.168.1.150:45203 dest: /192.168.1.150:50010
2017-03-12 18:00:06,439 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3578749477758466902_1454 src: /192.168.1.150:45203 dest: /192.168.1.150:50010 of size 91176
2017-03-12 18:00:06,459 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6225540910075272792_1456 to 192.168.1.152:50010
2017-03-12 18:00:06,462 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-6225540910075272792_1456 to /192.168.1.152:50010
2017-03-12 18:00:09,460 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_3578749477758466902_1454 to 192.168.1.151:50010
2017-03-12 18:00:09,468 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_3578749477758466902_1454 to /192.168.1.151:50010
2017-03-12 18:00:12,435 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5927088077310948172_1458 src: /192.168.1.151:52425 dest: /192.168.1.151:50010
2017-03-12 18:00:12,436 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5927088077310948172_1458 src: /192.168.1.151:52425 dest: /192.168.1.151:50010 of size 13545
2017-03-12 18:00:15,468 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3788892995941694757_1453 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3788892995941694757
2017-03-12 18:00:15,468 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3218568153723620629_1449 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3218568153723620629
2017-03-12 18:00:15,468 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3645844314607823310_1450 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3645844314607823310
2017-03-12 18:00:15,469 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7028025949438617111_1451 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7028025949438617111
2017-03-12 18:00:16,827 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2597118070594322412_1322 to /192.168.1.153
2017-03-12 18:00:21,668 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7925426400168019642_1322 to /192.168.1.153
2017-03-12 18:00:37,364 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_8323398072542634072_1322 to /192.168.1.153
2017-03-12 18:01:01,309 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_8323398072542634072_1322 to /192.168.1.153
2017-03-12 18:01:16,967 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6991344143272659216_1322 to /192.168.1.153
2017-03-12 18:01:27,490 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6947548195006547338_1455 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6947548195006547338
2017-03-12 18:01:27,491 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6225540910075272792_1456 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6225540910075272792
2017-03-12 18:01:27,491 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3578749477758466902_1454 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3578749477758466902
2017-03-12 18:01:27,492 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5927088077310948172_1458 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5927088077310948172
2017-03-12 18:06:37,888 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 18:06:44,796 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 18:06:45,009 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 18:06:45,011 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 18:06:45,013 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 18:06:45,089 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 18:06:45,147 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 18:06:45,148 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 18:06:45,148 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 18:06:45,394 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-03-12 18:06:45,432 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 18:06:45,435 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 18:06:45,435 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 18:06:45,440 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 18:06:45,458 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 18:06:45,463 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 18:06:45,464 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 18:06:45,465 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 18:06:45,466 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 18:06:45,466 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 18:06:45,466 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 18:06:45,470 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 18:06:45,471 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 18:06:45,479 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 18:06:48,475 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 4 msecs
2017-03-12 18:07:45,687 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7925426400168019642_1322 to /192.168.1.153
2017-03-12 18:07:48,281 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1298436770877946074_1463 src: /192.168.1.150:45242 dest: /192.168.1.150:50010
2017-03-12 18:07:48,298 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1298436770877946074_1463 src: /192.168.1.150:45242 dest: /192.168.1.150:50010 of size 13548
2017-03-12 18:07:48,477 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3238398476776940841_1459 src: /192.168.1.152:34893 dest: /192.168.1.152:50010
2017-03-12 18:07:48,483 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3238398476776940841_1459 src: /192.168.1.152:34893 dest: /192.168.1.152:50010 of size 91176
2017-03-12 18:07:51,282 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_762662251699650808_1460 src: /192.168.1.152:34894 dest: /192.168.1.152:50010
2017-03-12 18:07:51,283 INFO org.apache.hadoop.dfs.DataNode: Received block blk_762662251699650808_1460 src: /192.168.1.152:34894 dest: /192.168.1.152:50010 of size 525
2017-03-12 18:07:57,418 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3331250812652448928_1461 src: /192.168.1.152:34896 dest: /192.168.1.152:50010
2017-03-12 18:07:57,419 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3331250812652448928_1461 src: /192.168.1.152:34896 dest: /192.168.1.152:50010 of size 13562
2017-03-12 18:08:01,458 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_8323398072542634072_1322 to /192.168.1.153
2017-03-12 18:08:16,583 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_6991344143272659216_1322 to /192.168.1.153
2017-03-12 18:08:25,682 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_5635846406904869563_1322 to /192.168.1.153
2017-03-12 18:08:41,556 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_2597118070594322412_1322 to /192.168.1.153
2017-03-12 18:08:55,277 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_7925426400168019642_1322 to /192.168.1.153
2017-03-12 18:10:48,487 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_280831814250959012_1467 src: /192.168.1.150:45275 dest: /192.168.1.150:50010
2017-03-12 18:10:49,323 INFO org.apache.hadoop.dfs.DataNode: Received block blk_280831814250959012_1467 src: /192.168.1.150:45275 dest: /192.168.1.150:50010 of size 31964396
2017-03-12 18:10:54,494 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8886944774303618011_1472 src: /192.168.1.151:52471 dest: /192.168.1.151:50010
2017-03-12 18:10:54,496 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8886944774303618011_1472 src: /192.168.1.151:52471 dest: /192.168.1.151:50010 of size 13548
2017-03-12 18:11:00,480 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3499482280166785252_1470 src: /192.168.1.151:52479 dest: /192.168.1.151:50010
2017-03-12 18:11:00,481 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3499482280166785252_1470 src: /192.168.1.151:52479 dest: /192.168.1.151:50010 of size 13562
2017-03-12 18:11:00,501 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7109356453021239783_1468 src: /192.168.1.150:45288 dest: /192.168.1.150:50010
2017-03-12 18:11:00,503 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7109356453021239783_1468 src: /192.168.1.150:45288 dest: /192.168.1.150:50010 of size 91176
2017-03-12 18:11:03,497 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7434270357665646634_1469 src: /192.168.1.150:45289 dest: /192.168.1.150:50010
2017-03-12 18:11:03,498 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7434270357665646634_1469 src: /192.168.1.150:45289 dest: /192.168.1.150:50010 of size 525
2017-03-12 18:11:09,568 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3238398476776940841_1459 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3238398476776940841
2017-03-12 18:11:09,568 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1298436770877946074_1463 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1298436770877946074
2017-03-12 18:11:09,568 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_762662251699650808_1460 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_762662251699650808
2017-03-12 18:11:09,569 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3331250812652448928_1461 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3331250812652448928
2017-03-12 18:13:54,705 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6238742407220897006_1474 src: /192.168.1.150:45322 dest: /192.168.1.150:50010
2017-03-12 18:13:55,210 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6238742407220897006_1474 src: /192.168.1.150:45322 dest: /192.168.1.150:50010 of size 31981189
2017-03-12 18:13:57,701 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2136580233900617910_1473 src: /192.168.1.150:45323 dest: /192.168.1.150:50010
2017-03-12 18:13:58,152 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2136580233900617910_1473 src: /192.168.1.150:45323 dest: /192.168.1.150:50010 of size 31976695
2017-03-12 18:14:06,707 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8319363394483129378_1475 src: /192.168.1.150:45325 dest: /192.168.1.150:50010
2017-03-12 18:14:07,222 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8319363394483129378_1475 src: /192.168.1.150:45325 dest: /192.168.1.150:50010 of size 31980463
2017-03-12 18:14:09,715 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2757431290151750651_1476 src: /192.168.1.150:45330 dest: /192.168.1.150:50010
2017-03-12 18:14:10,279 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2757431290151750651_1476 src: /192.168.1.150:45330 dest: /192.168.1.150:50010 of size 31964396
2017-03-12 18:14:15,633 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8886944774303618011_1472 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8886944774303618011
2017-03-12 18:14:15,633 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3499482280166785252_1470 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3499482280166785252
2017-03-12 18:14:15,644 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2136580233900617910_1473 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2136580233900617910
2017-03-12 18:14:15,651 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6238742407220897006_1474 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6238742407220897006
2017-03-12 18:14:15,652 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7109356453021239783_1468 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7109356453021239783
2017-03-12 18:14:15,652 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7434270357665646634_1469 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7434270357665646634
2017-03-12 18:14:15,659 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8319363394483129378_1475 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8319363394483129378
2017-03-12 18:14:18,723 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3268388112272852889_1481 src: /192.168.1.151:52506 dest: /192.168.1.151:50010
2017-03-12 18:14:18,738 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3268388112272852889_1481 src: /192.168.1.151:52506 dest: /192.168.1.151:50010 of size 13548
2017-03-12 18:14:21,725 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2966005300372430128_1478 src: /192.168.1.150:45339 dest: /192.168.1.150:50010
2017-03-12 18:14:21,725 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2966005300372430128_1478 src: /192.168.1.150:45340 dest: /192.168.1.150:50010
2017-03-12 18:14:21,726 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2966005300372430128_1478 received exception java.io.IOException: Block blk_-2966005300372430128_1478 has already been started (though not completed), and thus cannot be created.
2017-03-12 18:14:21,726 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2966005300372430128_1478 src: /192.168.1.150:45339 dest: /192.168.1.150:50010 of size 525
2017-03-12 18:14:21,728 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-2966005300372430128_1478 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 18:14:24,635 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2966005300372430128_1478 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 18:14:24,640 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-2966005300372430128_1478 to /192.168.1.152:50010
2017-03-12 18:14:24,732 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1851903803714663448_1479 src: /192.168.1.152:34914 dest: /192.168.1.152:50010
2017-03-12 18:14:24,733 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1851903803714663448_1479 src: /192.168.1.152:34914 dest: /192.168.1.152:50010 of size 13562
2017-03-12 18:14:27,636 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1851903803714663448_1479 to 192.168.1.151:50010
2017-03-12 18:14:27,640 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-1851903803714663448_1479 to /192.168.1.151:50010
2017-03-12 18:14:27,734 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5292123728193645047_1477 src: /192.168.1.150:45343 dest: /192.168.1.150:50010
2017-03-12 18:14:27,736 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5292123728193645047_1477 src: /192.168.1.150:45343 dest: /192.168.1.150:50010 of size 91176
2017-03-12 18:14:30,638 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_5292123728193645047_1477 to 192.168.1.151:50010
2017-03-12 18:14:30,646 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_5292123728193645047_1477 to /192.168.1.151:50010
2017-03-12 18:17:42,716 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3268388112272852889_1481 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3268388112272852889
2017-03-12 18:17:42,716 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2966005300372430128_1478 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2966005300372430128
2017-03-12 18:17:42,716 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1851903803714663448_1479 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1851903803714663448
2017-03-12 18:17:42,717 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5292123728193645047_1477 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5292123728193645047
2017-03-12 18:23:42,864 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1023911497645659605_1322 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1023911497645659605
2017-03-12 18:23:42,877 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_190219405230331044_1322 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_190219405230331044
2017-03-12 18:23:42,890 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2597118070594322412_1322 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2597118070594322412
2017-03-12 18:23:42,902 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5635846406904869563_1322 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5635846406904869563
2017-03-12 18:23:42,915 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6953776988626442917_1322 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6953776988626442917
2017-03-12 18:23:42,928 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6991344143272659216_1322 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6991344143272659216
2017-03-12 18:23:42,939 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7925426400168019642_1322 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7925426400168019642
2017-03-12 18:23:42,951 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8323398072542634072_1322 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8323398072542634072
2017-03-12 18:24:09,418 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 18:24:15,431 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 18:24:15,651 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 18:24:15,653 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 18:24:15,655 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 18:24:15,727 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 18:24:15,785 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 18:24:15,786 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 18:24:15,786 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 18:24:16,031 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-03-12 18:24:16,063 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 18:24:16,066 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 18:24:16,066 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 18:24:16,071 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 18:24:16,086 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 18:24:16,091 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 18:24:16,091 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 18:24:16,093 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 18:24:16,093 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 18:24:16,094 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 18:24:16,094 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 18:24:16,096 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 18:24:16,097 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 18:24:16,104 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 18:24:19,103 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 2 blocks got processed in 6 msecs
2017-03-12 18:24:22,121 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_280831814250959012_1467 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_280831814250959012
2017-03-12 18:24:22,122 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2757431290151750651_1476 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2757431290151750651
2017-03-12 18:24:44,867 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_2757431290151750651_1476
2017-03-12 18:25:20,569 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3530359500607374331_1486 src: /192.168.1.151:52527 dest: /192.168.1.151:50010
2017-03-12 18:25:23,065 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3530359500607374331_1486 of size 67108864 from /192.168.1.151
2017-03-12 18:25:23,066 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_3530359500607374331_1486 terminating
2017-03-12 18:25:23,080 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5074910699574139327_1486 src: /192.168.1.151:52528 dest: /192.168.1.151:50010
2017-03-12 18:25:25,913 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5074910699574139327_1486 of size 67108864 from /192.168.1.151
2017-03-12 18:25:25,914 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_-5074910699574139327_1486 terminating
2017-03-12 18:25:25,936 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5226239773727901148_1486 src: /192.168.1.152:34917 dest: /192.168.1.152:50010
2017-03-12 18:25:28,176 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5226239773727901148_1486 of size 67108864 from /192.168.1.152
2017-03-12 18:25:28,177 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-5226239773727901148_1486 terminating
2017-03-12 18:25:28,202 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_631597496783626488_1486 src: /192.168.1.152:34918 dest: /192.168.1.152:50010
2017-03-12 18:25:30,567 INFO org.apache.hadoop.dfs.DataNode: Received block blk_631597496783626488_1486 of size 67108864 from /192.168.1.152
2017-03-12 18:25:30,568 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_631597496783626488_1486 terminating
2017-03-12 18:25:30,582 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3313291319270606547_1486 src: /192.168.1.150:45392 dest: /192.168.1.150:50010
2017-03-12 18:25:32,888 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3313291319270606547_1486 of size 67108864 from /192.168.1.150
2017-03-12 18:25:32,889 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_-3313291319270606547_1486 terminating
2017-03-12 18:25:32,903 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-563747461064131208_1486 src: /192.168.1.150:45393 dest: /192.168.1.150:50010
2017-03-12 18:25:35,558 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-563747461064131208_1486 of size 67108864 from /192.168.1.150
2017-03-12 18:25:35,558 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-563747461064131208_1486 terminating
2017-03-12 18:25:35,578 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6529693818616013818_1486 src: /192.168.1.152:34920 dest: /192.168.1.152:50010
2017-03-12 18:25:38,096 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6529693818616013818_1486 of size 67108864 from /192.168.1.152
2017-03-12 18:25:38,096 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_-6529693818616013818_1486 terminating
2017-03-12 18:25:38,112 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3615259698331015578_1486 src: /192.168.1.151:52533 dest: /192.168.1.151:50010
2017-03-12 18:25:40,574 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3615259698331015578_1486 of size 67103998 from /192.168.1.151
2017-03-12 18:25:40,575 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-3615259698331015578_1486 terminating
2017-03-12 18:26:16,003 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3420416406836683703_1487 src: /192.168.1.152:34922 dest: /192.168.1.152:50010
2017-03-12 18:26:16,025 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3420416406836683703_1487 of size 91176 from /192.168.1.152
2017-03-12 18:26:16,026 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-3420416406836683703_1487 terminating
2017-03-12 18:26:16,131 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4127709487482046893_1488 src: /192.168.1.151:52535 dest: /192.168.1.151:50010
2017-03-12 18:26:16,139 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4127709487482046893_1488 of size 525 from /192.168.1.151
2017-03-12 18:26:16,139 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-4127709487482046893_1488 terminating
2017-03-12 18:26:20,518 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-3420416406836683703_1487 to /192.168.1.153
2017-03-12 18:26:21,444 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-5074910699574139327_1486 to /192.168.1.153
2017-03-12 18:26:22,209 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2673761543101611216_1491 src: /192.168.1.152:34934 dest: /192.168.1.152:50010
2017-03-12 18:26:22,210 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2673761543101611216_1491 src: /192.168.1.152:34934 dest: /192.168.1.152:50010 of size 13548
2017-03-12 18:26:25,198 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8997389008808528780_1489 src: /192.168.1.151:52545 dest: /192.168.1.151:50010
2017-03-12 18:26:25,200 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8997389008808528780_1489 src: /192.168.1.151:52545 dest: /192.168.1.151:50010 of size 13562
2017-03-12 18:26:37,497 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-5226239773727901148_1486 to /192.168.1.153
2017-03-12 18:26:50,305 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_3530359500607374331_1486
2017-03-12 18:26:52,024 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_631597496783626488_1486 to /192.168.1.153
2017-03-12 18:27:01,531 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-563747461064131208_1486 to /192.168.1.153
2017-03-12 18:27:16,980 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-6529693818616013818_1486 to /192.168.1.153
2017-03-12 18:27:32,224 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-3615259698331015578_1486 to /192.168.1.153
2017-03-12 18:27:54,905 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-5074910699574139327_1486
2017-03-12 18:28:49,199 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4127709487482046893_1488 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4127709487482046893
2017-03-12 18:28:49,199 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3420416406836683703_1487 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3420416406836683703
2017-03-12 18:28:49,200 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2673761543101611216_1491 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2673761543101611216
2017-03-12 18:28:49,200 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8997389008808528780_1489 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8997389008808528780
2017-03-12 18:30:37,616 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-5074910699574139327_1486 to /192.168.1.153
2017-03-12 18:30:43,301 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7142602577234746417_1494 src: /192.168.1.152:34959 dest: /192.168.1.152:50010
2017-03-12 18:30:43,304 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7142602577234746417_1494 src: /192.168.1.152:34959 dest: /192.168.1.152:50010 of size 13562
2017-03-12 18:30:43,366 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2462372887034648044_1493 src: /192.168.1.150:45441 dest: /192.168.1.150:50010
2017-03-12 18:30:43,367 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2462372887034648044_1493 src: /192.168.1.150:45441 dest: /192.168.1.150:50010 of size 525
2017-03-12 18:30:46,240 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2462372887034648044_1493 to 192.168.1.152:50010
2017-03-12 18:30:46,243 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-2462372887034648044_1493 to /192.168.1.152:50010
2017-03-12 18:30:49,289 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1370188160022068755_1496 src: /192.168.1.151:52565 dest: /192.168.1.151:50010
2017-03-12 18:30:49,294 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1370188160022068755_1496 src: /192.168.1.151:52565 dest: /192.168.1.151:50010 of size 13548
2017-03-12 18:30:49,378 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8033447717416004864_1492 src: /192.168.1.150:45443 dest: /192.168.1.150:50010
2017-03-12 18:30:49,378 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8033447717416004864_1492 src: /192.168.1.150:45444 dest: /192.168.1.150:50010
2017-03-12 18:30:49,378 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8033447717416004864_1492 received exception java.io.IOException: Block blk_8033447717416004864_1492 has already been started (though not completed), and thus cannot be created.
2017-03-12 18:30:49,379 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8033447717416004864_1492 src: /192.168.1.150:45443 dest: /192.168.1.150:50010 of size 91176
2017-03-12 18:30:49,380 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8033447717416004864_1492 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-03-12 18:30:52,242 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8033447717416004864_1492 to 192.168.1.152:50010, 192.168.1.151:50010
2017-03-12 18:30:52,246 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_8033447717416004864_1492 to /192.168.1.152:50010
2017-03-12 18:30:52,779 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-5226239773727901148_1486 to /192.168.1.153
2017-03-12 18:31:06,245 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_631597496783626488_1486 to /192.168.1.153
2017-03-12 18:32:07,269 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7142602577234746417_1494 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7142602577234746417
2017-03-12 18:32:07,270 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2462372887034648044_1493 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2462372887034648044
2017-03-12 18:32:07,270 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1370188160022068755_1496 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1370188160022068755
2017-03-12 18:32:07,271 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8033447717416004864_1492 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8033447717416004864
2017-03-12 18:32:55,419 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-3313291319270606547_1486
2017-03-12 18:35:09,880 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-03-12 18:35:19,772 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-03-12 18:35:19,983 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-03-12 18:35:19,984 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-03-12 18:35:19,986 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-03-12 18:35:20,056 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-03-12 18:35:20,116 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-03-12 18:35:20,116 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-03-12 18:35:20,117 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-03-12 18:35:20,345 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-03-12 18:35:20,376 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-03-12 18:35:20,379 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-03-12 18:35:20,379 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@7fb716
2017-03-12 18:35:20,384 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-03-12 18:35:20,405 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-03-12 18:35:20,411 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-03-12 18:35:20,412 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-03-12 18:35:20,412 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-03-12 18:35:20,412 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-03-12 18:35:20,413 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)
2017-03-12 18:35:20,413 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-03-12 18:35:20,415 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-03-12 18:35:20,416 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-03-12 18:35:20,423 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-03-12 18:35:23,423 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-03-12 18:36:22,992 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-563747461064131208_1486
2017-03-12 18:36:35,154 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6296393313007326432_1501 src: /192.168.1.151:52579 dest: /192.168.1.151:50010
2017-03-12 18:36:35,167 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6296393313007326432_1501 src: /192.168.1.151:52579 dest: /192.168.1.151:50010 of size 13547
2017-03-12 18:36:35,716 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-5074910699574139327_1486 to /192.168.1.153
2017-03-12 18:36:38,133 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4170788671887503550_1497 src: /192.168.1.150:45469 dest: /192.168.1.150:50010
2017-03-12 18:36:38,136 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4170788671887503550_1497 src: /192.168.1.150:45469 dest: /192.168.1.150:50010 of size 91176
2017-03-12 18:36:38,446 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6296393313007326432_1501 to 192.168.1.152:50010
2017-03-12 18:36:38,454 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-6296393313007326432_1501 to /192.168.1.152:50010
2017-03-12 18:36:41,138 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3113128954027902529_1498 src: /192.168.1.150:45471 dest: /192.168.1.150:50010
2017-03-12 18:36:41,141 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3113128954027902529_1498 src: /192.168.1.150:45471 dest: /192.168.1.150:50010 of size 525
2017-03-12 18:36:47,455 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2159766570403330337_1499 src: /192.168.1.152:34982 dest: /192.168.1.152:50010
2017-03-12 18:36:47,456 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2159766570403330337_1499 src: /192.168.1.152:34982 dest: /192.168.1.152:50010 of size 13561
2017-03-12 18:36:51,565 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-5226239773727901148_1486 to /192.168.1.153
2017-03-12 18:37:05,553 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_631597496783626488_1486 to /192.168.1.153
2017-03-12 18:37:15,720 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-563747461064131208_1486 to /192.168.1.153
2017-03-12 18:37:31,396 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-6529693818616013818_1486 to /192.168.1.153
2017-03-12 18:37:55,646 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_631597496783626488_1486 to /192.168.1.153
2017-03-12 18:38:16,071 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-6296393313007326432_1501
2017-03-12 18:38:17,252 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4210247574424887029_1502 src: /192.168.1.150:45490 dest: /192.168.1.150:50010
2017-03-12 18:38:17,256 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4210247574424887029_1502 src: /192.168.1.150:45490 dest: /192.168.1.150:50010 of size 91176
2017-03-12 18:38:19,817 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-4210247574424887029_1502 to /192.168.1.153
2017-03-12 18:38:20,257 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2733873186596017316_1503 src: /192.168.1.152:35004 dest: /192.168.1.152:50010
2017-03-12 18:38:20,258 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2733873186596017316_1503 src: /192.168.1.152:35004 dest: /192.168.1.152:50010 of size 525
2017-03-12 18:38:20,489 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-4210247574424887029_1502 to 192.168.1.151:50010
2017-03-12 18:38:20,494 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-4210247574424887029_1502 to /192.168.1.151:50010
2017-03-12 18:38:20,729 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-563747461064131208_1486 to /192.168.1.153
2017-03-12 18:38:23,256 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2994545200630556618_1504 src: /192.168.1.150:45495 dest: /192.168.1.150:50010
2017-03-12 18:38:23,256 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2994545200630556618_1504 src: /192.168.1.150:45495 dest: /192.168.1.150:50010 of size 13561
2017-03-12 18:38:29,264 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8155087101511196569_1506 src: /192.168.1.150:45497 dest: /192.168.1.150:50010
2017-03-12 18:38:29,266 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8155087101511196569_1506 src: /192.168.1.150:45497 dest: /192.168.1.150:50010 of size 13547
2017-03-12 18:38:32,489 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6296393313007326432_1501 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6296393313007326432
2017-03-12 18:38:32,490 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4170788671887503550_1497 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4170788671887503550
2017-03-12 18:38:32,490 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3113128954027902529_1498 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3113128954027902529
2017-03-12 18:38:32,491 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2159766570403330337_1499 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2159766570403330337
2017-03-12 18:38:35,489 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 12 blocks got processed in 3 msecs
2017-03-12 18:38:36,294 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-6529693818616013818_1486 to /192.168.1.153
2017-03-12 18:38:51,006 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_-3615259698331015578_1486 to /192.168.1.153
2017-03-12 18:39:50,357 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1537617369494940305_1507 src: /192.168.1.150:45512 dest: /192.168.1.150:50010
2017-03-12 18:39:50,362 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1537617369494940305_1507 src: /192.168.1.150:45512 dest: /192.168.1.150:50010 of size 91176
2017-03-12 18:39:56,360 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5746530373852131428_1508 src: /192.168.1.150:45524 dest: /192.168.1.150:50010
2017-03-12 18:39:56,361 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5746530373852131428_1508 src: /192.168.1.150:45524 dest: /192.168.1.150:50010 of size 525
2017-03-12 18:39:56,576 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7307285470362766227_1511 src: /192.168.1.151:52618 dest: /192.168.1.151:50010
2017-03-12 18:39:56,577 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7307285470362766227_1511 src: /192.168.1.151:52618 dest: /192.168.1.151:50010 of size 13547
2017-03-12 18:39:59,369 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8653383995553234168_1509 src: /192.168.1.151:52619 dest: /192.168.1.151:50010
2017-03-12 18:39:59,370 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8653383995553234168_1509 src: /192.168.1.151:52619 dest: /192.168.1.151:50010 of size 13561
2017-03-12 18:40:02,523 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8653383995553234168_1509 to 192.168.1.152:50010
2017-03-12 18:40:02,527 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020):Transmitted block blk_-8653383995553234168_1509 to /192.168.1.152:50010
2017-03-12 18:40:05,524 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8155087101511196569_1506 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8155087101511196569
2017-03-12 18:40:05,525 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4210247574424887029_1502 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4210247574424887029
2017-03-12 18:40:05,525 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2733873186596017316_1503 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2733873186596017316
2017-03-12 18:40:05,525 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2994545200630556618_1504 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2994545200630556618
2017-03-12 18:40:10,033 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_3530359500607374331_1486 to /192.168.1.153
2017-03-12 18:41:27,661 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-177065084-192.168.1.153-50010-1489303089088, infoPort=50075, ipcPort=50020) Served block blk_631597496783626488_1486 to /192.168.1.153
2017-03-12 18:41:41,559 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8653383995553234168_1509 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8653383995553234168
2017-03-12 18:41:41,559 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7307285470362766227_1511 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7307285470362766227
2017-03-12 18:41:41,560 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1537617369494940305_1507 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1537617369494940305
2017-03-12 18:41:41,560 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5746530373852131428_1508 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5746530373852131428
2017-03-12 19:38:36,777 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-03-12 20:38:38,061 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 7 msecs
2017-03-12 21:38:39,402 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-03-12 22:38:40,690 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-03-12 23:38:42,002 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
