2017-05-22 00:17:15,873 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 5 msecs
2017-05-22 01:17:16,229 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-22 02:17:16,832 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-22 03:17:17,039 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 5 msecs
2017-05-22 04:17:17,149 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-05-22 05:17:17,787 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-22 06:17:18,013 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-22 07:17:20,713 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-22 08:17:20,898 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-22 08:17:59,609 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 08:18:10,437 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 08:18:10,624 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 08:18:10,626 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 08:18:10,628 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 08:18:10,689 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 08:18:10,734 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 08:18:10,735 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 08:18:10,736 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 08:18:10,955 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 08:18:10,994 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 08:18:10,997 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 08:18:10,997 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 08:18:11,002 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 08:18:11,024 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 08:18:11,029 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 08:18:11,030 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 08:18:11,031 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 08:18:11,035 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 08:18:11,035 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 08:18:11,035 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 08:18:11,046 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 08:18:11,046 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 08:18:11,059 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 08:18:14,062 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 16 msecs
2017-05-22 08:19:11,175 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7256632260643635250_1888 src: /192.168.1.158:59850 dest: /192.168.1.158:50010
2017-05-22 08:19:11,187 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7256632260643635250_1888 src: /192.168.1.158:59850 dest: /192.168.1.158:50010 of size 13553
2017-05-22 08:19:14,103 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7256632260643635250_1888 to 192.168.1.157:50010
2017-05-22 08:19:14,110 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-7256632260643635250_1888 to /192.168.1.157:50010
2017-05-22 08:19:14,122 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6098357009998363581_1886 src: /192.168.1.156:53835 dest: /192.168.1.156:50010
2017-05-22 08:19:14,122 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6098357009998363581_1886 src: /192.168.1.156:53834 dest: /192.168.1.156:50010
2017-05-22 08:19:14,123 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-6098357009998363581_1886 received exception java.io.IOException: Block blk_-6098357009998363581_1886 has already been started (though not completed), and thus cannot be created.
2017-05-22 08:19:14,124 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-6098357009998363581_1886 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 08:19:14,127 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6098357009998363581_1886 src: /192.168.1.156:53835 dest: /192.168.1.156:50010 of size 13568
2017-05-22 08:19:16,297 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 08:19:16,896 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 08:19:17,106 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6098357009998363581_1886 to 192.168.1.158:50010, 192.168.1.157:50010
2017-05-22 08:19:17,110 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-6098357009998363581_1886 to /192.168.1.158:50010
2017-05-22 08:19:20,122 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5053064453177574257_1885 src: /192.168.1.156:53845 dest: /192.168.1.156:50010
2017-05-22 08:19:20,124 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5053064453177574257_1885 src: /192.168.1.156:53846 dest: /192.168.1.156:50010
2017-05-22 08:19:20,124 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5053064453177574257_1885 received exception java.io.IOException: Block blk_5053064453177574257_1885 has already been started (though not completed), and thus cannot be created.
2017-05-22 08:19:20,124 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_5053064453177574257_1885 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 08:19:20,131 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1266958488035673645_1884 src: /192.168.1.158:59866 dest: /192.168.1.158:50010
2017-05-22 08:19:20,132 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1266958488035673645_1884 src: /192.168.1.158:59866 dest: /192.168.1.158:50010 of size 91176
2017-05-22 08:19:20,134 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5053064453177574257_1885 src: /192.168.1.156:53845 dest: /192.168.1.156:50010 of size 8645
2017-05-22 08:19:23,108 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_5053064453177574257_1885 to 192.168.1.158:50010, 192.168.1.157:50010
2017-05-22 08:19:23,110 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_5053064453177574257_1885 to /192.168.1.158:50010
2017-05-22 08:19:24,195 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 08:19:34,045 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 08:19:46,418 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 08:19:52,955 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 08:19:58,653 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 08:20:14,134 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6098357009998363581_1886 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6098357009998363581
2017-05-22 08:20:14,135 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1266958488035673645_1884 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1266958488035673645
2017-05-22 08:20:14,136 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5053064453177574257_1885 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5053064453177574257
2017-05-22 08:20:20,135 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7256632260643635250_1888 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7256632260643635250
2017-05-22 08:20:25,350 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 08:20:36,216 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 08:20:36,431 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 08:20:36,433 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 08:20:36,434 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 08:20:36,495 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 08:20:36,543 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 08:20:36,544 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 08:20:36,544 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 08:20:36,764 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 08:20:36,801 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 08:20:36,804 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 08:20:36,804 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 08:20:36,809 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 08:20:36,831 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 08:20:36,839 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 08:20:36,839 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 08:20:36,840 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 08:20:36,840 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 08:20:36,841 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 08:20:36,841 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 08:20:36,843 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 08:20:36,843 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 08:20:36,851 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 08:20:39,856 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 12 msecs
2017-05-22 08:21:42,886 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6237746904694496725_1891 src: /192.168.1.156:53930 dest: /192.168.1.156:50010
2017-05-22 08:21:42,900 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6237746904694496725_1891 src: /192.168.1.156:53930 dest: /192.168.1.156:50010 of size 13568
2017-05-22 08:21:45,884 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6237746904694496725_1891 to 192.168.1.158:50010
2017-05-22 08:21:45,892 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-6237746904694496725_1891 to /192.168.1.158:50010
2017-05-22 08:21:48,891 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2005610379712301497_1889 src: /192.168.1.158:59938 dest: /192.168.1.158:50010
2017-05-22 08:21:48,894 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2005610379712301497_1889 src: /192.168.1.158:59938 dest: /192.168.1.158:50010 of size 91176
2017-05-22 08:21:48,898 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2090005981105643240_1893 src: /192.168.1.158:59939 dest: /192.168.1.158:50010
2017-05-22 08:21:48,900 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2090005981105643240_1893 src: /192.168.1.158:59939 dest: /192.168.1.158:50010 of size 13553
2017-05-22 08:21:51,887 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2005610379712301497_1889 to 192.168.1.157:50010
2017-05-22 08:21:51,891 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-2005610379712301497_1889 to /192.168.1.157:50010
2017-05-22 08:21:54,908 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5809937476295556993_1890 src: /192.168.1.157:42120 dest: /192.168.1.157:50010
2017-05-22 08:21:54,909 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5809937476295556993_1890 src: /192.168.1.157:42120 dest: /192.168.1.157:50010 of size 8645
2017-05-22 08:21:57,932 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 08:22:03,513 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 08:22:09,942 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 08:22:17,027 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 08:22:23,496 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 08:22:23,868 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 08:22:35,824 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 08:22:37,867 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 08:22:48,920 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6237746904694496725_1891 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6237746904694496725
2017-05-22 08:22:48,920 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2005610379712301497_1889 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2005610379712301497
2017-05-22 08:22:48,921 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5809937476295556993_1890 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5809937476295556993
2017-05-22 08:22:51,913 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2090005981105643240_1893 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2090005981105643240
2017-05-22 08:22:58,920 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 08:23:09,719 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 08:23:09,922 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 08:23:09,924 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 08:23:09,925 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 08:23:09,993 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 08:23:10,050 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 08:23:10,050 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 08:23:10,051 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 08:23:10,292 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 08:23:10,328 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 08:23:10,331 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 08:23:10,331 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 08:23:10,336 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 08:23:10,353 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 08:23:10,358 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 08:23:10,359 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 08:23:10,360 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 08:23:10,361 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 08:23:10,361 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 08:23:10,362 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 08:23:10,365 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 08:23:10,365 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 08:23:10,374 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 08:23:13,374 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 08:24:16,463 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8220543320199551170_1896 src: /192.168.1.156:54016 dest: /192.168.1.156:50010
2017-05-22 08:24:16,481 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8220543320199551170_1896 src: /192.168.1.156:54016 dest: /192.168.1.156:50010 of size 13568
2017-05-22 08:24:19,417 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8220543320199551170_1896 to 192.168.1.158:50010
2017-05-22 08:24:19,421 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-8220543320199551170_1896 to /192.168.1.158:50010
2017-05-22 08:24:19,460 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-209084618796672846_1898 src: /192.168.1.156:54017 dest: /192.168.1.156:50010
2017-05-22 08:24:19,461 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-209084618796672846_1898 src: /192.168.1.156:54017 dest: /192.168.1.156:50010 of size 13553
2017-05-22 08:24:19,468 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-209084618796672846_1898 src: /192.168.1.156:54018 dest: /192.168.1.156:50010
2017-05-22 08:24:19,469 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-209084618796672846_1898 received exception java.io.IOException: Block blk_-209084618796672846_1898 is valid, and cannot be written to.
2017-05-22 08:24:19,470 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-209084618796672846_1898 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 08:24:22,417 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-209084618796672846_1898 to 192.168.1.157:50010, 192.168.1.158:50010
2017-05-22 08:24:22,420 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-209084618796672846_1898 to /192.168.1.157:50010
2017-05-22 08:24:22,461 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5827973311701947216_1894 src: /192.168.1.156:54021 dest: /192.168.1.156:50010
2017-05-22 08:24:22,466 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5827973311701947216_1894 src: /192.168.1.156:54021 dest: /192.168.1.156:50010 of size 91176
2017-05-22 08:24:23,606 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 08:24:25,460 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7796855493081769495_1895 src: /192.168.1.156:54028 dest: /192.168.1.156:50010
2017-05-22 08:24:25,460 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7796855493081769495_1895 src: /192.168.1.156:54028 dest: /192.168.1.156:50010 of size 8645
2017-05-22 08:24:57,284 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 08:25:06,605 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 08:25:17,642 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 08:28:31,502 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8220543320199551170_1896 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8220543320199551170
2017-05-22 08:28:31,503 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5827973311701947216_1894 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5827973311701947216
2017-05-22 08:28:31,503 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7796855493081769495_1895 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7796855493081769495
2017-05-22 08:28:37,503 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-209084618796672846_1898 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-209084618796672846
2017-05-22 08:28:45,375 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 08:28:56,261 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 08:28:56,464 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 08:28:56,465 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 08:28:56,467 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 08:28:56,537 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 08:28:56,593 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 08:28:56,595 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 08:28:56,595 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 08:28:56,825 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@14a8af0
2017-05-22 08:28:56,868 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 08:28:56,870 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 08:28:56,870 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-22 08:28:56,875 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 08:28:56,890 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 08:28:56,895 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 08:28:56,896 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 08:28:56,897 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 08:28:56,898 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 08:28:56,899 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 08:28:56,899 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 08:28:56,901 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 08:28:56,901 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 08:28:56,909 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 08:28:59,909 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 08:29:57,019 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2951174068798267999_1904 src: /192.168.1.158:60107 dest: /192.168.1.158:50010
2017-05-22 08:29:57,031 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2951174068798267999_1904 src: /192.168.1.158:60107 dest: /192.168.1.158:50010 of size 4325
2017-05-22 08:29:57,321 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 08:29:59,967 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1412751215318647606_1903 src: /192.168.1.156:54167 dest: /192.168.1.156:50010
2017-05-22 08:29:59,969 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1412751215318647606_1903 src: /192.168.1.156:54167 dest: /192.168.1.156:50010 of size 91176
2017-05-22 08:30:02,965 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7672693683790683372_1905 src: /192.168.1.157:42277 dest: /192.168.1.157:50010
2017-05-22 08:30:02,966 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7672693683790683372_1905 src: /192.168.1.157:42277 dest: /192.168.1.157:50010 of size 13568
2017-05-22 08:30:03,001 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1412751215318647606_1903 to 192.168.1.158:50010
2017-05-22 08:30:03,008 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-1412751215318647606_1903 to /192.168.1.158:50010
2017-05-22 08:30:06,001 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7672693683790683372_1905 to 192.168.1.158:50010
2017-05-22 08:30:06,003 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_7672693683790683372_1905 to /192.168.1.158:50010
2017-05-22 08:30:07,553 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 08:30:08,949 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8554700478513184484_1907 src: /192.168.1.158:60117 dest: /192.168.1.158:50010
2017-05-22 08:30:08,950 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8554700478513184484_1907 src: /192.168.1.158:60117 dest: /192.168.1.158:50010 of size 13553
2017-05-22 08:30:10,166 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 08:30:21,036 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 08:30:22,024 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 08:30:33,111 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 08:30:36,600 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 08:30:41,023 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 08:30:48,001 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 08:30:54,099 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 08:30:57,125 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 08:31:12,025 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2951174068798267999_1904 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2951174068798267999
2017-05-22 08:31:12,025 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1412751215318647606_1903 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1412751215318647606
2017-05-22 08:31:12,026 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7672693683790683372_1905 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7672693683790683372
2017-05-22 08:31:15,031 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8554700478513184484_1907 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8554700478513184484
2017-05-22 08:31:22,113 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 08:31:32,918 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 08:31:33,130 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 08:31:33,132 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 08:31:33,134 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 08:31:33,203 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 08:31:33,260 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 08:31:33,261 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 08:31:33,261 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 08:31:33,491 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 08:31:33,527 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 08:31:33,529 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 08:31:33,529 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 08:31:33,534 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 08:31:33,552 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 08:31:33,557 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 08:31:33,558 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 08:31:33,560 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 08:31:33,561 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 08:31:33,561 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 08:31:33,561 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 08:31:33,563 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 08:31:33,564 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 08:31:33,572 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 08:31:36,573 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 9 msecs
2017-05-22 08:32:42,602 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3834792330254124539_1912 src: /192.168.1.158:60188 dest: /192.168.1.158:50010
2017-05-22 08:32:42,614 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3834792330254124539_1912 src: /192.168.1.158:60188 dest: /192.168.1.158:50010 of size 13553
2017-05-22 08:32:42,625 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-940867742773927795_1910 src: /192.168.1.156:54250 dest: /192.168.1.156:50010
2017-05-22 08:32:42,626 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-940867742773927795_1910 src: /192.168.1.156:54250 dest: /192.168.1.156:50010 of size 13568
2017-05-22 08:32:47,344 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 08:32:48,599 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4339418063203721820_1909 src: /192.168.1.158:60193 dest: /192.168.1.158:50010
2017-05-22 08:32:48,600 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4339418063203721820_1909 src: /192.168.1.158:60193 dest: /192.168.1.158:50010 of size 4325
2017-05-22 08:32:48,647 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5228571587700451627_1908 src: /192.168.1.156:54258 dest: /192.168.1.156:50010
2017-05-22 08:32:48,650 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5228571587700451627_1908 src: /192.168.1.156:54258 dest: /192.168.1.156:50010 of size 91176
2017-05-22 08:32:49,399 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 08:32:53,632 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 08:32:59,405 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 08:33:11,662 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 08:33:13,962 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 08:33:15,317 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 08:33:33,390 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 08:33:42,637 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-940867742773927795_1910 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-940867742773927795
2017-05-22 08:33:42,638 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4339418063203721820_1909 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4339418063203721820
2017-05-22 08:33:42,638 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5228571587700451627_1908 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5228571587700451627
2017-05-22 08:33:45,639 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3834792330254124539_1912 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3834792330254124539
2017-05-22 08:33:52,756 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 08:34:03,581 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 08:34:03,763 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 08:34:03,765 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 08:34:03,767 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 08:34:03,828 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 08:34:03,878 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 08:34:03,878 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 08:34:03,878 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 08:34:04,106 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 08:34:04,144 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 08:34:04,152 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 08:34:04,152 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@5876a5
2017-05-22 08:34:04,158 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 08:34:04,180 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 08:34:04,185 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 08:34:04,186 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 08:34:04,186 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 08:34:04,186 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 08:34:04,186 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 08:34:04,186 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 08:34:04,196 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 08:34:04,196 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 08:34:04,221 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 08:34:07,212 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-22 08:35:10,407 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7591543071306740640_1917 src: /192.168.1.156:54321 dest: /192.168.1.156:50010
2017-05-22 08:35:10,423 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7591543071306740640_1917 src: /192.168.1.156:54321 dest: /192.168.1.156:50010 of size 13553
2017-05-22 08:35:13,296 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7591543071306740640_1917 to 192.168.1.158:50010
2017-05-22 08:35:13,301 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-7591543071306740640_1917 to /192.168.1.158:50010
2017-05-22 08:35:16,296 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1021077162815779438_1913 src: /192.168.1.157:42427 dest: /192.168.1.157:50010
2017-05-22 08:35:16,302 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1021077162815779438_1913 src: /192.168.1.157:42427 dest: /192.168.1.157:50010 of size 91176
2017-05-22 08:35:18,119 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 08:35:19,299 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_894062470944717066_1914 src: /192.168.1.157:42430 dest: /192.168.1.157:50010
2017-05-22 08:35:19,299 INFO org.apache.hadoop.dfs.DataNode: Received block blk_894062470944717066_1914 src: /192.168.1.157:42430 dest: /192.168.1.157:50010 of size 4325
2017-05-22 08:35:20,086 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 08:35:22,408 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4364270022211783690_1915 src: /192.168.1.156:54334 dest: /192.168.1.156:50010
2017-05-22 08:35:22,411 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4364270022211783690_1915 src: /192.168.1.156:54334 dest: /192.168.1.156:50010 of size 13568
2017-05-22 08:35:24,546 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 08:35:30,539 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 08:35:34,409 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 08:35:48,466 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 08:35:54,808 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 08:35:57,373 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 08:36:00,275 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 08:36:13,319 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1021077162815779438_1913 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1021077162815779438
2017-05-22 08:36:13,319 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_894062470944717066_1914 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_894062470944717066
2017-05-22 08:36:13,320 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4364270022211783690_1915 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4364270022211783690
2017-05-22 08:36:16,323 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7591543071306740640_1917 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7591543071306740640
2017-05-22 09:30:00,754 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-22 10:30:01,041 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 5 msecs
2017-05-22 11:13:47,763 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 11:13:58,601 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 11:13:58,783 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 11:13:58,785 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 11:13:58,786 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 11:13:58,853 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 11:13:58,909 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 11:13:58,910 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 11:13:58,910 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 11:13:59,145 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 11:13:59,179 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 11:13:59,182 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 11:13:59,182 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 11:13:59,188 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 11:13:59,208 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 11:13:59,213 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 11:13:59,214 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 11:13:59,214 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 11:13:59,214 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 11:13:59,214 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 11:13:59,214 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 11:13:59,225 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 11:13:59,225 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 11:13:59,237 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 11:14:02,248 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 23 msecs
2017-05-22 11:14:59,364 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4705674233951619765_1922 src: /192.168.1.156:54384 dest: /192.168.1.156:50010
2017-05-22 11:14:59,382 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4705674233951619765_1922 src: /192.168.1.156:54384 dest: /192.168.1.156:50010 of size 13554
2017-05-22 11:15:02,324 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1844582891440915780_1920 src: /192.168.1.156:54392 dest: /192.168.1.156:50010
2017-05-22 11:15:02,326 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1844582891440915780_1920 src: /192.168.1.156:54392 dest: /192.168.1.156:50010 of size 13569
2017-05-22 11:15:02,357 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-4705674233951619765_1922 to 192.168.1.157:50010
2017-05-22 11:15:02,366 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-4705674233951619765_1922 to /192.168.1.157:50010
2017-05-22 11:15:05,327 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2734089080774486919_1919 src: /192.168.1.158:60334 dest: /192.168.1.158:50010
2017-05-22 11:15:05,329 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2734089080774486919_1919 src: /192.168.1.158:60334 dest: /192.168.1.158:50010 of size 1085
2017-05-22 11:15:08,357 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_2734089080774486919_1919 to 192.168.1.157:50010
2017-05-22 11:15:08,360 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_2734089080774486919_1919 to /192.168.1.157:50010
2017-05-22 11:15:11,286 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8942151985496564050_1918 src: /192.168.1.158:60335 dest: /192.168.1.158:50010
2017-05-22 11:15:11,290 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8942151985496564050_1918 src: /192.168.1.158:60335 dest: /192.168.1.158:50010 of size 91176
2017-05-22 11:20:17,629 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1844582891440915780_1920 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1844582891440915780
2017-05-22 11:20:17,629 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2734089080774486919_1919 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2734089080774486919
2017-05-22 11:20:17,630 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8942151985496564050_1918 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8942151985496564050
2017-05-22 11:20:20,475 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4288940915783915629_1926 src: /192.168.1.156:54471 dest: /192.168.1.156:50010
2017-05-22 11:20:20,480 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4288940915783915629_1926 src: /192.168.1.156:54471 dest: /192.168.1.156:50010 of size 14555
2017-05-22 11:20:23,630 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4705674233951619765_1922 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4705674233951619765
2017-05-22 11:20:28,621 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 11:20:39,427 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 11:20:39,619 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 11:20:39,621 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 11:20:39,623 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 11:20:39,694 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 11:20:39,750 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 11:20:39,751 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 11:20:39,751 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 11:20:39,987 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 11:20:40,021 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 11:20:40,024 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 11:20:40,024 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 11:20:40,029 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 11:20:40,046 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 11:20:40,051 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 11:20:40,052 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 11:20:40,053 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 11:20:40,054 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 11:20:40,054 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 11:20:40,054 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 11:20:40,065 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 11:20:40,066 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 11:20:40,074 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 11:20:40,117 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-4288940915783915629_1926
2017-05-22 11:20:43,073 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 7 msecs
2017-05-22 11:21:16,117 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4288940915783915629_1926 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4288940915783915629
2017-05-22 11:21:46,114 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9216674978305513305_1928 src: /192.168.1.157:42486 dest: /192.168.1.157:50010
2017-05-22 11:21:46,130 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9216674978305513305_1928 src: /192.168.1.157:42486 dest: /192.168.1.157:50010 of size 1085
2017-05-22 11:21:49,085 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8143430343973195395_1929 src: /192.168.1.156:54485 dest: /192.168.1.156:50010
2017-05-22 11:21:49,086 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8143430343973195395_1929 src: /192.168.1.156:54485 dest: /192.168.1.156:50010 of size 13569
2017-05-22 11:21:49,146 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-9216674978305513305_1928 to 192.168.1.158:50010
2017-05-22 11:21:49,152 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-9216674978305513305_1928 to /192.168.1.158:50010
2017-05-22 11:21:52,090 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5537831626660196534_1931 src: /192.168.1.158:60338 dest: /192.168.1.158:50010
2017-05-22 11:21:52,092 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5537831626660196534_1931 src: /192.168.1.158:60338 dest: /192.168.1.158:50010 of size 13554
2017-05-22 11:21:52,146 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8143430343973195395_1929 to 192.168.1.157:50010
2017-05-22 11:21:52,149 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-8143430343973195395_1929 to /192.168.1.157:50010
2017-05-22 11:21:55,094 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7231854512116875435_1927 src: /192.168.1.156:54490 dest: /192.168.1.156:50010
2017-05-22 11:21:55,096 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7231854512116875435_1927 src: /192.168.1.156:54490 dest: /192.168.1.156:50010 of size 91176
2017-05-22 11:21:55,149 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-5537831626660196534_1931 to 192.168.1.157:50010
2017-05-22 11:21:55,152 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-5537831626660196534_1931 to /192.168.1.157:50010
2017-05-22 11:21:58,149 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7231854512116875435_1927 to 192.168.1.157:50010
2017-05-22 11:21:58,157 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_7231854512116875435_1927 to /192.168.1.157:50010
2017-05-22 11:27:04,217 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5637482602517433194_1935 src: /192.168.1.157:42487 dest: /192.168.1.157:50010
2017-05-22 11:27:04,218 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5637482602517433194_1935 src: /192.168.1.157:42487 dest: /192.168.1.157:50010 of size 14555
2017-05-22 11:27:07,372 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9216674978305513305_1928 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9216674978305513305
2017-05-22 11:27:07,373 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8143430343973195395_1929 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8143430343973195395
2017-05-22 11:27:07,373 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5637482602517433194_1935 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5637482602517433194
2017-05-22 11:27:07,374 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5537831626660196534_1931 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5537831626660196534
2017-05-22 11:27:07,374 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7231854512116875435_1927 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7231854512116875435
2017-05-22 11:27:14,113 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 11:27:24,943 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 11:27:25,157 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 11:27:25,158 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 11:27:25,160 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 11:27:25,225 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 11:27:25,286 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 11:27:25,287 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 11:27:25,287 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 11:27:25,520 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 11:27:25,561 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 11:27:25,564 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 11:27:25,564 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 11:27:25,570 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 11:27:25,593 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 11:27:25,599 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 11:27:25,599 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 11:27:25,601 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 11:27:25,602 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 11:27:25,603 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 11:27:25,603 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 11:27:25,604 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 11:27:25,604 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 11:27:25,613 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 11:27:28,612 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 11:28:31,699 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6792886505458926136_1937 src: /192.168.1.158:60341 dest: /192.168.1.158:50010
2017-05-22 11:28:31,710 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6792886505458926136_1937 src: /192.168.1.158:60341 dest: /192.168.1.158:50010 of size 1085
2017-05-22 11:28:34,639 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2872356864835150101_1936 src: /192.168.1.156:54579 dest: /192.168.1.156:50010
2017-05-22 11:28:34,642 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2872356864835150101_1936 src: /192.168.1.156:54579 dest: /192.168.1.156:50010 of size 91176
2017-05-22 11:28:37,640 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1237168883489516166_1940 src: /192.168.1.158:60343 dest: /192.168.1.158:50010
2017-05-22 11:28:37,642 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1237168883489516166_1940 src: /192.168.1.158:60343 dest: /192.168.1.158:50010 of size 13554
2017-05-22 11:28:37,731 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2872356864835150101_1936 to 192.168.1.158:50010
2017-05-22 11:28:37,742 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-2872356864835150101_1936 to /192.168.1.158:50010
2017-05-22 11:28:40,639 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-668922491356505223_1938 src: /192.168.1.156:54583 dest: /192.168.1.156:50010
2017-05-22 11:28:40,643 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-668922491356505223_1938 src: /192.168.1.156:54583 dest: /192.168.1.156:50010 of size 13569
2017-05-22 11:28:40,731 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1237168883489516166_1940 to 192.168.1.157:50010
2017-05-22 11:28:40,734 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-1237168883489516166_1940 to /192.168.1.157:50010
2017-05-22 11:28:43,734 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-668922491356505223_1938 to 192.168.1.157:50010
2017-05-22 11:28:43,737 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-668922491356505223_1938 to /192.168.1.157:50010
2017-05-22 11:29:49,853 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 28 blocks got processed in 3 msecs
2017-05-22 11:33:55,781 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8692093153775556229_1944 src: /192.168.1.156:54661 dest: /192.168.1.156:50010
2017-05-22 11:33:55,786 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8692093153775556229_1944 src: /192.168.1.156:54661 dest: /192.168.1.156:50010 of size 14555
2017-05-22 11:33:59,148 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6792886505458926136_1937 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6792886505458926136
2017-05-22 11:33:59,148 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2872356864835150101_1936 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2872356864835150101
2017-05-22 11:33:59,149 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1237168883489516166_1940 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1237168883489516166
2017-05-22 11:33:59,149 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-668922491356505223_1938 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-668922491356505223
2017-05-22 11:34:06,534 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 11:34:17,422 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 11:34:17,624 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 11:34:17,625 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 11:34:17,627 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 11:34:17,696 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 11:34:17,755 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 11:34:17,756 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 11:34:17,756 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 11:34:17,992 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 11:34:18,028 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 11:34:18,030 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 11:34:18,031 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 11:34:18,036 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 11:34:18,053 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 11:34:18,058 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 11:34:18,058 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 11:34:18,060 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 11:34:18,060 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 11:34:18,061 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 11:34:18,061 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 11:34:18,063 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 11:34:18,064 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 11:34:18,073 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 11:34:18,118 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_8692093153775556229_1944
2017-05-22 11:34:21,074 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 8 msecs
2017-05-22 11:34:54,084 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8692093153775556229_1944 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8692093153775556229
2017-05-22 11:35:18,114 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2909816760453438137_1946 src: /192.168.1.156:54669 dest: /192.168.1.156:50010
2017-05-22 11:35:18,128 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2909816760453438137_1946 src: /192.168.1.156:54669 dest: /192.168.1.156:50010 of size 2165
2017-05-22 11:35:21,100 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1738351148532787474_1945 src: /192.168.1.156:54676 dest: /192.168.1.156:50010
2017-05-22 11:35:21,106 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1738351148532787474_1945 src: /192.168.1.156:54676 dest: /192.168.1.156:50010 of size 91176
2017-05-22 11:35:24,098 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_1738351148532787474_1945 to 192.168.1.157:50010
2017-05-22 11:35:24,108 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_1738351148532787474_1945 to /192.168.1.157:50010
2017-05-22 11:35:27,037 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3652779018580997898_1947 src: /192.168.1.157:42494 dest: /192.168.1.157:50010
2017-05-22 11:35:27,039 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3652779018580997898_1947 src: /192.168.1.157:42494 dest: /192.168.1.157:50010 of size 13568
2017-05-22 11:35:27,114 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7480557121737703942_1949 src: /192.168.1.156:54687 dest: /192.168.1.156:50010
2017-05-22 11:35:27,116 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7480557121737703942_1949 src: /192.168.1.156:54687 dest: /192.168.1.156:50010 of size 13553
2017-05-22 11:35:30,100 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7480557121737703942_1949 to 192.168.1.158:50010
2017-05-22 11:35:30,103 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_7480557121737703942_1949 to /192.168.1.158:50010
2017-05-22 11:40:24,241 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3343450038431691928_1953 src: /192.168.1.158:60346 dest: /192.168.1.158:50010
2017-05-22 11:40:24,243 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3343450038431691928_1953 src: /192.168.1.158:60346 dest: /192.168.1.158:50010 of size 23547
2017-05-22 11:40:30,414 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2909816760453438137_1946 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2909816760453438137
2017-05-22 11:40:30,415 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1738351148532787474_1945 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1738351148532787474
2017-05-22 11:40:30,415 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3343450038431691928_1953 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3343450038431691928
2017-05-22 11:40:30,416 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3652779018580997898_1947 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3652779018580997898
2017-05-22 11:40:30,416 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7480557121737703942_1949 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7480557121737703942
2017-05-22 11:40:35,201 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 11:40:46,122 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 11:40:46,341 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 11:40:46,343 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 11:40:46,345 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 11:40:46,415 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 11:40:46,474 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 11:40:46,474 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 11:40:46,474 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 11:40:46,711 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 11:40:46,748 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 11:40:46,750 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 11:40:46,751 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 11:40:46,755 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 11:40:46,770 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 11:40:46,775 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 11:40:46,775 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 11:40:46,776 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 11:40:46,777 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 11:40:46,777 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 11:40:46,777 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 11:40:46,780 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 11:40:46,780 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 11:40:46,789 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 11:40:49,788 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 11:40:52,799 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 6 msecs
2017-05-22 11:41:52,877 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_700186441600617080_1956 src: /192.168.1.156:54813 dest: /192.168.1.156:50010
2017-05-22 11:41:52,893 INFO org.apache.hadoop.dfs.DataNode: Received block blk_700186441600617080_1956 src: /192.168.1.156:54813 dest: /192.168.1.156:50010 of size 13568
2017-05-22 11:41:55,867 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_700186441600617080_1956 to 192.168.1.157:50010
2017-05-22 11:41:55,877 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_700186441600617080_1956 to /192.168.1.157:50010
2017-05-22 11:41:58,841 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2440100797092893985_1955 src: /192.168.1.157:42497 dest: /192.168.1.157:50010
2017-05-22 11:41:58,844 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2440100797092893985_1955 src: /192.168.1.157:42497 dest: /192.168.1.157:50010 of size 2165
2017-05-22 11:41:58,857 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4818119621979746508_1958 src: /192.168.1.156:54824 dest: /192.168.1.156:50010
2017-05-22 11:41:58,860 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4818119621979746508_1958 src: /192.168.1.156:54824 dest: /192.168.1.156:50010 of size 13553
2017-05-22 11:42:01,862 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5905704983458101258_1954 src: /192.168.1.156:54825 dest: /192.168.1.156:50010
2017-05-22 11:42:01,867 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4818119621979746508_1958 to 192.168.1.158:50010
2017-05-22 11:42:01,873 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5905704983458101258_1954 src: /192.168.1.156:54825 dest: /192.168.1.156:50010 of size 91176
2017-05-22 11:42:01,875 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_4818119621979746508_1958 to /192.168.1.158:50010
2017-05-22 11:42:04,876 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_5905704983458101258_1954 to 192.168.1.158:50010
2017-05-22 11:42:04,884 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_5905704983458101258_1954 to /192.168.1.158:50010
2017-05-22 11:47:05,047 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6512538566040844260_1962 src: /192.168.1.158:60349 dest: /192.168.1.158:50010
2017-05-22 11:47:05,049 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6512538566040844260_1962 src: /192.168.1.158:60349 dest: /192.168.1.158:50010 of size 23547
2017-05-22 11:47:08,175 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6512538566040844260_1962 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6512538566040844260
2017-05-22 11:47:08,175 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_700186441600617080_1956 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_700186441600617080
2017-05-22 11:47:08,176 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2440100797092893985_1955 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2440100797092893985
2017-05-22 11:47:08,176 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4818119621979746508_1958 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4818119621979746508
2017-05-22 11:47:08,177 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5905704983458101258_1954 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5905704983458101258
2017-05-22 11:47:14,907 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 11:47:25,779 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 11:47:25,973 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 11:47:25,975 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 11:47:25,977 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 11:47:26,049 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 11:47:26,107 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 11:47:26,108 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 11:47:26,108 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 11:47:26,345 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 11:47:26,383 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 11:47:26,398 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 11:47:26,398 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 11:47:26,403 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 11:47:26,420 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 11:47:26,424 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 11:47:26,424 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 11:47:26,425 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 11:47:26,426 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 11:47:26,426 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 11:47:26,426 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 11:47:26,428 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 11:47:26,429 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 11:47:26,438 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 11:47:29,435 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 6 msecs
2017-05-22 11:48:32,476 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3809692110246928226_1967 src: /192.168.1.157:42500 dest: /192.168.1.157:50010
2017-05-22 11:48:32,488 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3809692110246928226_1967 src: /192.168.1.157:42500 dest: /192.168.1.157:50010 of size 13553
2017-05-22 11:48:35,514 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-3809692110246928226_1967 to 192.168.1.158:50010
2017-05-22 11:48:35,523 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-3809692110246928226_1967 to /192.168.1.158:50010
2017-05-22 11:48:38,475 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3309474223285923337_1963 src: /192.168.1.157:42502 dest: /192.168.1.157:50010
2017-05-22 11:48:38,483 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3309474223285923337_1963 src: /192.168.1.157:42502 dest: /192.168.1.157:50010 of size 91176
2017-05-22 11:48:41,418 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4057198837449594012_1964 src: /192.168.1.156:54965 dest: /192.168.1.156:50010
2017-05-22 11:48:41,419 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4057198837449594012_1964 src: /192.168.1.156:54965 dest: /192.168.1.156:50010 of size 2165
2017-05-22 11:48:41,466 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1628694580661546344_1965 src: /192.168.1.158:60352 dest: /192.168.1.158:50010
2017-05-22 11:48:41,469 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1628694580661546344_1965 src: /192.168.1.158:60352 dest: /192.168.1.158:50010 of size 13568
2017-05-22 11:50:25,849 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-3309474223285923337_1963
2017-05-22 11:53:44,544 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4453749468976929047_1971 src: /192.168.1.158:60353 dest: /192.168.1.158:50010
2017-05-22 11:53:44,545 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4453749468976929047_1971 src: /192.168.1.158:60353 dest: /192.168.1.158:50010 of size 23547
2017-05-22 11:53:47,813 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3809692110246928226_1967 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3809692110246928226
2017-05-22 11:53:47,813 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3309474223285923337_1963 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3309474223285923337
2017-05-22 11:53:47,814 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1628694580661546344_1965 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1628694580661546344
2017-05-22 11:53:47,814 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4057198837449594012_1964 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4057198837449594012
2017-05-22 11:53:55,454 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 11:54:06,159 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 11:54:06,348 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 11:54:06,350 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 11:54:06,352 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 11:54:06,419 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 11:54:06,475 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 11:54:06,476 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 11:54:06,476 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 11:54:06,711 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 11:54:06,750 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 11:54:06,753 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 11:54:06,753 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 11:54:06,758 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 11:54:06,775 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 11:54:06,780 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 11:54:06,781 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 11:54:06,782 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 11:54:06,783 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 11:54:06,783 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 11:54:06,784 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 11:54:06,786 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 11:54:06,786 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 11:54:06,795 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 11:54:06,842 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-4453749468976929047_1971
2017-05-22 11:54:09,795 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 9 msecs
2017-05-22 11:54:42,869 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4453749468976929047_1971 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4453749468976929047
2017-05-22 11:55:06,935 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8784377756517057393_1973 src: /192.168.1.157:42506 dest: /192.168.1.157:50010
2017-05-22 11:55:06,949 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8784377756517057393_1973 src: /192.168.1.157:42506 dest: /192.168.1.157:50010 of size 1085
2017-05-22 11:55:09,888 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8784377756517057393_1973 to 192.168.1.158:50010
2017-05-22 11:55:09,896 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-8784377756517057393_1973 to /192.168.1.158:50010
2017-05-22 11:55:12,881 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-43181190956740508_1972 src: /192.168.1.156:55094 dest: /192.168.1.156:50010
2017-05-22 11:55:12,885 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-43181190956740508_1972 src: /192.168.1.156:55094 dest: /192.168.1.156:50010 of size 91176
2017-05-22 11:55:12,932 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3776408035601762911_1976 src: /192.168.1.158:60356 dest: /192.168.1.158:50010
2017-05-22 11:55:12,933 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3776408035601762911_1976 src: /192.168.1.158:60356 dest: /192.168.1.158:50010 of size 13554
2017-05-22 11:55:15,877 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1102140828290981738_1974 src: /192.168.1.156:55095 dest: /192.168.1.156:50010
2017-05-22 11:55:15,879 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1102140828290981738_1974 src: /192.168.1.156:55095 dest: /192.168.1.156:50010 of size 13569
2017-05-22 12:00:34,026 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8784377756517057393_1973 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8784377756517057393
2017-05-22 12:00:34,027 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3776408035601762911_1976 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3776408035601762911
2017-05-22 12:00:34,027 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-43181190956740508_1972 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-43181190956740508
2017-05-22 12:00:34,028 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1102140828290981738_1974 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1102140828290981738
2017-05-22 12:00:40,044 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-22 12:00:40,113 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 12:00:50,942 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 12:00:51,127 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 12:00:51,129 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 12:00:51,130 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 12:00:51,194 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 12:00:51,242 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 12:00:51,243 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 12:00:51,243 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 12:00:51,470 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 12:00:51,508 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 12:00:51,523 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 12:00:51,523 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 12:00:51,531 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 12:00:51,550 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 12:00:51,557 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 12:00:51,557 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 12:00:51,558 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 12:00:51,558 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 12:00:51,559 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 12:00:51,559 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 12:00:51,566 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 12:00:51,567 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 12:00:51,587 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 12:00:54,583 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-22 12:01:57,722 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8848256247224480896_1982 src: /192.168.1.157:42512 dest: /192.168.1.157:50010
2017-05-22 12:01:57,734 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8848256247224480896_1982 src: /192.168.1.157:42512 dest: /192.168.1.157:50010 of size 1085
2017-05-22 12:02:00,646 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8848256247224480896_1982 to 192.168.1.158:50010
2017-05-22 12:02:00,657 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-8848256247224480896_1982 to /192.168.1.158:50010
2017-05-22 12:02:03,628 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2317123234334943727_1983 src: /192.168.1.157:42513 dest: /192.168.1.157:50010
2017-05-22 12:02:03,632 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2317123234334943727_1983 src: /192.168.1.157:42513 dest: /192.168.1.157:50010 of size 13569
2017-05-22 12:02:03,682 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-820720474199248958_1981 src: /192.168.1.156:55188 dest: /192.168.1.156:50010
2017-05-22 12:02:03,689 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-820720474199248958_1981 src: /192.168.1.156:55188 dest: /192.168.1.156:50010 of size 91176
2017-05-22 12:02:06,653 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-820720474199248958_1981 to 192.168.1.157:50010
2017-05-22 12:02:06,661 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-820720474199248958_1981 to /192.168.1.157:50010
2017-05-22 12:02:09,685 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8951948973990029984_1985 src: /192.168.1.156:55192 dest: /192.168.1.156:50010
2017-05-22 12:02:09,686 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8951948973990029984_1985 src: /192.168.1.156:55192 dest: /192.168.1.156:50010 of size 13554
2017-05-22 12:07:18,982 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8848256247224480896_1982 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8848256247224480896
2017-05-22 12:07:18,982 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2317123234334943727_1983 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2317123234334943727
2017-05-22 12:07:18,983 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-820720474199248958_1981 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-820720474199248958
2017-05-22 12:07:18,983 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8951948973990029984_1985 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8951948973990029984
2017-05-22 12:07:24,840 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 12:07:35,648 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 12:07:35,847 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 12:07:35,849 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 12:07:35,851 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 12:07:35,925 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 12:07:35,987 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 12:07:35,988 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 12:07:35,988 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 12:07:36,206 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 12:07:36,245 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 12:07:36,249 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 12:07:36,249 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 12:07:36,254 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 12:07:36,271 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 12:07:36,276 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 12:07:36,277 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 12:07:36,278 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 12:07:36,279 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 12:07:36,279 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 12:07:36,279 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 12:07:36,282 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 12:07:36,282 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 12:07:36,290 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 12:07:39,292 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 12:08:42,386 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6726249528279714876_1991 src: /192.168.1.156:55282 dest: /192.168.1.156:50010
2017-05-22 12:08:42,401 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6726249528279714876_1991 src: /192.168.1.156:55282 dest: /192.168.1.156:50010 of size 1085
2017-05-22 12:08:45,361 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6726249528279714876_1991 to 192.168.1.157:50010
2017-05-22 12:08:45,370 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-6726249528279714876_1991 to /192.168.1.157:50010
2017-05-22 12:08:48,356 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5579634416972556171_1994 src: /192.168.1.157:42517 dest: /192.168.1.157:50010
2017-05-22 12:08:48,358 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5579634416972556171_1994 src: /192.168.1.157:42517 dest: /192.168.1.157:50010 of size 13554
2017-05-22 12:08:51,228 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2796875169863780825_1990 src: /192.168.1.158:60361 dest: /192.168.1.158:50010
2017-05-22 12:08:51,236 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2796875169863780825_1990 src: /192.168.1.158:60361 dest: /192.168.1.158:50010 of size 91176
2017-05-22 12:08:51,371 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6783689899475743203_1992 src: /192.168.1.156:55289 dest: /192.168.1.156:50010
2017-05-22 12:08:51,372 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6783689899475743203_1992 src: /192.168.1.156:55289 dest: /192.168.1.156:50010 of size 13569
2017-05-22 12:08:54,365 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_6783689899475743203_1992 to 192.168.1.157:50010
2017-05-22 12:08:54,369 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_6783689899475743203_1992 to /192.168.1.157:50010
2017-05-22 12:14:09,682 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6726249528279714876_1991 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6726249528279714876
2017-05-22 12:14:09,682 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2796875169863780825_1990 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2796875169863780825
2017-05-22 12:14:09,683 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6783689899475743203_1992 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6783689899475743203
2017-05-22 12:14:12,693 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5579634416972556171_1994 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5579634416972556171
2017-05-22 12:17:36,933 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 5 msecs
2017-05-22 13:17:39,571 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-22 14:17:39,632 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-22 15:02:09,760 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:02:20,627 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:02:20,817 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:02:20,819 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:02:20,821 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:02:20,882 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:02:20,928 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:02:20,929 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:02:20,929 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:02:21,143 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 15:02:21,181 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:02:21,184 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:02:21,184 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 15:02:21,189 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:02:21,206 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:02:21,211 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:02:21,211 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:02:21,213 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:02:21,213 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:02:21,220 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:02:21,220 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:02:21,222 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:02:21,223 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:02:21,231 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:02:24,231 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 15:03:21,325 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2461549613430229790_1999 src: /192.168.1.158:60369 dest: /192.168.1.158:50010
2017-05-22 15:03:21,337 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2461549613430229790_1999 src: /192.168.1.158:60369 dest: /192.168.1.158:50010 of size 91176
2017-05-22 15:03:21,397 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7213783647631088312_2003 src: /192.168.1.157:42528 dest: /192.168.1.157:50010
2017-05-22 15:03:21,399 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7213783647631088312_2003 src: /192.168.1.157:42528 dest: /192.168.1.157:50010 of size 13545
2017-05-22 15:03:24,392 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1166325698480259740_2000 src: /192.168.1.157:42532 dest: /192.168.1.157:50010
2017-05-22 15:03:24,393 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_115341720249567620_2001 src: /192.168.1.157:42533 dest: /192.168.1.157:50010
2017-05-22 15:03:24,394 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1166325698480259740_2000 src: /192.168.1.157:42532 dest: /192.168.1.157:50010 of size 8645
2017-05-22 15:03:24,396 INFO org.apache.hadoop.dfs.DataNode: Received block blk_115341720249567620_2001 src: /192.168.1.157:42533 dest: /192.168.1.157:50010 of size 13560
2017-05-22 15:03:35,043 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 15:03:41,490 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 15:04:58,368 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 15:05:09,101 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 15:05:23,934 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 15:06:27,334 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2219516759360331770_2003 src: /192.168.1.156:55490 dest: /192.168.1.156:50010
2017-05-22 15:06:27,335 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2219516759360331770_2003 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 15:06:27,337 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:06:30,363 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7213783647631088312_2003 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7213783647631088312
2017-05-22 15:06:30,363 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2461549613430229790_1999 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2461549613430229790
2017-05-22 15:06:30,364 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1166325698480259740_2000 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1166325698480259740
2017-05-22 15:06:30,364 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_115341720249567620_2001 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_115341720249567620
2017-05-22 15:06:37,502 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:06:48,370 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:06:48,564 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:06:48,566 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:06:48,568 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:06:48,633 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:06:48,684 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:06:48,685 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:06:48,685 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:06:48,925 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 15:06:48,963 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:06:48,970 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:06:48,970 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 15:06:48,977 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:06:49,001 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:06:49,008 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:06:49,009 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:06:49,010 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:06:49,010 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:06:49,010 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:06:49,011 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:06:49,014 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:06:49,015 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:06:49,023 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:06:52,025 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 15:07:54,998 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4762740809558256606_2008 src: /192.168.1.158:60480 dest: /192.168.1.158:50010
2017-05-22 15:07:55,003 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1361732753205174058_2009 src: /192.168.1.156:55501 dest: /192.168.1.156:50010
2017-05-22 15:07:55,015 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4762740809558256606_2008 src: /192.168.1.158:60480 dest: /192.168.1.158:50010 of size 91176
2017-05-22 15:07:55,017 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1361732753205174058_2009 src: /192.168.1.156:55501 dest: /192.168.1.156:50010 of size 8645
2017-05-22 15:07:57,981 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7325144735353189938_2010 src: /192.168.1.157:42656 dest: /192.168.1.157:50010
2017-05-22 15:07:57,983 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7325144735353189938_2010 src: /192.168.1.157:42656 dest: /192.168.1.157:50010 of size 13560
2017-05-22 15:07:57,985 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7325144735353189938_2010 src: /192.168.1.157:42657 dest: /192.168.1.157:50010
2017-05-22 15:07:57,985 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7325144735353189938_2010 received exception java.io.IOException: Block blk_-7325144735353189938_2010 is valid, and cannot be written to.
2017-05-22 15:07:57,987 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-7325144735353189938_2010 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:07:58,001 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6070896095606127596_2012 src: /192.168.1.156:55502 dest: /192.168.1.156:50010
2017-05-22 15:07:58,002 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6070896095606127596_2012 src: /192.168.1.156:55502 dest: /192.168.1.156:50010 of size 13545
2017-05-22 15:07:58,004 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6070896095606127596_2012 src: /192.168.1.156:55503 dest: /192.168.1.156:50010
2017-05-22 15:07:58,005 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6070896095606127596_2012 received exception java.io.IOException: Block blk_6070896095606127596_2012 is valid, and cannot be written to.
2017-05-22 15:07:58,006 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_6070896095606127596_2012 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:07:59,427 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 15:08:01,075 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_6070896095606127596_2012 to 192.168.1.158:50010
2017-05-22 15:08:01,080 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_6070896095606127596_2012 to /192.168.1.158:50010
2017-05-22 15:08:02,033 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 15:09:32,118 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 15:09:41,699 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 15:09:55,465 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 15:11:04,105 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4520155837597869303_2012 src: /192.168.1.156:55622 dest: /192.168.1.156:50010
2017-05-22 15:11:04,106 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-4520155837597869303_2012 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 15:11:04,106 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:11:07,145 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7325144735353189938_2010 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7325144735353189938
2017-05-22 15:11:07,145 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4762740809558256606_2008 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4762740809558256606
2017-05-22 15:11:07,146 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1361732753205174058_2009 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1361732753205174058
2017-05-22 15:11:07,146 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6070896095606127596_2012 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6070896095606127596
2017-05-22 15:11:14,180 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:11:25,112 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:11:25,346 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:11:25,348 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:11:25,350 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:11:25,419 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:11:25,477 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:11:25,478 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:11:25,478 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:11:25,714 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 15:11:25,752 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:11:25,755 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:11:25,755 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 15:11:25,760 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:11:25,777 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:11:25,783 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:11:25,783 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:11:25,785 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:11:25,786 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:11:25,786 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:11:25,786 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:11:25,791 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:11:25,791 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:11:25,800 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:11:28,798 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 15:12:31,786 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7624416548139547251_2018 src: /192.168.1.158:60579 dest: /192.168.1.158:50010
2017-05-22 15:12:31,793 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7310342133455581153_2017 src: /192.168.1.158:60580 dest: /192.168.1.158:50010
2017-05-22 15:12:31,815 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7310342133455581153_2017 src: /192.168.1.158:60580 dest: /192.168.1.158:50010 of size 91176
2017-05-22 15:12:31,815 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7624416548139547251_2018 src: /192.168.1.158:60579 dest: /192.168.1.158:50010 of size 8645
2017-05-22 15:12:34,771 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-121641818793508127_2021 src: /192.168.1.156:55637 dest: /192.168.1.156:50010
2017-05-22 15:12:34,773 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-121641818793508127_2021 src: /192.168.1.156:55637 dest: /192.168.1.156:50010 of size 13545
2017-05-22 15:12:34,774 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8090647293035473783_2019 src: /192.168.1.156:55638 dest: /192.168.1.156:50010
2017-05-22 15:12:34,775 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8090647293035473783_2019 src: /192.168.1.156:55638 dest: /192.168.1.156:50010 of size 13560
2017-05-22 15:12:34,777 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-121641818793508127_2021 src: /192.168.1.157:42775 dest: /192.168.1.157:50010
2017-05-22 15:12:34,778 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-121641818793508127_2021 received exception java.io.IOException: Block blk_-121641818793508127_2021 is valid, and cannot be written to.
2017-05-22 15:12:34,779 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-121641818793508127_2021 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:13:12,450 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 15:13:19,220 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 15:13:25,966 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 15:13:32,725 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 15:13:39,519 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 15:13:52,818 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 15:14:06,412 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 15:14:17,137 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 15:15:34,994 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8090647293035473783_2019 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8090647293035473783
2017-05-22 15:15:34,995 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7624416548139547251_2018 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7624416548139547251
2017-05-22 15:15:34,995 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-121641818793508127_2021 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-121641818793508127
2017-05-22 15:15:34,996 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7310342133455581153_2017 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7310342133455581153
2017-05-22 15:15:43,678 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:15:54,636 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:15:54,844 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:15:54,846 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:15:54,848 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:15:54,910 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:15:54,960 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:15:54,961 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:15:54,961 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:15:55,170 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 15:15:55,205 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:15:55,207 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:15:55,207 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 15:15:55,213 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:15:55,229 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:15:55,234 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:15:55,234 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:15:55,235 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:15:55,236 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:15:55,236 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:15:55,236 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:15:55,238 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:15:55,239 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:15:55,245 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:15:58,246 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 15:16:55,282 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2092199402548294723_2026 src: /192.168.1.156:55770 dest: /192.168.1.156:50010
2017-05-22 15:16:55,297 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1928964488364323047_2028 src: /192.168.1.158:60666 dest: /192.168.1.158:50010
2017-05-22 15:16:55,299 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2092199402548294723_2026 src: /192.168.1.156:55770 dest: /192.168.1.156:50010 of size 91176
2017-05-22 15:16:55,304 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1928964488364323047_2028 src: /192.168.1.158:60666 dest: /192.168.1.158:50010 of size 13560
2017-05-22 15:16:58,239 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7455593751470297456_2027 src: /192.168.1.157:42898 dest: /192.168.1.157:50010
2017-05-22 15:16:58,240 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7455593751470297456_2027 src: /192.168.1.157:42898 dest: /192.168.1.157:50010 of size 4325
2017-05-22 15:16:58,241 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6051257787785829338_2030 src: /192.168.1.157:42899 dest: /192.168.1.157:50010
2017-05-22 15:16:58,242 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6051257787785829338_2030 src: /192.168.1.157:42899 dest: /192.168.1.157:50010 of size 13545
2017-05-22 15:16:58,245 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6051257787785829338_2030 src: /192.168.1.156:55775 dest: /192.168.1.156:50010
2017-05-22 15:16:58,245 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6051257787785829338_2030 received exception java.io.IOException: Block blk_6051257787785829338_2030 is valid, and cannot be written to.
2017-05-22 15:16:58,247 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_6051257787785829338_2030 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:17:01,279 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_6051257787785829338_2030 to 192.168.1.158:50010
2017-05-22 15:17:01,284 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_6051257787785829338_2030 to /192.168.1.158:50010
2017-05-22 15:17:04,523 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 15:17:16,285 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 28 blocks got processed in 5 msecs
2017-05-22 15:17:17,119 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 15:17:29,189 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 15:17:33,418 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 15:17:45,203 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 15:18:04,749 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 15:18:08,777 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 15:18:26,429 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 15:18:39,384 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 15:19:34,308 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2103447124209229898_2034 src: /192.168.1.156:55868 dest: /192.168.1.156:50010
2017-05-22 15:19:34,308 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2103447124209229898_2034 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 15:19:34,309 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:19:37,370 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2092199402548294723_2026 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2092199402548294723
2017-05-22 15:19:37,371 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1928964488364323047_2028 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1928964488364323047
2017-05-22 15:19:37,371 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6051257787785829338_2030 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6051257787785829338
2017-05-22 15:19:37,372 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7455593751470297456_2027 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7455593751470297456
2017-05-22 15:19:44,492 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:19:55,267 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:19:55,459 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:19:55,461 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:19:55,463 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:19:55,541 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:19:55,602 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:19:55,603 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:19:55,603 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:19:55,839 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 15:19:55,876 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:19:55,880 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:19:55,880 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 15:19:55,885 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:19:55,903 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:19:55,908 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:19:55,909 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:19:55,909 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:19:55,910 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:19:55,910 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:19:55,910 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:19:55,924 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:19:55,924 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:19:55,943 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:19:58,938 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-05-22 15:21:01,335 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 15:21:01,998 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_409904461895671188_2037 src: /192.168.1.157:43007 dest: /192.168.1.157:50010
2017-05-22 15:21:02,017 INFO org.apache.hadoop.dfs.DataNode: Received block blk_409904461895671188_2037 src: /192.168.1.157:43007 dest: /192.168.1.157:50010 of size 13560
2017-05-22 15:21:02,074 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8371818517604058542_2035 src: /192.168.1.156:55880 dest: /192.168.1.156:50010
2017-05-22 15:21:02,079 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8371818517604058542_2035 src: /192.168.1.156:55880 dest: /192.168.1.156:50010 of size 91176
2017-05-22 15:21:04,999 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4300107830240987750_2036 src: /192.168.1.157:43009 dest: /192.168.1.157:50010
2017-05-22 15:21:05,000 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4300107830240987750_2036 src: /192.168.1.157:43009 dest: /192.168.1.157:50010 of size 4325
2017-05-22 15:21:05,070 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4418035928894847339_2039 src: /192.168.1.156:55881 dest: /192.168.1.156:50010
2017-05-22 15:21:05,072 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4418035928894847339_2039 src: /192.168.1.156:55881 dest: /192.168.1.156:50010 of size 13545
2017-05-22 15:21:15,083 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 15:21:26,852 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 15:21:38,646 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 15:21:58,296 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 15:22:09,731 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 15:22:15,255 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 15:22:27,043 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 15:22:46,471 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 15:23:59,163 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3371153816534739650_2043 src: /192.168.1.156:55983 dest: /192.168.1.156:50010
2017-05-22 15:23:59,165 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3371153816534739650_2043 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 15:23:59,166 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:24:02,074 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8371818517604058542_2035 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8371818517604058542
2017-05-22 15:24:02,074 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4418035928894847339_2039 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4418035928894847339
2017-05-22 15:24:02,075 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_409904461895671188_2037 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_409904461895671188
2017-05-22 15:24:02,075 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4300107830240987750_2036 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4300107830240987750
2017-05-22 15:24:09,169 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:24:19,992 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:24:20,176 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:24:20,177 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:24:20,179 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:24:20,248 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:24:20,305 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:24:20,306 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:24:20,306 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:24:20,540 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 15:24:20,572 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:24:20,574 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:24:20,574 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 15:24:20,579 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:24:20,595 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:24:20,599 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:24:20,600 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:24:20,602 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:24:20,603 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:24:20,603 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:24:20,604 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:24:20,628 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:24:20,628 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:24:20,640 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:24:23,644 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 16 msecs
2017-05-22 15:25:26,694 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7347227658056014528_2048 src: /192.168.1.158:60850 dest: /192.168.1.158:50010
2017-05-22 15:25:26,707 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7347227658056014528_2048 src: /192.168.1.158:60850 dest: /192.168.1.158:50010 of size 13545
2017-05-22 15:25:26,768 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1229499236865284914_2044 src: /192.168.1.158:60851 dest: /192.168.1.158:50010
2017-05-22 15:25:26,774 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1229499236865284914_2044 src: /192.168.1.158:60851 dest: /192.168.1.158:50010 of size 91176
2017-05-22 15:25:29,679 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1394743437588288129_2045 src: /192.168.1.157:43118 dest: /192.168.1.157:50010
2017-05-22 15:25:29,680 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1394743437588288129_2045 src: /192.168.1.157:43118 dest: /192.168.1.157:50010 of size 4325
2017-05-22 15:25:29,766 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8833627718689202735_2046 src: /192.168.1.156:55998 dest: /192.168.1.156:50010
2017-05-22 15:25:29,767 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8833627718689202735_2046 src: /192.168.1.156:55998 dest: /192.168.1.156:50010 of size 13560
2017-05-22 15:25:34,461 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 15:25:46,902 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 15:25:58,837 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 15:26:02,241 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 15:26:13,983 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 15:26:25,783 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 15:26:36,612 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 15:26:49,897 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 15:27:09,435 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 15:28:17,853 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5563711559078104602_2052 src: /192.168.1.156:56093 dest: /192.168.1.156:50010
2017-05-22 15:28:17,854 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5563711559078104602_2052 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 15:28:17,856 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:28:20,880 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8833627718689202735_2046 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8833627718689202735
2017-05-22 15:28:20,881 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7347227658056014528_2048 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7347227658056014528
2017-05-22 15:28:20,881 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1394743437588288129_2045 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1394743437588288129
2017-05-22 15:28:20,882 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1229499236865284914_2044 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1229499236865284914
2017-05-22 15:28:29,627 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:28:40,389 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:28:40,574 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:28:40,576 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:28:40,578 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:28:40,641 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:28:40,689 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:28:40,690 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:28:40,690 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:28:40,903 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 15:28:40,941 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:28:40,944 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:28:40,944 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 15:28:40,949 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:28:40,972 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:28:40,978 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:28:40,979 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:28:40,980 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:28:40,980 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:28:40,980 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:28:40,980 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:28:40,996 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:28:40,997 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:28:41,009 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:28:44,014 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-05-22 15:29:41,120 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3582426377659832647_2053 src: /192.168.1.157:43222 dest: /192.168.1.157:50010
2017-05-22 15:29:41,137 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3582426377659832647_2053 src: /192.168.1.157:43222 dest: /192.168.1.157:50010 of size 91176
2017-05-22 15:29:41,212 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7181251408431727760_2055 src: /192.168.1.158:60935 dest: /192.168.1.158:50010
2017-05-22 15:29:41,214 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7181251408431727760_2055 src: /192.168.1.158:60935 dest: /192.168.1.158:50010 of size 13567
2017-05-22 15:29:44,081 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3297305184944385569_2054 src: /192.168.1.157:43227 dest: /192.168.1.157:50010
2017-05-22 15:29:44,081 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3297305184944385569_2054 src: /192.168.1.157:43226 dest: /192.168.1.157:50010
2017-05-22 15:29:44,082 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3297305184944385569_2054 received exception java.io.IOException: Block blk_3297305184944385569_2054 has already been started (though not completed), and thus cannot be created.
2017-05-22 15:29:44,083 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3297305184944385569_2054 src: /192.168.1.157:43227 dest: /192.168.1.157:50010 of size 4325
2017-05-22 15:29:44,085 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_3297305184944385569_2054 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:29:47,065 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_3297305184944385569_2054 to 192.168.1.158:50010
2017-05-22 15:29:47,071 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_3297305184944385569_2054 to /192.168.1.158:50010
2017-05-22 15:29:47,152 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5217228461299344635_2057 src: /192.168.1.158:60938 dest: /192.168.1.158:50010
2017-05-22 15:29:47,154 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5217228461299344635_2057 src: /192.168.1.158:60938 dest: /192.168.1.158:50010 of size 13552
2017-05-22 15:30:04,575 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 15:30:16,443 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 15:30:28,226 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 15:30:39,726 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 15:30:51,347 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 15:32:35,145 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2459905050445567518_2061 src: /192.168.1.157:43322 dest: /192.168.1.157:50010
2017-05-22 15:32:35,152 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2459905050445567518_2061 src: /192.168.1.157:43322 dest: /192.168.1.157:50010 of size 43809
2017-05-22 15:32:38,152 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7181251408431727760_2055 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7181251408431727760
2017-05-22 15:32:38,153 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3297305184944385569_2054 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3297305184944385569
2017-05-22 15:32:38,153 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3582426377659832647_2053 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3582426377659832647
2017-05-22 15:32:38,154 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5217228461299344635_2057 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5217228461299344635
2017-05-22 15:32:44,205 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-22 15:32:44,249 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:32:55,068 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:32:55,254 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:32:55,256 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:32:55,257 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:32:55,333 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:32:55,390 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:32:55,391 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:32:55,391 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:32:55,633 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 15:32:55,672 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:32:55,676 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:32:55,676 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 15:32:55,681 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:32:55,698 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:32:55,703 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:32:55,704 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:32:55,705 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:32:55,706 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:32:55,706 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:32:55,707 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:32:55,709 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:32:55,709 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:32:55,716 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:32:55,760 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-2459905050445567518_2061
2017-05-22 15:32:58,717 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 8 msecs
2017-05-22 15:33:31,796 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2459905050445567518_2061 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2459905050445567518
2017-05-22 15:34:01,712 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8885829544359027943_2066 src: /192.168.1.158:32773 dest: /192.168.1.158:50010
2017-05-22 15:34:01,720 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8885829544359027943_2066 src: /192.168.1.158:32773 dest: /192.168.1.158:50010 of size 13552
2017-05-22 15:34:01,776 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8114434076232762351_2062 src: /192.168.1.158:32774 dest: /192.168.1.158:50010
2017-05-22 15:34:01,781 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8114434076232762351_2062 src: /192.168.1.158:32774 dest: /192.168.1.158:50010 of size 91176
2017-05-22 15:34:04,703 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5265590383730832334_2063 src: /192.168.1.157:43337 dest: /192.168.1.157:50010
2017-05-22 15:34:04,705 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5265590383730832334_2063 src: /192.168.1.157:43337 dest: /192.168.1.157:50010 of size 4325
2017-05-22 15:34:04,775 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5265590383730832334_2063 src: /192.168.1.156:56222 dest: /192.168.1.156:50010
2017-05-22 15:34:04,775 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-5265590383730832334_2063 received exception java.io.IOException: Block blk_-5265590383730832334_2063 is valid, and cannot be written to.
2017-05-22 15:34:04,777 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-5265590383730832334_2063 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:34:07,702 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_182946611346466739_2064 src: /192.168.1.157:43340 dest: /192.168.1.157:50010
2017-05-22 15:34:07,703 INFO org.apache.hadoop.dfs.DataNode: Received block blk_182946611346466739_2064 src: /192.168.1.157:43340 dest: /192.168.1.157:50010 of size 13567
2017-05-22 15:34:24,386 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 15:34:35,660 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 15:34:47,643 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 15:34:58,991 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 15:37:01,931 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5265590383730832334_2063 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5265590383730832334
2017-05-22 15:37:01,932 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_182946611346466739_2064 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_182946611346466739
2017-05-22 15:37:01,932 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8114434076232762351_2062 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8114434076232762351
2017-05-22 15:37:04,933 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8885829544359027943_2066 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8885829544359027943
2017-05-22 15:37:11,918 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:37:22,705 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:37:22,889 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:37:22,891 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:37:22,892 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:37:22,961 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:37:23,022 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:37:23,023 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:37:23,023 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:37:23,251 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 15:37:23,285 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:37:23,287 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:37:23,287 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 15:37:23,292 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:37:23,308 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:37:23,313 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:37:23,314 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:37:23,315 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:37:23,315 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:37:23,316 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:37:23,316 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:37:23,330 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:37:23,331 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:37:23,342 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:37:26,350 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-22 15:38:29,380 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2075118465375183020_2071 src: /192.168.1.157:43462 dest: /192.168.1.157:50010
2017-05-22 15:38:29,400 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2075118465375183020_2071 src: /192.168.1.157:43462 dest: /192.168.1.157:50010 of size 91176
2017-05-22 15:38:29,432 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6945809389299658992_2075 src: /192.168.1.156:56334 dest: /192.168.1.156:50010
2017-05-22 15:38:29,435 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6945809389299658992_2075 src: /192.168.1.156:56334 dest: /192.168.1.156:50010 of size 13552
2017-05-22 15:38:32,428 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4947500966001278767_2073 src: /192.168.1.156:56335 dest: /192.168.1.156:50010
2017-05-22 15:38:32,429 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4947500966001278767_2073 src: /192.168.1.156:56335 dest: /192.168.1.156:50010 of size 13567
2017-05-22 15:38:35,379 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7512483044676010483_2072 src: /192.168.1.157:43465 dest: /192.168.1.157:50010
2017-05-22 15:38:35,381 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7512483044676010483_2072 src: /192.168.1.157:43465 dest: /192.168.1.157:50010 of size 4325
2017-05-22 15:38:51,438 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 15:39:03,351 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 15:39:15,179 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 15:39:26,385 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 15:41:23,528 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2670086571967910175_2079 src: /192.168.1.156:56432 dest: /192.168.1.156:50010
2017-05-22 15:41:23,544 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2670086571967910175_2079 src: /192.168.1.156:56432 dest: /192.168.1.156:50010 of size 42313
2017-05-22 15:41:26,553 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7512483044676010483_2072 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7512483044676010483
2017-05-22 15:41:26,553 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6945809389299658992_2075 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6945809389299658992
2017-05-22 15:41:26,554 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4947500966001278767_2073 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4947500966001278767
2017-05-22 15:41:26,554 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2075118465375183020_2071 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2075118465375183020
2017-05-22 15:41:34,239 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:41:45,062 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:41:45,260 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:41:45,262 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:41:45,263 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:41:45,331 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:41:45,389 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:41:45,390 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:41:45,390 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:41:45,627 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 15:41:45,665 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:41:45,668 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:41:45,668 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 15:41:45,673 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:41:45,691 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:41:45,695 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:41:45,696 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:41:45,697 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:41:45,698 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:41:45,698 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:41:45,699 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:41:45,701 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:41:45,701 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:41:45,710 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:41:45,754 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_2670086571967910175_2079
2017-05-22 15:41:48,710 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 9 msecs
2017-05-22 15:42:21,746 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2670086571967910175_2079 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2670086571967910175
2017-05-22 15:42:45,715 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3735196899328374320_2080 src: /192.168.1.158:32879 dest: /192.168.1.158:50010
2017-05-22 15:42:45,741 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3735196899328374320_2080 src: /192.168.1.158:32879 dest: /192.168.1.158:50010 of size 91176
2017-05-22 15:42:45,769 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8280689132795721939_2082 src: /192.168.1.158:32880 dest: /192.168.1.158:50010
2017-05-22 15:42:45,770 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8280689132795721939_2082 src: /192.168.1.158:32880 dest: /192.168.1.158:50010 of size 13560
2017-05-22 15:42:46,039 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 15:42:48,695 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1289550100121827591_2084 src: /192.168.1.156:56448 dest: /192.168.1.156:50010
2017-05-22 15:42:48,695 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7323806628822237366_2081 src: /192.168.1.156:56447 dest: /192.168.1.156:50010
2017-05-22 15:42:48,698 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1289550100121827591_2084 src: /192.168.1.156:56448 dest: /192.168.1.156:50010 of size 13545
2017-05-22 15:42:48,700 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7323806628822237366_2081 src: /192.168.1.156:56447 dest: /192.168.1.156:50010 of size 2165
2017-05-22 15:42:48,753 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7323806628822237366_2081 src: /192.168.1.157:43579 dest: /192.168.1.157:50010
2017-05-22 15:42:48,753 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7323806628822237366_2081 received exception java.io.IOException: Block blk_-7323806628822237366_2081 is valid, and cannot be written to.
2017-05-22 15:42:48,755 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-7323806628822237366_2081 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:43:02,405 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 15:43:07,867 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 15:43:24,262 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 15:43:28,701 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 15:43:44,986 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 15:43:49,463 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 15:44:05,149 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 15:44:11,282 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 15:44:27,047 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 15:45:30,761 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5687606950418342830_2089 src: /192.168.1.156:56512 dest: /192.168.1.156:50010
2017-05-22 15:45:30,762 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5687606950418342830_2089 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 15:45:30,762 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:45:33,830 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8280689132795721939_2082 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8280689132795721939
2017-05-22 15:45:33,830 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7323806628822237366_2081 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7323806628822237366
2017-05-22 15:45:33,831 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3735196899328374320_2080 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3735196899328374320
2017-05-22 15:45:33,832 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1289550100121827591_2084 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1289550100121827591
2017-05-22 15:45:40,930 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:45:51,850 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:45:52,046 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:45:52,047 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:45:52,049 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:45:52,115 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:45:52,173 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:45:52,174 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:45:52,174 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:45:52,408 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 15:45:52,443 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:45:52,445 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:45:52,445 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 15:45:52,450 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:45:52,466 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:45:52,470 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:45:52,470 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:45:52,472 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:45:52,472 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:45:52,472 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:45:52,473 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:45:52,475 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:45:52,475 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:45:52,484 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:45:55,485 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 15:46:57,883 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 15:46:58,451 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8499539893316997510_2092 src: /192.168.1.157:43645 dest: /192.168.1.157:50010
2017-05-22 15:46:58,472 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8499539893316997510_2092 src: /192.168.1.157:43645 dest: /192.168.1.157:50010 of size 13560
2017-05-22 15:46:58,591 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5340320187573639638_2090 src: /192.168.1.158:32931 dest: /192.168.1.158:50010
2017-05-22 15:46:58,597 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5340320187573639638_2090 src: /192.168.1.158:32931 dest: /192.168.1.158:50010 of size 91176
2017-05-22 15:47:01,587 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1361449238966455608_2091 src: /192.168.1.156:56527 dest: /192.168.1.156:50010
2017-05-22 15:47:01,588 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1361449238966455608_2091 src: /192.168.1.156:56527 dest: /192.168.1.156:50010 of size 2165
2017-05-22 15:47:01,589 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1361449238966455608_2091 src: /192.168.1.156:56528 dest: /192.168.1.156:50010
2017-05-22 15:47:01,590 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1361449238966455608_2091 received exception java.io.IOException: Block blk_1361449238966455608_2091 is valid, and cannot be written to.
2017-05-22 15:47:01,592 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_1361449238966455608_2091 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:47:04,505 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_1361449238966455608_2091 to 192.168.1.158:50010
2017-05-22 15:47:04,510 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_1361449238966455608_2091 to /192.168.1.158:50010
2017-05-22 15:47:04,538 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-995135734499283889_2094 src: /192.168.1.158:32932 dest: /192.168.1.158:50010
2017-05-22 15:47:04,539 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-995135734499283889_2094 src: /192.168.1.158:32932 dest: /192.168.1.158:50010 of size 13545
2017-05-22 15:47:13,623 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 15:47:19,641 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 15:47:35,631 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 15:47:40,506 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 15:47:56,415 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 15:48:02,273 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 15:48:18,170 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 15:48:23,118 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 15:48:37,906 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 15:49:43,507 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8070865345967986016_2098 src: /192.168.1.157:43716 dest: /192.168.1.157:50010
2017-05-22 15:49:43,510 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8070865345967986016_2098 src: /192.168.1.157:43716 dest: /192.168.1.157:50010 of size 27729
2017-05-22 15:49:46,585 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8499539893316997510_2092 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8499539893316997510
2017-05-22 15:49:46,585 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-995135734499283889_2094 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-995135734499283889
2017-05-22 15:49:46,586 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1361449238966455608_2091 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1361449238966455608
2017-05-22 15:49:46,586 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5340320187573639638_2090 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5340320187573639638
2017-05-22 15:49:46,587 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8070865345967986016_2098 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8070865345967986016
2017-05-22 15:49:53,615 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:50:04,517 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:50:04,709 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:50:04,711 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:50:04,712 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:50:04,773 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:50:04,821 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:50:04,821 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:50:04,821 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:50:05,051 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 15:50:05,088 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:50:05,091 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:50:05,091 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@5876a5
2017-05-22 15:50:05,096 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:50:05,118 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:50:05,123 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:50:05,131 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:50:05,132 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:50:05,135 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:50:05,135 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:50:05,136 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:50:05,137 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:50:05,137 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:50:05,145 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:50:08,147 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 9 msecs
2017-05-22 15:51:10,540 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 15:51:11,163 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8445773307681319186_2099 src: /192.168.1.156:56605 dest: /192.168.1.156:50010
2017-05-22 15:51:11,184 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8445773307681319186_2099 src: /192.168.1.156:56605 dest: /192.168.1.156:50010 of size 91176
2017-05-22 15:51:11,212 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5063782645770212931_2101 src: /192.168.1.158:32987 dest: /192.168.1.158:50010
2017-05-22 15:51:11,213 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5063782645770212931_2101 src: /192.168.1.158:32987 dest: /192.168.1.158:50010 of size 13560
2017-05-22 15:51:14,152 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2062614039290400485_2100 src: /192.168.1.156:56606 dest: /192.168.1.156:50010
2017-05-22 15:51:14,155 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2062614039290400485_2100 src: /192.168.1.156:56606 dest: /192.168.1.156:50010 of size 2165
2017-05-22 15:51:17,210 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6653217360954095594_2103 src: /192.168.1.157:43733 dest: /192.168.1.157:50010
2017-05-22 15:51:17,211 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6653217360954095594_2103 src: /192.168.1.157:43733 dest: /192.168.1.157:50010 of size 13545
2017-05-22 15:51:27,436 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 15:51:33,297 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 15:51:49,460 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 15:51:54,151 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 15:52:09,438 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 15:52:14,928 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 15:52:30,146 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 15:52:34,926 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 15:52:50,867 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 15:52:55,667 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 15:53:10,862 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 15:53:53,269 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3871397594493180030_2107 src: /192.168.1.157:43792 dest: /192.168.1.157:50010
2017-05-22 15:53:53,271 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3871397594493180030_2107 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 15:53:53,273 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:53:56,338 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2062614039290400485_2100 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2062614039290400485
2017-05-22 15:53:56,339 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5063782645770212931_2101 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5063782645770212931
2017-05-22 15:53:56,340 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8445773307681319186_2099 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8445773307681319186
2017-05-22 15:53:59,340 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6653217360954095594_2103 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6653217360954095594
2017-05-22 15:54:06,969 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:54:17,787 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:54:17,974 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:54:17,977 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:54:17,978 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:54:18,041 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:54:18,090 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:54:18,090 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:54:18,091 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:54:18,305 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 15:54:18,338 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:54:18,340 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:54:18,341 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 15:54:18,346 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:54:18,364 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:54:18,373 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:54:18,374 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:54:18,376 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:54:18,377 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:54:18,378 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:54:18,378 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:54:18,399 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:54:18,399 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:54:18,412 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:54:21,414 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-22 15:55:18,523 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2865208863104816724_2112 src: /192.168.1.157:43801 dest: /192.168.1.157:50010
2017-05-22 15:55:18,535 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2865208863104816724_2112 src: /192.168.1.157:43801 dest: /192.168.1.157:50010 of size 13553
2017-05-22 15:55:18,624 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8579483325624526605_2108 src: /192.168.1.156:56679 dest: /192.168.1.156:50010
2017-05-22 15:55:18,632 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8579483325624526605_2108 src: /192.168.1.156:56679 dest: /192.168.1.156:50010 of size 91176
2017-05-22 15:55:18,820 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 15:55:21,501 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8835643248558875211_2110 src: /192.168.1.157:43807 dest: /192.168.1.157:50010
2017-05-22 15:55:21,502 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3296584184748829799_2109 src: /192.168.1.157:43806 dest: /192.168.1.157:50010
2017-05-22 15:55:21,504 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3296584184748829799_2109 src: /192.168.1.157:43806 dest: /192.168.1.157:50010 of size 2165
2017-05-22 15:55:21,505 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8835643248558875211_2110 src: /192.168.1.157:43807 dest: /192.168.1.157:50010 of size 13568
2017-05-22 15:55:35,221 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 15:55:40,592 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 15:55:57,441 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 15:56:02,424 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 15:56:18,070 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 15:56:23,329 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 15:56:39,140 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 15:58:00,559 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4978241653332978885_2116 src: /192.168.1.157:43862 dest: /192.168.1.157:50010
2017-05-22 15:58:00,560 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-4978241653332978885_2116 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 15:58:00,562 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 15:58:03,518 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8579483325624526605_2108 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8579483325624526605
2017-05-22 15:58:03,519 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2865208863104816724_2112 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2865208863104816724
2017-05-22 15:58:03,519 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3296584184748829799_2109 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3296584184748829799
2017-05-22 15:58:03,520 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8835643248558875211_2110 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8835643248558875211
2017-05-22 15:58:09,812 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 15:58:20,597 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 15:58:20,789 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 15:58:20,791 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 15:58:20,793 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 15:58:20,864 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 15:58:20,921 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 15:58:20,922 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 15:58:20,922 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 15:58:21,155 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@e7b92e
2017-05-22 15:58:21,191 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 15:58:21,194 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 15:58:21,194 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 15:58:21,200 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 15:58:21,226 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 15:58:21,234 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 15:58:21,234 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 15:58:21,234 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 15:58:21,235 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 15:58:21,236 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 15:58:21,236 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 15:58:21,263 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 15:58:21,263 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 15:58:21,275 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 15:58:24,276 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-22 15:59:27,346 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4321787390300755479_2117 src: /192.168.1.158:33080 dest: /192.168.1.158:50010
2017-05-22 15:59:27,347 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3811088210670773077_2121 src: /192.168.1.158:33081 dest: /192.168.1.158:50010
2017-05-22 15:59:27,361 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4321787390300755479_2117 src: /192.168.1.158:33080 dest: /192.168.1.158:50010 of size 91176
2017-05-22 15:59:27,363 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3811088210670773077_2121 src: /192.168.1.158:33081 dest: /192.168.1.158:50010 of size 13553
2017-05-22 15:59:30,315 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8994068294844312429_2119 src: /192.168.1.157:43877 dest: /192.168.1.157:50010
2017-05-22 15:59:30,320 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8994068294844312429_2119 src: /192.168.1.157:43877 dest: /192.168.1.157:50010 of size 13568
2017-05-22 15:59:30,340 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8498258054694058199_2118 src: /192.168.1.156:56758 dest: /192.168.1.156:50010
2017-05-22 15:59:30,341 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8498258054694058199_2118 src: /192.168.1.156:56758 dest: /192.168.1.156:50010 of size 2165
2017-05-22 15:59:46,820 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 15:59:53,400 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 16:00:09,864 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 16:00:14,231 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 16:00:29,159 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 16:02:12,405 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4321787390300755479_2117 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4321787390300755479
2017-05-22 16:02:12,406 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8498258054694058199_2118 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8498258054694058199
2017-05-22 16:02:12,406 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8994068294844312429_2119 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8994068294844312429
2017-05-22 16:02:15,404 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3811088210670773077_2121 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3811088210670773077
2017-05-22 16:02:20,528 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:02:31,383 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:02:31,567 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:02:31,569 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:02:31,571 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:02:31,638 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:02:31,695 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:02:31,696 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:02:31,696 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:02:31,934 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 16:02:31,974 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:02:31,976 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:02:31,976 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 16:02:31,981 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:02:31,998 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:02:32,002 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:02:32,003 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:02:32,004 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:02:32,005 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:02:32,005 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:02:32,005 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:02:32,016 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:02:32,016 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:02:32,043 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:02:35,034 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-22 16:03:37,424 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 16:03:38,080 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9085901941477040936_2126 src: /192.168.1.157:43960 dest: /192.168.1.157:50010
2017-05-22 16:03:38,097 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9085901941477040936_2126 src: /192.168.1.157:43960 dest: /192.168.1.157:50010 of size 91176
2017-05-22 16:03:38,123 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5218892582999619045_2128 src: /192.168.1.158:33121 dest: /192.168.1.158:50010
2017-05-22 16:03:38,124 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5218892582999619045_2128 src: /192.168.1.158:33121 dest: /192.168.1.158:50010 of size 13568
2017-05-22 16:03:41,118 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4875035541430371762_2127 src: /192.168.1.156:56835 dest: /192.168.1.156:50010
2017-05-22 16:03:41,118 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4875035541430371762_2127 src: /192.168.1.156:56835 dest: /192.168.1.156:50010 of size 2165
2017-05-22 16:03:41,123 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1309955050079573478_2130 src: /192.168.1.156:56836 dest: /192.168.1.156:50010
2017-05-22 16:03:41,124 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1309955050079573478_2130 src: /192.168.1.156:56836 dest: /192.168.1.156:50010 of size 13553
2017-05-22 16:03:53,201 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 16:03:59,172 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 16:04:15,337 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 16:04:19,997 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 16:04:36,220 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 16:06:26,140 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2270302543013713249_2134 src: /192.168.1.157:44017 dest: /192.168.1.157:50010
2017-05-22 16:06:26,144 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2270302543013713249_2134 src: /192.168.1.157:44017 dest: /192.168.1.157:50010 of size 25159
2017-05-22 16:06:29,295 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9085901941477040936_2126 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9085901941477040936
2017-05-22 16:06:29,296 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5218892582999619045_2128 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5218892582999619045
2017-05-22 16:06:29,296 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2270302543013713249_2134 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2270302543013713249
2017-05-22 16:06:29,297 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1309955050079573478_2130 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1309955050079573478
2017-05-22 16:06:29,297 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4875035541430371762_2127 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4875035541430371762
2017-05-22 16:06:37,974 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:06:48,847 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:06:49,045 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:06:49,046 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:06:49,048 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:06:49,118 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:06:49,175 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:06:49,175 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:06:49,176 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:06:49,421 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 16:06:49,459 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:06:49,461 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:06:49,462 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 16:06:49,466 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:06:49,489 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:06:49,494 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:06:49,495 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:06:49,496 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:06:49,496 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:06:49,496 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:06:49,496 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:06:49,503 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:06:49,504 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:06:49,515 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:06:52,517 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 10 msecs
2017-05-22 16:07:49,574 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7185062154029119845_2139 src: /192.168.1.157:44028 dest: /192.168.1.157:50010
2017-05-22 16:07:49,574 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8358783397911328172_2135 src: /192.168.1.156:56903 dest: /192.168.1.156:50010
2017-05-22 16:07:49,601 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8358783397911328172_2135 src: /192.168.1.156:56903 dest: /192.168.1.156:50010 of size 91176
2017-05-22 16:07:49,609 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7185062154029119845_2139 src: /192.168.1.157:44028 dest: /192.168.1.157:50010 of size 13551
2017-05-22 16:07:52,410 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 16:07:52,552 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5475162612269209969_2136 src: /192.168.1.157:44032 dest: /192.168.1.157:50010
2017-05-22 16:07:52,553 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5475162612269209969_2136 src: /192.168.1.157:44032 dest: /192.168.1.157:50010 of size 17286
2017-05-22 16:07:52,564 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5475162612269209969_2136 src: /192.168.1.156:56909 dest: /192.168.1.156:50010
2017-05-22 16:07:52,564 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5475162612269209969_2136 received exception java.io.IOException: Block blk_5475162612269209969_2136 is valid, and cannot be written to.
2017-05-22 16:07:52,566 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_5475162612269209969_2136 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 16:07:52,568 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8712874266109976098_2137 src: /192.168.1.156:56908 dest: /192.168.1.156:50010
2017-05-22 16:07:52,569 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8712874266109976098_2137 src: /192.168.1.156:56908 dest: /192.168.1.156:50010 of size 13566
2017-05-22 16:07:54,550 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 16:07:55,587 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_5475162612269209969_2136 to 192.168.1.158:50010
2017-05-22 16:07:55,590 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_5475162612269209969_2136 to /192.168.1.158:50010
2017-05-22 16:08:04,104 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 16:08:08,873 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 16:08:13,690 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 16:08:18,457 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 16:08:23,139 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 16:08:27,949 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 16:08:32,683 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 16:08:37,525 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 16:08:42,297 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 16:08:47,085 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 16:08:51,864 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 16:10:58,650 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2214327437942802162_2139 src: /192.168.1.156:57060 dest: /192.168.1.156:50010
2017-05-22 16:10:58,651 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_2214327437942802162_2139 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 16:10:58,652 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 16:11:01,667 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7185062154029119845_2139 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7185062154029119845
2017-05-22 16:11:01,667 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5475162612269209969_2136 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5475162612269209969
2017-05-22 16:11:01,668 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8358783397911328172_2135 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8358783397911328172
2017-05-22 16:11:01,668 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8712874266109976098_2137 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8712874266109976098
2017-05-22 16:11:07,590 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:11:18,490 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:11:18,680 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:11:18,682 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:11:18,684 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:11:18,744 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:11:18,793 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:11:18,793 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:11:18,793 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:11:19,014 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@14a8af0
2017-05-22 16:11:19,056 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:11:19,058 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:11:19,058 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 16:11:19,063 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:11:19,081 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:11:19,085 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:11:19,085 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:11:19,086 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:11:19,087 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:11:19,087 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:11:19,087 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:11:19,089 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:11:19,090 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:11:19,098 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:11:22,102 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 16:12:25,085 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4303467913286682493_2145 src: /192.168.1.158:33293 dest: /192.168.1.158:50010
2017-05-22 16:12:25,100 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4303467913286682493_2145 src: /192.168.1.158:33293 dest: /192.168.1.158:50010 of size 17286
2017-05-22 16:12:25,164 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5419846314831349850_2144 src: /192.168.1.156:57073 dest: /192.168.1.156:50010
2017-05-22 16:12:25,167 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5419846314831349850_2144 src: /192.168.1.156:57073 dest: /192.168.1.156:50010 of size 91176
2017-05-22 16:12:27,366 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 16:12:28,068 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6429074962591327402_2148 src: /192.168.1.157:44194 dest: /192.168.1.157:50010
2017-05-22 16:12:28,069 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6429074962591327402_2148 src: /192.168.1.157:44194 dest: /192.168.1.157:50010 of size 13551
2017-05-22 16:12:28,164 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7262309700004202105_2146 src: /192.168.1.156:57075 dest: /192.168.1.156:50010
2017-05-22 16:12:28,165 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7262309700004202105_2146 src: /192.168.1.156:57075 dest: /192.168.1.156:50010 of size 13566
2017-05-22 16:12:28,165 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7262309700004202105_2146 src: /192.168.1.156:57074 dest: /192.168.1.156:50010
2017-05-22 16:12:28,166 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7262309700004202105_2146 received exception java.io.IOException: Block blk_7262309700004202105_2146 is valid, and cannot be written to.
2017-05-22 16:12:28,168 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7262309700004202105_2146 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 16:12:31,120 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7262309700004202105_2146 to 192.168.1.158:50010
2017-05-22 16:12:31,129 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_7262309700004202105_2146 to /192.168.1.158:50010
2017-05-22 16:12:32,413 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 16:12:36,902 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 16:12:46,409 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 16:13:36,178 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 16:16:25,163 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3066988571911706077_2148 src: /192.168.1.157:44331 dest: /192.168.1.157:50010
2017-05-22 16:16:25,163 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3066988571911706077_2148 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 16:16:25,164 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 16:16:28,254 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5419846314831349850_2144 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5419846314831349850
2017-05-22 16:16:28,254 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4303467913286682493_2145 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4303467913286682493
2017-05-22 16:16:28,254 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6429074962591327402_2148 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6429074962591327402
2017-05-22 16:16:28,255 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7262309700004202105_2146 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7262309700004202105
2017-05-22 16:16:34,278 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-22 16:16:34,340 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:16:45,177 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:16:45,397 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:16:45,399 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:16:45,401 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:16:45,471 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:16:45,530 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:16:45,531 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:16:45,531 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:16:45,758 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 16:16:45,803 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:16:45,806 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:16:45,806 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 16:16:45,811 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:16:45,830 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:16:45,835 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:16:45,836 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:16:45,836 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:16:45,836 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:16:45,837 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:16:45,837 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:16:45,840 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:16:45,840 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:16:45,847 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:16:48,847 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 16:17:51,846 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3047051404030301635_2153 src: /192.168.1.158:33430 dest: /192.168.1.158:50010
2017-05-22 16:17:51,857 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3047051404030301635_2153 src: /192.168.1.158:33430 dest: /192.168.1.158:50010 of size 91176
2017-05-22 16:17:51,867 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8924409770759147189_2154 src: /192.168.1.158:33431 dest: /192.168.1.158:50010
2017-05-22 16:17:51,869 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8924409770759147189_2154 src: /192.168.1.158:33431 dest: /192.168.1.158:50010 of size 17286
2017-05-22 16:17:54,838 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6388279141051760535_2157 src: /192.168.1.157:44346 dest: /192.168.1.157:50010
2017-05-22 16:17:54,840 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6388279141051760535_2157 src: /192.168.1.157:44346 dest: /192.168.1.157:50010 of size 13551
2017-05-22 16:17:54,842 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3693277229898885709_2155 src: /192.168.1.157:44347 dest: /192.168.1.157:50010
2017-05-22 16:17:54,844 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3693277229898885709_2155 src: /192.168.1.157:44347 dest: /192.168.1.157:50010 of size 13566
2017-05-22 16:21:18,996 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8924409770759147189_2154 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8924409770759147189
2017-05-22 16:21:18,996 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3693277229898885709_2155 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3693277229898885709
2017-05-22 16:21:18,997 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3047051404030301635_2153 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3047051404030301635
2017-05-22 16:21:18,997 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6388279141051760535_2157 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6388279141051760535
2017-05-22 16:21:26,742 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:21:37,636 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:21:37,861 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:21:37,863 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:21:37,865 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:21:37,937 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:21:37,997 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:21:37,998 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:21:37,998 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:21:38,238 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 16:21:38,275 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:21:38,278 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:21:38,278 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 16:21:38,284 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:21:38,306 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:21:38,311 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:21:38,312 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:21:38,312 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:21:38,312 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:21:38,313 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:21:38,312 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:21:38,317 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:21:38,317 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:21:38,324 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:21:41,325 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 16:22:38,282 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2798418124247700479_2162 src: /192.168.1.156:57417 dest: /192.168.1.156:50010
2017-05-22 16:22:38,296 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2798418124247700479_2162 src: /192.168.1.156:57417 dest: /192.168.1.156:50010 of size 91176
2017-05-22 16:22:38,298 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-232485637659424614_2164 src: /192.168.1.158:33572 dest: /192.168.1.158:50010
2017-05-22 16:22:38,300 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-232485637659424614_2164 src: /192.168.1.158:33572 dest: /192.168.1.158:50010 of size 13567
2017-05-22 16:22:41,240 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_219519020477252879_2166 src: /192.168.1.157:44524 dest: /192.168.1.157:50010
2017-05-22 16:22:41,241 INFO org.apache.hadoop.dfs.DataNode: Received block blk_219519020477252879_2166 src: /192.168.1.157:44524 dest: /192.168.1.157:50010 of size 13552
2017-05-22 16:22:44,124 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 16:22:44,285 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4509673060182529290_2163 src: /192.168.1.158:33579 dest: /192.168.1.158:50010
2017-05-22 16:22:44,286 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4509673060182529290_2163 src: /192.168.1.158:33579 dest: /192.168.1.158:50010 of size 8645
2017-05-22 16:22:51,314 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 16:22:54,487 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 16:23:02,335 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 16:23:09,174 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 16:23:16,340 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 16:23:19,150 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 16:23:28,748 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 16:23:31,480 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 16:24:56,574 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4509673060182529290_2163 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4509673060182529290
2017-05-22 16:24:56,575 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-232485637659424614_2164 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-232485637659424614
2017-05-22 16:24:56,575 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_219519020477252879_2166 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_219519020477252879
2017-05-22 16:24:56,576 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2798418124247700479_2162 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2798418124247700479
2017-05-22 16:25:03,562 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:25:14,438 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:25:14,628 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:25:14,629 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:25:14,631 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:25:14,698 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:25:14,754 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:25:14,755 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:25:14,755 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:25:14,990 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 16:25:15,030 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:25:15,032 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:25:15,032 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 16:25:15,037 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:25:15,055 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:25:15,060 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:25:15,060 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:25:15,062 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:25:15,062 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:25:15,062 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:25:15,062 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:25:15,064 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:25:15,065 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:25:15,073 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:25:18,073 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 16:26:21,083 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6826548219670167517_2171 src: /192.168.1.158:33668 dest: /192.168.1.158:50010
2017-05-22 16:26:21,092 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1706148581038911763_2173 src: /192.168.1.158:33669 dest: /192.168.1.158:50010
2017-05-22 16:26:21,100 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6826548219670167517_2171 src: /192.168.1.158:33668 dest: /192.168.1.158:50010 of size 91176
2017-05-22 16:26:21,101 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1706148581038911763_2173 src: /192.168.1.158:33669 dest: /192.168.1.158:50010 of size 13567
2017-05-22 16:26:24,063 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4820356372227582172_2172 src: /192.168.1.156:57534 dest: /192.168.1.156:50010
2017-05-22 16:26:24,071 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4820356372227582172_2172 src: /192.168.1.156:57534 dest: /192.168.1.156:50010 of size 8645
2017-05-22 16:26:24,079 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2523953064930109603_2175 src: /192.168.1.157:44635 dest: /192.168.1.157:50010
2017-05-22 16:26:24,086 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2523953064930109603_2175 src: /192.168.1.157:44635 dest: /192.168.1.157:50010 of size 13552
2017-05-22 16:26:25,827 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 16:26:36,295 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 16:26:43,071 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 16:26:48,448 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 16:26:49,835 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 16:26:55,233 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 16:26:56,658 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 16:27:02,129 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 16:27:10,329 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 16:27:17,149 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 16:28:51,153 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3234754974151720511_2175 src: /192.168.1.158:33737 dest: /192.168.1.158:50010
2017-05-22 16:28:51,160 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3234754974151720511_2175 src: /192.168.1.158:33737 dest: /192.168.1.158:50010 of size 83599
2017-05-22 16:28:54,226 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1706148581038911763_2173 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1706148581038911763
2017-05-22 16:28:54,227 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4820356372227582172_2172 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4820356372227582172
2017-05-22 16:28:54,227 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6826548219670167517_2171 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6826548219670167517
2017-05-22 16:28:57,225 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2523953064930109603_2175 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2523953064930109603
2017-05-22 16:28:57,226 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3234754974151720511_2175 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3234754974151720511
2017-05-22 16:29:02,363 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:29:13,146 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:29:13,341 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:29:13,343 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:29:13,344 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:29:13,413 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:29:13,469 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:29:13,470 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:29:13,470 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:29:13,713 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 16:29:13,750 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:29:13,753 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:29:13,753 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-22 16:29:13,758 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:29:13,776 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:29:13,781 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:29:13,782 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:29:13,783 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:29:13,783 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:29:13,784 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:29:13,784 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:29:13,785 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:29:13,785 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:29:13,792 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:29:16,795 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 16:30:19,131 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 16:30:19,851 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5103766892615940451_2180 src: /192.168.1.158:33749 dest: /192.168.1.158:50010
2017-05-22 16:30:19,851 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6763493287923176859_2184 src: /192.168.1.158:33750 dest: /192.168.1.158:50010
2017-05-22 16:30:19,876 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6763493287923176859_2184 src: /192.168.1.158:33750 dest: /192.168.1.158:50010 of size 13552
2017-05-22 16:30:19,877 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5103766892615940451_2180 src: /192.168.1.158:33749 dest: /192.168.1.158:50010 of size 91176
2017-05-22 16:30:22,845 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1901202950809341529_2181 src: /192.168.1.157:44751 dest: /192.168.1.157:50010
2017-05-22 16:30:22,847 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1901202950809341529_2181 src: /192.168.1.157:44751 dest: /192.168.1.157:50010 of size 8645
2017-05-22 16:30:22,848 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1901202950809341529_2181 src: /192.168.1.157:44752 dest: /192.168.1.157:50010
2017-05-22 16:30:22,849 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1901202950809341529_2181 received exception java.io.IOException: Block blk_1901202950809341529_2181 is valid, and cannot be written to.
2017-05-22 16:30:22,850 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_1901202950809341529_2181 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 16:30:25,847 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3638537255840564696_2182 src: /192.168.1.157:44757 dest: /192.168.1.157:50010
2017-05-22 16:30:25,847 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3638537255840564696_2182 src: /192.168.1.157:44757 dest: /192.168.1.157:50010 of size 13567
2017-05-22 16:30:33,635 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 16:30:45,891 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 16:30:52,339 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 16:30:59,531 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 16:31:05,138 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 16:31:11,966 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 16:32:34,890 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5103766892615940451_2180 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5103766892615940451
2017-05-22 16:32:34,892 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3638537255840564696_2182 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3638537255840564696
2017-05-22 16:32:34,892 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1901202950809341529_2181 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1901202950809341529
2017-05-22 16:32:37,888 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6763493287923176859_2184 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6763493287923176859
2017-05-22 16:32:44,647 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:32:55,556 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:32:55,787 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:32:55,789 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:32:55,791 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:32:55,855 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:32:55,916 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:32:55,917 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:32:55,917 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:32:56,149 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 16:32:56,178 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:32:56,180 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:32:56,181 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 16:32:56,185 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:32:56,205 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:32:56,211 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:32:56,212 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:32:56,213 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:32:56,214 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:32:56,214 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:32:56,214 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:32:56,218 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:32:56,218 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:32:56,225 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:32:59,226 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 16:33:56,236 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6025127517597074935_2189 src: /192.168.1.158:33837 dest: /192.168.1.158:50010
2017-05-22 16:33:56,243 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1896268265480071909_2191 src: /192.168.1.158:33836 dest: /192.168.1.158:50010
2017-05-22 16:33:56,258 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6025127517597074935_2189 src: /192.168.1.158:33837 dest: /192.168.1.158:50010 of size 91176
2017-05-22 16:33:56,260 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1896268265480071909_2191 src: /192.168.1.158:33836 dest: /192.168.1.158:50010 of size 13567
2017-05-22 16:33:59,178 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8626452849625449577_2193 src: /192.168.1.157:44876 dest: /192.168.1.157:50010
2017-05-22 16:33:59,180 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8626452849625449577_2193 src: /192.168.1.157:44876 dest: /192.168.1.157:50010 of size 13552
2017-05-22 16:33:59,194 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8626452849625449577_2193 src: /192.168.1.156:57757 dest: /192.168.1.156:50010
2017-05-22 16:33:59,194 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_901707834004660066_2190 src: /192.168.1.156:57758 dest: /192.168.1.156:50010
2017-05-22 16:33:59,194 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8626452849625449577_2193 received exception java.io.IOException: Block blk_-8626452849625449577_2193 is valid, and cannot be written to.
2017-05-22 16:33:59,195 INFO org.apache.hadoop.dfs.DataNode: Received block blk_901707834004660066_2190 src: /192.168.1.156:57758 dest: /192.168.1.156:50010 of size 4325
2017-05-22 16:33:59,196 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-8626452849625449577_2193 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 16:34:04,913 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 16:34:05,254 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 16:34:16,873 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 16:34:17,937 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 16:34:21,159 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 16:34:22,310 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 16:34:44,505 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 16:34:52,460 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 16:36:14,243 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7763232714998639639_2197 src: /192.168.1.156:57844 dest: /192.168.1.156:50010
2017-05-22 16:36:14,248 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7763232714998639639_2197 src: /192.168.1.156:57844 dest: /192.168.1.156:50010 of size 47767
2017-05-22 16:36:17,418 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8626452849625449577_2193 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8626452849625449577
2017-05-22 16:36:17,418 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1896268265480071909_2191 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1896268265480071909
2017-05-22 16:36:17,419 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_901707834004660066_2190 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_901707834004660066
2017-05-22 16:36:17,419 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6025127517597074935_2189 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6025127517597074935
2017-05-22 16:36:17,420 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7763232714998639639_2197 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7763232714998639639
2017-05-22 16:36:24,334 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:36:35,145 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:36:35,360 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:36:35,362 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:36:35,363 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:36:35,424 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:36:35,477 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:36:35,478 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:36:35,478 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:36:35,711 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 16:36:35,741 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:36:35,744 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:36:35,744 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-22 16:36:35,753 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:36:35,776 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:36:35,781 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:36:35,782 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:36:35,783 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:36:35,784 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:36:35,784 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:36:35,784 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:36:35,788 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:36:35,789 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:36:35,800 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:36:38,803 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-22 16:37:41,855 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-202185754082056922_2200 src: /192.168.1.156:57860 dest: /192.168.1.156:50010
2017-05-22 16:37:41,867 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4843886999384396149_2198 src: /192.168.1.158:33897 dest: /192.168.1.158:50010
2017-05-22 16:37:41,875 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-202185754082056922_2200 src: /192.168.1.156:57860 dest: /192.168.1.156:50010 of size 13567
2017-05-22 16:37:41,879 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4843886999384396149_2198 src: /192.168.1.158:33897 dest: /192.168.1.158:50010 of size 91176
2017-05-22 16:37:44,850 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2600568632290509604_2202 src: /192.168.1.157:44976 dest: /192.168.1.157:50010
2017-05-22 16:37:44,851 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2600568632290509604_2202 src: /192.168.1.157:44976 dest: /192.168.1.157:50010 of size 13552
2017-05-22 16:37:47,852 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5126765967869204605_2199 src: /192.168.1.156:57865 dest: /192.168.1.156:50010
2017-05-22 16:37:47,852 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5126765967869204605_2199 src: /192.168.1.156:57865 dest: /192.168.1.156:50010 of size 4325
2017-05-22 16:37:49,166 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 16:37:50,042 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 16:37:53,946 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 16:38:01,331 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 16:38:04,733 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 16:38:06,779 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 16:38:19,552 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 16:38:24,641 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 16:38:30,423 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 16:38:37,693 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 16:39:35,943 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5340722671367898570_2206 src: /192.168.1.158:33943 dest: /192.168.1.158:50010
2017-05-22 16:39:35,954 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5340722671367898570_2206 src: /192.168.1.158:33943 dest: /192.168.1.158:50010 of size 46176
2017-05-22 16:39:38,967 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4843886999384396149_2198 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4843886999384396149
2017-05-22 16:39:38,967 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-202185754082056922_2200 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-202185754082056922
2017-05-22 16:39:38,968 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5126765967869204605_2199 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5126765967869204605
2017-05-22 16:39:41,965 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2600568632290509604_2202 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2600568632290509604
2017-05-22 16:39:41,966 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5340722671367898570_2206 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5340722671367898570
2017-05-22 16:39:46,808 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:39:57,511 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:39:57,705 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:39:57,707 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:39:57,708 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:39:57,774 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:39:57,831 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:39:57,832 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:39:57,832 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:39:58,068 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 16:39:58,108 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:39:58,111 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:39:58,111 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 16:39:58,116 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:39:58,134 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:39:58,139 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:39:58,140 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:39:58,141 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:39:58,142 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:39:58,142 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:39:58,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:39:58,178 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:39:58,178 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:39:58,192 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:40:01,191 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-22 16:41:03,595 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 16:41:04,276 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4080701693817585188_2207 src: /192.168.1.157:45069 dest: /192.168.1.157:50010
2017-05-22 16:41:04,292 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4080701693817585188_2207 src: /192.168.1.157:45069 dest: /192.168.1.157:50010 of size 91176
2017-05-22 16:41:04,321 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3170186260953263525_2208 src: /192.168.1.156:57954 dest: /192.168.1.156:50010
2017-05-22 16:41:04,322 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3170186260953263525_2208 src: /192.168.1.156:57954 dest: /192.168.1.156:50010 of size 4325
2017-05-22 16:41:07,275 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7187682448449963849_2209 src: /192.168.1.157:45071 dest: /192.168.1.157:50010
2017-05-22 16:41:07,276 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7187682448449963849_2209 src: /192.168.1.157:45071 dest: /192.168.1.157:50010 of size 13567
2017-05-22 16:41:07,320 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7187682448449963849_2209 src: /192.168.1.156:57955 dest: /192.168.1.156:50010
2017-05-22 16:41:07,321 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7187682448449963849_2209 received exception java.io.IOException: Block blk_7187682448449963849_2209 is valid, and cannot be written to.
2017-05-22 16:41:07,322 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7187682448449963849_2209 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 16:41:10,266 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5397430479903366193_2211 src: /192.168.1.158:33957 dest: /192.168.1.158:50010
2017-05-22 16:41:10,267 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5397430479903366193_2211 src: /192.168.1.158:33957 dest: /192.168.1.158:50010 of size 13552
2017-05-22 16:41:10,297 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7187682448449963849_2209 to 192.168.1.158:50010
2017-05-22 16:41:10,302 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_7187682448449963849_2209 to /192.168.1.158:50010
2017-05-22 16:41:15,458 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 16:41:27,042 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 16:41:28,213 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 16:41:37,993 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 16:41:48,195 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 16:41:50,093 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 16:41:51,158 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 16:42:01,328 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 16:43:04,322 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1096130230837316298_2215 src: /192.168.1.158:34000 dest: /192.168.1.158:50010
2017-05-22 16:43:04,324 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1096130230837316298_2215 src: /192.168.1.158:34000 dest: /192.168.1.158:50010 of size 46258
2017-05-22 16:43:07,391 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4080701693817585188_2207 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4080701693817585188
2017-05-22 16:43:07,392 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1096130230837316298_2215 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1096130230837316298
2017-05-22 16:43:07,392 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3170186260953263525_2208 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3170186260953263525
2017-05-22 16:43:07,393 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5397430479903366193_2211 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5397430479903366193
2017-05-22 16:43:07,393 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7187682448449963849_2209 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7187682448449963849
2017-05-22 16:43:16,141 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:43:27,030 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:43:27,223 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:43:27,224 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:43:27,226 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:43:27,281 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:43:27,338 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:43:27,339 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:43:27,339 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:43:27,561 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 16:43:27,595 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:43:27,598 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:43:27,598 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 16:43:27,603 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:43:27,625 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:43:27,629 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:43:27,629 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:43:27,631 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:43:27,631 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:43:27,631 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:43:27,631 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:43:27,634 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:43:27,634 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:43:27,643 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:43:30,642 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 16:44:27,686 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3800923802342258370_2220 src: /192.168.1.157:45152 dest: /192.168.1.157:50010
2017-05-22 16:44:27,701 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3800923802342258370_2220 src: /192.168.1.157:45152 dest: /192.168.1.157:50010 of size 13553
2017-05-22 16:44:27,787 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3790588021949342440_2216 src: /192.168.1.158:34008 dest: /192.168.1.158:50010
2017-05-22 16:44:27,791 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3790588021949342440_2216 src: /192.168.1.158:34008 dest: /192.168.1.158:50010 of size 91176
2017-05-22 16:44:30,652 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8037844623015141587_2217 src: /192.168.1.157:45158 dest: /192.168.1.157:50010
2017-05-22 16:44:30,660 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8037844623015141587_2217 src: /192.168.1.157:45158 dest: /192.168.1.157:50010 of size 4325
2017-05-22 16:44:30,661 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_809276560153687572_2218 src: /192.168.1.157:45159 dest: /192.168.1.157:50010
2017-05-22 16:44:30,665 INFO org.apache.hadoop.dfs.DataNode: Received block blk_809276560153687572_2218 src: /192.168.1.157:45159 dest: /192.168.1.157:50010 of size 13568
2017-05-22 16:44:30,686 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_809276560153687572_2218 src: /192.168.1.156:58042 dest: /192.168.1.156:50010
2017-05-22 16:44:30,686 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_809276560153687572_2218 received exception java.io.IOException: Block blk_809276560153687572_2218 is valid, and cannot be written to.
2017-05-22 16:44:30,688 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_809276560153687572_2218 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 16:44:33,677 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_809276560153687572_2218 to 192.168.1.158:50010
2017-05-22 16:44:33,680 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_809276560153687572_2218 to /192.168.1.158:50010
2017-05-22 16:44:36,368 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 16:44:37,756 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 16:44:41,955 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 16:44:48,242 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 16:44:54,690 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 16:44:59,885 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 16:45:03,732 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 16:45:15,880 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 16:46:21,716 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3800923802342258370_2220 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3800923802342258370
2017-05-22 16:46:21,717 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_809276560153687572_2218 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_809276560153687572
2017-05-22 16:46:21,717 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3790588021949342440_2216 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3790588021949342440
2017-05-22 16:46:21,718 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8037844623015141587_2217 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8037844623015141587
2017-05-22 16:46:27,955 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:46:38,874 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:46:39,064 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:46:39,066 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:46:39,067 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:46:39,131 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:46:39,176 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:46:39,177 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:46:39,177 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:46:39,402 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 16:46:39,440 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:46:39,442 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:46:39,443 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 16:46:39,449 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:46:39,469 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:46:39,473 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:46:39,474 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:46:39,474 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:46:39,474 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:46:39,475 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:46:39,475 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:46:39,477 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:46:39,477 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:46:39,485 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:46:42,485 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 16:47:44,874 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 16:47:45,491 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3827724970797871330_2225 src: /192.168.1.158:34084 dest: /192.168.1.158:50010
2017-05-22 16:47:45,502 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3827724970797871330_2225 src: /192.168.1.158:34084 dest: /192.168.1.158:50010 of size 91176
2017-05-22 16:47:45,576 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4404001471599229199_2229 src: /192.168.1.158:34085 dest: /192.168.1.158:50010
2017-05-22 16:47:45,578 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4404001471599229199_2229 src: /192.168.1.158:34085 dest: /192.168.1.158:50010 of size 13553
2017-05-22 16:47:48,472 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8563632914112637161_2227 src: /192.168.1.157:45249 dest: /192.168.1.157:50010
2017-05-22 16:47:48,474 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8563632914112637161_2227 src: /192.168.1.157:45250 dest: /192.168.1.157:50010
2017-05-22 16:47:48,474 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8563632914112637161_2227 received exception java.io.IOException: Block blk_-8563632914112637161_2227 has already been started (though not completed), and thus cannot be created.
2017-05-22 16:47:48,476 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-8563632914112637161_2227 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 16:47:48,480 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8563632914112637161_2227 src: /192.168.1.157:45249 dest: /192.168.1.157:50010 of size 13568
2017-05-22 16:47:51,557 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1567662881749946088_2226 src: /192.168.1.158:34088 dest: /192.168.1.158:50010
2017-05-22 16:47:51,558 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1567662881749946088_2226 src: /192.168.1.158:34088 dest: /192.168.1.158:50010 of size 4325
2017-05-22 16:47:53,858 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 16:47:57,670 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 16:48:06,361 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 16:48:09,345 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 16:48:18,507 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 16:48:32,227 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 16:48:42,255 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 16:49:48,619 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8563632914112637161_2227 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8563632914112637161
2017-05-22 16:49:48,620 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1567662881749946088_2226 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1567662881749946088
2017-05-22 16:49:48,620 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3827724970797871330_2225 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3827724970797871330
2017-05-22 16:49:51,618 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4404001471599229199_2229 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4404001471599229199
2017-05-22 16:49:57,621 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-22 16:49:57,693 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:50:08,488 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:50:08,674 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:50:08,676 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:50:08,678 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:50:08,740 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:50:08,789 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:50:08,790 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:50:08,790 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:50:09,036 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 16:50:09,075 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:50:09,077 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:50:09,077 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 16:50:09,083 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:50:09,104 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:50:09,109 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:50:09,110 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:50:09,111 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:50:09,112 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:50:09,112 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:50:09,113 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:50:09,138 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:50:09,139 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:50:09,151 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:50:12,152 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-22 16:51:14,623 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 16:51:15,295 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_677163008096217864_2234 src: /192.168.1.158:34154 dest: /192.168.1.158:50010
2017-05-22 16:51:15,313 INFO org.apache.hadoop.dfs.DataNode: Received block blk_677163008096217864_2234 src: /192.168.1.158:34154 dest: /192.168.1.158:50010 of size 91176
2017-05-22 16:51:15,329 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6139181356282616247_2236 src: /192.168.1.158:34155 dest: /192.168.1.158:50010
2017-05-22 16:51:15,330 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6139181356282616247_2236 src: /192.168.1.158:34155 dest: /192.168.1.158:50010 of size 13568
2017-05-22 16:51:18,276 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7582134225403275463_2235 src: /192.168.1.156:58218 dest: /192.168.1.156:50010
2017-05-22 16:51:18,277 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7582134225403275463_2235 src: /192.168.1.156:58218 dest: /192.168.1.156:50010 of size 4325
2017-05-22 16:51:18,277 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7582134225403275463_2235 src: /192.168.1.156:58217 dest: /192.168.1.156:50010
2017-05-22 16:51:18,278 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7582134225403275463_2235 received exception java.io.IOException: Block blk_-7582134225403275463_2235 is valid, and cannot be written to.
2017-05-22 16:51:18,279 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-7582134225403275463_2235 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 16:51:18,325 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7060425063765683810_2238 src: /192.168.1.157:45342 dest: /192.168.1.157:50010
2017-05-22 16:51:18,326 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7060425063765683810_2238 src: /192.168.1.157:45342 dest: /192.168.1.157:50010 of size 13553
2017-05-22 16:51:21,250 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7582134225403275463_2235 to 192.168.1.158:50010
2017-05-22 16:51:21,254 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-7582134225403275463_2235 to /192.168.1.158:50010
2017-05-22 16:51:23,295 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 16:51:27,427 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 16:51:37,574 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 16:51:40,207 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 16:51:41,415 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 16:51:54,264 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 28 blocks got processed in 6 msecs
2017-05-22 16:51:55,277 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 16:52:04,390 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 16:52:06,441 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 16:53:15,381 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8919425091054943090_2242 src: /192.168.1.158:34203 dest: /192.168.1.158:50010
2017-05-22 16:53:15,384 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8919425091054943090_2242 src: /192.168.1.158:34203 dest: /192.168.1.158:50010 of size 48001
2017-05-22 16:53:18,316 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7582134225403275463_2235 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7582134225403275463
2017-05-22 16:53:18,316 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6139181356282616247_2236 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6139181356282616247
2017-05-22 16:53:18,317 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_677163008096217864_2234 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_677163008096217864
2017-05-22 16:53:21,319 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7060425063765683810_2238 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7060425063765683810
2017-05-22 16:53:21,320 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8919425091054943090_2242 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8919425091054943090
2017-05-22 16:53:28,237 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:53:39,004 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:53:39,193 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:53:39,195 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:53:39,197 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:53:39,268 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:53:39,325 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:53:39,325 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:53:39,326 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:53:39,557 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 16:53:39,592 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:53:39,596 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:53:39,596 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 16:53:39,601 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:53:39,623 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:53:39,628 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:53:39,628 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:53:39,629 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:53:39,629 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:53:39,629 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:53:39,629 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:53:39,649 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:53:39,650 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:53:39,662 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:53:42,668 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-05-22 16:54:39,768 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4880738780915570150_2243 src: /192.168.1.157:45444 dest: /192.168.1.157:50010
2017-05-22 16:54:39,782 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4880738780915570150_2243 src: /192.168.1.157:45444 dest: /192.168.1.157:50010 of size 91176
2017-05-22 16:54:39,816 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5745106771297359134_2247 src: /192.168.1.158:34211 dest: /192.168.1.158:50010
2017-05-22 16:54:39,817 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5745106771297359134_2247 src: /192.168.1.158:34211 dest: /192.168.1.158:50010 of size 13553
2017-05-22 16:54:42,724 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-321491444864190575_2245 src: /192.168.1.157:45450 dest: /192.168.1.157:50010
2017-05-22 16:54:42,729 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-321491444864190575_2245 src: /192.168.1.157:45450 dest: /192.168.1.157:50010 of size 13568
2017-05-22 16:54:42,805 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7919856433095648784_2244 src: /192.168.1.156:58308 dest: /192.168.1.156:50010
2017-05-22 16:54:42,811 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7919856433095648784_2244 src: /192.168.1.156:58308 dest: /192.168.1.156:50010 of size 8645
2017-05-22 16:54:45,255 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 16:54:49,173 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 16:54:50,168 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 16:54:55,912 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 16:54:58,167 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 16:55:02,758 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 16:55:07,807 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 16:55:10,704 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 16:55:12,709 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 16:55:16,497 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 16:55:28,151 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 16:56:48,877 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4082578557361848305_2247 src: /192.168.1.156:58406 dest: /192.168.1.156:50010
2017-05-22 16:56:48,878 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-4082578557361848305_2247 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 16:56:48,880 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 16:56:51,855 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-321491444864190575_2245 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-321491444864190575
2017-05-22 16:56:51,856 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4880738780915570150_2243 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4880738780915570150
2017-05-22 16:56:51,856 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7919856433095648784_2244 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7919856433095648784
2017-05-22 16:56:54,855 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5745106771297359134_2247 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5745106771297359134
2017-05-22 16:56:59,881 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 16:57:10,751 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 16:57:10,943 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 16:57:10,945 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 16:57:10,947 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 16:57:11,002 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 16:57:11,049 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 16:57:11,049 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 16:57:11,049 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 16:57:11,261 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@12e8099
2017-05-22 16:57:11,299 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 16:57:11,303 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 16:57:11,303 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-22 16:57:11,312 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 16:57:11,330 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 16:57:11,335 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 16:57:11,336 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 16:57:11,337 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 16:57:11,338 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 16:57:11,338 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 16:57:11,339 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 16:57:11,351 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 16:57:11,352 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 16:57:11,379 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 16:57:14,367 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-22 16:58:16,768 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 16:58:17,468 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3926828354626673293_2253 src: /192.168.1.157:45556 dest: /192.168.1.157:50010
2017-05-22 16:58:17,479 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_654407918464389605_2252 src: /192.168.1.156:58420 dest: /192.168.1.156:50010
2017-05-22 16:58:17,485 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3926828354626673293_2253 src: /192.168.1.157:45556 dest: /192.168.1.157:50010 of size 8645
2017-05-22 16:58:17,488 INFO org.apache.hadoop.dfs.DataNode: Received block blk_654407918464389605_2252 src: /192.168.1.156:58420 dest: /192.168.1.156:50010 of size 91176
2017-05-22 16:58:21,842 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 16:58:23,416 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6890503693397178942_2256 src: /192.168.1.158:34299 dest: /192.168.1.158:50010
2017-05-22 16:58:23,417 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6890503693397178942_2256 src: /192.168.1.158:34299 dest: /192.168.1.158:50010 of size 13553
2017-05-22 16:58:23,480 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8245861253197393827_2254 src: /192.168.1.156:58430 dest: /192.168.1.156:50010
2017-05-22 16:58:23,480 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8245861253197393827_2254 src: /192.168.1.156:58430 dest: /192.168.1.156:50010 of size 13568
2017-05-22 16:58:24,582 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 16:58:35,036 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 16:58:37,411 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 16:58:38,427 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 16:58:40,275 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 16:58:48,702 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 16:59:04,785 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 16:59:05,004 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 17:00:23,508 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3926828354626673293_2253 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3926828354626673293
2017-05-22 17:00:23,509 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_654407918464389605_2252 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_654407918464389605
2017-05-22 17:00:23,509 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8245861253197393827_2254 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8245861253197393827
2017-05-22 17:00:26,512 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6890503693397178942_2256 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6890503693397178942
2017-05-22 17:00:33,624 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:00:44,489 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:00:44,679 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:00:44,681 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:00:44,683 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:00:44,742 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:00:44,792 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:00:44,793 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:00:44,793 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:00:45,005 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-05-22 17:00:45,038 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:00:45,040 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:00:45,040 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 17:00:45,045 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:00:45,062 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:00:45,067 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:00:45,067 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:00:45,068 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:00:45,069 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:00:45,069 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:00:45,069 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:00:45,097 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:00:45,097 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:00:45,110 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:00:48,113 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 16 msecs
2017-05-22 17:01:51,158 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4579338246694000341_2261 src: /192.168.1.158:34373 dest: /192.168.1.158:50010
2017-05-22 17:01:51,173 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4579338246694000341_2261 src: /192.168.1.158:34373 dest: /192.168.1.158:50010 of size 91176
2017-05-22 17:01:51,212 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7437217561560174583_2265 src: /192.168.1.156:58536 dest: /192.168.1.156:50010
2017-05-22 17:01:51,214 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7437217561560174583_2265 src: /192.168.1.156:58536 dest: /192.168.1.156:50010 of size 13553
2017-05-22 17:01:54,144 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3069374648624932824_2263 src: /192.168.1.157:45667 dest: /192.168.1.157:50010
2017-05-22 17:01:54,144 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3069374648624932824_2263 src: /192.168.1.157:45667 dest: /192.168.1.157:50010 of size 13568
2017-05-22 17:01:54,146 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5921297749080674990_2262 src: /192.168.1.157:45668 dest: /192.168.1.157:50010
2017-05-22 17:01:54,147 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5921297749080674990_2262 src: /192.168.1.157:45668 dest: /192.168.1.157:50010 of size 8645
2017-05-22 17:01:54,213 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3069374648624932824_2263 src: /192.168.1.156:58539 dest: /192.168.1.156:50010
2017-05-22 17:01:54,214 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3069374648624932824_2263 received exception java.io.IOException: Block blk_-3069374648624932824_2263 is valid, and cannot be written to.
2017-05-22 17:01:54,216 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-3069374648624932824_2263 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 17:01:54,938 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 17:01:57,144 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-3069374648624932824_2263 to 192.168.1.158:50010
2017-05-22 17:01:57,148 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-3069374648624932824_2263 to /192.168.1.158:50010
2017-05-22 17:01:58,302 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 17:02:13,180 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 17:02:20,811 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 17:02:29,154 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 17:02:36,607 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 17:03:48,260 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2607012090510217471_2265 src: /192.168.1.156:58620 dest: /192.168.1.156:50010
2017-05-22 17:03:48,260 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2607012090510217471_2265 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 17:03:48,261 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 17:03:51,204 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7437217561560174583_2265 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7437217561560174583
2017-05-22 17:03:51,204 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5921297749080674990_2262 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5921297749080674990
2017-05-22 17:03:51,205 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3069374648624932824_2263 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3069374648624932824
2017-05-22 17:03:51,205 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4579338246694000341_2261 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4579338246694000341
2017-05-22 17:03:59,961 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:04:10,806 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:04:10,995 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:04:10,997 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:04:10,998 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:04:11,064 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:04:11,120 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:04:11,121 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:04:11,121 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:04:11,355 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 17:04:11,391 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:04:11,394 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:04:11,394 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 17:04:11,399 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:04:11,417 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:04:11,422 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:04:11,423 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:04:11,425 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:04:11,425 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:04:11,426 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:04:11,426 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:04:11,428 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:04:11,428 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:04:11,435 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:04:14,436 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 17:05:11,495 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6560461199719633073_2274 src: /192.168.1.157:45768 dest: /192.168.1.157:50010
2017-05-22 17:05:11,525 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6560461199719633073_2274 src: /192.168.1.157:45768 dest: /192.168.1.157:50010 of size 13553
2017-05-22 17:05:11,563 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3543264025869144106_2270 src: /192.168.1.158:34450 dest: /192.168.1.158:50010
2017-05-22 17:05:11,636 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3543264025869144106_2270 src: /192.168.1.158:34450 dest: /192.168.1.158:50010 of size 91176
2017-05-22 17:05:17,443 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5481121483021058616_2272 src: /192.168.1.158:34461 dest: /192.168.1.158:50010
2017-05-22 17:05:17,447 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2683669570812564983_2271 src: /192.168.1.158:34462 dest: /192.168.1.158:50010
2017-05-22 17:05:17,448 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2683669570812564983_2271 src: /192.168.1.158:34462 dest: /192.168.1.158:50010 of size 4325
2017-05-22 17:05:17,452 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5481121483021058616_2272 src: /192.168.1.158:34461 dest: /192.168.1.158:50010 of size 13568
2017-05-22 17:05:20,500 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 17:05:21,059 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 17:05:26,351 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 17:05:34,341 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 17:05:35,652 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 17:05:40,639 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 17:05:49,087 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 17:05:50,043 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 17:07:11,522 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-330160929845226162_2278 src: /192.168.1.158:34501 dest: /192.168.1.158:50010
2017-05-22 17:07:11,522 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-330160929845226162_2278 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 17:07:11,524 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 17:07:14,577 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5481121483021058616_2272 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5481121483021058616
2017-05-22 17:07:14,578 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3543264025869144106_2270 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3543264025869144106
2017-05-22 17:07:14,578 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2683669570812564983_2271 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2683669570812564983
2017-05-22 17:07:17,578 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6560461199719633073_2274 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6560461199719633073
2017-05-22 17:07:22,577 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:07:33,456 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:07:33,659 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:07:33,661 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:07:33,662 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:07:33,731 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:07:33,788 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:07:33,789 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:07:33,789 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:07:34,023 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 17:07:34,057 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:07:34,073 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:07:34,073 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 17:07:34,079 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:07:34,100 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:07:34,106 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:07:34,107 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:07:34,107 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:07:34,108 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:07:34,108 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:07:34,108 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:07:34,109 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:07:34,110 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:07:34,116 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:07:37,121 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 17:08:39,430 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 17:08:39,507 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 17:08:40,158 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8038220635942127201_2279 src: /192.168.1.156:58734 dest: /192.168.1.156:50010
2017-05-22 17:08:40,177 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8038220635942127201_2279 src: /192.168.1.156:58734 dest: /192.168.1.156:50010 of size 91176
2017-05-22 17:08:40,195 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3609818064814945962_2283 src: /192.168.1.158:34513 dest: /192.168.1.158:50010
2017-05-22 17:08:40,196 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3609818064814945962_2283 src: /192.168.1.158:34513 dest: /192.168.1.158:50010 of size 13553
2017-05-22 17:08:43,160 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8749783382335299324_2281 src: /192.168.1.156:58735 dest: /192.168.1.156:50010
2017-05-22 17:08:43,164 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8749783382335299324_2281 src: /192.168.1.156:58735 dest: /192.168.1.156:50010 of size 13568
2017-05-22 17:08:43,165 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8749783382335299324_2281 src: /192.168.1.156:58736 dest: /192.168.1.156:50010
2017-05-22 17:08:43,166 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8749783382335299324_2281 received exception java.io.IOException: Block blk_8749783382335299324_2281 is valid, and cannot be written to.
2017-05-22 17:08:43,168 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8749783382335299324_2281 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 17:08:43,179 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2055680974345692303_2280 src: /192.168.1.157:45870 dest: /192.168.1.157:50010
2017-05-22 17:08:43,180 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2055680974345692303_2280 src: /192.168.1.157:45870 dest: /192.168.1.157:50010 of size 4325
2017-05-22 17:08:43,178 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2055680974345692303_2280 src: /192.168.1.157:45869 dest: /192.168.1.157:50010
2017-05-22 17:08:43,181 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2055680974345692303_2280 received exception java.io.IOException: Block blk_-2055680974345692303_2280 is valid, and cannot be written to.
2017-05-22 17:08:43,181 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-2055680974345692303_2280 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 17:08:44,549 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 17:08:46,207 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8749783382335299324_2281 to 192.168.1.158:50010
2017-05-22 17:08:46,214 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_8749783382335299324_2281 to /192.168.1.158:50010
2017-05-22 17:08:53,286 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 17:08:58,474 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 17:09:03,491 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 17:09:08,377 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 17:09:18,071 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 17:10:25,257 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2055680974345692303_2280 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2055680974345692303
2017-05-22 17:10:25,258 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8038220635942127201_2279 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8038220635942127201
2017-05-22 17:10:25,258 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8749783382335299324_2281 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8749783382335299324
2017-05-22 17:10:28,260 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3609818064814945962_2283 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3609818064814945962
2017-05-22 17:10:35,160 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:10:46,060 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:10:46,262 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:10:46,264 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:10:46,266 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:10:46,339 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:10:46,396 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:10:46,397 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:10:46,397 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:10:46,631 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 17:10:46,673 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:10:46,679 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:10:46,679 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 17:10:46,685 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:10:46,704 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:10:46,709 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:10:46,710 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:10:46,711 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:10:46,712 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:10:46,712 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:10:46,712 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:10:46,715 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:10:46,715 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:10:46,724 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:10:49,725 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 9 msecs
2017-05-22 17:11:52,040 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 17:11:52,090 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 17:11:52,745 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2354158137400186252_2292 src: /192.168.1.158:34573 dest: /192.168.1.158:50010
2017-05-22 17:11:52,754 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2354158137400186252_2292 src: /192.168.1.158:34573 dest: /192.168.1.158:50010 of size 13553
2017-05-22 17:11:52,764 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6218404490850578134_2288 src: /192.168.1.156:58819 dest: /192.168.1.156:50010
2017-05-22 17:11:52,767 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6218404490850578134_2288 src: /192.168.1.156:58819 dest: /192.168.1.156:50010 of size 91176
2017-05-22 17:11:55,732 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6661512288416047686_2289 src: /192.168.1.157:45960 dest: /192.168.1.157:50010
2017-05-22 17:11:55,732 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6661512288416047686_2289 src: /192.168.1.157:45960 dest: /192.168.1.157:50010 of size 4325
2017-05-22 17:11:55,760 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2671801185136720127_2290 src: /192.168.1.156:58821 dest: /192.168.1.156:50010
2017-05-22 17:11:55,761 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2671801185136720127_2290 src: /192.168.1.156:58821 dest: /192.168.1.156:50010 of size 13568
2017-05-22 17:11:57,222 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 17:12:05,937 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 17:12:15,466 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 17:12:19,960 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 17:12:20,035 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 17:12:27,423 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 17:12:32,760 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 17:13:40,808 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2019898484805981201_2296 src: /192.168.1.158:34608 dest: /192.168.1.158:50010
2017-05-22 17:13:40,809 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_2019898484805981201_2296 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 17:13:40,810 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 17:13:43,850 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2671801185136720127_2290 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2671801185136720127
2017-05-22 17:13:43,851 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2354158137400186252_2292 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2354158137400186252
2017-05-22 17:13:43,851 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6218404490850578134_2288 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6218404490850578134
2017-05-22 17:13:43,852 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6661512288416047686_2289 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6661512288416047686
2017-05-22 17:13:52,586 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:14:03,455 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:14:03,664 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:14:03,666 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:14:03,668 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:14:03,726 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:14:03,777 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:14:03,778 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:14:03,778 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:14:04,004 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 17:14:04,042 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:14:04,045 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:14:04,045 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 17:14:04,050 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:14:04,067 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:14:04,073 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:14:04,073 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:14:04,075 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:14:04,075 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:14:04,076 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:14:04,076 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:14:04,079 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:14:04,079 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:14:04,086 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:14:07,085 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 6 msecs
2017-05-22 17:15:04,107 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4145558740401675481_2297 src: /192.168.1.157:46039 dest: /192.168.1.157:50010
2017-05-22 17:15:04,135 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4145558740401675481_2297 src: /192.168.1.157:46039 dest: /192.168.1.157:50010 of size 91176
2017-05-22 17:15:04,199 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-583210931700565844_2301 src: /192.168.1.156:58902 dest: /192.168.1.156:50010
2017-05-22 17:15:04,204 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-583210931700565844_2301 src: /192.168.1.156:58902 dest: /192.168.1.156:50010 of size 13553
2017-05-22 17:15:07,199 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7850255765815317161_2298 src: /192.168.1.156:58907 dest: /192.168.1.156:50010
2017-05-22 17:15:07,199 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7850255765815317161_2298 src: /192.168.1.156:58909 dest: /192.168.1.156:50010
2017-05-22 17:15:07,200 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7850255765815317161_2298 received exception java.io.IOException: Block blk_7850255765815317161_2298 has already been started (though not completed), and thus cannot be created.
2017-05-22 17:15:07,200 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7850255765815317161_2298 src: /192.168.1.156:58907 dest: /192.168.1.156:50010 of size 4325
2017-05-22 17:15:07,201 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7850255765815317161_2298 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 17:15:10,188 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7850255765815317161_2298 to 192.168.1.158:50010
2017-05-22 17:15:10,192 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6198614523903403659_2299 src: /192.168.1.156:58916 dest: /192.168.1.156:50010
2017-05-22 17:15:10,194 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6198614523903403659_2299 src: /192.168.1.156:58916 dest: /192.168.1.156:50010 of size 13568
2017-05-22 17:15:10,201 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_7850255765815317161_2298 to /192.168.1.158:50010
2017-05-22 17:17:31,260 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2489698738267715015_2305 src: /192.168.1.156:58993 dest: /192.168.1.156:50010
2017-05-22 17:17:31,266 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2489698738267715015_2305 src: /192.168.1.156:58993 dest: /192.168.1.156:50010 of size 41886
2017-05-22 17:17:34,388 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6198614523903403659_2299 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6198614523903403659
2017-05-22 17:17:34,389 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4145558740401675481_2297 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4145558740401675481
2017-05-22 17:17:34,390 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-583210931700565844_2301 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-583210931700565844
2017-05-22 17:17:34,390 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7850255765815317161_2298 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7850255765815317161
2017-05-22 17:17:40,293 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:17:51,039 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:17:51,228 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:17:51,230 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:17:51,232 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:17:51,293 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:17:51,342 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:17:51,343 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:17:51,343 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:17:51,569 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 17:17:51,611 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:17:51,613 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:17:51,614 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 17:17:51,618 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:17:51,638 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:17:51,646 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:17:51,646 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:17:51,648 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:17:51,648 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:17:51,648 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:17:51,649 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:17:51,682 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:17:51,682 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:17:51,698 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:17:51,747 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_2489698738267715015_2305
2017-05-22 17:17:54,700 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 15 msecs
2017-05-22 17:18:21,738 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 7 msecs
2017-05-22 17:18:27,743 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2489698738267715015_2305 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2489698738267715015
2017-05-22 17:18:57,777 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4049665015103435255_2306 src: /192.168.1.157:46145 dest: /192.168.1.157:50010
2017-05-22 17:18:57,799 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4049665015103435255_2306 src: /192.168.1.157:46145 dest: /192.168.1.157:50010 of size 91176
2017-05-22 17:18:57,828 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1173401364409227936_2308 src: /192.168.1.158:34613 dest: /192.168.1.158:50010
2017-05-22 17:18:57,829 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1173401364409227936_2308 src: /192.168.1.158:34613 dest: /192.168.1.158:50010 of size 13568
2017-05-22 17:19:00,762 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1350861974241527320_2307 src: /192.168.1.157:46146 dest: /192.168.1.157:50010
2017-05-22 17:19:00,764 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1350861974241527320_2307 src: /192.168.1.157:46146 dest: /192.168.1.157:50010 of size 4325
2017-05-22 17:19:00,768 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1350861974241527320_2307 src: /192.168.1.157:46147 dest: /192.168.1.157:50010
2017-05-22 17:19:00,769 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-1350861974241527320_2307 received exception java.io.IOException: Block blk_-1350861974241527320_2307 is valid, and cannot be written to.
2017-05-22 17:19:00,770 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-1350861974241527320_2307 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 17:19:00,793 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7649907492156586603_2310 src: /192.168.1.156:59010 dest: /192.168.1.156:50010
2017-05-22 17:19:00,796 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7649907492156586603_2310 src: /192.168.1.156:59010 dest: /192.168.1.156:50010 of size 13553
2017-05-22 17:21:18,870 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4923533059188849903_2314 src: /192.168.1.158:34614 dest: /192.168.1.158:50010
2017-05-22 17:21:18,873 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4923533059188849903_2314 src: /192.168.1.158:34614 dest: /192.168.1.158:50010 of size 41886
2017-05-22 17:21:21,928 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4923533059188849903_2314 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4923533059188849903
2017-05-22 17:21:21,929 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1350861974241527320_2307 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1350861974241527320
2017-05-22 17:21:21,929 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1173401364409227936_2308 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1173401364409227936
2017-05-22 17:21:21,930 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4049665015103435255_2306 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4049665015103435255
2017-05-22 17:21:21,930 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7649907492156586603_2310 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7649907492156586603
2017-05-22 17:21:28,875 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:21:39,698 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:21:39,893 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:21:39,894 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:21:39,896 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:21:39,962 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:21:40,012 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:21:40,013 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:21:40,013 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:21:40,229 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 17:21:40,274 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:21:40,277 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:21:40,277 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 17:21:40,283 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:21:40,300 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:21:40,305 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:21:40,305 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:21:40,306 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:21:40,307 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:21:40,307 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:21:40,307 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:21:40,326 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:21:40,326 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:21:40,340 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:21:43,339 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-22 17:22:46,487 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1958585996167524057_2315 src: /192.168.1.158:34617 dest: /192.168.1.158:50010
2017-05-22 17:22:46,494 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2575329100689273927_2316 src: /192.168.1.156:59108 dest: /192.168.1.156:50010
2017-05-22 17:22:46,502 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1958585996167524057_2315 src: /192.168.1.158:34617 dest: /192.168.1.158:50010 of size 91176
2017-05-22 17:22:46,504 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2575329100689273927_2316 src: /192.168.1.156:59108 dest: /192.168.1.156:50010 of size 4325
2017-05-22 17:22:49,415 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8628015386990404908_2317 src: /192.168.1.157:46248 dest: /192.168.1.157:50010
2017-05-22 17:22:49,417 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8628015386990404908_2317 src: /192.168.1.157:46248 dest: /192.168.1.157:50010 of size 13568
2017-05-22 17:22:49,496 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8628015386990404908_2317 src: /192.168.1.156:59110 dest: /192.168.1.156:50010
2017-05-22 17:22:49,496 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8628015386990404908_2317 received exception java.io.IOException: Block blk_8628015386990404908_2317 is valid, and cannot be written to.
2017-05-22 17:22:49,498 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8628015386990404908_2317 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 17:22:52,379 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8241337508207911146_2319 src: /192.168.1.158:34618 dest: /192.168.1.158:50010
2017-05-22 17:22:52,381 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8241337508207911146_2319 src: /192.168.1.158:34618 dest: /192.168.1.158:50010 of size 13553
2017-05-22 17:25:10,556 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3604383474125924977_2323 src: /192.168.1.156:59195 dest: /192.168.1.156:50010
2017-05-22 17:25:10,562 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3604383474125924977_2323 src: /192.168.1.156:59195 dest: /192.168.1.156:50010 of size 41886
2017-05-22 17:25:13,659 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3604383474125924977_2323 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3604383474125924977
2017-05-22 17:25:13,659 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2575329100689273927_2316 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2575329100689273927
2017-05-22 17:25:13,660 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1958585996167524057_2315 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1958585996167524057
2017-05-22 17:25:13,660 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8241337508207911146_2319 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8241337508207911146
2017-05-22 17:25:13,661 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8628015386990404908_2317 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8628015386990404908
2017-05-22 17:25:22,286 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:25:33,121 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:25:33,336 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:25:33,337 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:25:33,340 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:25:33,407 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:25:33,464 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:25:33,465 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:25:33,465 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:25:33,681 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 17:25:33,715 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:25:33,718 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:25:33,718 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 17:25:33,722 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:25:33,739 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:25:33,744 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:25:33,745 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:25:33,746 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:25:33,746 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:25:33,747 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:25:33,747 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:25:33,749 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:25:33,749 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:25:33,756 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:25:36,758 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 6 msecs
2017-05-22 17:26:33,849 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1618976150955901185_2328 src: /192.168.1.158:34621 dest: /192.168.1.158:50010
2017-05-22 17:26:33,861 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1618976150955901185_2328 src: /192.168.1.158:34621 dest: /192.168.1.158:50010 of size 13553
2017-05-22 17:26:33,893 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2419143933212993780_2324 src: /192.168.1.158:34622 dest: /192.168.1.158:50010
2017-05-22 17:26:33,899 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2419143933212993780_2324 src: /192.168.1.158:34622 dest: /192.168.1.158:50010 of size 91176
2017-05-22 17:26:39,769 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1983222424568756719_2325 src: /192.168.1.158:34623 dest: /192.168.1.158:50010
2017-05-22 17:26:39,771 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1983222424568756719_2325 src: /192.168.1.158:34623 dest: /192.168.1.158:50010 of size 8645
2017-05-22 17:26:39,875 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8847170435315064083_2326 src: /192.168.1.156:59217 dest: /192.168.1.156:50010
2017-05-22 17:26:39,876 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8847170435315064083_2326 src: /192.168.1.156:59217 dest: /192.168.1.156:50010 of size 13568
2017-05-22 17:29:33,976 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4331560596240907962_2329 src: /192.168.1.156:59344 dest: /192.168.1.156:50010
2017-05-22 17:29:33,984 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4331560596240907962_2329 src: /192.168.1.156:59344 dest: /192.168.1.156:50010 of size 77826
2017-05-22 17:29:37,060 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2419143933212993780_2324 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2419143933212993780
2017-05-22 17:29:37,060 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1983222424568756719_2325 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1983222424568756719
2017-05-22 17:29:37,061 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1618976150955901185_2328 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1618976150955901185
2017-05-22 17:29:37,061 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4331560596240907962_2329 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4331560596240907962
2017-05-22 17:29:37,062 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8847170435315064083_2326 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8847170435315064083
2017-05-22 17:29:44,785 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:29:55,655 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:29:55,852 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:29:55,854 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:29:55,856 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:29:55,917 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:29:55,966 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:29:55,966 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:29:55,966 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:29:56,190 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 17:29:56,231 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:29:56,234 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:29:56,234 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 17:29:56,239 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:29:56,258 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:29:56,263 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:29:56,264 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:29:56,265 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:29:56,266 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:29:56,266 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:29:56,267 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:29:56,269 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:29:56,270 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:29:56,278 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:29:59,281 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 17:31:02,339 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4681549092505334539_2335 src: /192.168.1.158:34626 dest: /192.168.1.158:50010
2017-05-22 17:31:02,339 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2468862496978714318_2333 src: /192.168.1.158:34627 dest: /192.168.1.158:50010
2017-05-22 17:31:02,360 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4681549092505334539_2335 src: /192.168.1.158:34626 dest: /192.168.1.158:50010 of size 13568
2017-05-22 17:31:02,361 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2468862496978714318_2333 src: /192.168.1.158:34627 dest: /192.168.1.158:50010 of size 91176
2017-05-22 17:31:05,308 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5456029802101270663_2337 src: /192.168.1.156:59361 dest: /192.168.1.156:50010
2017-05-22 17:31:05,309 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5456029802101270663_2337 src: /192.168.1.156:59361 dest: /192.168.1.156:50010 of size 13553
2017-05-22 17:31:08,305 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8907557348169376682_2334 src: /192.168.1.158:34628 dest: /192.168.1.158:50010
2017-05-22 17:31:08,307 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8907557348169376682_2334 src: /192.168.1.158:34628 dest: /192.168.1.158:50010 of size 8645
2017-05-22 17:34:08,396 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6062177997603001183_2338 src: /192.168.1.158:34629 dest: /192.168.1.158:50010
2017-05-22 17:34:08,461 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6062177997603001183_2338 src: /192.168.1.158:34629 dest: /192.168.1.158:50010 of size 77826
2017-05-22 17:34:11,464 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8907557348169376682_2334 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8907557348169376682
2017-05-22 17:34:11,464 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4681549092505334539_2335 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4681549092505334539
2017-05-22 17:34:11,465 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2468862496978714318_2333 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2468862496978714318
2017-05-22 17:34:11,465 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5456029802101270663_2337 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5456029802101270663
2017-05-22 17:34:11,466 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6062177997603001183_2338 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6062177997603001183
2017-05-22 17:34:18,432 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:34:29,273 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:34:29,450 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:34:29,451 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:34:29,453 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:34:29,511 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:34:29,556 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:34:29,557 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:34:29,557 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:34:29,771 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 17:34:29,804 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:34:29,806 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:34:29,806 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 17:34:29,810 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:34:29,826 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:34:29,831 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:34:29,832 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:34:29,833 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:34:29,833 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:34:29,834 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:34:29,834 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:34:29,843 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:34:29,844 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:34:29,868 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:34:32,857 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-22 17:35:35,954 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8584730107159724424_2346 src: /192.168.1.157:46649 dest: /192.168.1.157:50010
2017-05-22 17:35:35,957 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4000846019022163693_2342 src: /192.168.1.156:59502 dest: /192.168.1.156:50010
2017-05-22 17:35:35,974 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4000846019022163693_2342 src: /192.168.1.156:59502 dest: /192.168.1.156:50010 of size 91176
2017-05-22 17:35:35,976 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8584730107159724424_2346 src: /192.168.1.157:46649 dest: /192.168.1.157:50010 of size 13553
2017-05-22 17:35:38,931 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4830785429082602514_2343 src: /192.168.1.157:46650 dest: /192.168.1.157:50010
2017-05-22 17:35:38,932 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4830785429082602514_2343 src: /192.168.1.157:46650 dest: /192.168.1.157:50010 of size 8645
2017-05-22 17:35:38,954 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5729634852572832416_2344 src: /192.168.1.156:59503 dest: /192.168.1.156:50010
2017-05-22 17:35:38,956 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5729634852572832416_2344 src: /192.168.1.156:59504 dest: /192.168.1.156:50010
2017-05-22 17:35:38,956 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5729634852572832416_2344 src: /192.168.1.156:59503 dest: /192.168.1.156:50010 of size 13568
2017-05-22 17:35:38,956 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5729634852572832416_2344 received exception java.io.IOException: Block blk_5729634852572832416_2344 is valid, and cannot be written to.
2017-05-22 17:35:38,959 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_5729634852572832416_2344 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 17:35:41,899 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_5729634852572832416_2344 to 192.168.1.158:50010
2017-05-22 17:35:41,910 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_5729634852572832416_2344 to /192.168.1.158:50010
2017-05-22 17:39:03,133 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4000846019022163693_2342 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4000846019022163693
2017-05-22 17:39:03,133 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4830785429082602514_2343 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4830785429082602514
2017-05-22 17:39:03,134 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5729634852572832416_2344 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5729634852572832416
2017-05-22 17:39:06,057 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9213940651532312459_2347 src: /192.168.1.156:59651 dest: /192.168.1.156:50010
2017-05-22 17:39:06,063 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9213940651532312459_2347 src: /192.168.1.156:59651 dest: /192.168.1.156:50010 of size 77826
2017-05-22 17:39:09,134 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8584730107159724424_2346 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8584730107159724424
2017-05-22 17:39:15,778 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:39:26,550 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:39:26,747 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:39:26,749 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:39:26,750 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:39:26,817 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:39:26,874 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:39:26,875 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:39:26,875 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:39:27,102 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 17:39:27,135 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:39:27,138 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:39:27,138 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 17:39:27,147 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:39:27,169 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:39:27,176 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:39:27,177 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:39:27,177 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:39:27,177 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:39:27,177 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:39:27,177 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:39:27,181 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:39:27,181 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:39:27,192 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:39:27,242 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-9213940651532312459_2347
2017-05-22 17:39:30,195 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 14 msecs
2017-05-22 17:40:03,236 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9213940651532312459_2347 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9213940651532312459
2017-05-22 17:40:27,224 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4790462770981463482_2355 src: /192.168.1.156:59660 dest: /192.168.1.156:50010
2017-05-22 17:40:27,251 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4790462770981463482_2355 src: /192.168.1.156:59660 dest: /192.168.1.156:50010 of size 13553
2017-05-22 17:40:27,276 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-894941503370754092_2351 src: /192.168.1.158:34634 dest: /192.168.1.158:50010
2017-05-22 17:40:27,278 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-894941503370754092_2351 src: /192.168.1.158:34634 dest: /192.168.1.158:50010 of size 91176
2017-05-22 17:40:30,209 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7267288253889738594_2353 src: /192.168.1.156:59667 dest: /192.168.1.156:50010
2017-05-22 17:40:30,218 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7267288253889738594_2353 src: /192.168.1.156:59667 dest: /192.168.1.156:50010 of size 13568
2017-05-22 17:40:33,276 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6702514613143154117_2352 src: /192.168.1.158:34635 dest: /192.168.1.158:50010
2017-05-22 17:40:33,277 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6702514613143154117_2352 src: /192.168.1.158:34635 dest: /192.168.1.158:50010 of size 4325
2017-05-22 17:42:48,271 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_709767010073881014_2359 src: /192.168.1.157:46867 dest: /192.168.1.157:50010
2017-05-22 17:42:48,277 INFO org.apache.hadoop.dfs.DataNode: Received block blk_709767010073881014_2359 src: /192.168.1.157:46867 dest: /192.168.1.157:50010 of size 41886
2017-05-22 17:42:51,428 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-894941503370754092_2351 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-894941503370754092
2017-05-22 17:42:51,429 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4790462770981463482_2355 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4790462770981463482
2017-05-22 17:42:51,429 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6702514613143154117_2352 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6702514613143154117
2017-05-22 17:42:51,430 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7267288253889738594_2353 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7267288253889738594
2017-05-22 17:42:57,436 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-22 17:42:57,439 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:43:08,204 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:43:08,443 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:43:08,445 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:43:08,446 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:43:08,522 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:43:08,583 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:43:08,584 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:43:08,584 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:43:08,813 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 17:43:08,846 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:43:08,849 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:43:08,849 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-22 17:43:08,854 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:43:08,870 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:43:08,875 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:43:08,875 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:43:08,877 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:43:08,877 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:43:08,878 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:43:08,878 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:43:08,883 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:43:08,884 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:43:08,893 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:43:08,935 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_709767010073881014_2359
2017-05-22 17:43:11,893 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 9 msecs
2017-05-22 17:43:44,917 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_709767010073881014_2359 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_709767010073881014
2017-05-22 17:44:14,966 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_810043803893717155_2360 src: /192.168.1.156:59775 dest: /192.168.1.156:50010
2017-05-22 17:44:14,989 INFO org.apache.hadoop.dfs.DataNode: Received block blk_810043803893717155_2360 src: /192.168.1.156:59775 dest: /192.168.1.156:50010 of size 91176
2017-05-22 17:44:15,003 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6506929699000605792_2361 src: /192.168.1.158:34638 dest: /192.168.1.158:50010
2017-05-22 17:44:15,004 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6506929699000605792_2361 src: /192.168.1.158:34638 dest: /192.168.1.158:50010 of size 4325
2017-05-22 17:44:17,957 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8752412584456878730_2364 src: /192.168.1.156:59776 dest: /192.168.1.156:50010
2017-05-22 17:44:17,958 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8752412584456878730_2364 src: /192.168.1.156:59777 dest: /192.168.1.156:50010
2017-05-22 17:44:17,959 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8752412584456878730_2364 src: /192.168.1.156:59776 dest: /192.168.1.156:50010 of size 13553
2017-05-22 17:44:17,961 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8752412584456878730_2364 received exception java.io.IOException: Block blk_8752412584456878730_2364 is valid, and cannot be written to.
2017-05-22 17:44:17,963 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8752412584456878730_2364 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 17:44:17,972 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1029393328982889467_2362 src: /192.168.1.157:46883 dest: /192.168.1.157:50010
2017-05-22 17:44:17,978 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1029393328982889467_2362 src: /192.168.1.157:46883 dest: /192.168.1.157:50010 of size 13568
2017-05-22 17:44:20,947 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8752412584456878730_2364 to 192.168.1.158:50010
2017-05-22 17:44:20,955 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_8752412584456878730_2364 to /192.168.1.158:50010
2017-05-22 17:46:24,017 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5389512404429587070_2368 src: /192.168.1.156:59859 dest: /192.168.1.156:50010
2017-05-22 17:46:24,020 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5389512404429587070_2368 src: /192.168.1.156:59859 dest: /192.168.1.156:50010 of size 41886
2017-05-22 17:46:27,073 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6506929699000605792_2361 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6506929699000605792
2017-05-22 17:46:27,074 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1029393328982889467_2362 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1029393328982889467
2017-05-22 17:46:27,074 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_810043803893717155_2360 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_810043803893717155
2017-05-22 17:46:30,076 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5389512404429587070_2368 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5389512404429587070
2017-05-22 17:46:30,076 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8752412584456878730_2364 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8752412584456878730
2017-05-22 17:46:35,084 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:46:45,926 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:46:46,110 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:46:46,112 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:46:46,114 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:46:46,174 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:46:46,220 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:46:46,221 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:46:46,221 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:46:46,447 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 17:46:46,484 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:46:46,487 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:46:46,487 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-22 17:46:46,492 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:46:46,510 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:46:46,514 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:46:46,514 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:46:46,516 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:46:46,516 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:46:46,517 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:46:46,517 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:46:46,532 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:46:46,532 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:46:46,544 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:46:49,545 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 10 msecs
2017-05-22 17:47:52,632 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7151287694026742169_2371 src: /192.168.1.158:34641 dest: /192.168.1.158:50010
2017-05-22 17:47:52,644 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7151287694026742169_2371 src: /192.168.1.158:34641 dest: /192.168.1.158:50010 of size 13568
2017-05-22 17:47:52,659 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_67322694403076899_2369 src: /192.168.1.158:34642 dest: /192.168.1.158:50010
2017-05-22 17:47:52,666 INFO org.apache.hadoop.dfs.DataNode: Received block blk_67322694403076899_2369 src: /192.168.1.158:34642 dest: /192.168.1.158:50010 of size 91176
2017-05-22 17:47:55,577 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8701596416203619123_2370 src: /192.168.1.156:59874 dest: /192.168.1.156:50010
2017-05-22 17:47:55,578 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8701596416203619123_2370 src: /192.168.1.156:59874 dest: /192.168.1.156:50010 of size 4325
2017-05-22 17:47:58,624 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2260459064003005351_2373 src: /192.168.1.158:34643 dest: /192.168.1.158:50010
2017-05-22 17:47:58,627 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2260459064003005351_2373 src: /192.168.1.158:34643 dest: /192.168.1.158:50010 of size 13553
2017-05-22 17:49:55,639 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1972253176164382045_2377 src: /192.168.1.158:34644 dest: /192.168.1.158:50010
2017-05-22 17:49:55,641 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1972253176164382045_2377 src: /192.168.1.158:34644 dest: /192.168.1.158:50010 of size 41886
2017-05-22 17:49:58,737 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1972253176164382045_2377 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1972253176164382045
2017-05-22 17:49:58,737 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_67322694403076899_2369 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_67322694403076899
2017-05-22 17:49:58,738 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2260459064003005351_2373 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2260459064003005351
2017-05-22 17:49:58,738 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7151287694026742169_2371 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7151287694026742169
2017-05-22 17:49:58,738 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8701596416203619123_2370 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8701596416203619123
2017-05-22 17:50:08,416 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:50:19,337 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:50:19,533 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:50:19,535 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:50:19,536 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:50:19,593 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:50:19,642 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:50:19,642 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:50:19,642 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:50:19,868 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 17:50:19,900 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:50:19,903 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:50:19,903 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 17:50:19,907 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:50:19,924 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:50:19,928 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:50:19,929 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:50:19,930 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:50:19,930 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:50:19,931 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:50:19,931 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:50:19,950 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:50:19,951 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:50:19,966 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:50:22,966 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-22 17:51:20,087 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9012858397761755609_2379 src: /192.168.1.158:34647 dest: /192.168.1.158:50010
2017-05-22 17:51:20,100 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9012858397761755609_2379 src: /192.168.1.158:34647 dest: /192.168.1.158:50010 of size 2165
2017-05-22 17:51:20,142 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5281355469198362653_2378 src: /192.168.1.156:59969 dest: /192.168.1.156:50010
2017-05-22 17:51:20,149 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5281355469198362653_2378 src: /192.168.1.156:59969 dest: /192.168.1.156:50010 of size 91176
2017-05-22 17:51:23,029 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3124996194095097044_2380 src: /192.168.1.157:47093 dest: /192.168.1.157:50010
2017-05-22 17:51:23,036 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3124996194095097044_2380 src: /192.168.1.157:47093 dest: /192.168.1.157:50010 of size 13568
2017-05-22 17:51:26,002 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-799093383019549502_2382 src: /192.168.1.158:34648 dest: /192.168.1.158:50010
2017-05-22 17:51:26,004 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-799093383019549502_2382 src: /192.168.1.158:34648 dest: /192.168.1.158:50010 of size 13553
2017-05-22 17:53:32,093 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9012858397761755609_2379 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9012858397761755609
2017-05-22 17:53:32,094 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5281355469198362653_2378 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5281355469198362653
2017-05-22 17:53:32,094 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3124996194095097044_2380 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3124996194095097044
2017-05-22 17:53:35,094 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-799093383019549502_2382 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-799093383019549502
2017-05-22 17:53:41,158 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-22 17:53:41,253 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:53:52,118 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:53:52,302 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:53:52,304 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:53:52,306 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:53:52,366 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:53:52,413 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:53:52,414 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:53:52,414 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:53:52,632 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 17:53:52,666 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:53:52,669 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:53:52,669 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 17:53:52,673 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:53:52,690 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:53:52,695 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:53:52,695 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:53:52,696 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:53:52,697 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:53:52,697 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:53:52,697 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:53:52,718 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:53:52,719 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:53:52,733 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:53:55,736 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-05-22 17:54:58,845 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2782034661705506855_2387 src: /192.168.1.156:60051 dest: /192.168.1.156:50010
2017-05-22 17:54:58,845 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2839701980024495877_2389 src: /192.168.1.157:47170 dest: /192.168.1.157:50010
2017-05-22 17:54:58,864 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2839701980024495877_2389 src: /192.168.1.157:47170 dest: /192.168.1.157:50010 of size 13568
2017-05-22 17:54:58,870 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2782034661705506855_2387 src: /192.168.1.156:60051 dest: /192.168.1.156:50010 of size 91176
2017-05-22 17:55:01,820 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4122215285661584047_2391 src: /192.168.1.156:60053 dest: /192.168.1.156:50010
2017-05-22 17:55:01,821 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4122215285661584047_2391 src: /192.168.1.156:60053 dest: /192.168.1.156:50010 of size 13553
2017-05-22 17:55:01,838 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6780989882309460232_2388 src: /192.168.1.157:47171 dest: /192.168.1.157:50010
2017-05-22 17:55:01,839 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6780989882309460232_2388 src: /192.168.1.157:47171 dest: /192.168.1.157:50010 of size 2165
2017-05-22 17:56:49,869 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6034693821641097701_2395 src: /192.168.1.158:34651 dest: /192.168.1.158:50010
2017-05-22 17:56:49,871 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6034693821641097701_2395 src: /192.168.1.158:34651 dest: /192.168.1.158:50010 of size 23545
2017-05-22 17:56:52,830 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2839701980024495877_2389 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2839701980024495877
2017-05-22 17:56:52,831 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2782034661705506855_2387 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2782034661705506855
2017-05-22 17:56:52,831 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6780989882309460232_2388 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6780989882309460232
2017-05-22 17:56:55,823 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4122215285661584047_2391 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4122215285661584047
2017-05-22 17:56:55,823 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6034693821641097701_2395 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6034693821641097701
2017-05-22 17:57:00,907 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 17:57:11,793 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 17:57:11,996 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 17:57:11,998 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 17:57:12,000 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 17:57:12,065 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 17:57:12,121 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 17:57:12,121 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 17:57:12,122 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 17:57:12,356 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 17:57:12,393 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 17:57:12,396 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 17:57:12,396 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 17:57:12,402 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 17:57:12,420 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 17:57:12,424 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 17:57:12,425 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 17:57:12,426 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 17:57:12,427 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 17:57:12,427 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 17:57:12,427 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 17:57:12,429 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 17:57:12,430 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 17:57:12,438 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 17:57:15,445 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-22 17:58:18,524 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7416556400762549719_2396 src: /192.168.1.157:47241 dest: /192.168.1.157:50010
2017-05-22 17:58:18,529 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8016063657028546669_2400 src: /192.168.1.156:60121 dest: /192.168.1.156:50010
2017-05-22 17:58:18,541 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8016063657028546669_2400 src: /192.168.1.156:60121 dest: /192.168.1.156:50010 of size 13553
2017-05-22 17:58:18,545 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7416556400762549719_2396 src: /192.168.1.157:47241 dest: /192.168.1.157:50010 of size 91176
2017-05-22 17:58:21,498 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5297431147474847681_2397 src: /192.168.1.157:47242 dest: /192.168.1.157:50010
2017-05-22 17:58:21,499 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5297431147474847681_2397 src: /192.168.1.157:47242 dest: /192.168.1.157:50010 of size 2165
2017-05-22 17:58:21,500 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5297431147474847681_2397 src: /192.168.1.157:47243 dest: /192.168.1.157:50010
2017-05-22 17:58:21,501 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5297431147474847681_2397 received exception java.io.IOException: Block blk_5297431147474847681_2397 is valid, and cannot be written to.
2017-05-22 17:58:21,502 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_5297431147474847681_2397 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 17:58:21,529 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6663248030539168054_2398 src: /192.168.1.156:60122 dest: /192.168.1.156:50010
2017-05-22 17:58:21,530 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6663248030539168054_2398 src: /192.168.1.156:60122 dest: /192.168.1.156:50010 of size 13568
2017-05-22 18:00:09,576 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1165705042382391115_2404 src: /192.168.1.156:60180 dest: /192.168.1.156:50010
2017-05-22 18:00:09,581 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1165705042382391115_2404 src: /192.168.1.156:60180 dest: /192.168.1.156:50010 of size 23949
2017-05-22 18:00:12,683 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7416556400762549719_2396 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7416556400762549719
2017-05-22 18:00:12,684 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5297431147474847681_2397 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5297431147474847681
2017-05-22 18:00:12,684 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6663248030539168054_2398 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6663248030539168054
2017-05-22 18:00:15,672 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8016063657028546669_2400 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8016063657028546669
2017-05-22 18:00:15,672 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1165705042382391115_2404 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1165705042382391115
2017-05-22 18:00:22,267 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 18:00:33,025 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 18:00:33,249 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 18:00:33,250 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 18:00:33,252 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 18:00:33,313 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 18:00:33,362 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 18:00:33,363 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 18:00:33,363 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 18:00:33,587 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 18:00:33,626 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 18:00:33,629 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 18:00:33,629 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 18:00:33,634 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 18:00:33,651 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 18:00:33,656 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 18:00:33,657 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 18:00:33,658 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 18:00:33,659 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 18:00:33,659 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 18:00:33,659 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 18:00:33,662 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 18:00:33,662 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 18:00:33,670 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 18:00:36,674 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 9 msecs
2017-05-22 18:01:33,762 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4143862863229717668_2405 src: /192.168.1.158:34656 dest: /192.168.1.158:50010
2017-05-22 18:01:33,775 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4143862863229717668_2405 src: /192.168.1.158:34656 dest: /192.168.1.158:50010 of size 91176
2017-05-22 18:01:33,875 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7814881477699021349_2407 src: /192.168.1.158:34657 dest: /192.168.1.158:50010
2017-05-22 18:01:33,876 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7814881477699021349_2407 src: /192.168.1.158:34657 dest: /192.168.1.158:50010 of size 13569
2017-05-22 18:01:36,864 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6386580698524365942_2406 src: /192.168.1.156:60197 dest: /192.168.1.156:50010
2017-05-22 18:01:36,864 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8840135998480266826_2409 src: /192.168.1.156:60198 dest: /192.168.1.156:50010
2017-05-22 18:01:36,866 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8840135998480266826_2409 src: /192.168.1.156:60198 dest: /192.168.1.156:50010 of size 13554
2017-05-22 18:01:36,868 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6386580698524365942_2406 src: /192.168.1.156:60197 dest: /192.168.1.156:50010 of size 1085
2017-05-22 18:04:03,733 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4707884441243406705_2413 src: /192.168.1.158:34658 dest: /192.168.1.158:50010
2017-05-22 18:04:03,735 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4707884441243406705_2413 src: /192.168.1.158:34658 dest: /192.168.1.158:50010 of size 14960
2017-05-22 18:04:06,893 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7814881477699021349_2407 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7814881477699021349
2017-05-22 18:04:06,894 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6386580698524365942_2406 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6386580698524365942
2017-05-22 18:04:06,895 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4143862863229717668_2405 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4143862863229717668
2017-05-22 18:04:09,896 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8840135998480266826_2409 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8840135998480266826
2017-05-22 18:04:09,896 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4707884441243406705_2413 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4707884441243406705
2017-05-22 18:04:14,980 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 18:04:25,834 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 18:04:26,048 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 18:04:26,050 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 18:04:26,052 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 18:04:26,120 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 18:04:26,179 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 18:04:26,180 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 18:04:26,180 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 18:04:26,418 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 18:04:26,454 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 18:04:26,456 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 18:04:26,457 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 18:04:26,461 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 18:04:26,479 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 18:04:26,483 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 18:04:26,484 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 18:04:26,485 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 18:04:26,486 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 18:04:26,486 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 18:04:26,486 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 18:04:26,494 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 18:04:26,494 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 18:04:26,503 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 18:04:29,502 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 18:05:32,599 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_854194255745196975_2416 src: /192.168.1.158:34661 dest: /192.168.1.158:50010
2017-05-22 18:05:32,599 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1514866187361921586_2414 src: /192.168.1.158:34662 dest: /192.168.1.158:50010
2017-05-22 18:05:32,614 INFO org.apache.hadoop.dfs.DataNode: Received block blk_854194255745196975_2416 src: /192.168.1.158:34661 dest: /192.168.1.158:50010 of size 13569
2017-05-22 18:05:32,616 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1514866187361921586_2414 src: /192.168.1.158:34662 dest: /192.168.1.158:50010 of size 91176
2017-05-22 18:05:35,525 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7412485229941552341_2415 src: /192.168.1.157:47371 dest: /192.168.1.157:50010
2017-05-22 18:05:35,527 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7412485229941552341_2415 src: /192.168.1.157:47371 dest: /192.168.1.157:50010 of size 1085
2017-05-22 18:05:35,552 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7412485229941552341_2415 src: /192.168.1.156:60260 dest: /192.168.1.156:50010
2017-05-22 18:05:35,552 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7412485229941552341_2415 received exception java.io.IOException: Block blk_7412485229941552341_2415 is valid, and cannot be written to.
2017-05-22 18:05:35,554 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4239132737898116224_2418 src: /192.168.1.156:60261 dest: /192.168.1.156:50010
2017-05-22 18:05:35,555 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7412485229941552341_2415 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 18:05:35,556 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4239132737898116224_2418 src: /192.168.1.156:60261 dest: /192.168.1.156:50010 of size 13554
2017-05-22 18:05:38,559 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7412485229941552341_2415 to 192.168.1.158:50010
2017-05-22 18:05:38,570 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_7412485229941552341_2415 to /192.168.1.158:50010
2017-05-22 18:08:05,584 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6819654200438991677_2422 src: /192.168.1.157:47415 dest: /192.168.1.157:50010
2017-05-22 18:08:05,589 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6819654200438991677_2422 src: /192.168.1.157:47415 dest: /192.168.1.157:50010 of size 14958
2017-05-22 18:08:08,711 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_854194255745196975_2416 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_854194255745196975
2017-05-22 18:08:08,711 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1514866187361921586_2414 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1514866187361921586
2017-05-22 18:08:08,712 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4239132737898116224_2418 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4239132737898116224
2017-05-22 18:08:08,712 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6819654200438991677_2422 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6819654200438991677
2017-05-22 18:08:08,713 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7412485229941552341_2415 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7412485229941552341
2017-05-22 18:08:15,598 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 18:08:26,512 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 18:08:26,728 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 18:08:26,730 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 18:08:26,732 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 18:08:26,801 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 18:08:26,860 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 18:08:26,861 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 18:08:26,861 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 18:08:27,093 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 18:08:27,126 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 18:08:27,129 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 18:08:27,129 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 18:08:27,133 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 18:08:27,150 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 18:08:27,154 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 18:08:27,154 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 18:08:27,156 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 18:08:27,156 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 18:08:27,157 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 18:08:27,157 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 18:08:27,164 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 18:08:27,164 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 18:08:27,172 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 18:08:30,174 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 18:09:33,210 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6523048452350113935_2423 src: /192.168.1.157:47431 dest: /192.168.1.157:50010
2017-05-22 18:09:33,229 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6523048452350113935_2423 src: /192.168.1.157:47431 dest: /192.168.1.157:50010 of size 91176
2017-05-22 18:09:33,267 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3112281832575584302_2427 src: /192.168.1.158:34665 dest: /192.168.1.158:50010
2017-05-22 18:09:33,269 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3112281832575584302_2427 src: /192.168.1.158:34665 dest: /192.168.1.158:50010 of size 13554
2017-05-22 18:09:36,182 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3974396391903617027_2424 src: /192.168.1.157:47433 dest: /192.168.1.157:50010
2017-05-22 18:09:36,183 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3974396391903617027_2424 src: /192.168.1.157:47433 dest: /192.168.1.157:50010 of size 1085
2017-05-22 18:09:36,244 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3974396391903617027_2424 src: /192.168.1.156:60313 dest: /192.168.1.156:50010
2017-05-22 18:09:36,245 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3974396391903617027_2424 received exception java.io.IOException: Block blk_3974396391903617027_2424 is valid, and cannot be written to.
2017-05-22 18:09:36,245 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2986239833990855315_2425 src: /192.168.1.156:60314 dest: /192.168.1.156:50010
2017-05-22 18:09:36,247 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_3974396391903617027_2424 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 18:09:36,249 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2986239833990855315_2425 src: /192.168.1.156:60314 dest: /192.168.1.156:50010 of size 13569
2017-05-22 18:12:09,239 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5818087446208867448_2431 src: /192.168.1.158:34666 dest: /192.168.1.158:50010
2017-05-22 18:12:09,240 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5818087446208867448_2431 src: /192.168.1.158:34666 dest: /192.168.1.158:50010 of size 14958
2017-05-22 18:12:12,447 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2986239833990855315_2425 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2986239833990855315
2017-05-22 18:12:12,448 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3112281832575584302_2427 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3112281832575584302
2017-05-22 18:12:12,448 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3974396391903617027_2424 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3974396391903617027
2017-05-22 18:12:12,449 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6523048452350113935_2423 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6523048452350113935
2017-05-22 18:31:24,688 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 18:31:35,596 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 18:31:35,789 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 18:31:35,791 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 18:31:35,792 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 18:31:35,860 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 18:31:35,919 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 18:31:35,920 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 18:31:35,920 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 18:31:36,153 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 18:31:36,186 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 18:31:36,188 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 18:31:36,188 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 18:31:36,196 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 18:31:36,216 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 18:31:36,221 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 18:31:36,221 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 18:31:36,222 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 18:31:36,223 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 18:31:36,223 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 18:31:36,223 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 18:31:36,225 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 18:31:36,226 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 18:31:36,234 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 18:31:36,280 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-5818087446208867448_2431
2017-05-22 18:31:39,237 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 11 msecs
2017-05-22 18:32:12,283 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5818087446208867448_2431 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5818087446208867448
2017-05-22 18:32:36,302 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4550914238078242209_2432 src: /192.168.1.156:60356 dest: /192.168.1.156:50010
2017-05-22 18:32:36,302 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1044322886443675183_2434 src: /192.168.1.157:47486 dest: /192.168.1.157:50010
2017-05-22 18:32:36,316 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4550914238078242209_2432 src: /192.168.1.156:60356 dest: /192.168.1.156:50010 of size 91176
2017-05-22 18:32:36,325 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1044322886443675183_2434 src: /192.168.1.157:47486 dest: /192.168.1.157:50010 of size 13560
2017-05-22 18:32:39,287 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5716447598310218159_2433 src: /192.168.1.157:47492 dest: /192.168.1.157:50010
2017-05-22 18:32:39,288 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5716447598310218159_2433 src: /192.168.1.157:47492 dest: /192.168.1.157:50010 of size 8645
2017-05-22 18:32:42,300 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4901031910318691830_2436 src: /192.168.1.158:34677 dest: /192.168.1.158:50010
2017-05-22 18:32:42,503 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4901031910318691830_2436 src: /192.168.1.158:34677 dest: /192.168.1.158:50010 of size 13545
2017-05-22 18:32:49,857 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 18:32:56,955 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 18:33:03,729 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 18:33:10,615 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 18:33:17,439 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 18:33:23,986 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 18:33:31,050 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 18:33:37,611 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 18:33:44,510 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 18:33:51,133 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 18:33:57,993 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 18:34:05,068 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 18:34:23,629 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 18:34:29,936 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 18:35:42,367 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_989415198764239629_2436 src: /192.168.1.156:60468 dest: /192.168.1.156:50010
2017-05-22 18:35:42,367 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_989415198764239629_2436 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 18:35:42,369 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 18:35:45,388 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4901031910318691830_2436 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4901031910318691830
2017-05-22 18:35:45,389 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1044322886443675183_2434 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1044322886443675183
2017-05-22 18:35:45,389 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4550914238078242209_2432 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4550914238078242209
2017-05-22 18:35:45,389 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5716447598310218159_2433 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5716447598310218159
2017-05-22 18:35:52,484 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 18:36:03,405 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 18:36:03,603 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 18:36:03,605 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 18:36:03,606 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 18:36:03,668 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 18:36:03,717 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 18:36:03,717 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 18:36:03,717 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 18:36:03,937 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 18:36:03,970 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 18:36:03,983 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 18:36:03,983 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-22 18:36:03,988 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 18:36:04,006 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 18:36:04,011 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 18:36:04,012 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 18:36:04,013 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 18:36:04,014 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 18:36:04,014 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 18:36:04,015 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 18:36:04,017 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 18:36:04,017 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 18:36:04,025 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 18:36:07,027 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 9 msecs
2017-05-22 18:37:10,040 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2314744181259674729_2442 src: /192.168.1.156:60482 dest: /192.168.1.156:50010
2017-05-22 18:37:10,058 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2314744181259674729_2442 src: /192.168.1.156:60482 dest: /192.168.1.156:50010 of size 8645
2017-05-22 18:37:10,098 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5193531790019765184_2441 src: /192.168.1.157:47605 dest: /192.168.1.157:50010
2017-05-22 18:37:10,107 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5193531790019765184_2441 src: /192.168.1.157:47605 dest: /192.168.1.157:50010 of size 91176
2017-05-22 18:37:13,039 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9027613750339037901_2445 src: /192.168.1.156:60483 dest: /192.168.1.156:50010
2017-05-22 18:37:13,040 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9027613750339037901_2445 src: /192.168.1.156:60483 dest: /192.168.1.156:50010 of size 13545
2017-05-22 18:37:13,041 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4220696721103957003_2443 src: /192.168.1.156:60484 dest: /192.168.1.156:50010
2017-05-22 18:37:13,043 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4220696721103957003_2443 src: /192.168.1.156:60484 dest: /192.168.1.156:50010 of size 13560
2017-05-22 18:37:13,101 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4220696721103957003_2443 src: /192.168.1.157:47606 dest: /192.168.1.157:50010
2017-05-22 18:37:13,102 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-4220696721103957003_2443 received exception java.io.IOException: Block blk_-4220696721103957003_2443 is valid, and cannot be written to.
2017-05-22 18:37:13,102 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9027613750339037901_2445 src: /192.168.1.157:47607 dest: /192.168.1.157:50010
2017-05-22 18:37:13,102 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_9027613750339037901_2445 received exception java.io.IOException: Block blk_9027613750339037901_2445 is valid, and cannot be written to.
2017-05-22 18:37:13,104 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-4220696721103957003_2443 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 18:37:13,104 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_9027613750339037901_2445 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 18:37:16,118 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-4220696721103957003_2443 to 192.168.1.158:50010
2017-05-22 18:37:16,121 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_9027613750339037901_2445 to 192.168.1.158:50010
2017-05-22 18:37:16,124 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_9027613750339037901_2445 to /192.168.1.158:50010
2017-05-22 18:37:16,126 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-4220696721103957003_2443 to /192.168.1.158:50010
2017-05-22 18:38:18,629 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 18:38:25,413 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 18:38:32,217 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 18:39:05,119 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 18:40:13,193 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4220696721103957003_2443 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4220696721103957003
2017-05-22 18:40:13,194 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2314744181259674729_2442 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2314744181259674729
2017-05-22 18:40:13,194 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5193531790019765184_2441 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5193531790019765184
2017-05-22 18:40:13,195 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9027613750339037901_2445 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9027613750339037901
2017-05-22 18:40:19,193 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-22 18:40:19,202 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 18:40:29,963 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 18:40:30,172 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 18:40:30,174 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 18:40:30,176 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 18:40:30,243 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 18:40:30,302 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 18:40:30,303 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 18:40:30,303 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 18:40:30,542 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 18:40:30,581 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 18:40:30,584 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 18:40:30,584 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 18:40:30,589 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 18:40:30,612 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 18:40:30,619 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 18:40:30,621 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 18:40:30,621 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 18:40:30,621 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 18:40:30,622 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 18:40:30,622 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 18:40:30,624 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 18:40:30,625 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 18:40:30,634 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 18:40:33,636 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 18:41:36,602 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6799534393737233614_2450 src: /192.168.1.157:47743 dest: /192.168.1.157:50010
2017-05-22 18:41:36,614 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6799534393737233614_2450 src: /192.168.1.157:47743 dest: /192.168.1.157:50010 of size 91176
2017-05-22 18:41:36,668 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1381195306888508922_2451 src: /192.168.1.156:60599 dest: /192.168.1.156:50010
2017-05-22 18:41:36,671 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1381195306888508922_2451 src: /192.168.1.156:60599 dest: /192.168.1.156:50010 of size 8645
2017-05-22 18:41:39,665 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3022068302194117554_2452 src: /192.168.1.156:60600 dest: /192.168.1.156:50010
2017-05-22 18:41:39,666 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3022068302194117554_2452 src: /192.168.1.156:60600 dest: /192.168.1.156:50010 of size 13560
2017-05-22 18:41:40,823 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 18:41:42,652 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6015421142191655589_2454 src: /192.168.1.158:34875 dest: /192.168.1.158:50010
2017-05-22 18:41:42,654 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6015421142191655589_2454 src: /192.168.1.158:34875 dest: /192.168.1.158:50010 of size 13545
2017-05-22 18:42:31,742 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 18:42:38,527 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 18:42:45,300 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 18:42:52,099 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 18:42:58,915 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 18:43:05,651 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 18:43:22,347 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 18:43:30,470 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 18:44:42,750 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9194811971855505288_2454 src: /192.168.1.156:60705 dest: /192.168.1.156:50010
2017-05-22 18:44:42,751 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_9194811971855505288_2454 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 18:44:42,753 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 18:44:45,874 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6799534393737233614_2450 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6799534393737233614
2017-05-22 18:44:45,875 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6015421142191655589_2454 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6015421142191655589
2017-05-22 18:44:45,876 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1381195306888508922_2451 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1381195306888508922
2017-05-22 18:44:45,876 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3022068302194117554_2452 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3022068302194117554
2017-05-22 18:44:53,571 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 18:45:04,367 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 18:45:04,553 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 18:45:04,555 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 18:45:04,556 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 18:45:04,619 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 18:45:04,665 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 18:45:04,666 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 18:45:04,666 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 18:45:04,871 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 18:45:04,903 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 18:45:04,905 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 18:45:04,906 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 18:45:04,916 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 18:45:04,934 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 18:45:04,939 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 18:45:04,940 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 18:45:04,941 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 18:45:04,942 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 18:45:04,943 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 18:45:04,943 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 18:45:04,955 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 18:45:04,955 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 18:45:04,968 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 18:45:07,969 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-05-22 18:46:05,046 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2584395646363149227_2461 src: /192.168.1.157:47866 dest: /192.168.1.157:50010
2017-05-22 18:46:05,065 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2584395646363149227_2461 src: /192.168.1.157:47866 dest: /192.168.1.157:50010 of size 13560
2017-05-22 18:46:05,165 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2553835530260414134_2459 src: /192.168.1.158:34969 dest: /192.168.1.158:50010
2017-05-22 18:46:05,170 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2553835530260414134_2459 src: /192.168.1.158:34969 dest: /192.168.1.158:50010 of size 91176
2017-05-22 18:46:05,363 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 18:46:08,028 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8914115493113232015_2460 src: /192.168.1.157:47870 dest: /192.168.1.157:50010
2017-05-22 18:46:08,030 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7948053310025323750_2463 src: /192.168.1.157:47871 dest: /192.168.1.157:50010
2017-05-22 18:46:08,031 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8914115493113232015_2460 src: /192.168.1.157:47870 dest: /192.168.1.157:50010 of size 4325
2017-05-22 18:46:08,033 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7948053310025323750_2463 src: /192.168.1.157:47871 dest: /192.168.1.157:50010 of size 13545
2017-05-22 18:46:08,154 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8914115493113232015_2460 src: /192.168.1.156:60720 dest: /192.168.1.156:50010
2017-05-22 18:46:08,155 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8914115493113232015_2460 received exception java.io.IOException: Block blk_8914115493113232015_2460 is valid, and cannot be written to.
2017-05-22 18:46:08,156 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8914115493113232015_2460 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 18:46:11,001 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8914115493113232015_2460 to 192.168.1.158:50010
2017-05-22 18:46:11,009 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_8914115493113232015_2460 to /192.168.1.158:50010
2017-05-22 18:46:19,164 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 18:46:30,889 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 18:46:42,684 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 18:46:54,488 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 18:47:14,566 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 18:47:19,372 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 18:47:31,391 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 18:48:50,076 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2553835530260414134_2459 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2553835530260414134
2017-05-22 18:48:50,076 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2584395646363149227_2461 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2584395646363149227
2017-05-22 18:48:50,077 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8914115493113232015_2460 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8914115493113232015
2017-05-22 18:48:53,076 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7948053310025323750_2463 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7948053310025323750
2017-05-22 18:48:58,336 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 18:49:09,281 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 18:49:09,492 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 18:49:09,494 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 18:49:09,496 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 18:49:09,566 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 18:49:09,630 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 18:49:09,631 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 18:49:09,631 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 18:49:09,879 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 18:49:09,919 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 18:49:09,927 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 18:49:09,927 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 18:49:09,936 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 18:49:09,956 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 18:49:09,962 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 18:49:09,963 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 18:49:09,964 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 18:49:09,965 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 18:49:09,965 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 18:49:09,965 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 18:49:09,969 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 18:49:09,970 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 18:49:09,979 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 18:49:12,984 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 18:50:15,375 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 18:50:15,932 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7722044868416540750_2469 src: /192.168.1.157:47977 dest: /192.168.1.157:50010
2017-05-22 18:50:15,948 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7722044868416540750_2469 src: /192.168.1.157:47977 dest: /192.168.1.157:50010 of size 4325
2017-05-22 18:50:16,003 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7943844170847916287_2468 src: /192.168.1.156:60821 dest: /192.168.1.156:50010
2017-05-22 18:50:16,008 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7943844170847916287_2468 src: /192.168.1.156:60821 dest: /192.168.1.156:50010 of size 91176
2017-05-22 18:50:18,931 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6246075804550999325_2472 src: /192.168.1.157:47978 dest: /192.168.1.157:50010
2017-05-22 18:50:18,932 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6246075804550999325_2472 src: /192.168.1.157:47978 dest: /192.168.1.157:50010 of size 13545
2017-05-22 18:50:18,934 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6246075804550999325_2472 src: /192.168.1.157:47979 dest: /192.168.1.157:50010
2017-05-22 18:50:18,935 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6246075804550999325_2472 received exception java.io.IOException: Block blk_6246075804550999325_2472 is valid, and cannot be written to.
2017-05-22 18:50:18,937 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_6246075804550999325_2472 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 18:50:18,996 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2289002887090738002_2470 src: /192.168.1.156:60823 dest: /192.168.1.156:50010
2017-05-22 18:50:18,997 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2289002887090738002_2470 src: /192.168.1.156:60823 dest: /192.168.1.156:50010 of size 13560
2017-05-22 18:50:29,084 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 18:50:50,709 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 18:51:03,371 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 18:51:14,945 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 18:51:26,971 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 18:51:30,607 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 18:51:43,406 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 18:53:01,085 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4215665695029973070_2476 src: /192.168.1.156:60919 dest: /192.168.1.156:50010
2017-05-22 18:53:01,085 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4215665695029973070_2476 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 18:53:01,086 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 18:53:04,200 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7722044868416540750_2469 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7722044868416540750
2017-05-22 18:53:04,201 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2289002887090738002_2470 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2289002887090738002
2017-05-22 18:53:04,201 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6246075804550999325_2472 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6246075804550999325
2017-05-22 18:53:04,202 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7943844170847916287_2468 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7943844170847916287
2017-05-22 18:53:11,266 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 18:53:22,120 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 18:53:22,318 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 18:53:22,320 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 18:53:22,322 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 18:53:22,385 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 18:53:22,443 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 18:53:22,444 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 18:53:22,444 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 18:53:22,690 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 18:53:22,726 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 18:53:22,729 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 18:53:22,729 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 18:53:22,734 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 18:53:22,756 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 18:53:22,762 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 18:53:22,763 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 18:53:22,765 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 18:53:22,765 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 18:53:22,765 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 18:53:22,765 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 18:53:22,769 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 18:53:22,769 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 18:53:22,777 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 18:53:25,775 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 6 msecs
2017-05-22 18:54:28,780 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5612533858274837919_2477 src: /192.168.1.156:60934 dest: /192.168.1.156:50010
2017-05-22 18:54:28,788 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_21021834627018904_2479 src: /192.168.1.158:35133 dest: /192.168.1.158:50010
2017-05-22 18:54:28,796 INFO org.apache.hadoop.dfs.DataNode: Received block blk_21021834627018904_2479 src: /192.168.1.158:35133 dest: /192.168.1.158:50010 of size 13560
2017-05-22 18:54:28,797 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5612533858274837919_2477 src: /192.168.1.156:60934 dest: /192.168.1.156:50010 of size 91176
2017-05-22 18:54:34,708 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8646465081865271045_2481 src: /192.168.1.158:35134 dest: /192.168.1.158:50010
2017-05-22 18:54:34,711 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8646465081865271045_2481 src: /192.168.1.158:35134 dest: /192.168.1.158:50010 of size 13545
2017-05-22 18:54:34,777 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7245809123117924991_2478 src: /192.168.1.156:60937 dest: /192.168.1.156:50010
2017-05-22 18:54:34,777 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7245809123117924991_2478 src: /192.168.1.156:60937 dest: /192.168.1.156:50010 of size 4325
2017-05-22 18:54:36,679 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 18:54:40,838 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 18:54:53,055 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 18:55:04,868 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 18:55:16,594 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 18:55:35,821 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 18:55:39,109 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 18:55:49,865 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 18:56:05,516 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 18:56:10,563 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 18:57:16,850 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8768735032565105634_2485 src: /192.168.1.156:32794 dest: /192.168.1.156:50010
2017-05-22 18:57:16,851 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8768735032565105634_2485 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 18:57:16,853 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 18:57:19,915 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8646465081865271045_2481 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8646465081865271045
2017-05-22 18:57:19,915 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5612533858274837919_2477 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5612533858274837919
2017-05-22 18:57:19,916 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_21021834627018904_2479 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_21021834627018904
2017-05-22 18:57:19,916 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7245809123117924991_2478 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7245809123117924991
2017-05-22 18:57:28,653 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 18:57:39,442 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 18:57:39,638 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 18:57:39,639 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 18:57:39,641 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 18:57:39,707 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 18:57:39,764 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 18:57:39,765 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 18:57:39,766 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 18:57:40,002 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 18:57:40,039 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 18:57:40,042 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 18:57:40,042 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 18:57:40,047 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 18:57:40,062 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 18:57:40,067 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 18:57:40,068 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 18:57:40,069 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 18:57:40,069 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 18:57:40,069 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 18:57:40,070 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 18:57:40,071 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 18:57:40,072 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 18:57:40,079 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 18:57:43,080 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 18:58:40,226 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4920245347381511302_2488 src: /192.168.1.158:35213 dest: /192.168.1.158:50010
2017-05-22 18:58:40,239 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8737950047355353709_2486 src: /192.168.1.158:35214 dest: /192.168.1.158:50010
2017-05-22 18:58:40,243 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4920245347381511302_2488 src: /192.168.1.158:35213 dest: /192.168.1.158:50010 of size 13567
2017-05-22 18:58:40,254 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8737950047355353709_2486 src: /192.168.1.158:35214 dest: /192.168.1.158:50010 of size 91176
2017-05-22 18:58:43,180 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3418181444641024482_2487 src: /192.168.1.156:32808 dest: /192.168.1.156:50010
2017-05-22 18:58:43,181 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3418181444641024482_2487 src: /192.168.1.156:32808 dest: /192.168.1.156:50010 of size 4325
2017-05-22 18:58:43,184 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3418181444641024482_2487 src: /192.168.1.156:32809 dest: /192.168.1.156:50010
2017-05-22 18:58:43,184 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3418181444641024482_2487 received exception java.io.IOException: Block blk_-3418181444641024482_2487 is valid, and cannot be written to.
2017-05-22 18:58:43,186 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-3418181444641024482_2487 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 18:58:46,128 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8019780331985826019_2490 src: /192.168.1.158:35217 dest: /192.168.1.158:50010
2017-05-22 18:58:46,131 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8019780331985826019_2490 src: /192.168.1.158:35217 dest: /192.168.1.158:50010 of size 13552
2017-05-22 18:59:06,634 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 18:59:18,941 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 18:59:32,107 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 18:59:44,169 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 19:01:40,333 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6894671384855469582_2494 src: /192.168.1.158:35264 dest: /192.168.1.158:50010
2017-05-22 19:01:40,334 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6894671384855469582_2494 src: /192.168.1.158:35264 dest: /192.168.1.158:50010 of size 43172
2017-05-22 19:01:43,289 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8737950047355353709_2486 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8737950047355353709
2017-05-22 19:01:43,291 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8019780331985826019_2490 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8019780331985826019
2017-05-22 19:01:43,291 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4920245347381511302_2488 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4920245347381511302
2017-05-22 19:01:43,292 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3418181444641024482_2487 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3418181444641024482
2017-05-22 19:01:49,323 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 19:02:00,184 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 19:02:00,383 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 19:02:00,385 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 19:02:00,387 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 19:02:00,454 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 19:02:00,512 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 19:02:00,513 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 19:02:00,513 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 19:02:00,760 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 19:02:00,800 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 19:02:00,803 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 19:02:00,803 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 19:02:00,808 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 19:02:00,828 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 19:02:00,832 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 19:02:00,833 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 19:02:00,833 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 19:02:00,834 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 19:02:00,834 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 19:02:00,834 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 19:02:00,836 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 19:02:00,837 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 19:02:00,844 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 19:02:00,892 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_6894671384855469582_2494
2017-05-22 19:02:03,846 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 6 msecs
2017-05-22 19:02:36,883 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6894671384855469582_2494 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6894671384855469582
2017-05-22 19:03:06,847 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4043513675305833667_2496 src: /192.168.1.158:35276 dest: /192.168.1.158:50010
2017-05-22 19:03:06,862 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4043513675305833667_2496 src: /192.168.1.158:35276 dest: /192.168.1.158:50010 of size 4325
2017-05-22 19:03:06,870 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3666580032551090583_2495 src: /192.168.1.157:48328 dest: /192.168.1.157:50010
2017-05-22 19:03:06,874 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3666580032551090583_2495 src: /192.168.1.157:48328 dest: /192.168.1.157:50010 of size 91176
2017-05-22 19:03:09,833 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6690408564823928681_2497 src: /192.168.1.156:32919 dest: /192.168.1.156:50010
2017-05-22 19:03:09,835 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6690408564823928681_2497 src: /192.168.1.156:32919 dest: /192.168.1.156:50010 of size 13567
2017-05-22 19:03:12,876 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1113237794805531154_2499 src: /192.168.1.158:35277 dest: /192.168.1.158:50010
2017-05-22 19:03:12,878 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1113237794805531154_2499 src: /192.168.1.158:35277 dest: /192.168.1.158:50010 of size 13552
2017-05-22 19:03:28,766 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 19:03:41,020 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 19:03:48,916 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 28 blocks got processed in 6 msecs
2017-05-22 19:03:52,899 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 19:04:04,080 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 19:06:00,911 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7971166378291474696_2503 src: /192.168.1.156:33020 dest: /192.168.1.156:50010
2017-05-22 19:06:00,913 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7971166378291474696_2503 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 19:06:00,915 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 19:06:03,982 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1113237794805531154_2499 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1113237794805531154
2017-05-22 19:06:03,983 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3666580032551090583_2495 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3666580032551090583
2017-05-22 19:06:03,983 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4043513675305833667_2496 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4043513675305833667
2017-05-22 19:06:03,984 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6690408564823928681_2497 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6690408564823928681
2017-05-22 19:06:09,985 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-22 19:06:10,080 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 19:06:20,881 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 19:06:21,095 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 19:06:21,097 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 19:06:21,098 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 19:06:21,165 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 19:06:21,224 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 19:06:21,225 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 19:06:21,225 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 19:06:21,463 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 19:06:21,499 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 19:06:21,501 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 19:06:21,501 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-22 19:06:21,506 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 19:06:21,523 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 19:06:21,528 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 19:06:21,528 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 19:06:21,529 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 19:06:21,530 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 19:06:21,530 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 19:06:21,530 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 19:06:21,532 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 19:06:21,532 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 19:06:21,540 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 19:06:24,542 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 10 msecs
2017-05-22 19:07:27,565 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6310376760233298478_2504 src: /192.168.1.157:48437 dest: /192.168.1.157:50010
2017-05-22 19:07:27,577 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6310376760233298478_2504 src: /192.168.1.157:48437 dest: /192.168.1.157:50010 of size 91176
2017-05-22 19:07:27,679 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3007725297324880634_2508 src: /192.168.1.156:33034 dest: /192.168.1.156:50010
2017-05-22 19:07:27,681 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3007725297324880634_2508 src: /192.168.1.156:33034 dest: /192.168.1.156:50010 of size 13552
2017-05-22 19:07:30,564 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2828171184385991810_2506 src: /192.168.1.157:48438 dest: /192.168.1.157:50010
2017-05-22 19:07:30,564 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2828171184385991810_2506 src: /192.168.1.157:48439 dest: /192.168.1.157:50010
2017-05-22 19:07:30,569 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_2828171184385991810_2506 received exception java.io.IOException: Block blk_2828171184385991810_2506 has already been started (though not completed), and thus cannot be created.
2017-05-22 19:07:30,570 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2828171184385991810_2506 src: /192.168.1.157:48438 dest: /192.168.1.157:50010 of size 13567
2017-05-22 19:07:30,572 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_2828171184385991810_2506 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 19:07:30,676 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5488376903331222575_2505 src: /192.168.1.156:33035 dest: /192.168.1.156:50010
2017-05-22 19:07:30,678 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5488376903331222575_2505 src: /192.168.1.156:33035 dest: /192.168.1.156:50010 of size 4325
2017-05-22 19:07:33,630 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_2828171184385991810_2506 to 192.168.1.158:50010
2017-05-22 19:07:33,637 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_2828171184385991810_2506 to /192.168.1.158:50010
2017-05-22 19:07:36,727 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 19:07:48,535 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 19:07:51,936 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 19:08:03,725 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 19:08:15,497 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 19:10:21,634 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_961694693245138359_2512 src: /192.168.1.157:48540 dest: /192.168.1.157:50010
2017-05-22 19:10:21,639 INFO org.apache.hadoop.dfs.DataNode: Received block blk_961694693245138359_2512 src: /192.168.1.157:48540 dest: /192.168.1.157:50010 of size 43172
2017-05-22 19:10:24,746 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6310376760233298478_2504 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6310376760233298478
2017-05-22 19:10:24,747 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2828171184385991810_2506 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2828171184385991810
2017-05-22 19:10:24,748 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5488376903331222575_2505 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5488376903331222575
2017-05-22 19:10:27,749 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3007725297324880634_2508 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3007725297324880634
2017-05-22 19:10:27,750 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_961694693245138359_2512 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_961694693245138359
2017-05-22 19:10:34,407 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 19:10:45,216 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 19:10:45,409 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 19:10:45,411 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 19:10:45,412 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 19:10:45,466 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 19:10:45,514 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 19:10:45,514 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 19:10:45,515 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 19:10:45,730 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 19:10:45,761 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 19:10:45,764 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 19:10:45,764 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 19:10:45,769 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 19:10:45,783 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 19:10:45,787 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 19:10:45,788 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 19:10:45,789 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 19:10:45,790 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 19:10:45,790 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 19:10:45,790 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 19:10:45,793 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 19:10:45,793 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 19:10:45,804 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 19:10:48,810 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 17 msecs
2017-05-22 19:11:45,886 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6562779991441802729_2517 src: /192.168.1.158:35391 dest: /192.168.1.158:50010
2017-05-22 19:11:45,886 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3768851356894413431_2513 src: /192.168.1.158:35390 dest: /192.168.1.158:50010
2017-05-22 19:11:45,899 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6562779991441802729_2517 src: /192.168.1.158:35391 dest: /192.168.1.158:50010 of size 13545
2017-05-22 19:11:45,904 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3768851356894413431_2513 src: /192.168.1.158:35390 dest: /192.168.1.158:50010 of size 91176
2017-05-22 19:11:48,826 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8562884550990503415_2515 src: /192.168.1.156:33144 dest: /192.168.1.156:50010
2017-05-22 19:11:48,827 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8562884550990503415_2515 src: /192.168.1.156:33144 dest: /192.168.1.156:50010 of size 13560
2017-05-22 19:11:48,843 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8562884550990503415_2515 src: /192.168.1.157:48555 dest: /192.168.1.157:50010
2017-05-22 19:11:48,844 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8562884550990503415_2515 received exception java.io.IOException: Block blk_8562884550990503415_2515 is valid, and cannot be written to.
2017-05-22 19:11:48,845 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8562884550990503415_2515 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 19:11:51,916 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8009977964149435925_2514 src: /192.168.1.158:35396 dest: /192.168.1.158:50010
2017-05-22 19:11:51,919 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8009977964149435925_2514 src: /192.168.1.158:35396 dest: /192.168.1.158:50010 of size 2165
2017-05-22 19:12:04,738 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 19:12:11,938 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 19:12:28,249 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 19:12:32,764 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 19:12:48,513 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 19:12:52,559 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 19:13:08,232 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 19:13:12,673 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 19:13:28,113 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 19:13:33,332 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 19:13:47,996 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 19:14:27,900 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2193088299577401250_2522 src: /192.168.1.157:48608 dest: /192.168.1.157:50010
2017-05-22 19:14:27,901 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2193088299577401250_2522 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 19:14:27,901 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 19:14:30,915 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8009977964149435925_2514 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8009977964149435925
2017-05-22 19:14:30,916 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3768851356894413431_2513 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3768851356894413431
2017-05-22 19:14:30,916 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8562884550990503415_2515 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8562884550990503415
2017-05-22 19:14:33,914 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6562779991441802729_2517 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6562779991441802729
2017-05-22 19:14:38,999 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 19:14:49,820 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 19:14:50,008 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 19:14:50,009 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 19:14:50,011 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 19:14:50,073 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 19:14:50,121 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 19:14:50,122 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 19:14:50,122 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 19:14:50,324 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 19:14:50,357 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 19:14:50,360 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 19:14:50,360 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 19:14:50,364 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 19:14:50,384 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 19:14:50,390 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 19:14:50,390 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 19:14:50,392 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 19:14:50,392 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 19:14:50,393 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 19:14:50,393 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 19:14:50,420 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 19:14:50,420 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 19:14:50,431 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 19:14:53,433 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-22 19:15:55,809 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 19:15:56,520 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6902267185378042512_2527 src: /192.168.1.158:35459 dest: /192.168.1.158:50010
2017-05-22 19:15:56,533 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6902267185378042512_2527 src: /192.168.1.158:35459 dest: /192.168.1.158:50010 of size 13545
2017-05-22 19:15:56,542 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4505124931259227944_2523 src: /192.168.1.158:35460 dest: /192.168.1.158:50010
2017-05-22 19:15:56,548 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4505124931259227944_2523 src: /192.168.1.158:35460 dest: /192.168.1.158:50010 of size 91176
2017-05-22 19:15:59,505 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2990738181699453560_2525 src: /192.168.1.157:48623 dest: /192.168.1.157:50010
2017-05-22 19:15:59,506 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2990738181699453560_2525 src: /192.168.1.157:48623 dest: /192.168.1.157:50010 of size 13560
2017-05-22 19:15:59,508 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2990738181699453560_2525 src: /192.168.1.157:48624 dest: /192.168.1.157:50010
2017-05-22 19:15:59,509 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2990738181699453560_2525 received exception java.io.IOException: Block blk_-2990738181699453560_2525 is valid, and cannot be written to.
2017-05-22 19:15:59,511 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-2990738181699453560_2525 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 19:15:59,515 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1517142287170860632_2524 src: /192.168.1.156:33216 dest: /192.168.1.156:50010
2017-05-22 19:15:59,517 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1517142287170860632_2524 src: /192.168.1.156:33216 dest: /192.168.1.156:50010 of size 2165
2017-05-22 19:16:12,477 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 19:16:17,592 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 19:16:33,987 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 19:16:38,474 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 19:16:54,015 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 19:16:59,212 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 19:17:15,381 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 19:17:20,008 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 19:17:35,263 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 19:17:44,306 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 19:18:38,588 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4505124931259227944_2523 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4505124931259227944
2017-05-22 19:18:38,588 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2990738181699453560_2525 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2990738181699453560
2017-05-22 19:18:38,589 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1517142287170860632_2524 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1517142287170860632
2017-05-22 19:18:41,593 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6019804317952104103_2532 src: /192.168.1.156:33282 dest: /192.168.1.156:50010
2017-05-22 19:18:41,594 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-6019804317952104103_2532 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 19:18:41,594 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 19:18:44,593 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6902267185378042512_2527 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6902267185378042512
2017-05-22 19:18:49,525 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 19:19:00,331 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 19:19:00,516 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 19:19:00,518 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 19:19:00,520 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 19:19:00,586 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 19:19:00,642 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 19:19:00,643 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 19:19:00,643 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 19:19:00,881 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 19:19:00,920 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 19:19:00,936 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 19:19:00,936 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 19:19:00,942 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 19:19:00,962 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 19:19:00,967 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 19:19:00,967 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 19:19:00,969 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 19:19:00,969 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 19:19:00,969 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 19:19:00,969 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 19:19:00,972 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 19:19:00,973 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 19:19:00,982 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 19:19:03,981 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 19:20:06,394 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 19:20:06,983 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8655126899582920134_2533 src: /192.168.1.158:35516 dest: /192.168.1.158:50010
2017-05-22 19:20:06,997 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8655126899582920134_2533 src: /192.168.1.158:35516 dest: /192.168.1.158:50010 of size 91176
2017-05-22 19:20:07,040 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4796133358038649463_2534 src: /192.168.1.157:48698 dest: /192.168.1.157:50010
2017-05-22 19:20:07,042 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4796133358038649463_2534 src: /192.168.1.157:48698 dest: /192.168.1.157:50010 of size 2165
2017-05-22 19:20:09,968 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7948912735294673932_2537 src: /192.168.1.156:33298 dest: /192.168.1.156:50010
2017-05-22 19:20:09,969 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7948912735294673932_2537 src: /192.168.1.156:33298 dest: /192.168.1.156:50010 of size 13545
2017-05-22 19:20:10,039 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7103079275882589664_2535 src: /192.168.1.157:48699 dest: /192.168.1.157:50010
2017-05-22 19:20:10,040 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7103079275882589664_2535 src: /192.168.1.157:48700 dest: /192.168.1.157:50010
2017-05-22 19:20:10,040 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7103079275882589664_2535 src: /192.168.1.157:48699 dest: /192.168.1.157:50010 of size 13560
2017-05-22 19:20:10,042 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7103079275882589664_2535 received exception java.io.IOException: Block blk_7103079275882589664_2535 is valid, and cannot be written to.
2017-05-22 19:20:10,044 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7103079275882589664_2535 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 19:20:13,055 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7103079275882589664_2535 to 192.168.1.158:50010
2017-05-22 19:20:13,059 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_7103079275882589664_2535 to /192.168.1.158:50010
2017-05-22 19:20:22,148 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 19:20:28,177 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 19:20:44,014 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 19:20:49,022 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 19:21:05,146 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 19:21:09,821 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 19:21:25,050 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 19:21:30,631 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 19:21:46,779 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 19:22:49,098 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1940709704665371503_2541 src: /192.168.1.157:48762 dest: /192.168.1.157:50010
2017-05-22 19:22:49,102 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1940709704665371503_2541 src: /192.168.1.157:48762 dest: /192.168.1.157:50010 of size 27731
2017-05-22 19:22:52,122 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4796133358038649463_2534 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4796133358038649463
2017-05-22 19:22:52,123 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7103079275882589664_2535 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7103079275882589664
2017-05-22 19:22:52,123 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8655126899582920134_2533 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8655126899582920134
2017-05-22 19:22:55,123 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1940709704665371503_2541 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1940709704665371503
2017-05-22 19:22:55,123 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7948912735294673932_2537 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7948912735294673932
2017-05-22 19:23:01,894 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 19:23:12,762 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 19:23:12,970 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 19:23:12,972 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 19:23:12,973 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 19:23:13,044 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 19:23:13,105 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 19:23:13,106 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 19:23:13,106 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 19:23:13,345 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 19:23:13,382 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 19:23:13,384 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 19:23:13,384 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 19:23:13,389 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 19:23:13,412 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 19:23:13,417 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 19:23:13,419 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 19:23:13,419 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 19:23:13,419 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 19:23:13,419 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 19:23:13,420 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 19:23:13,422 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 19:23:13,422 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 19:23:13,432 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 19:23:16,437 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-05-22 19:24:13,540 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4972718347895399479_2542 src: /192.168.1.158:35572 dest: /192.168.1.158:50010
2017-05-22 19:24:13,540 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5446443305495107651_2544 src: /192.168.1.158:35571 dest: /192.168.1.158:50010
2017-05-22 19:24:13,565 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4972718347895399479_2542 src: /192.168.1.158:35572 dest: /192.168.1.158:50010 of size 91176
2017-05-22 19:24:13,566 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5446443305495107651_2544 src: /192.168.1.158:35571 dest: /192.168.1.158:50010 of size 13568
2017-05-22 19:24:13,709 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 19:24:16,451 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5081577573119387454_2546 src: /192.168.1.157:48778 dest: /192.168.1.157:50010
2017-05-22 19:24:16,453 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5081577573119387454_2546 src: /192.168.1.157:48778 dest: /192.168.1.157:50010 of size 13553
2017-05-22 19:24:19,450 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5395807405692889943_2543 src: /192.168.1.157:48780 dest: /192.168.1.157:50010
2017-05-22 19:24:19,451 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5395807405692889943_2543 src: /192.168.1.157:48780 dest: /192.168.1.157:50010 of size 2165
2017-05-22 19:24:30,157 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 19:24:36,431 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 19:24:52,783 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 19:24:57,282 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 19:25:12,932 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 19:25:18,058 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 19:25:33,783 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 19:27:01,517 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_72886941467572843_2551 src: /192.168.1.157:48847 dest: /192.168.1.157:50010
2017-05-22 19:27:01,517 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_72886941467572843_2551 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 19:27:01,519 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 19:27:04,593 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5446443305495107651_2544 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5446443305495107651
2017-05-22 19:27:04,594 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5395807405692889943_2543 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5395807405692889943
2017-05-22 19:27:04,595 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4972718347895399479_2542 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4972718347895399479
2017-05-22 19:27:07,592 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5081577573119387454_2546 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5081577573119387454
2017-05-22 19:27:12,478 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 19:27:23,311 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 19:27:23,510 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 19:27:23,512 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 19:27:23,513 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 19:27:23,586 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 19:27:23,644 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 19:27:23,645 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 19:27:23,645 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 19:27:23,893 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 19:27:23,931 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 19:27:23,935 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 19:27:23,935 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 19:27:23,940 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 19:27:23,960 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 19:27:23,964 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 19:27:23,965 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 19:27:23,966 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 19:27:23,966 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 19:27:23,967 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 19:27:23,967 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 19:27:23,970 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 19:27:23,970 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 19:27:23,978 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 19:27:26,982 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 19:28:30,000 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-540614197223671525_2552 src: /192.168.1.157:48861 dest: /192.168.1.157:50010
2017-05-22 19:28:30,013 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-540614197223671525_2552 src: /192.168.1.157:48861 dest: /192.168.1.157:50010 of size 91176
2017-05-22 19:28:30,072 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3426062850192249946_2556 src: /192.168.1.158:35621 dest: /192.168.1.158:50010
2017-05-22 19:28:30,072 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3426062850192249946_2556 src: /192.168.1.158:35621 dest: /192.168.1.158:50010 of size 13553
2017-05-22 19:28:33,002 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1575321492754684033_2553 src: /192.168.1.157:48862 dest: /192.168.1.157:50010
2017-05-22 19:28:33,003 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1575321492754684033_2553 src: /192.168.1.157:48862 dest: /192.168.1.157:50010 of size 2165
2017-05-22 19:28:33,005 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1575321492754684033_2553 src: /192.168.1.157:48863 dest: /192.168.1.157:50010
2017-05-22 19:28:33,006 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1575321492754684033_2553 received exception java.io.IOException: Block blk_1575321492754684033_2553 is valid, and cannot be written to.
2017-05-22 19:28:33,008 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_1575321492754684033_2553 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 19:28:33,064 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6532685637484979309_2554 src: /192.168.1.156:33457 dest: /192.168.1.156:50010
2017-05-22 19:28:33,065 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6532685637484979309_2554 src: /192.168.1.156:33457 dest: /192.168.1.156:50010 of size 13568
2017-05-22 19:28:36,057 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_1575321492754684033_2553 to 192.168.1.158:50010
2017-05-22 19:28:36,064 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_1575321492754684033_2553 to /192.168.1.158:50010
2017-05-22 19:28:49,212 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 19:28:56,051 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 19:29:12,040 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 19:29:16,841 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 19:29:32,279 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 19:31:15,155 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-540614197223671525_2552 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-540614197223671525
2017-05-22 19:31:15,156 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1575321492754684033_2553 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1575321492754684033
2017-05-22 19:31:15,156 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6532685637484979309_2554 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6532685637484979309
2017-05-22 19:31:18,155 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3426062850192249946_2556 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3426062850192249946
2017-05-22 19:31:23,204 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 19:31:34,013 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 19:31:34,202 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 19:31:34,204 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 19:31:34,206 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 19:31:34,281 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 19:31:34,338 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 19:31:34,339 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 19:31:34,339 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 19:31:34,576 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 19:31:34,614 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 19:31:34,617 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 19:31:34,617 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 19:31:34,622 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 19:31:34,640 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 19:31:34,644 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 19:31:34,645 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 19:31:34,646 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 19:31:34,646 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 19:31:34,647 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 19:31:34,647 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 19:31:34,649 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 19:31:34,650 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 19:31:34,658 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 19:31:37,658 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 19:32:40,007 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 19:32:40,729 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3329331025504089912_2562 src: /192.168.1.157:48946 dest: /192.168.1.157:50010
2017-05-22 19:32:40,742 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3329331025504089912_2562 src: /192.168.1.157:48946 dest: /192.168.1.157:50010 of size 91176
2017-05-22 19:32:40,745 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5211328348549313373_2566 src: /192.168.1.156:33530 dest: /192.168.1.156:50010
2017-05-22 19:32:40,746 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5211328348549313373_2566 src: /192.168.1.156:33530 dest: /192.168.1.156:50010 of size 13553
2017-05-22 19:32:43,730 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3320368918927345647_2564 src: /192.168.1.157:48948 dest: /192.168.1.157:50010
2017-05-22 19:32:43,731 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3320368918927345647_2564 src: /192.168.1.157:48948 dest: /192.168.1.157:50010 of size 13568
2017-05-22 19:32:46,611 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7096419352473509737_2563 src: /192.168.1.158:35661 dest: /192.168.1.158:50010
2017-05-22 19:32:46,613 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7096419352473509737_2563 src: /192.168.1.158:35661 dest: /192.168.1.158:50010 of size 2165
2017-05-22 19:32:55,346 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 19:33:00,755 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 19:33:16,359 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 19:33:20,591 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 19:33:36,182 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 19:35:40,812 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3329331025504089912_2562 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3329331025504089912
2017-05-22 19:35:40,813 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3320368918927345647_2564 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3320368918927345647
2017-05-22 19:35:40,813 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7096419352473509737_2563 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7096419352473509737
2017-05-22 19:35:43,800 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2346431392535738213_2571 src: /192.168.1.157:49015 dest: /192.168.1.157:50010
2017-05-22 19:35:43,806 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2346431392535738213_2571 src: /192.168.1.157:49015 dest: /192.168.1.157:50010 of size 25574
2017-05-22 19:35:46,817 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5211328348549313373_2566 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5211328348549313373
2017-05-22 19:35:54,456 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 19:36:05,265 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 19:36:05,451 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 19:36:05,453 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 19:36:05,454 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 19:36:05,525 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 19:36:05,581 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 19:36:05,581 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 19:36:05,581 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 19:36:05,824 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 19:36:05,861 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 19:36:05,864 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 19:36:05,864 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 19:36:05,869 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 19:36:05,887 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 19:36:05,891 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 19:36:05,892 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 19:36:05,893 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 19:36:05,894 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 19:36:05,894 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 19:36:05,894 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 19:36:05,896 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 19:36:05,897 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 19:36:05,906 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 19:36:05,955 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_2346431392535738213_2571
2017-05-22 19:36:08,907 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 7 msecs
2017-05-22 19:36:41,934 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2346431392535738213_2571 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2346431392535738213
2017-05-22 19:37:05,972 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6376207145723013294_2574 src: /192.168.1.156:33610 dest: /192.168.1.156:50010
2017-05-22 19:37:05,979 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7034795727749991745_2572 src: /192.168.1.158:35697 dest: /192.168.1.158:50010
2017-05-22 19:37:05,988 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7034795727749991745_2572 src: /192.168.1.158:35697 dest: /192.168.1.158:50010 of size 91176
2017-05-22 19:37:05,991 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6376207145723013294_2574 src: /192.168.1.156:33610 dest: /192.168.1.156:50010 of size 13566
2017-05-22 19:37:08,962 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7037178482009997896_2576 src: /192.168.1.156:33616 dest: /192.168.1.156:50010
2017-05-22 19:37:08,962 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4373269001730026503_2573 src: /192.168.1.156:33615 dest: /192.168.1.156:50010
2017-05-22 19:37:08,969 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7037178482009997896_2576 src: /192.168.1.156:33616 dest: /192.168.1.156:50010 of size 13551
2017-05-22 19:37:08,971 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4373269001730026503_2573 src: /192.168.1.156:33615 dest: /192.168.1.156:50010 of size 17286
2017-05-22 19:37:13,925 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 19:37:19,272 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 19:37:24,282 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 19:37:28,829 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 19:37:33,773 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 19:37:38,521 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 19:37:43,442 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 19:37:48,258 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 19:37:49,437 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 19:37:53,108 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 19:37:54,172 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 19:37:57,862 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 19:37:59,006 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 19:38:02,575 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 19:38:03,765 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 19:38:07,373 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 19:38:08,458 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 19:38:12,054 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 19:41:21,177 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6376207145723013294_2574 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6376207145723013294
2017-05-22 19:41:21,178 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4373269001730026503_2573 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4373269001730026503
2017-05-22 19:41:21,178 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7034795727749991745_2572 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7034795727749991745
2017-05-22 19:41:24,180 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7037178482009997896_2576 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7037178482009997896
2017-05-22 19:41:30,151 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 19:41:40,955 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 19:41:41,148 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 19:41:41,150 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 19:41:41,152 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 19:41:41,223 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 19:41:41,282 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 19:41:41,283 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 19:41:41,283 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 19:41:41,512 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 19:41:41,543 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 19:41:41,549 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 19:41:41,549 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 19:41:41,554 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 19:41:41,574 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 19:41:41,579 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 19:41:41,581 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 19:41:41,581 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 19:41:41,581 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 19:41:41,581 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 19:41:41,582 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 19:41:41,584 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 19:41:41,584 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 19:41:41,594 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 19:41:44,591 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 6 msecs
2017-05-22 19:42:47,571 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2987962695135552623_2583 src: /192.168.1.157:49200 dest: /192.168.1.157:50010
2017-05-22 19:42:47,588 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2987962695135552623_2583 src: /192.168.1.157:49200 dest: /192.168.1.157:50010 of size 13566
2017-05-22 19:42:47,749 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_590732676077190855_2581 src: /192.168.1.156:33768 dest: /192.168.1.156:50010
2017-05-22 19:42:47,761 INFO org.apache.hadoop.dfs.DataNode: Received block blk_590732676077190855_2581 src: /192.168.1.156:33768 dest: /192.168.1.156:50010 of size 91176
2017-05-22 19:42:50,576 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6869400468756405635_2582 src: /192.168.1.157:49202 dest: /192.168.1.157:50010
2017-05-22 19:42:50,576 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7918194063493009646_2585 src: /192.168.1.157:49201 dest: /192.168.1.157:50010
2017-05-22 19:42:50,579 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7918194063493009646_2585 src: /192.168.1.157:49201 dest: /192.168.1.157:50010 of size 13551
2017-05-22 19:42:50,579 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6869400468756405635_2582 src: /192.168.1.157:49202 dest: /192.168.1.157:50010 of size 17286
2017-05-22 19:42:50,746 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6869400468756405635_2582 src: /192.168.1.156:33770 dest: /192.168.1.156:50010
2017-05-22 19:42:50,746 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-6869400468756405635_2582 received exception java.io.IOException: Block blk_-6869400468756405635_2582 is valid, and cannot be written to.
2017-05-22 19:42:50,748 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7918194063493009646_2585 src: /192.168.1.156:33771 dest: /192.168.1.156:50010
2017-05-22 19:42:50,748 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7918194063493009646_2585 received exception java.io.IOException: Block blk_7918194063493009646_2585 is valid, and cannot be written to.
2017-05-22 19:42:50,749 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7918194063493009646_2585 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 19:42:50,749 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-6869400468756405635_2582 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 19:42:54,498 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 19:42:59,260 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 19:43:04,055 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 19:43:08,640 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 19:47:14,798 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6869400468756405635_2582 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6869400468756405635
2017-05-22 19:47:14,800 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2987962695135552623_2583 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2987962695135552623
2017-05-22 19:47:14,800 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_590732676077190855_2581 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_590732676077190855
2017-05-22 19:47:17,799 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7918194063493009646_2585 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7918194063493009646
2017-05-22 19:47:23,747 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 19:47:34,598 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 19:47:34,821 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 19:47:34,823 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 19:47:34,825 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 19:47:34,892 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 19:47:34,951 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 19:47:34,952 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 19:47:34,952 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 19:47:35,196 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 19:47:35,235 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 19:47:35,239 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 19:47:35,239 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 19:47:35,244 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 19:47:35,263 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 19:47:35,267 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 19:47:35,268 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 19:47:35,269 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 19:47:35,270 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 19:47:35,270 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 19:47:35,270 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 19:47:35,273 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 19:47:35,274 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 19:47:35,280 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 19:47:38,283 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 6 msecs
2017-05-22 19:48:41,277 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6137848421961555251_2590 src: /192.168.1.157:49356 dest: /192.168.1.157:50010
2017-05-22 19:48:41,290 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6137848421961555251_2590 src: /192.168.1.157:49356 dest: /192.168.1.157:50010 of size 91176
2017-05-22 19:48:41,299 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_312221413783939020_2594 src: /192.168.1.156:33932 dest: /192.168.1.156:50010
2017-05-22 19:48:41,303 INFO org.apache.hadoop.dfs.DataNode: Received block blk_312221413783939020_2594 src: /192.168.1.156:33932 dest: /192.168.1.156:50010 of size 13551
2017-05-22 19:48:44,301 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8777955143979414745_2592 src: /192.168.1.156:33934 dest: /192.168.1.156:50010
2017-05-22 19:48:44,302 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8777955143979414745_2592 src: /192.168.1.156:33934 dest: /192.168.1.156:50010 of size 13566
2017-05-22 19:48:47,299 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8563330239207881516_2591 src: /192.168.1.156:33948 dest: /192.168.1.156:50010
2017-05-22 19:48:47,301 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8563330239207881516_2591 src: /192.168.1.156:33948 dest: /192.168.1.156:50010 of size 17286
2017-05-22 19:48:48,324 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 19:53:05,432 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2240476615740634723_2594 src: /192.168.1.156:34104 dest: /192.168.1.156:50010
2017-05-22 19:53:05,433 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2240476615740634723_2594 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 19:53:05,435 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 19:53:08,456 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8563330239207881516_2591 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8563330239207881516
2017-05-22 19:53:08,458 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6137848421961555251_2590 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6137848421961555251
2017-05-22 19:53:08,458 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_312221413783939020_2594 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_312221413783939020
2017-05-22 19:53:08,458 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8777955143979414745_2592 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8777955143979414745
2017-05-22 19:53:16,208 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 19:53:26,927 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 19:53:27,109 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 19:53:27,111 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 19:53:27,113 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 19:53:27,171 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 19:53:27,216 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 19:53:27,216 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 19:53:27,216 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 19:53:27,422 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 19:53:27,454 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 19:53:27,456 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 19:53:27,456 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 19:53:27,461 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 19:53:27,477 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 19:53:27,482 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 19:53:27,482 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 19:53:27,484 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 19:53:27,485 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 19:53:27,485 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 19:53:27,486 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 19:53:27,495 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 19:53:27,496 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 19:53:27,512 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 19:53:30,515 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-22 19:54:27,633 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5565513485148577439_2601 src: /192.168.1.157:49521 dest: /192.168.1.157:50010
2017-05-22 19:54:27,648 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5565513485148577439_2601 src: /192.168.1.157:49521 dest: /192.168.1.157:50010 of size 13567
2017-05-22 19:54:27,685 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3634194477042967088_2599 src: /192.168.1.156:34114 dest: /192.168.1.156:50010
2017-05-22 19:54:27,690 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3634194477042967088_2599 src: /192.168.1.156:34114 dest: /192.168.1.156:50010 of size 91176
2017-05-22 19:54:30,610 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7373531440342118244_2603 src: /192.168.1.157:49528 dest: /192.168.1.157:50010
2017-05-22 19:54:30,614 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7373531440342118244_2603 src: /192.168.1.157:49528 dest: /192.168.1.157:50010 of size 13552
2017-05-22 19:54:30,682 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7112935691313071704_2600 src: /192.168.1.156:34121 dest: /192.168.1.156:50010
2017-05-22 19:54:30,683 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7112935691313071704_2600 src: /192.168.1.156:34121 dest: /192.168.1.156:50010 of size 8645
2017-05-22 19:54:32,887 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 19:54:33,350 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 19:54:35,872 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 19:54:40,733 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 19:55:28,547 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 19:56:42,638 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7112935691313071704_2600 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7112935691313071704
2017-05-22 19:56:42,639 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3634194477042967088_2599 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3634194477042967088
2017-05-22 19:56:42,639 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5565513485148577439_2601 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5565513485148577439
2017-05-22 19:56:42,640 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7373531440342118244_2603 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7373531440342118244
2017-05-22 19:56:49,886 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 19:57:00,768 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 19:57:00,963 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 19:57:00,965 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 19:57:00,967 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 19:57:01,031 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 19:57:01,079 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 19:57:01,080 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 19:57:01,080 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 19:57:01,293 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-05-22 19:57:01,325 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 19:57:01,328 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 19:57:01,328 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 19:57:01,333 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 19:57:01,349 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 19:57:01,354 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 19:57:01,354 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 19:57:01,356 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 19:57:01,356 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 19:57:01,357 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 19:57:01,357 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 19:57:01,360 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 19:57:01,360 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 19:57:01,372 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 19:57:04,376 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-22 19:58:07,448 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4522391253359327340_2609 src: /192.168.1.158:36130 dest: /192.168.1.158:50010
2017-05-22 19:58:07,458 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4522391253359327340_2609 src: /192.168.1.158:36130 dest: /192.168.1.158:50010 of size 8645
2017-05-22 19:58:07,463 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3217655301978103079_2608 src: /192.168.1.158:36131 dest: /192.168.1.158:50010
2017-05-22 19:58:07,472 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3217655301978103079_2608 src: /192.168.1.158:36131 dest: /192.168.1.158:50010 of size 91176
2017-05-22 19:58:10,431 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5035643570345776662_2610 src: /192.168.1.156:34231 dest: /192.168.1.156:50010
2017-05-22 19:58:10,432 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5035643570345776662_2610 src: /192.168.1.156:34231 dest: /192.168.1.156:50010 of size 13567
2017-05-22 19:58:10,451 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5035643570345776662_2610 src: /192.168.1.157:49647 dest: /192.168.1.157:50010
2017-05-22 19:58:10,451 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5035643570345776662_2610 received exception java.io.IOException: Block blk_5035643570345776662_2610 is valid, and cannot be written to.
2017-05-22 19:58:10,453 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_5035643570345776662_2610 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 19:58:13,410 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1191141365200581576_2612 src: /192.168.1.158:36138 dest: /192.168.1.158:50010
2017-05-22 19:58:13,411 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1191141365200581576_2612 src: /192.168.1.158:36138 dest: /192.168.1.158:50010 of size 13552
2017-05-22 19:58:13,427 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_5035643570345776662_2610 to 192.168.1.158:50010
2017-05-22 19:58:13,431 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_5035643570345776662_2610 to /192.168.1.158:50010
2017-05-22 19:58:19,075 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 19:58:34,030 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 19:58:50,894 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 19:59:00,565 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 19:59:02,543 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:00:28,545 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4522391253359327340_2609 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4522391253359327340
2017-05-22 20:00:28,545 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3217655301978103079_2608 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3217655301978103079
2017-05-22 20:00:28,546 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5035643570345776662_2610 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5035643570345776662
2017-05-22 20:00:31,554 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1191141365200581576_2612 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1191141365200581576
2017-05-22 20:00:36,558 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:00:47,324 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:00:47,515 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:00:47,517 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:00:47,519 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:00:47,593 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:00:47,651 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:00:47,652 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:00:47,652 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:00:47,893 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 20:00:47,931 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:00:47,933 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:00:47,933 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:00:47,938 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:00:47,957 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:00:47,962 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:00:47,962 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:00:47,963 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:00:47,964 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:00:47,964 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:00:47,964 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:00:47,990 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:00:47,990 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:00:48,016 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:00:51,007 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 17 msecs
2017-05-22 20:01:54,045 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3005663114638355795_2617 src: /192.168.1.156:34349 dest: /192.168.1.156:50010
2017-05-22 20:01:54,061 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3005663114638355795_2617 src: /192.168.1.156:34349 dest: /192.168.1.156:50010 of size 91176
2017-05-22 20:01:54,071 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2230675269269339562_2618 src: /192.168.1.158:36222 dest: /192.168.1.158:50010
2017-05-22 20:01:54,072 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2230675269269339562_2618 src: /192.168.1.158:36222 dest: /192.168.1.158:50010 of size 8645
2017-05-22 20:01:57,039 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2616526104513953688_2621 src: /192.168.1.156:34350 dest: /192.168.1.156:50010
2017-05-22 20:01:57,041 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2616526104513953688_2621 src: /192.168.1.156:34351 dest: /192.168.1.156:50010
2017-05-22 20:01:57,042 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2616526104513953688_2621 received exception java.io.IOException: Block blk_-2616526104513953688_2621 has already been started (though not completed), and thus cannot be created.
2017-05-22 20:01:57,042 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-2616526104513953688_2621 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:01:57,044 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2616526104513953688_2621 src: /192.168.1.156:34350 dest: /192.168.1.156:50010 of size 13552
2017-05-22 20:01:57,052 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2080425200837928261_2619 src: /192.168.1.157:49759 dest: /192.168.1.157:50010
2017-05-22 20:01:57,052 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2080425200837928261_2619 src: /192.168.1.157:49758 dest: /192.168.1.157:50010
2017-05-22 20:01:57,053 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2080425200837928261_2619 received exception java.io.IOException: Block blk_-2080425200837928261_2619 has already been started (though not completed), and thus cannot be created.
2017-05-22 20:01:57,053 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2080425200837928261_2619 src: /192.168.1.157:49759 dest: /192.168.1.157:50010 of size 13567
2017-05-22 20:01:57,053 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-2080425200837928261_2619 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:02:00,083 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2616526104513953688_2621 to 192.168.1.158:50010
2017-05-22 20:02:00,085 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2080425200837928261_2619 to 192.168.1.158:50010
2017-05-22 20:02:00,089 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-2080425200837928261_2619 to /192.168.1.158:50010
2017-05-22 20:02:00,090 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-2616526104513953688_2621 to /192.168.1.158:50010
2017-05-22 20:02:05,735 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 20:02:06,699 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 20:02:20,654 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 20:02:37,414 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 20:02:42,219 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 20:02:46,775 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 20:02:49,044 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:04:06,100 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8770962162522792747_2621 src: /192.168.1.157:49857 dest: /192.168.1.157:50010
2017-05-22 20:04:06,100 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8770962162522792747_2621 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 20:04:06,101 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:04:09,154 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2616526104513953688_2621 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2616526104513953688
2017-05-22 20:04:09,154 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2230675269269339562_2618 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2230675269269339562
2017-05-22 20:04:09,155 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2080425200837928261_2619 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2080425200837928261
2017-05-22 20:04:09,155 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3005663114638355795_2617 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3005663114638355795
2017-05-22 20:04:16,884 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:04:27,753 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:04:27,948 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:04:27,950 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:04:27,952 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:04:28,020 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:04:28,079 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:04:28,080 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:04:28,080 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:04:28,318 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 20:04:28,359 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:04:28,362 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:04:28,362 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:04:28,367 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:04:28,385 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:04:28,390 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:04:28,390 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:04:28,392 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:04:28,392 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:04:28,393 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:04:28,393 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:04:28,395 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:04:28,396 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:04:28,404 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:04:31,407 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 20:05:28,428 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1983070516533379335_2628 src: /192.168.1.157:49868 dest: /192.168.1.157:50010
2017-05-22 20:05:28,457 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1983070516533379335_2628 src: /192.168.1.157:49868 dest: /192.168.1.157:50010 of size 13567
2017-05-22 20:05:28,510 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8551130162364608289_2626 src: /192.168.1.158:36307 dest: /192.168.1.158:50010
2017-05-22 20:05:28,515 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8551130162364608289_2626 src: /192.168.1.158:36307 dest: /192.168.1.158:50010 of size 91176
2017-05-22 20:05:31,402 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7597897877128115871_2627 src: /192.168.1.157:49874 dest: /192.168.1.157:50010
2017-05-22 20:05:31,404 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7597897877128115871_2627 src: /192.168.1.157:49874 dest: /192.168.1.157:50010 of size 4325
2017-05-22 20:05:31,494 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7597897877128115871_2627 src: /192.168.1.156:34465 dest: /192.168.1.156:50010
2017-05-22 20:05:31,495 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7597897877128115871_2627 received exception java.io.IOException: Block blk_7597897877128115871_2627 is valid, and cannot be written to.
2017-05-22 20:05:31,496 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7597897877128115871_2627 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:05:34,409 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1311930056707410688_2630 src: /192.168.1.158:36314 dest: /192.168.1.158:50010
2017-05-22 20:05:34,412 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1311930056707410688_2630 src: /192.168.1.158:36314 dest: /192.168.1.158:50010 of size 13552
2017-05-22 20:05:34,459 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7597897877128115871_2627 to 192.168.1.158:50010
2017-05-22 20:05:34,466 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_7597897877128115871_2627 to /192.168.1.158:50010
2017-05-22 20:05:36,761 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 20:05:37,893 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 20:05:40,620 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 20:05:50,087 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 20:05:53,407 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 20:05:54,503 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 20:06:08,474 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 20:07:40,562 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8551130162364608289_2626 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8551130162364608289
2017-05-22 20:07:40,563 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1983070516533379335_2628 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1983070516533379335
2017-05-22 20:07:40,563 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7597897877128115871_2627 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7597897877128115871
2017-05-22 20:07:43,563 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1311930056707410688_2630 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1311930056707410688
2017-05-22 20:07:48,682 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:07:59,619 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:07:59,803 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:07:59,805 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:07:59,806 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:07:59,865 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:07:59,911 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:07:59,912 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:07:59,912 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:08:00,120 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 20:08:00,150 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:08:00,152 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:08:00,152 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 20:08:00,156 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:08:00,170 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:08:00,174 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:08:00,174 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:08:00,175 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:08:00,176 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:08:00,176 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:08:00,176 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:08:00,204 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:08:00,204 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:08:00,215 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:08:03,225 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 18 msecs
2017-05-22 20:09:05,555 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 20:09:06,253 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2331062172487174152_2635 src: /192.168.1.158:36379 dest: /192.168.1.158:50010
2017-05-22 20:09:06,271 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2331062172487174152_2635 src: /192.168.1.158:36379 dest: /192.168.1.158:50010 of size 91176
2017-05-22 20:09:06,287 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5046800580403071222_2637 src: /192.168.1.158:36380 dest: /192.168.1.158:50010
2017-05-22 20:09:06,289 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5046800580403071222_2637 src: /192.168.1.158:36380 dest: /192.168.1.158:50010 of size 13567
2017-05-22 20:09:09,232 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_23032198053693800_2639 src: /192.168.1.157:49970 dest: /192.168.1.157:50010
2017-05-22 20:09:09,233 INFO org.apache.hadoop.dfs.DataNode: Received block blk_23032198053693800_2639 src: /192.168.1.157:49970 dest: /192.168.1.157:50010 of size 13552
2017-05-22 20:09:12,233 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6178827075687513482_2636 src: /192.168.1.157:49973 dest: /192.168.1.157:50010
2017-05-22 20:09:12,235 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6178827075687513482_2636 src: /192.168.1.157:49973 dest: /192.168.1.157:50010 of size 4325
2017-05-22 20:09:17,374 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 20:09:28,698 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 20:09:32,030 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 20:09:37,932 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 20:09:50,307 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 20:09:52,978 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:11:03,353 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6178827075687513482_2636 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6178827075687513482
2017-05-22 20:11:03,354 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5046800580403071222_2637 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5046800580403071222
2017-05-22 20:11:03,354 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2331062172487174152_2635 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2331062172487174152
2017-05-22 20:11:06,279 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7767220117328988827_2643 src: /192.168.1.157:50050 dest: /192.168.1.157:50010
2017-05-22 20:11:06,280 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7767220117328988827_2643 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 20:11:06,282 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:11:09,352 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_23032198053693800_2639 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_23032198053693800
2017-05-22 20:11:14,282 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:11:25,114 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:11:25,301 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:11:25,302 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:11:25,304 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:11:25,372 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:11:25,433 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:11:25,434 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:11:25,434 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:11:25,671 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 20:11:25,710 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:11:25,712 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:11:25,712 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:11:25,717 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:11:25,734 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:11:25,740 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:11:25,740 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:11:25,742 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:11:25,742 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:11:25,743 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:11:25,743 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:11:25,748 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:11:25,749 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:11:25,760 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:11:28,764 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-22 20:12:31,854 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2705110468680367672_2646 src: /192.168.1.157:50065 dest: /192.168.1.157:50010
2017-05-22 20:12:31,861 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6473806541244679266_2644 src: /192.168.1.158:36452 dest: /192.168.1.158:50010
2017-05-22 20:12:31,869 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6473806541244679266_2644 src: /192.168.1.158:36452 dest: /192.168.1.158:50010 of size 91176
2017-05-22 20:12:31,869 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2705110468680367672_2646 src: /192.168.1.157:50065 dest: /192.168.1.157:50010 of size 13567
2017-05-22 20:12:34,854 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1353311013498729029_2645 src: /192.168.1.157:50066 dest: /192.168.1.157:50010
2017-05-22 20:12:34,856 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1353311013498729029_2645 src: /192.168.1.157:50066 dest: /192.168.1.157:50010 of size 4325
2017-05-22 20:12:37,785 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7731183431863210208_2648 src: /192.168.1.158:36455 dest: /192.168.1.158:50010
2017-05-22 20:12:37,786 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7731183431863210208_2648 src: /192.168.1.158:36455 dest: /192.168.1.158:50010 of size 13552
2017-05-22 20:12:39,367 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 20:12:39,651 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 20:12:42,846 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 20:12:52,125 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 20:12:55,635 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 20:12:55,776 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 20:13:05,741 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 20:13:13,799 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 20:13:15,713 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 20:13:29,203 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 20:14:31,901 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6473806541244679266_2644 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6473806541244679266
2017-05-22 20:14:31,901 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2705110468680367672_2646 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2705110468680367672
2017-05-22 20:14:31,902 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1353311013498729029_2645 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1353311013498729029
2017-05-22 20:14:34,898 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7731183431863210208_2648 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7731183431863210208
2017-05-22 20:14:41,554 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:14:52,402 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:14:52,603 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:14:52,604 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:14:52,605 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:14:52,661 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:14:52,708 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:14:52,708 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:14:52,708 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:14:52,924 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 20:14:52,961 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:14:52,963 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:14:52,963 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:14:52,969 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:14:52,987 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:14:52,994 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:14:52,995 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:14:52,995 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:14:52,996 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:14:52,996 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:14:52,996 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:14:53,012 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:14:53,013 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:14:53,024 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:14:56,028 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-22 20:15:53,135 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1177093620764979278_2653 src: /192.168.1.157:50147 dest: /192.168.1.157:50010
2017-05-22 20:15:53,153 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1177093620764979278_2653 src: /192.168.1.157:50147 dest: /192.168.1.157:50010 of size 91176
2017-05-22 20:15:53,162 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2416498076171215889_2654 src: /192.168.1.158:36508 dest: /192.168.1.158:50010
2017-05-22 20:15:53,163 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2416498076171215889_2654 src: /192.168.1.158:36508 dest: /192.168.1.158:50010 of size 4325
2017-05-22 20:15:53,505 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 20:15:56,127 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9151856959387998422_2655 src: /192.168.1.156:34745 dest: /192.168.1.156:50010
2017-05-22 20:15:56,133 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9151856959387998422_2655 src: /192.168.1.156:34746 dest: /192.168.1.156:50010
2017-05-22 20:15:56,133 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_9151856959387998422_2655 received exception java.io.IOException: Block blk_9151856959387998422_2655 has already been started (though not completed), and thus cannot be created.
2017-05-22 20:15:56,135 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_9151856959387998422_2655 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:15:56,137 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9151856959387998422_2655 src: /192.168.1.156:34745 dest: /192.168.1.156:50010 of size 13568
2017-05-22 20:15:59,074 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7556649433405614226_2657 src: /192.168.1.158:36515 dest: /192.168.1.158:50010
2017-05-22 20:15:59,076 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7556649433405614226_2657 src: /192.168.1.158:36515 dest: /192.168.1.158:50010 of size 13553
2017-05-22 20:16:03,734 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 20:16:06,320 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 20:16:08,324 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 20:16:18,291 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 20:16:21,134 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 20:16:32,875 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 20:16:39,788 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 20:16:42,910 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 20:16:53,059 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:16:55,701 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:17:04,396 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 20:18:05,136 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6833757307675202573_2661 src: /192.168.1.157:50235 dest: /192.168.1.157:50010
2017-05-22 20:18:05,137 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6833757307675202573_2661 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 20:18:05,137 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:18:08,170 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2416498076171215889_2654 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2416498076171215889
2017-05-22 20:18:08,170 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1177093620764979278_2653 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1177093620764979278
2017-05-22 20:18:08,171 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7556649433405614226_2657 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7556649433405614226
2017-05-22 20:18:08,171 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9151856959387998422_2655 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9151856959387998422
2017-05-22 20:18:14,269 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:18:25,106 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:18:25,329 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:18:25,330 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:18:25,332 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:18:25,395 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:18:25,447 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:18:25,447 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:18:25,448 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:18:25,702 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 20:18:25,741 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:18:25,744 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:18:25,744 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-22 20:18:25,749 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:18:25,772 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:18:25,779 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:18:25,779 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:18:25,781 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:18:25,781 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:18:25,782 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:18:25,782 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:18:25,810 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:18:25,810 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:18:25,832 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:18:28,825 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-22 20:19:31,103 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 20:19:31,866 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4223426763335263167_2662 src: /192.168.1.158:36527 dest: /192.168.1.158:50010
2017-05-22 20:19:31,882 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4223426763335263167_2662 src: /192.168.1.158:36527 dest: /192.168.1.158:50010 of size 91176
2017-05-22 20:19:31,884 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3426349910585973234_2666 src: /192.168.1.157:50249 dest: /192.168.1.157:50010
2017-05-22 20:19:31,886 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3426349910585973234_2666 src: /192.168.1.157:50249 dest: /192.168.1.157:50010 of size 13553
2017-05-22 20:19:34,843 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5056831525304735012_2663 src: /192.168.1.156:34838 dest: /192.168.1.156:50010
2017-05-22 20:19:34,845 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5056831525304735012_2663 src: /192.168.1.156:34838 dest: /192.168.1.156:50010 of size 4325
2017-05-22 20:19:37,844 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6209472862256185416_2664 src: /192.168.1.156:34842 dest: /192.168.1.156:50010
2017-05-22 20:19:37,845 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6209472862256185416_2664 src: /192.168.1.156:34842 dest: /192.168.1.156:50010 of size 13568
2017-05-22 20:19:43,958 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 20:19:45,979 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 20:20:03,780 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 20:20:07,059 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 20:20:11,778 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 20:20:12,711 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 20:20:26,790 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:20:35,111 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:21:40,926 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-30937868223077083_2670 src: /192.168.1.157:50333 dest: /192.168.1.157:50010
2017-05-22 20:21:40,926 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-30937868223077083_2670 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 20:21:40,928 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:21:43,951 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5056831525304735012_2663 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5056831525304735012
2017-05-22 20:21:43,952 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4223426763335263167_2662 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4223426763335263167
2017-05-22 20:21:43,952 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6209472862256185416_2664 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6209472862256185416
2017-05-22 20:21:46,950 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3426349910585973234_2666 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3426349910585973234
2017-05-22 20:21:53,011 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:22:03,935 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:22:04,127 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:22:04,129 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:22:04,131 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:22:04,194 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:22:04,242 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:22:04,243 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:22:04,243 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:22:04,460 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 20:22:04,497 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:22:04,499 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:22:04,499 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@5876a5
2017-05-22 20:22:04,504 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:22:04,520 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:22:04,526 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:22:04,526 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:22:04,527 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:22:04,528 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:22:04,528 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:22:04,529 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:22:04,554 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:22:04,554 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:22:04,568 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:22:07,568 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-22 20:23:09,921 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 20:23:09,984 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 20:23:10,610 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4583355712611590135_2671 src: /192.168.1.158:36577 dest: /192.168.1.158:50010
2017-05-22 20:23:10,620 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4583355712611590135_2671 src: /192.168.1.158:36577 dest: /192.168.1.158:50010 of size 91176
2017-05-22 20:23:10,695 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3330772472180178457_2673 src: /192.168.1.158:36578 dest: /192.168.1.158:50010
2017-05-22 20:23:10,696 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3330772472180178457_2673 src: /192.168.1.158:36578 dest: /192.168.1.158:50010 of size 13568
2017-05-22 20:23:13,698 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1261263999324558998_2672 src: /192.168.1.156:34938 dest: /192.168.1.156:50010
2017-05-22 20:23:13,700 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1261263999324558998_2672 src: /192.168.1.156:34938 dest: /192.168.1.156:50010 of size 4325
2017-05-22 20:23:13,702 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8668431805208567980_2675 src: /192.168.1.156:34939 dest: /192.168.1.156:50010
2017-05-22 20:23:13,704 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8668431805208567980_2675 src: /192.168.1.156:34939 dest: /192.168.1.156:50010 of size 13553
2017-05-22 20:23:23,863 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 20:23:30,543 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 20:23:34,561 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 20:23:44,745 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 20:23:54,050 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 20:23:56,524 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:24:11,690 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-22 20:25:10,765 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5327882539198855132_2679 src: /192.168.1.156:35005 dest: /192.168.1.156:50010
2017-05-22 20:25:10,766 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5327882539198855132_2679 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 20:25:10,768 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:25:13,687 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4583355712611590135_2671 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4583355712611590135
2017-05-22 20:25:13,687 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3330772472180178457_2673 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3330772472180178457
2017-05-22 20:25:13,688 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1261263999324558998_2672 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1261263999324558998
2017-05-22 20:25:16,692 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8668431805208567980_2675 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8668431805208567980
2017-05-22 20:25:23,548 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:25:34,361 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:25:34,545 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:25:34,547 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:25:34,549 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:25:34,617 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:25:34,681 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:25:34,682 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:25:34,682 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:25:34,906 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 20:25:34,940 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:25:34,943 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:25:34,944 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:25:34,948 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:25:34,965 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:25:34,970 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:25:34,970 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:25:34,972 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:25:34,972 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:25:34,973 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:25:34,973 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:25:34,991 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:25:34,991 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:25:35,001 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:25:38,008 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-05-22 20:26:35,117 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4740221636618338120_2680 src: /192.168.1.158:36627 dest: /192.168.1.158:50010
2017-05-22 20:26:35,117 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7809411369638736064_2684 src: /192.168.1.157:50434 dest: /192.168.1.157:50010
2017-05-22 20:26:35,139 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4740221636618338120_2680 src: /192.168.1.158:36627 dest: /192.168.1.158:50010 of size 91176
2017-05-22 20:26:35,149 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7809411369638736064_2684 src: /192.168.1.157:50434 dest: /192.168.1.157:50010 of size 13553
2017-05-22 20:26:38,020 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-55830304358476112_2681 src: /192.168.1.156:35024 dest: /192.168.1.156:50010
2017-05-22 20:26:38,022 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-55830304358476112_2681 src: /192.168.1.156:35024 dest: /192.168.1.156:50010 of size 8645
2017-05-22 20:26:38,066 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1349986515611118274_2682 src: /192.168.1.157:50441 dest: /192.168.1.157:50010
2017-05-22 20:26:38,076 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1349986515611118274_2682 src: /192.168.1.157:50441 dest: /192.168.1.157:50010 of size 13568
2017-05-22 20:26:40,120 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 20:26:40,910 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 20:26:45,724 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 20:26:49,513 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 20:26:51,206 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 20:26:56,046 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 20:26:57,212 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 20:27:04,202 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 20:27:05,060 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 20:27:06,941 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 20:27:23,085 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:27:27,523 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:28:47,080 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1916331198427622956_2684 src: /192.168.1.156:35120 dest: /192.168.1.156:50010
2017-05-22 20:28:47,081 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-1916331198427622956_2684 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 20:28:47,083 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:28:50,121 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7809411369638736064_2684 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7809411369638736064
2017-05-22 20:28:50,121 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4740221636618338120_2680 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4740221636618338120
2017-05-22 20:28:50,122 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1349986515611118274_2682 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1349986515611118274
2017-05-22 20:28:50,122 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-55830304358476112_2681 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-55830304358476112
2017-05-22 20:28:57,196 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:29:08,155 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:29:08,375 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:29:08,377 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:29:08,378 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:29:08,450 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:29:08,509 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:29:08,509 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:29:08,510 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:29:08,724 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 20:29:08,759 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:29:08,761 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:29:08,761 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:29:08,766 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:29:08,782 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:29:08,786 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:29:08,787 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:29:08,788 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:29:08,789 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:29:08,789 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:29:08,789 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:29:08,802 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:29:08,802 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:29:08,821 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:29:11,817 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-05-22 20:30:14,198 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 20:30:14,847 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7751565576962241107_2689 src: /192.168.1.157:50556 dest: /192.168.1.157:50010
2017-05-22 20:30:14,868 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7751565576962241107_2689 src: /192.168.1.157:50556 dest: /192.168.1.157:50010 of size 91176
2017-05-22 20:30:14,913 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_924443475622807665_2693 src: /192.168.1.156:35133 dest: /192.168.1.156:50010
2017-05-22 20:30:14,916 INFO org.apache.hadoop.dfs.DataNode: Received block blk_924443475622807665_2693 src: /192.168.1.156:35133 dest: /192.168.1.156:50010 of size 13553
2017-05-22 20:30:19,247 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 20:30:20,860 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6917684700780790980_2691 src: /192.168.1.158:36711 dest: /192.168.1.158:50010
2017-05-22 20:30:20,861 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6917684700780790980_2691 src: /192.168.1.158:36711 dest: /192.168.1.158:50010 of size 13568
2017-05-22 20:30:20,913 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_209589025460063771_2690 src: /192.168.1.156:35143 dest: /192.168.1.156:50010
2017-05-22 20:30:20,915 INFO org.apache.hadoop.dfs.DataNode: Received block blk_209589025460063771_2690 src: /192.168.1.156:35143 dest: /192.168.1.156:50010 of size 8645
2017-05-22 20:30:29,275 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 20:30:36,856 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 20:30:39,667 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 20:30:42,730 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 20:30:44,863 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 20:30:51,226 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 20:30:53,697 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 20:30:54,502 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:32:17,958 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_209589025460063771_2690 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_209589025460063771
2017-05-22 20:32:17,959 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6917684700780790980_2691 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6917684700780790980
2017-05-22 20:32:17,960 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7751565576962241107_2689 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7751565576962241107
2017-05-22 20:32:20,957 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_924443475622807665_2693 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_924443475622807665
2017-05-22 20:32:28,126 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:32:38,975 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:32:39,168 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:32:39,169 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:32:39,171 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:32:39,231 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:32:39,279 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:32:39,279 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:32:39,280 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:32:39,492 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 20:32:39,530 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:32:39,533 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:32:39,533 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:32:39,539 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:32:39,559 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:32:39,565 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:32:39,566 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:32:39,566 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:32:39,566 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:32:39,566 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:32:39,566 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:32:39,568 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:32:39,569 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:32:39,577 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:32:42,578 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 9 msecs
2017-05-22 20:33:45,684 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4222055352831473915_2698 src: /192.168.1.158:36780 dest: /192.168.1.158:50010
2017-05-22 20:33:45,698 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4222055352831473915_2698 src: /192.168.1.158:36780 dest: /192.168.1.158:50010 of size 91176
2017-05-22 20:33:45,771 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7577395007541479395_2700 src: /192.168.1.156:35244 dest: /192.168.1.156:50010
2017-05-22 20:33:45,773 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7577395007541479395_2700 src: /192.168.1.156:35244 dest: /192.168.1.156:50010 of size 13568
2017-05-22 20:33:48,654 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4261139618632401521_2702 src: /192.168.1.157:50660 dest: /192.168.1.157:50010
2017-05-22 20:33:48,655 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4261139618632401521_2702 src: /192.168.1.157:50660 dest: /192.168.1.157:50010 of size 13553
2017-05-22 20:33:48,772 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3020570987589630732_2699 src: /192.168.1.156:35245 dest: /192.168.1.156:50010
2017-05-22 20:33:48,773 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4261139618632401521_2702 src: /192.168.1.156:35246 dest: /192.168.1.156:50010
2017-05-22 20:33:48,774 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4261139618632401521_2702 received exception java.io.IOException: Block blk_4261139618632401521_2702 is valid, and cannot be written to.
2017-05-22 20:33:48,774 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3020570987589630732_2699 src: /192.168.1.156:35245 dest: /192.168.1.156:50010 of size 8645
2017-05-22 20:33:48,781 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_4261139618632401521_2702 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:33:58,059 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 20:34:03,144 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 20:34:05,913 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 20:34:08,981 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-22 20:34:12,816 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 20:34:18,356 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-22 20:34:21,807 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-22 20:34:29,732 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 20:35:45,734 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7577395007541479395_2700 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7577395007541479395
2017-05-22 20:35:45,735 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4222055352831473915_2698 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4222055352831473915
2017-05-22 20:35:45,735 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3020570987589630732_2699 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3020570987589630732
2017-05-22 20:35:48,732 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4261139618632401521_2702 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4261139618632401521
2017-05-22 20:35:55,526 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:36:06,434 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:36:06,654 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:36:06,656 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:36:06,663 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:36:06,733 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:36:06,798 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:36:06,799 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:36:06,799 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:36:07,040 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 20:36:07,078 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:36:07,083 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:36:07,083 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:36:07,088 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:36:07,108 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:36:07,113 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:36:07,114 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:36:07,114 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:36:07,115 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:36:07,115 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:36:07,115 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:36:07,117 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:36:07,117 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:36:07,127 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:36:10,125 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 6 msecs
2017-05-22 20:37:07,100 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2482900783608165132_2707 src: /192.168.1.157:50756 dest: /192.168.1.157:50010
2017-05-22 20:37:07,118 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2482900783608165132_2707 src: /192.168.1.157:50756 dest: /192.168.1.157:50010 of size 91176
2017-05-22 20:37:07,243 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8866891485468837400_2709 src: /192.168.1.158:36853 dest: /192.168.1.158:50010
2017-05-22 20:37:07,244 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8866891485468837400_2709 src: /192.168.1.158:36853 dest: /192.168.1.158:50010 of size 13568
2017-05-22 20:37:07,477 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-22 20:37:10,085 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4192206449883082815_2708 src: /192.168.1.157:50763 dest: /192.168.1.157:50010
2017-05-22 20:37:10,087 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4192206449883082815_2708 src: /192.168.1.157:50763 dest: /192.168.1.157:50010 of size 4325
2017-05-22 20:37:10,232 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1444449660602849515_2711 src: /192.168.1.156:35360 dest: /192.168.1.156:50010
2017-05-22 20:37:10,236 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1444449660602849515_2711 src: /192.168.1.156:35360 dest: /192.168.1.156:50010 of size 13553
2017-05-22 20:37:16,339 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-22 20:37:20,530 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 20:37:22,124 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-22 20:37:26,496 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 20:37:31,857 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 20:37:45,099 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:39:04,136 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5753350219815090685_2715 src: /192.168.1.158:36858 dest: /192.168.1.158:50010
2017-05-22 20:39:04,136 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5753350219815090685_2715 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 20:39:04,138 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:39:07,276 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8866891485468837400_2709 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8866891485468837400
2017-05-22 20:39:07,277 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4192206449883082815_2708 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4192206449883082815
2017-05-22 20:39:07,277 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2482900783608165132_2707 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2482900783608165132
2017-05-22 20:39:10,264 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1444449660602849515_2711 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1444449660602849515
2017-05-22 20:39:15,264 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:39:26,078 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:39:26,302 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:39:26,304 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:39:26,306 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:39:26,370 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:39:26,422 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:39:26,423 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:39:26,423 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:39:26,647 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 20:39:26,691 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:39:26,694 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:39:26,694 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:39:26,699 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:39:26,717 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:39:26,721 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:39:26,722 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:39:26,723 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:39:26,724 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:39:26,724 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:39:26,724 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:39:26,728 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:39:26,729 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:39:26,737 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:39:29,738 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 6 msecs
2017-05-22 20:40:32,718 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6369760432775884329_2720 src: /192.168.1.157:50849 dest: /192.168.1.157:50010
2017-05-22 20:40:32,731 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6369760432775884329_2720 src: /192.168.1.157:50849 dest: /192.168.1.157:50010 of size 13553
2017-05-22 20:40:32,814 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8618599127921363672_2716 src: /192.168.1.158:36871 dest: /192.168.1.158:50010
2017-05-22 20:40:32,822 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8618599127921363672_2716 src: /192.168.1.158:36871 dest: /192.168.1.158:50010 of size 91176
2017-05-22 20:40:35,715 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3479464157942214243_2718 src: /192.168.1.157:50850 dest: /192.168.1.157:50010
2017-05-22 20:40:35,716 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6209270420298244770_2717 src: /192.168.1.157:50851 dest: /192.168.1.157:50010
2017-05-22 20:40:35,716 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3479464157942214243_2718 src: /192.168.1.157:50850 dest: /192.168.1.157:50010 of size 13568
2017-05-22 20:40:35,717 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6209270420298244770_2717 src: /192.168.1.157:50851 dest: /192.168.1.157:50010 of size 4325
2017-05-22 20:40:35,809 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6209270420298244770_2717 src: /192.168.1.156:35451 dest: /192.168.1.156:50010
2017-05-22 20:40:35,810 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6209270420298244770_2717 received exception java.io.IOException: Block blk_6209270420298244770_2717 is valid, and cannot be written to.
2017-05-22 20:40:35,812 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_6209270420298244770_2717 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:40:35,813 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3479464157942214243_2718 src: /192.168.1.156:35452 dest: /192.168.1.156:50010
2017-05-22 20:40:35,813 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3479464157942214243_2718 received exception java.io.IOException: Block blk_-3479464157942214243_2718 is valid, and cannot be written to.
2017-05-22 20:40:35,813 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-3479464157942214243_2718 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:40:38,769 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-3479464157942214243_2718 to 192.168.1.158:50010
2017-05-22 20:40:38,770 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_6209270420298244770_2717 to 192.168.1.158:50010
2017-05-22 20:40:38,773 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-3479464157942214243_2718 to /192.168.1.158:50010
2017-05-22 20:40:38,780 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_6209270420298244770_2717 to /192.168.1.158:50010
2017-05-22 20:40:41,003 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 20:40:41,377 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 20:40:44,949 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-22 20:40:46,209 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 20:40:46,527 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 20:40:51,133 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 20:41:01,087 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:41:03,928 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-22 20:41:09,264 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-22 20:42:38,772 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8440250224562981665_2724 src: /192.168.1.157:50927 dest: /192.168.1.157:50010
2017-05-22 20:42:38,772 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8440250224562981665_2724 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 20:42:38,773 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:42:41,812 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6369760432775884329_2720 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6369760432775884329
2017-05-22 20:42:41,812 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3479464157942214243_2718 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3479464157942214243
2017-05-22 20:42:41,813 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6209270420298244770_2717 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6209270420298244770
2017-05-22 20:42:41,813 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8618599127921363672_2716 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8618599127921363672
2017-05-22 20:42:48,875 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:42:59,760 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:42:59,970 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:42:59,972 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:42:59,974 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:43:00,045 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:43:00,106 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:43:00,106 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:43:00,107 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:43:00,340 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 20:43:00,379 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:43:00,382 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:43:00,382 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:43:00,387 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:43:00,404 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:43:00,409 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:43:00,409 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:43:00,411 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:43:00,411 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:43:00,412 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:43:00,412 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:43:00,414 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:43:00,415 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:43:00,424 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:43:03,425 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 20:44:06,441 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3704350212834931904_2725 src: /192.168.1.156:35538 dest: /192.168.1.156:50010
2017-05-22 20:44:06,448 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8576016784119853307_2729 src: /192.168.1.157:50941 dest: /192.168.1.157:50010
2017-05-22 20:44:06,456 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8576016784119853307_2729 src: /192.168.1.157:50941 dest: /192.168.1.157:50010 of size 13553
2017-05-22 20:44:06,458 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3704350212834931904_2725 src: /192.168.1.156:35538 dest: /192.168.1.156:50010 of size 91176
2017-05-22 20:44:09,444 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1570293375337724235_2726 src: /192.168.1.157:50942 dest: /192.168.1.157:50010
2017-05-22 20:44:09,445 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1570293375337724235_2726 src: /192.168.1.157:50942 dest: /192.168.1.157:50010 of size 4325
2017-05-22 20:44:12,438 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7980807095941179286_2727 src: /192.168.1.156:35547 dest: /192.168.1.156:50010
2017-05-22 20:44:12,439 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7980807095941179286_2727 src: /192.168.1.156:35547 dest: /192.168.1.156:50010 of size 13568
2017-05-22 20:44:14,929 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-22 20:44:15,556 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-22 20:44:18,632 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 20:44:20,237 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-22 20:44:29,984 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-22 20:44:32,587 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-22 20:44:33,803 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-22 20:45:51,485 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8102083384812708851_2733 src: /192.168.1.156:35608 dest: /192.168.1.156:50010
2017-05-22 20:45:51,486 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8102083384812708851_2733 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-22 20:45:51,488 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:45:54,514 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1570293375337724235_2726 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1570293375337724235
2017-05-22 20:45:54,515 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3704350212834931904_2725 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3704350212834931904
2017-05-22 20:45:54,516 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7980807095941179286_2727 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7980807095941179286
2017-05-22 20:45:57,513 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8576016784119853307_2729 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8576016784119853307
2017-05-22 20:46:04,270 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:46:15,132 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:46:15,330 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:46:15,332 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:46:15,334 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:46:15,404 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:46:15,464 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:46:15,465 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:46:15,465 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:46:15,673 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 20:46:15,702 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:46:15,705 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:46:15,705 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:46:15,709 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:46:15,729 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:46:15,734 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:46:15,735 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:46:15,736 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:46:15,737 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:46:15,737 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:46:15,738 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:46:15,741 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:46:15,741 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:46:15,752 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:46:18,756 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 11 msecs
2017-05-22 20:47:15,817 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-122709780516733511_2734 src: /192.168.1.157:51022 dest: /192.168.1.157:50010
2017-05-22 20:47:15,832 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-122709780516733511_2734 src: /192.168.1.157:51022 dest: /192.168.1.157:50010 of size 91176
2017-05-22 20:47:15,870 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6899528294595207827_2735 src: /192.168.1.158:36982 dest: /192.168.1.158:50010
2017-05-22 20:47:15,873 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6899528294595207827_2735 src: /192.168.1.158:36982 dest: /192.168.1.158:50010 of size 4325
2017-05-22 20:47:18,780 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4762807357505844420_2738 src: /192.168.1.157:51029 dest: /192.168.1.157:50010
2017-05-22 20:47:18,781 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4762807357505844420_2738 src: /192.168.1.157:51029 dest: /192.168.1.157:50010 of size 13553
2017-05-22 20:47:18,842 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4762807357505844420_2738 src: /192.168.1.156:35622 dest: /192.168.1.156:50010
2017-05-22 20:47:18,842 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4762807357505844420_2738 received exception java.io.IOException: Block blk_4762807357505844420_2738 is valid, and cannot be written to.
2017-05-22 20:47:18,844 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_4762807357505844420_2738 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:47:18,850 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4248898302162069823_2736 src: /192.168.1.156:35623 dest: /192.168.1.156:50010
2017-05-22 20:47:18,851 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4248898302162069823_2736 src: /192.168.1.156:35623 dest: /192.168.1.156:50010 of size 13568
2017-05-22 20:47:21,789 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4762807357505844420_2738 to 192.168.1.158:50010
2017-05-22 20:47:21,800 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_4762807357505844420_2738 to /192.168.1.158:50010
2017-05-22 20:49:30,887 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6899528294595207827_2735 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6899528294595207827
2017-05-22 20:49:30,888 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4248898302162069823_2736 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4248898302162069823
2017-05-22 20:49:30,888 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-122709780516733511_2734 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-122709780516733511
2017-05-22 20:49:33,891 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4762807357505844420_2738 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4762807357505844420
2017-05-22 20:49:39,919 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:49:50,757 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:49:50,950 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:49:50,952 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:49:50,954 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:49:51,027 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:49:51,087 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:49:51,088 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:49:51,088 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:49:51,313 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-05-22 20:49:51,346 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:49:51,349 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:49:51,349 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:49:51,353 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:49:51,371 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:49:51,379 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:49:51,380 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:49:51,381 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:49:51,381 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:49:51,381 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:49:51,382 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:49:51,403 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:49:51,403 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:49:51,416 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:49:54,416 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-22 20:50:57,483 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6685938414489171635_2743 src: /192.168.1.157:51125 dest: /192.168.1.157:50010
2017-05-22 20:50:57,502 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6685938414489171635_2743 src: /192.168.1.157:51125 dest: /192.168.1.157:50010 of size 91176
2017-05-22 20:50:57,529 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1275517095097699833_2744 src: /192.168.1.158:36985 dest: /192.168.1.158:50010
2017-05-22 20:50:57,530 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1275517095097699833_2744 src: /192.168.1.158:36985 dest: /192.168.1.158:50010 of size 4325
2017-05-22 20:51:00,460 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7298629596721350052_2747 src: /192.168.1.157:51126 dest: /192.168.1.157:50010
2017-05-22 20:51:00,460 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7298629596721350052_2747 src: /192.168.1.157:51127 dest: /192.168.1.157:50010
2017-05-22 20:51:00,461 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7298629596721350052_2747 received exception java.io.IOException: Block blk_-7298629596721350052_2747 has already been started (though not completed), and thus cannot be created.
2017-05-22 20:51:00,462 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7298629596721350052_2747 src: /192.168.1.157:51126 dest: /192.168.1.157:50010 of size 13553
2017-05-22 20:51:00,465 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-7298629596721350052_2747 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:51:03,467 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7298629596721350052_2747 to 192.168.1.158:50010
2017-05-22 20:51:03,477 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-7298629596721350052_2747 to /192.168.1.158:50010
2017-05-22 20:51:03,486 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7988526263417419893_2745 src: /192.168.1.156:35731 dest: /192.168.1.156:50010
2017-05-22 20:51:03,487 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7988526263417419893_2745 src: /192.168.1.156:35731 dest: /192.168.1.156:50010 of size 13568
2017-05-22 20:53:21,506 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1879666344364844788_2751 src: /192.168.1.157:51227 dest: /192.168.1.157:50010
2017-05-22 20:53:21,513 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1879666344364844788_2751 src: /192.168.1.157:51227 dest: /192.168.1.157:50010 of size 41886
2017-05-22 20:53:24,541 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7298629596721350052_2747 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7298629596721350052
2017-05-22 20:53:24,541 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6685938414489171635_2743 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6685938414489171635
2017-05-22 20:53:24,542 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1275517095097699833_2744 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1275517095097699833
2017-05-22 20:53:24,542 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7988526263417419893_2745 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7988526263417419893
2017-05-22 20:53:30,617 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:53:41,431 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:53:41,621 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:53:41,623 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:53:41,625 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:53:41,695 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:53:41,751 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:53:41,752 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:53:41,752 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:53:41,980 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 20:53:42,014 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:53:42,016 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:53:42,016 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:53:42,021 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:53:42,044 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:53:42,049 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:53:42,049 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:53:42,051 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:53:42,051 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:53:42,052 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:53:42,052 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:53:42,076 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:53:42,077 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:53:42,091 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:53:42,141 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-1879666344364844788_2751
2017-05-22 20:53:45,090 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 13 msecs
2017-05-22 20:54:18,107 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1879666344364844788_2751 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1879666344364844788
2017-05-22 20:54:48,156 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_602673119289754578_2752 src: /192.168.1.158:36988 dest: /192.168.1.158:50010
2017-05-22 20:54:48,170 INFO org.apache.hadoop.dfs.DataNode: Received block blk_602673119289754578_2752 src: /192.168.1.158:36988 dest: /192.168.1.158:50010 of size 91176
2017-05-22 20:54:48,185 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7391565231580081240_2754 src: /192.168.1.156:35822 dest: /192.168.1.156:50010
2017-05-22 20:54:48,188 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7391565231580081240_2754 src: /192.168.1.156:35822 dest: /192.168.1.156:50010 of size 13568
2017-05-22 20:54:51,126 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5094151722874555698_2756 src: /192.168.1.157:51242 dest: /192.168.1.157:50010
2017-05-22 20:54:51,128 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1309784430516037510_2753 src: /192.168.1.157:51243 dest: /192.168.1.157:50010
2017-05-22 20:54:51,129 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5094151722874555698_2756 src: /192.168.1.157:51242 dest: /192.168.1.157:50010 of size 13553
2017-05-22 20:54:51,131 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1309784430516037510_2753 src: /192.168.1.157:51243 dest: /192.168.1.157:50010 of size 4325
2017-05-22 20:54:51,188 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1309784430516037510_2753 src: /192.168.1.156:35823 dest: /192.168.1.156:50010
2017-05-22 20:54:51,188 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1309784430516037510_2753 received exception java.io.IOException: Block blk_1309784430516037510_2753 is valid, and cannot be written to.
2017-05-22 20:54:51,190 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_1309784430516037510_2753 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:54:51,191 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5094151722874555698_2756 src: /192.168.1.156:35824 dest: /192.168.1.156:50010
2017-05-22 20:54:51,192 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-5094151722874555698_2756 received exception java.io.IOException: Block blk_-5094151722874555698_2756 is valid, and cannot be written to.
2017-05-22 20:54:51,192 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-5094151722874555698_2756 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 20:57:06,371 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7391565231580081240_2754 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7391565231580081240
2017-05-22 20:57:06,373 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_602673119289754578_2752 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_602673119289754578
2017-05-22 20:57:06,373 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1309784430516037510_2753 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1309784430516037510
2017-05-22 20:57:09,181 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4257605129761856555_2760 src: /192.168.1.157:51332 dest: /192.168.1.157:50010
2017-05-22 20:57:09,187 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4257605129761856555_2760 src: /192.168.1.157:51332 dest: /192.168.1.157:50010 of size 41886
2017-05-22 20:57:12,373 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5094151722874555698_2756 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5094151722874555698
2017-05-22 20:57:18,887 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 20:57:29,747 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 20:57:29,939 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 20:57:29,941 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 20:57:29,942 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 20:57:30,001 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 20:57:30,049 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 20:57:30,050 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 20:57:30,050 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 20:57:30,258 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 20:57:30,295 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 20:57:30,298 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 20:57:30,298 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 20:57:30,302 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 20:57:30,319 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 20:57:30,324 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 20:57:30,325 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 20:57:30,326 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 20:57:30,326 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 20:57:30,327 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 20:57:30,327 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 20:57:30,334 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 20:57:30,334 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 20:57:30,347 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 20:57:30,390 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-4257605129761856555_2760
2017-05-22 20:57:33,352 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 14 msecs
2017-05-22 20:58:06,384 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4257605129761856555_2760 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4257605129761856555
2017-05-22 20:58:30,480 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1260801073931114155_2761 src: /192.168.1.158:36991 dest: /192.168.1.158:50010
2017-05-22 20:58:30,480 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2715295673921588492_2765 src: /192.168.1.158:36992 dest: /192.168.1.158:50010
2017-05-22 20:58:30,493 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2715295673921588492_2765 src: /192.168.1.158:36992 dest: /192.168.1.158:50010 of size 13553
2017-05-22 20:58:30,493 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1260801073931114155_2761 src: /192.168.1.158:36991 dest: /192.168.1.158:50010 of size 91176
2017-05-22 20:58:33,436 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6493462538740118272_2762 src: /192.168.1.157:51348 dest: /192.168.1.157:50010
2017-05-22 20:58:33,437 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6493462538740118272_2762 src: /192.168.1.157:51348 dest: /192.168.1.157:50010 of size 8645
2017-05-22 20:58:33,455 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7385627387251908674_2763 src: /192.168.1.156:35927 dest: /192.168.1.156:50010
2017-05-22 20:58:33,457 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7385627387251908674_2763 src: /192.168.1.156:35927 dest: /192.168.1.156:50010 of size 13568
2017-05-22 21:01:00,731 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-7385627387251908674_2763
2017-05-22 21:01:21,560 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6170481338860624554_2766 src: /192.168.1.156:36052 dest: /192.168.1.156:50010
2017-05-22 21:01:21,567 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6170481338860624554_2766 src: /192.168.1.156:36052 dest: /192.168.1.156:50010 of size 77826
2017-05-22 21:01:24,731 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7385627387251908674_2763 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7385627387251908674
2017-05-22 21:01:24,731 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1260801073931114155_2761 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1260801073931114155
2017-05-22 21:01:24,732 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6493462538740118272_2762 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6493462538740118272
2017-05-22 21:01:27,731 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6170481338860624554_2766 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6170481338860624554
2017-05-22 21:01:27,731 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2715295673921588492_2765 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2715295673921588492
2017-05-22 21:01:33,556 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 21:01:44,352 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 21:01:44,555 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 21:01:44,557 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 21:01:44,559 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 21:01:44,629 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 21:01:44,687 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 21:01:44,688 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 21:01:44,688 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 21:01:44,934 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 21:01:44,972 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 21:01:44,976 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 21:01:44,976 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 21:01:44,981 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 21:01:44,999 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 21:01:45,004 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 21:01:45,004 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 21:01:45,006 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 21:01:45,007 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 21:01:45,007 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 21:01:45,007 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 21:01:45,010 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 21:01:45,010 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 21:01:45,018 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 21:01:48,017 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-22 21:02:51,047 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2269177229329914635_2770 src: /192.168.1.158:36995 dest: /192.168.1.158:50010
2017-05-22 21:02:51,052 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1071939415541038315_2772 src: /192.168.1.156:36065 dest: /192.168.1.156:50010
2017-05-22 21:02:51,064 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2269177229329914635_2770 src: /192.168.1.158:36995 dest: /192.168.1.158:50010 of size 91176
2017-05-22 21:02:51,067 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1071939415541038315_2772 src: /192.168.1.156:36065 dest: /192.168.1.156:50010 of size 13568
2017-05-22 21:02:53,992 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5587576608449648561_2771 src: /192.168.1.157:51501 dest: /192.168.1.157:50010
2017-05-22 21:02:53,993 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5587576608449648561_2771 src: /192.168.1.157:51502 dest: /192.168.1.157:50010
2017-05-22 21:02:53,993 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-5587576608449648561_2771 received exception java.io.IOException: Block blk_-5587576608449648561_2771 has already been started (though not completed), and thus cannot be created.
2017-05-22 21:02:53,993 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5587576608449648561_2771 src: /192.168.1.157:51501 dest: /192.168.1.157:50010 of size 8645
2017-05-22 21:02:53,996 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-5587576608449648561_2771 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 21:02:54,054 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1856465619134655468_2774 src: /192.168.1.156:36066 dest: /192.168.1.156:50010
2017-05-22 21:02:54,060 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1856465619134655468_2774 src: /192.168.1.156:36066 dest: /192.168.1.156:50010 of size 13553
2017-05-22 21:02:54,060 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1856465619134655468_2774 src: /192.168.1.156:36067 dest: /192.168.1.156:50010
2017-05-22 21:02:54,062 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1856465619134655468_2774 received exception java.io.IOException: Block blk_1856465619134655468_2774 is valid, and cannot be written to.
2017-05-22 21:02:54,062 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_1856465619134655468_2774 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 21:02:57,095 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-5587576608449648561_2771 to 192.168.1.158:50010
2017-05-22 21:02:57,104 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-5587576608449648561_2771 to /192.168.1.158:50010
2017-05-22 21:06:18,066 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2235717295953850507_2776 src: /192.168.1.158:36996 dest: /192.168.1.158:50010
2017-05-22 21:06:18,072 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2235717295953850507_2776 src: /192.168.1.158:36996 dest: /192.168.1.158:50010 of size 77826
2017-05-22 21:06:21,300 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5587576608449648561_2771 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5587576608449648561
2017-05-22 21:06:21,301 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1071939415541038315_2772 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1071939415541038315
2017-05-22 21:06:21,301 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2269177229329914635_2770 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2269177229329914635
2017-05-22 21:06:24,304 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1856465619134655468_2774 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1856465619134655468
2017-05-22 21:06:24,305 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2235717295953850507_2776 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2235717295953850507
2017-05-22 21:06:30,303 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 21:06:41,211 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 21:06:41,417 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 21:06:41,419 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 21:06:41,420 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 21:06:41,490 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 21:06:41,551 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 21:06:41,552 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 21:06:41,552 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 21:06:41,785 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 21:06:41,822 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 21:06:41,825 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 21:06:41,825 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-22 21:06:41,841 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 21:06:41,862 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 21:06:41,867 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 21:06:41,868 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 21:06:41,868 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 21:06:41,869 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 21:06:41,869 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 21:06:41,869 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 21:06:41,871 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 21:06:41,871 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 21:06:41,878 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 21:06:44,879 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 21:07:47,916 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5827577690810547257_2779 src: /192.168.1.158:36999 dest: /192.168.1.158:50010
2017-05-22 21:07:47,928 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5827577690810547257_2779 src: /192.168.1.158:36999 dest: /192.168.1.158:50010 of size 91176
2017-05-22 21:07:47,930 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2350975217708816552_2780 src: /192.168.1.157:51656 dest: /192.168.1.157:50010
2017-05-22 21:07:47,936 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2350975217708816552_2780 src: /192.168.1.157:51656 dest: /192.168.1.157:50010 of size 8645
2017-05-22 21:07:50,854 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4194693045151980476_2781 src: /192.168.1.156:36201 dest: /192.168.1.156:50010
2017-05-22 21:07:50,855 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4194693045151980476_2781 src: /192.168.1.156:36201 dest: /192.168.1.156:50010 of size 13568
2017-05-22 21:07:53,855 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7957550198659525113_2783 src: /192.168.1.156:36209 dest: /192.168.1.156:50010
2017-05-22 21:07:53,863 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7957550198659525113_2783 src: /192.168.1.156:36209 dest: /192.168.1.156:50010 of size 13553
2017-05-22 21:10:39,022 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4721331196366693387_2785 src: /192.168.1.157:51786 dest: /192.168.1.157:50010
2017-05-22 21:10:39,040 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4721331196366693387_2785 src: /192.168.1.157:51786 dest: /192.168.1.157:50010 of size 77826
2017-05-22 21:10:42,102 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5827577690810547257_2779 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5827577690810547257
2017-05-22 21:10:42,107 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4194693045151980476_2781 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4194693045151980476
2017-05-22 21:10:42,107 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2350975217708816552_2780 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2350975217708816552
2017-05-22 21:10:42,108 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7957550198659525113_2783 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7957550198659525113
2017-05-22 21:10:49,798 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 21:11:00,577 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 21:11:00,800 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 21:11:00,802 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 21:11:00,804 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 21:11:00,873 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 21:11:00,931 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 21:11:00,932 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 21:11:00,932 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 21:11:01,167 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-22 21:11:01,200 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 21:11:01,208 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 21:11:01,208 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 21:11:01,213 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 21:11:01,231 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 21:11:01,235 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 21:11:01,236 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 21:11:01,236 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 21:11:01,236 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 21:11:01,236 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 21:11:01,236 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 21:11:01,250 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 21:11:01,251 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 21:11:01,263 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 21:11:01,311 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-4721331196366693387_2785
2017-05-22 21:11:04,267 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 12 msecs
2017-05-22 21:11:37,304 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4721331196366693387_2785 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4721331196366693387
2017-05-22 21:12:01,305 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4669448434822353188_2788 src: /192.168.1.157:51798 dest: /192.168.1.157:50010
2017-05-22 21:12:01,337 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4669448434822353188_2788 src: /192.168.1.157:51798 dest: /192.168.1.157:50010 of size 91176
2017-05-22 21:12:01,363 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3944408552255202267_2792 src: /192.168.1.158:37002 dest: /192.168.1.158:50010
2017-05-22 21:12:01,365 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3944408552255202267_2792 src: /192.168.1.158:37002 dest: /192.168.1.158:50010 of size 13553
2017-05-22 21:12:04,290 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3586384027620794492_2790 src: /192.168.1.157:51803 dest: /192.168.1.157:50010
2017-05-22 21:12:04,300 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3586384027620794492_2790 src: /192.168.1.157:51803 dest: /192.168.1.157:50010 of size 13568
2017-05-22 21:12:04,326 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3586384027620794492_2790 src: /192.168.1.156:36349 dest: /192.168.1.156:50010
2017-05-22 21:12:04,327 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3586384027620794492_2790 received exception java.io.IOException: Block blk_-3586384027620794492_2790 is valid, and cannot be written to.
2017-05-22 21:12:04,328 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-3586384027620794492_2790 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 21:12:07,328 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8975871067465584536_2789 src: /192.168.1.156:36356 dest: /192.168.1.156:50010
2017-05-22 21:12:07,329 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8975871067465584536_2789 src: /192.168.1.156:36356 dest: /192.168.1.156:50010 of size 4325
2017-05-22 21:14:19,422 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7635393704982465607_2796 src: /192.168.1.156:36433 dest: /192.168.1.156:50010
2017-05-22 21:14:19,428 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7635393704982465607_2796 src: /192.168.1.156:36433 dest: /192.168.1.156:50010 of size 41886
2017-05-22 21:14:22,470 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3944408552255202267_2792 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3944408552255202267
2017-05-22 21:14:22,471 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3586384027620794492_2790 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3586384027620794492
2017-05-22 21:14:22,472 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4669448434822353188_2788 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4669448434822353188
2017-05-22 21:14:22,472 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8975871067465584536_2789 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8975871067465584536
2017-05-22 21:14:28,453 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 21:14:39,269 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 21:14:39,479 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 21:14:39,481 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 21:14:39,483 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 21:14:39,555 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 21:14:39,615 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 21:14:39,616 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 21:14:39,616 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 21:14:39,857 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 21:14:39,894 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 21:14:39,897 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 21:14:39,897 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 21:14:39,903 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 21:14:39,921 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 21:14:39,926 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 21:14:39,927 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 21:14:39,928 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 21:14:39,929 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 21:14:39,929 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 21:14:39,930 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 21:14:39,932 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 21:14:39,933 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 21:14:39,943 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 21:14:39,992 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_7635393704982465607_2796
2017-05-22 21:14:42,941 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 8 msecs
2017-05-22 21:15:15,969 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7635393704982465607_2796 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7635393704982465607
2017-05-22 21:15:45,889 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8036636909931020706_2797 src: /192.168.1.156:36449 dest: /192.168.1.156:50010
2017-05-22 21:15:45,914 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8036636909931020706_2797 src: /192.168.1.156:36449 dest: /192.168.1.156:50010 of size 91176
2017-05-22 21:15:45,945 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3672363394747522612_2799 src: /192.168.1.158:37005 dest: /192.168.1.158:50010
2017-05-22 21:15:45,947 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3672363394747522612_2799 src: /192.168.1.158:37005 dest: /192.168.1.158:50010 of size 13568
2017-05-22 21:15:48,880 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5241839244569404411_2801 src: /192.168.1.156:36450 dest: /192.168.1.156:50010
2017-05-22 21:15:48,882 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5241839244569404411_2801 src: /192.168.1.156:36450 dest: /192.168.1.156:50010 of size 13553
2017-05-22 21:15:48,884 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5241839244569404411_2801 src: /192.168.1.156:36451 dest: /192.168.1.156:50010
2017-05-22 21:15:48,885 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5241839244569404411_2801 received exception java.io.IOException: Block blk_5241839244569404411_2801 is valid, and cannot be written to.
2017-05-22 21:15:48,887 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_5241839244569404411_2801 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 21:15:48,903 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8513973640797391481_2798 src: /192.168.1.157:51912 dest: /192.168.1.157:50010
2017-05-22 21:15:48,904 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8513973640797391481_2798 src: /192.168.1.157:51912 dest: /192.168.1.157:50010 of size 4325
2017-05-22 21:18:03,962 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4150941752412397453_2805 src: /192.168.1.158:37006 dest: /192.168.1.158:50010
2017-05-22 21:18:03,964 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4150941752412397453_2805 src: /192.168.1.158:37006 dest: /192.168.1.158:50010 of size 41886
2017-05-22 21:18:07,279 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3672363394747522612_2799 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3672363394747522612
2017-05-22 21:18:07,280 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5241839244569404411_2801 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5241839244569404411
2017-05-22 21:18:07,280 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8036636909931020706_2797 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8036636909931020706
2017-05-22 21:18:07,281 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8513973640797391481_2798 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8513973640797391481
2017-05-22 21:18:13,134 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 21:18:23,904 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 21:18:24,089 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 21:18:24,091 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 21:18:24,093 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 21:18:24,149 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 21:18:24,197 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 21:18:24,198 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 21:18:24,198 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 21:18:24,411 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-05-22 21:18:24,450 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 21:18:24,453 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 21:18:24,453 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 21:18:24,458 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 21:18:24,475 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 21:18:24,480 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 21:18:24,491 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 21:18:24,493 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 21:18:24,493 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 21:18:24,494 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 21:18:24,494 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 21:18:24,514 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 21:18:24,514 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 21:18:24,528 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 21:18:24,580 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_4150941752412397453_2805
2017-05-22 21:18:27,528 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 14 msecs
2017-05-22 21:19:00,578 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4150941752412397453_2805 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4150941752412397453
2017-05-22 21:19:30,656 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5611978902197907332_2807 src: /192.168.1.157:52021 dest: /192.168.1.157:50010
2017-05-22 21:19:30,672 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5611978902197907332_2807 src: /192.168.1.157:52021 dest: /192.168.1.157:50010 of size 4325
2017-05-22 21:19:30,752 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-429869123796941300_2806 src: /192.168.1.156:36547 dest: /192.168.1.156:50010
2017-05-22 21:19:30,762 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-429869123796941300_2806 src: /192.168.1.156:36547 dest: /192.168.1.156:50010 of size 91176
2017-05-22 21:19:33,673 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8301113711316015472_2810 src: /192.168.1.157:52023 dest: /192.168.1.157:50010
2017-05-22 21:19:33,674 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8301113711316015472_2810 src: /192.168.1.157:52023 dest: /192.168.1.157:50010 of size 13553
2017-05-22 21:19:33,786 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3575660527182940807_2808 src: /192.168.1.156:36549 dest: /192.168.1.156:50010
2017-05-22 21:19:33,786 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3575660527182940807_2808 src: /192.168.1.156:36549 dest: /192.168.1.156:50010 of size 13568
2017-05-22 21:21:45,842 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1565031040915822905_2814 src: /192.168.1.158:37009 dest: /192.168.1.158:50010
2017-05-22 21:21:45,844 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1565031040915822905_2814 src: /192.168.1.158:37009 dest: /192.168.1.158:50010 of size 41886
2017-05-22 21:21:48,742 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5611978902197907332_2807 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5611978902197907332
2017-05-22 21:21:48,743 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3575660527182940807_2808 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3575660527182940807
2017-05-22 21:21:48,743 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-429869123796941300_2806 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-429869123796941300
2017-05-22 21:21:51,743 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8301113711316015472_2810 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8301113711316015472
2017-05-22 21:21:51,744 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1565031040915822905_2814 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1565031040915822905
2017-05-22 21:21:58,537 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 21:22:09,467 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 21:22:09,689 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 21:22:09,691 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 21:22:09,692 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 21:22:09,756 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 21:22:09,823 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 21:22:09,824 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 21:22:09,824 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 21:22:10,071 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 21:22:10,113 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 21:22:10,116 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 21:22:10,116 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 21:22:10,121 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 21:22:10,140 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 21:22:10,145 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 21:22:10,146 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 21:22:10,147 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 21:22:10,148 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 21:22:10,148 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 21:22:10,148 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 21:22:10,161 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 21:22:10,161 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 21:22:10,174 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 21:22:13,173 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 12 msecs
2017-05-22 21:23:10,246 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3351717395851299544_2815 src: /192.168.1.157:52126 dest: /192.168.1.157:50010
2017-05-22 21:23:10,267 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3351717395851299544_2815 src: /192.168.1.157:52126 dest: /192.168.1.157:50010 of size 91176
2017-05-22 21:23:10,306 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7041426440782360082_2819 src: /192.168.1.158:37012 dest: /192.168.1.158:50010
2017-05-22 21:23:10,308 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7041426440782360082_2819 src: /192.168.1.158:37012 dest: /192.168.1.158:50010 of size 13553
2017-05-22 21:23:13,209 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7110726726920503961_2817 src: /192.168.1.157:52131 dest: /192.168.1.157:50010
2017-05-22 21:23:13,212 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7110726726920503961_2817 src: /192.168.1.157:52131 dest: /192.168.1.157:50010 of size 13568
2017-05-22 21:23:13,270 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2421913013234482003_2816 src: /192.168.1.156:36654 dest: /192.168.1.156:50010
2017-05-22 21:23:13,279 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2421913013234482003_2816 src: /192.168.1.156:36654 dest: /192.168.1.156:50010 of size 2165
2017-05-22 21:25:22,325 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8291366635608967108_2823 src: /192.168.1.156:36714 dest: /192.168.1.156:50010
2017-05-22 21:25:22,330 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8291366635608967108_2823 src: /192.168.1.156:36714 dest: /192.168.1.156:50010 of size 23950
2017-05-22 21:25:25,295 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7110726726920503961_2817 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7110726726920503961
2017-05-22 21:25:25,295 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7041426440782360082_2819 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7041426440782360082
2017-05-22 21:25:25,296 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2421913013234482003_2816 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2421913013234482003
2017-05-22 21:25:25,296 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3351717395851299544_2815 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3351717395851299544
2017-05-22 21:25:25,297 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8291366635608967108_2823 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8291366635608967108
2017-05-22 21:25:32,405 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 21:25:43,313 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 21:25:43,505 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 21:25:43,507 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 21:25:43,508 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 21:25:43,583 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 21:25:43,641 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 21:25:43,642 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 21:25:43,642 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 21:25:43,863 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 21:25:43,902 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 21:25:43,905 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 21:25:43,905 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 21:25:43,909 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 21:25:43,927 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 21:25:43,931 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 21:25:43,932 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 21:25:43,933 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 21:25:43,934 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 21:25:43,934 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 21:25:43,934 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 21:25:43,951 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 21:25:43,951 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 21:25:43,962 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 21:25:46,970 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 19 msecs
2017-05-22 21:26:50,049 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6708438080819010129_2824 src: /192.168.1.158:37015 dest: /192.168.1.158:50010
2017-05-22 21:26:50,062 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6708438080819010129_2824 src: /192.168.1.158:37015 dest: /192.168.1.158:50010 of size 91176
2017-05-22 21:26:50,096 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2848060888781841965_2826 src: /192.168.1.158:37016 dest: /192.168.1.158:50010
2017-05-22 21:26:50,097 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2848060888781841965_2826 src: /192.168.1.158:37016 dest: /192.168.1.158:50010 of size 13568
2017-05-22 21:26:52,983 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2146810782412555929_2828 src: /192.168.1.157:52215 dest: /192.168.1.157:50010
2017-05-22 21:26:52,985 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6038132912512148986_2825 src: /192.168.1.157:52216 dest: /192.168.1.157:50010
2017-05-22 21:26:52,986 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2146810782412555929_2828 src: /192.168.1.157:52215 dest: /192.168.1.157:50010 of size 13553
2017-05-22 21:26:52,988 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6038132912512148986_2825 src: /192.168.1.157:52216 dest: /192.168.1.157:50010 of size 2165
2017-05-22 21:26:53,093 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6038132912512148986_2825 src: /192.168.1.156:36730 dest: /192.168.1.156:50010
2017-05-22 21:26:53,093 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6038132912512148986_2825 received exception java.io.IOException: Block blk_6038132912512148986_2825 is valid, and cannot be written to.
2017-05-22 21:26:53,095 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_6038132912512148986_2825 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 21:26:56,035 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_6038132912512148986_2825 to 192.168.1.158:50010
2017-05-22 21:26:56,045 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_6038132912512148986_2825 to /192.168.1.158:50010
2017-05-22 21:28:44,049 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6485633456726945559_2832 src: /192.168.1.157:52279 dest: /192.168.1.157:50010
2017-05-22 21:28:44,055 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6485633456726945559_2832 src: /192.168.1.157:52279 dest: /192.168.1.157:50010 of size 23547
2017-05-22 21:28:47,202 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2848060888781841965_2826 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2848060888781841965
2017-05-22 21:28:47,203 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6038132912512148986_2825 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6038132912512148986
2017-05-22 21:28:47,203 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6708438080819010129_2824 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6708438080819010129
2017-05-22 21:28:50,205 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2146810782412555929_2828 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2146810782412555929
2017-05-22 21:28:50,206 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6485633456726945559_2832 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6485633456726945559
2017-05-22 21:28:55,194 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 21:29:05,986 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 21:29:06,181 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 21:29:06,183 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 21:29:06,185 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 21:29:06,246 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 21:29:06,294 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 21:29:06,295 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 21:29:06,295 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 21:29:06,503 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-22 21:29:06,534 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 21:29:06,537 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 21:29:06,537 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 21:29:06,541 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 21:29:06,558 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 21:29:06,562 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 21:29:06,563 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 21:29:06,565 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 21:29:06,565 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 21:29:06,566 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 21:29:06,566 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 21:29:06,576 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 21:29:06,576 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 21:29:06,588 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 21:29:09,590 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-05-22 21:30:12,811 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2312557783159478516_2833 src: /192.168.1.157:52294 dest: /192.168.1.157:50010
2017-05-22 21:30:12,830 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2312557783159478516_2833 src: /192.168.1.157:52294 dest: /192.168.1.157:50010 of size 91176
2017-05-22 21:30:12,841 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5582004913328636231_2834 src: /192.168.1.158:37019 dest: /192.168.1.158:50010
2017-05-22 21:30:12,843 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5582004913328636231_2834 src: /192.168.1.158:37019 dest: /192.168.1.158:50010 of size 2165
2017-05-22 21:30:15,808 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2943329845150718813_2835 src: /192.168.1.156:36806 dest: /192.168.1.156:50010
2017-05-22 21:30:15,809 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2943329845150718813_2835 src: /192.168.1.156:36806 dest: /192.168.1.156:50010 of size 13568
2017-05-22 21:30:18,669 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9133117798657024215_2837 src: /192.168.1.158:37020 dest: /192.168.1.158:50010
2017-05-22 21:30:18,672 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9133117798657024215_2837 src: /192.168.1.158:37020 dest: /192.168.1.158:50010 of size 13553
2017-05-22 21:32:27,833 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8958695998195090540_2841 src: /192.168.1.158:37021 dest: /192.168.1.158:50010
2017-05-22 21:32:27,835 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8958695998195090540_2841 src: /192.168.1.158:37021 dest: /192.168.1.158:50010 of size 23948
2017-05-22 21:32:30,842 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2943329845150718813_2835 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2943329845150718813
2017-05-22 21:32:30,842 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2312557783159478516_2833 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2312557783159478516
2017-05-22 21:32:30,843 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5582004913328636231_2834 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5582004913328636231
2017-05-22 21:32:30,844 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8958695998195090540_2841 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8958695998195090540
2017-05-22 21:32:30,844 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9133117798657024215_2837 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9133117798657024215
2017-05-22 21:32:39,814 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 21:32:50,714 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 21:32:50,913 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 21:32:50,915 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 21:32:50,917 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 21:32:50,979 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 21:32:51,030 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 21:32:51,031 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 21:32:51,031 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 21:32:51,253 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-22 21:32:51,290 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 21:32:51,293 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 21:32:51,293 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-22 21:32:51,298 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 21:32:51,315 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 21:32:51,320 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 21:32:51,321 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 21:32:51,322 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 21:32:51,323 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 21:32:51,323 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 21:32:51,323 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 21:32:51,325 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 21:32:51,326 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 21:32:51,334 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 21:32:54,334 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 21:33:51,382 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4150677510951042550_2842 src: /192.168.1.156:36873 dest: /192.168.1.156:50010
2017-05-22 21:33:51,401 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4150677510951042550_2842 src: /192.168.1.156:36873 dest: /192.168.1.156:50010 of size 91176
2017-05-22 21:33:51,412 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4634461007921361671_2844 src: /192.168.1.158:37024 dest: /192.168.1.158:50010
2017-05-22 21:33:51,413 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4634461007921361671_2844 src: /192.168.1.158:37024 dest: /192.168.1.158:50010 of size 13569
2017-05-22 21:33:54,350 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5435452925639756299_2843 src: /192.168.1.156:36880 dest: /192.168.1.156:50010
2017-05-22 21:33:54,351 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5435452925639756299_2843 src: /192.168.1.156:36880 dest: /192.168.1.156:50010 of size 1085
2017-05-22 21:33:54,365 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6615075479184960956_2846 src: /192.168.1.157:52379 dest: /192.168.1.157:50010
2017-05-22 21:33:54,372 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6615075479184960956_2846 src: /192.168.1.157:52379 dest: /192.168.1.157:50010 of size 13554
2017-05-22 21:36:21,416 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-22575884477019935_2850 src: /192.168.1.158:37025 dest: /192.168.1.158:50010
2017-05-22 21:36:21,418 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-22575884477019935_2850 src: /192.168.1.158:37025 dest: /192.168.1.158:50010 of size 14960
2017-05-22 21:36:24,509 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5435452925639756299_2843 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5435452925639756299
2017-05-22 21:36:24,510 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-22575884477019935_2850 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-22575884477019935
2017-05-22 21:36:24,510 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4150677510951042550_2842 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4150677510951042550
2017-05-22 21:36:24,511 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4634461007921361671_2844 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4634461007921361671
2017-05-22 21:36:24,511 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6615075479184960956_2846 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6615075479184960956
2017-05-22 21:36:31,483 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 21:36:42,294 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 21:36:42,501 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 21:36:42,503 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 21:36:42,505 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 21:36:42,577 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 21:36:42,634 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 21:36:42,635 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 21:36:42,635 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 21:36:42,883 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 21:36:42,926 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 21:36:42,929 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 21:36:42,929 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 21:36:42,934 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 21:36:42,952 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 21:36:42,957 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 21:36:42,958 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 21:36:42,959 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 21:36:42,960 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 21:36:42,960 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 21:36:42,960 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 21:36:42,963 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 21:36:42,963 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 21:36:42,972 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 21:36:45,972 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 9 msecs
2017-05-22 21:37:49,100 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2703299048982294649_2852 src: /192.168.1.156:36932 dest: /192.168.1.156:50010
2017-05-22 21:37:49,100 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8812902800101776828_2851 src: /192.168.1.158:37028 dest: /192.168.1.158:50010
2017-05-22 21:37:49,117 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2703299048982294649_2852 src: /192.168.1.156:36932 dest: /192.168.1.156:50010 of size 1085
2017-05-22 21:37:49,117 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8812902800101776828_2851 src: /192.168.1.158:37028 dest: /192.168.1.158:50010 of size 91176
2017-05-22 21:37:54,943 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4772811959112806350_2855 src: /192.168.1.158:37030 dest: /192.168.1.158:50010
2017-05-22 21:37:54,943 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2659156358999054293_2853 src: /192.168.1.158:37029 dest: /192.168.1.158:50010
2017-05-22 21:37:54,946 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4772811959112806350_2855 src: /192.168.1.158:37030 dest: /192.168.1.158:50010 of size 13554
2017-05-22 21:37:54,947 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2659156358999054293_2853 src: /192.168.1.158:37029 dest: /192.168.1.158:50010 of size 13569
2017-05-22 21:40:22,149 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1407131647412352977_2859 src: /192.168.1.158:37031 dest: /192.168.1.158:50010
2017-05-22 21:40:22,151 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1407131647412352977_2859 src: /192.168.1.158:37031 dest: /192.168.1.158:50010 of size 14958
2017-05-22 21:40:25,127 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8812902800101776828_2851 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8812902800101776828
2017-05-22 21:40:25,127 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2703299048982294649_2852 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2703299048982294649
2017-05-22 21:40:25,128 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2659156358999054293_2853 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2659156358999054293
2017-05-22 21:40:28,125 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1407131647412352977_2859 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1407131647412352977
2017-05-22 21:40:28,125 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4772811959112806350_2855 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4772811959112806350
2017-05-22 21:40:33,129 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-22 21:40:44,064 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-22 21:40:44,250 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-22 21:40:44,252 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-22 21:40:44,253 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-22 21:40:44,304 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-22 21:40:44,350 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-22 21:40:44,350 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-22 21:40:44,350 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-22 21:40:44,554 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-22 21:40:44,586 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-22 21:40:44,589 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-22 21:40:44,589 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-22 21:40:44,593 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-22 21:40:44,610 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-22 21:40:44,615 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-22 21:40:44,616 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-22 21:40:44,617 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-22 21:40:44,618 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-22 21:40:44,618 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-22 21:40:44,618 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-22 21:40:44,620 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-22 21:40:44,620 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-22 21:40:44,628 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-22 21:40:47,628 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-22 21:41:50,734 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3417815180423776740_2860 src: /192.168.1.156:36994 dest: /192.168.1.156:50010
2017-05-22 21:41:50,753 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3417815180423776740_2860 src: /192.168.1.156:36994 dest: /192.168.1.156:50010 of size 91176
2017-05-22 21:41:50,787 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3793887978165445870_2861 src: /192.168.1.157:52494 dest: /192.168.1.157:50010
2017-05-22 21:41:50,791 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3793887978165445870_2861 src: /192.168.1.157:52494 dest: /192.168.1.157:50010 of size 1085
2017-05-22 21:41:53,709 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5545871126850796404_2864 src: /192.168.1.156:36995 dest: /192.168.1.156:50010
2017-05-22 21:41:53,710 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5545871126850796404_2864 src: /192.168.1.156:36995 dest: /192.168.1.156:50010 of size 13554
2017-05-22 21:41:53,788 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5545871126850796404_2864 src: /192.168.1.157:52496 dest: /192.168.1.157:50010
2017-05-22 21:41:53,789 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5545871126850796404_2864 received exception java.io.IOException: Block blk_5545871126850796404_2864 is valid, and cannot be written to.
2017-05-22 21:41:53,791 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_5545871126850796404_2864 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-22 21:41:56,654 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2585679486120055196_2862 src: /192.168.1.158:37034 dest: /192.168.1.158:50010
2017-05-22 21:41:56,656 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2585679486120055196_2862 src: /192.168.1.158:37034 dest: /192.168.1.158:50010 of size 13569
2017-05-22 21:41:56,725 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_5545871126850796404_2864 to 192.168.1.158:50010
2017-05-22 21:41:56,737 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_5545871126850796404_2864 to /192.168.1.158:50010
2017-05-22 21:44:23,848 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7648592710437976195_2868 src: /192.168.1.157:52533 dest: /192.168.1.157:50010
2017-05-22 21:44:23,852 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7648592710437976195_2868 src: /192.168.1.157:52533 dest: /192.168.1.157:50010 of size 14960
2017-05-22 21:44:26,860 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3793887978165445870_2861 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3793887978165445870
2017-05-22 21:44:26,861 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2585679486120055196_2862 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2585679486120055196
2017-05-22 21:44:26,861 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3417815180423776740_2860 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3417815180423776740
2017-05-22 21:44:26,862 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5545871126850796404_2864 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5545871126850796404
2017-05-22 21:44:26,862 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7648592710437976195_2868 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7648592710437976195
2017-05-22 22:21:37,288 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-22 23:21:40,136 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
