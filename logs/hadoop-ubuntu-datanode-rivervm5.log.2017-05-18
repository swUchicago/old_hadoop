2017-05-18 00:06:33,535 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 2 msecs
2017-05-18 01:06:34,939 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 02:06:36,215 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 03:06:37,512 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 04:06:38,835 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 05:06:40,143 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 06:06:41,428 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 07:06:42,781 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 2 msecs
2017-05-18 08:06:44,098 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 09:06:45,417 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 10:06:46,691 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 11:06:47,983 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 12:06:49,284 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 13:06:50,602 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 14:04:07,722 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 14:04:20,581 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 14:04:20,759 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 14:04:20,761 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 14:04:20,763 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 14:04:20,830 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 14:04:20,885 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 14:04:20,886 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 14:04:20,886 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 14:04:21,120 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-18 14:04:21,156 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 14:04:21,159 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 14:04:21,159 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-18 14:04:21,165 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 14:04:21,181 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 14:04:21,187 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 14:04:21,188 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 14:04:21,190 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 14:04:21,191 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 14:04:21,191 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 14:04:21,191 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 14:04:21,195 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 14:04:21,195 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 14:04:21,204 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 14:04:24,204 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 8 msecs
2017-05-18 14:05:30,313 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4606353696211132109_1002 src: /192.168.1.151:38913 dest: /192.168.1.151:50010
2017-05-18 14:05:30,326 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4606353696211132109_1002 src: /192.168.1.151:38913 dest: /192.168.1.151:50010 of size 91176
2017-05-18 14:05:33,233 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4606353696211132109_1002 to 192.168.1.152:50010
2017-05-18 14:05:33,248 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_4606353696211132109_1002 to /192.168.1.152:50010
2017-05-18 14:05:42,237 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-517388464095627113_1003 src: /192.168.1.150:40845 dest: /192.168.1.150:50010
2017-05-18 14:05:42,243 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-517388464095627113_1003 src: /192.168.1.150:40845 dest: /192.168.1.150:50010 of size 91176
2017-05-18 14:05:57,241 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4371183379725399540_1004 src: /192.168.1.150:40846 dest: /192.168.1.150:50010
2017-05-18 14:05:57,250 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4371183379725399540_1004 src: /192.168.1.150:40846 dest: /192.168.1.150:50010 of size 91176
2017-05-18 14:07:07,669 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 14:07:20,468 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 14:07:20,650 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 14:07:20,652 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 14:07:20,654 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 14:07:20,706 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 14:07:20,751 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 14:07:20,751 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 14:07:20,752 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 14:07:20,952 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-18 14:07:20,983 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 14:07:20,985 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 14:07:20,985 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-18 14:07:20,990 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 14:07:21,005 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 14:07:21,009 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 14:07:21,010 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 14:07:21,011 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 14:07:21,012 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 14:07:21,012 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 14:07:21,013 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 14:07:21,037 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 14:07:21,037 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 14:07:21,050 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 14:07:21,078 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_4606353696211132109_1002
2017-05-18 14:07:24,053 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 11 blocks got processed in 13 msecs
2017-05-18 14:08:06,060 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-517388464095627113_1003 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-517388464095627113
2017-05-18 14:08:06,060 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4371183379725399540_1004 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4371183379725399540
2017-05-18 14:08:06,061 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4606353696211132109_1002 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4606353696211132109
2017-05-18 14:08:31,718 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.151
2017-05-18 14:08:33,146 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8739388525776731942_1005 src: /192.168.1.152:53723 dest: /192.168.1.152:50010
2017-05-18 14:08:33,158 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8739388525776731942_1005 src: /192.168.1.152:53723 dest: /192.168.1.152:50010 of size 91176
2017-05-18 14:08:36,121 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1291170711098790794_1006 src: /192.168.1.151:38925 dest: /192.168.1.151:50010
2017-05-18 14:08:36,122 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1291170711098790794_1006 src: /192.168.1.151:38925 dest: /192.168.1.151:50010 of size 973
2017-05-18 14:08:36,168 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3595807094391396284_1009 src: /192.168.1.151:38926 dest: /192.168.1.151:50010
2017-05-18 14:08:36,169 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3595807094391396284_1009 src: /192.168.1.151:38926 dest: /192.168.1.151:50010 of size 13538
2017-05-18 14:08:39,068 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1291170711098790794_1006 to 192.168.1.152:50010
2017-05-18 14:08:39,075 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-1291170711098790794_1006 to /192.168.1.152:50010
2017-05-18 14:08:39,120 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1215719821347186418_1007 src: /192.168.1.150:40862 dest: /192.168.1.150:50010
2017-05-18 14:08:39,120 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1215719821347186418_1007 src: /192.168.1.150:40862 dest: /192.168.1.150:50010 of size 13552
2017-05-18 14:08:50,595 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.153
2017-05-18 14:08:53,578 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.150
2017-05-18 14:08:57,580 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 14:09:11,369 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 14:09:30,069 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.150
2017-05-18 14:18:06,592 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.153
2017-05-18 14:18:36,301 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8739388525776731942_1005 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8739388525776731942
2017-05-18 14:18:36,302 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1291170711098790794_1006 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1291170711098790794
2017-05-18 14:18:36,303 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1215719821347186418_1007 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1215719821347186418
2017-05-18 14:18:39,302 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3595807094391396284_1009 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3595807094391396284
2017-05-18 14:18:46,854 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.152
2017-05-18 14:18:48,305 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 14:19:00,891 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8873189496677999500_1011 src: /192.168.1.151:38956 dest: /192.168.1.151:50010
2017-05-18 14:19:00,892 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8873189496677999500_1011 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 14:19:00,894 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 14:19:05,389 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.153
2017-05-18 14:19:08,596 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.151
2017-05-18 14:19:08,782 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.150
2017-05-18 14:19:12,157 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 14:19:24,385 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2110667269243744031_1010 src: /192.168.1.152:53761 dest: /192.168.1.152:50010
2017-05-18 14:19:24,387 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2110667269243744031_1010 src: /192.168.1.152:53761 dest: /192.168.1.152:50010 of size 91176
2017-05-18 14:19:24,899 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5627541419534733989_1012 src: /192.168.1.151:38967 dest: /192.168.1.151:50010
2017-05-18 14:19:24,902 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5627541419534733989_1012 src: /192.168.1.151:38967 dest: /192.168.1.151:50010 of size 13552
2017-05-18 14:19:24,904 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6602637448520716603_1014 src: /192.168.1.151:38968 dest: /192.168.1.151:50010
2017-05-18 14:19:24,905 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6602637448520716603_1014 src: /192.168.1.151:38968 dest: /192.168.1.151:50010 of size 13538
2017-05-18 14:19:32,917 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 14:19:53,766 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 14:19:54,693 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7972400381619806669_1001 to /192.168.1.150
2017-05-18 14:19:59,598 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.150
2017-05-18 14:20:16,584 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.150
2017-05-18 14:27:24,551 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8873189496677999500_1011 src: /192.168.1.152:53772 dest: /192.168.1.152:50010
2017-05-18 14:27:24,552 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8873189496677999500_1011 src: /192.168.1.152:53772 dest: /192.168.1.152:50010 of size 973
2017-05-18 14:27:53,815 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.153
2017-05-18 14:31:01,642 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.153
2017-05-18 14:31:33,579 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2110667269243744031_1010 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2110667269243744031
2017-05-18 14:31:33,580 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5627541419534733989_1012 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5627541419534733989
2017-05-18 14:31:33,580 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8873189496677999500_1011 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8873189496677999500
2017-05-18 14:31:36,580 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6602637448520716603_1014 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6602637448520716603
2017-05-18 14:31:44,116 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 14:31:48,609 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6826075061854860182_1019 src: /192.168.1.150:40948 dest: /192.168.1.150:50010
2017-05-18 14:31:48,610 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-6826075061854860182_1019 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 14:31:48,610 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 14:31:49,304 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8507863635010945764_1016 src: /192.168.1.151:39008 dest: /192.168.1.151:50010
2017-05-18 14:31:49,305 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8507863635010945764_1016 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 14:31:49,305 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 14:31:59,969 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.153
2017-05-18 14:32:04,758 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.153
2017-05-18 14:32:24,659 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5155855503412751882_1015 src: /192.168.1.152:53797 dest: /192.168.1.152:50010
2017-05-18 14:32:24,660 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6294915529854143679_1017 src: /192.168.1.152:53798 dest: /192.168.1.152:50010
2017-05-18 14:32:24,662 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6294915529854143679_1017 src: /192.168.1.152:53798 dest: /192.168.1.152:50010 of size 13552
2017-05-18 14:32:24,667 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5155855503412751882_1015 src: /192.168.1.152:53797 dest: /192.168.1.152:50010 of size 91176
2017-05-18 14:32:25,329 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6826075061854860182_1019 src: /192.168.1.151:39023 dest: /192.168.1.151:50010
2017-05-18 14:32:25,330 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6826075061854860182_1019 src: /192.168.1.151:39023 dest: /192.168.1.151:50010 of size 13538
2017-05-18 14:32:25,597 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 14:33:29,087 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7972400381619806669_1001 to /192.168.1.150
2017-05-18 14:36:57,705 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6826075061854860182_1019 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6826075061854860182
2017-05-18 14:37:25,474 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8507863635010945764_1016 src: /192.168.1.151:39034 dest: /192.168.1.151:50010
2017-05-18 14:37:25,475 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8507863635010945764_1016 src: /192.168.1.151:39034 dest: /192.168.1.151:50010 of size 973
2017-05-18 14:38:09,729 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8507863635010945764_1016 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8507863635010945764
2017-05-18 14:38:09,730 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5155855503412751882_1015 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5155855503412751882
2017-05-18 14:38:09,730 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6294915529854143679_1017 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6294915529854143679
2017-05-18 14:39:49,163 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 14:40:02,074 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 14:40:02,282 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 14:40:02,284 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 14:40:02,285 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 14:40:02,347 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 14:40:02,400 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 14:40:02,401 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 14:40:02,401 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 14:40:02,601 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-18 14:40:02,632 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 14:40:02,635 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 14:40:02,635 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-18 14:40:02,641 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 14:40:02,657 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 14:40:02,661 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 14:40:02,662 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 14:40:02,663 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 14:40:02,664 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 14:40:02,664 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 14:40:02,664 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 14:40:02,667 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 14:40:02,667 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 14:40:02,675 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 14:40:05,675 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-18 14:41:11,711 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2566714410429223758_1022 src: /192.168.1.150:40980 dest: /192.168.1.150:50010
2017-05-18 14:41:11,727 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2566714410429223758_1022 src: /192.168.1.150:40980 dest: /192.168.1.150:50010 of size 13552
2017-05-18 14:41:11,941 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2566714410429223758_1022 to /192.168.1.153
2017-05-18 14:41:12,913 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 14:41:14,697 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2566714410429223758_1022 to 192.168.1.152:50010
2017-05-18 14:41:14,705 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-2566714410429223758_1022 to /192.168.1.152:50010
2017-05-18 14:41:17,683 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2767299187015020010_1024 src: /192.168.1.150:40989 dest: /192.168.1.150:50010
2017-05-18 14:41:17,686 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2767299187015020010_1024 src: /192.168.1.150:40989 dest: /192.168.1.150:50010 of size 13538
2017-05-18 14:41:17,720 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_211858620657873440_1020 src: /192.168.1.152:53818 dest: /192.168.1.152:50010
2017-05-18 14:41:17,726 INFO org.apache.hadoop.dfs.DataNode: Received block blk_211858620657873440_1020 src: /192.168.1.152:53818 dest: /192.168.1.152:50010 of size 91176
2017-05-18 14:41:20,709 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_2767299187015020010_1024 to 192.168.1.151:50010
2017-05-18 14:41:20,711 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_2767299187015020010_1024 to /192.168.1.151:50010
2017-05-18 14:41:23,668 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8923752149614950425_1021 src: /192.168.1.151:39047 dest: /192.168.1.151:50010
2017-05-18 14:41:23,670 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8923752149614950425_1021 src: /192.168.1.151:39047 dest: /192.168.1.151:50010 of size 973
2017-05-18 14:41:28,428 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.153
2017-05-18 14:41:33,635 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.153
2017-05-18 14:41:53,707 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 14:41:59,441 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 14:44:44,791 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2767299187015020010_1024 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2767299187015020010
2017-05-18 14:45:26,804 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2566714410429223758_1022 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2566714410429223758
2017-05-18 14:45:26,805 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_211858620657873440_1020 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_211858620657873440
2017-05-18 14:45:26,805 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8923752149614950425_1021 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8923752149614950425
2017-05-18 14:49:37,693 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 14:49:50,536 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 14:49:50,727 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 14:49:50,729 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 14:49:50,731 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 14:49:50,799 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 14:49:50,855 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 14:49:50,856 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 14:49:50,856 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 14:49:51,091 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-18 14:49:51,125 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 14:49:51,131 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 14:49:51,131 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-18 14:49:51,140 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 14:49:51,160 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 14:49:51,164 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 14:49:51,165 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 14:49:51,165 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 14:49:51,166 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 14:49:51,166 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 14:49:51,166 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 14:49:51,168 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 14:49:51,168 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 14:49:51,175 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 14:49:54,173 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-18 14:51:00,227 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8584096249369591871_1025 src: /192.168.1.150:41018 dest: /192.168.1.150:50010
2017-05-18 14:51:00,246 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8584096249369591871_1025 src: /192.168.1.150:41018 dest: /192.168.1.150:50010 of size 91176
2017-05-18 14:51:00,456 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8584096249369591871_1025 to /192.168.1.152
2017-05-18 14:51:00,488 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8584096249369591871_1025 to /192.168.1.153
2017-05-18 14:51:01,382 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.152
2017-05-18 14:51:03,202 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8584096249369591871_1025 to 192.168.1.152:50010
2017-05-18 14:51:03,215 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-8584096249369591871_1025 to /192.168.1.152:50010
2017-05-18 14:51:06,186 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6399536567468761919_1026 src: /192.168.1.151:39072 dest: /192.168.1.151:50010
2017-05-18 14:51:06,190 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6399536567468761919_1026 src: /192.168.1.151:39072 dest: /192.168.1.151:50010 of size 1941
2017-05-18 14:51:09,251 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_172150687803807076_1027 src: /192.168.1.151:39073 dest: /192.168.1.151:50010
2017-05-18 14:51:09,252 INFO org.apache.hadoop.dfs.DataNode: Received block blk_172150687803807076_1027 src: /192.168.1.151:39073 dest: /192.168.1.151:50010 of size 13553
2017-05-18 14:51:10,660 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.153
2017-05-18 14:51:12,204 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1319910504571325978_1029 src: /192.168.1.150:41031 dest: /192.168.1.150:50010
2017-05-18 14:51:12,207 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1319910504571325978_1029 src: /192.168.1.150:41031 dest: /192.168.1.150:50010 of size 13539
2017-05-18 14:51:14,087 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.151
2017-05-18 14:51:22,821 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 14:51:33,248 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 14:51:36,700 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 14:51:55,861 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7972400381619806669_1001 to /192.168.1.153
2017-05-18 14:58:12,349 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1319910504571325978_1029 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1319910504571325978
2017-05-18 14:58:18,350 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8584096249369591871_1025 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8584096249369591871
2017-05-18 14:58:18,351 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6399536567468761919_1026 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6399536567468761919
2017-05-18 14:58:18,351 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_172150687803807076_1027 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_172150687803807076
2017-05-18 14:58:49,758 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 14:59:02,531 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 14:59:02,723 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 14:59:02,725 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 14:59:02,727 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 14:59:02,787 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 14:59:02,834 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 14:59:02,835 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 14:59:02,835 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 14:59:03,061 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-18 14:59:03,092 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 14:59:03,095 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 14:59:03,095 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-18 14:59:03,100 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 14:59:03,116 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 14:59:03,121 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 14:59:03,122 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 14:59:03,123 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 14:59:03,124 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 14:59:03,124 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 14:59:03,124 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 14:59:03,127 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 14:59:03,127 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 14:59:03,134 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 14:59:06,136 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 9 msecs
2017-05-18 15:00:15,092 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4473559771668309614_1032 src: /192.168.1.152:53898 dest: /192.168.1.152:50010
2017-05-18 15:00:15,108 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4473559771668309614_1032 src: /192.168.1.152:53898 dest: /192.168.1.152:50010 of size 13553
2017-05-18 15:00:15,208 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2153643057636241641_1034 src: /192.168.1.150:41070 dest: /192.168.1.150:50010
2017-05-18 15:00:15,214 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2153643057636241641_1034 src: /192.168.1.150:41069 dest: /192.168.1.150:50010
2017-05-18 15:00:15,214 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2153643057636241641_1034 received exception java.io.IOException: Block blk_-2153643057636241641_1034 has already been started (though not completed), and thus cannot be created.
2017-05-18 15:00:15,215 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2153643057636241641_1034 src: /192.168.1.150:41070 dest: /192.168.1.150:50010 of size 13539
2017-05-18 15:00:15,216 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-2153643057636241641_1034 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:00:18,167 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2153643057636241641_1034 to 192.168.1.152:50010, 192.168.1.151:50010
2017-05-18 15:00:18,176 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-2153643057636241641_1034 to /192.168.1.152:50010
2017-05-18 15:00:21,093 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1055369902899471868_1030 src: /192.168.1.152:53903 dest: /192.168.1.152:50010
2017-05-18 15:00:21,095 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1055369902899471868_1030 src: /192.168.1.152:53903 dest: /192.168.1.152:50010 of size 91176
2017-05-18 15:00:21,170 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.151
2017-05-18 15:00:21,209 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8378286517828743762_1031 src: /192.168.1.150:41076 dest: /192.168.1.150:50010
2017-05-18 15:00:21,210 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8378286517828743762_1031 src: /192.168.1.150:41076 dest: /192.168.1.150:50010 of size 3877
2017-05-18 15:00:40,824 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 15:01:01,595 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 15:01:08,161 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7972400381619806669_1001 to /192.168.1.153
2017-05-18 15:01:27,243 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6021706252600745906_1038 src: /192.168.1.152:53947 dest: /192.168.1.152:50010
2017-05-18 15:01:27,243 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6021706252600745906_1038 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:01:27,243 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:01:30,244 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6021706252600745906_1038 src: /192.168.1.151:39170 dest: /192.168.1.151:50010
2017-05-18 15:01:30,244 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6021706252600745906_1038 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:01:30,244 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:01:33,197 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4473559771668309614_1032 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4473559771668309614
2017-05-18 15:01:33,198 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2153643057636241641_1034 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2153643057636241641
2017-05-18 15:01:33,198 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1055369902899471868_1030 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1055369902899471868
2017-05-18 15:01:33,199 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8378286517828743762_1031 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8378286517828743762
2017-05-18 15:01:42,239 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-938452157557465995_1039 src: /192.168.1.150:41125 dest: /192.168.1.150:50010
2017-05-18 15:01:42,240 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-938452157557465995_1039 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:01:42,241 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:01:43,418 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.152
2017-05-18 15:01:48,127 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-938452157557465995_1039 src: /192.168.1.151:39179 dest: /192.168.1.151:50010
2017-05-18 15:01:48,128 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-938452157557465995_1039 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:01:48,128 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:01:51,122 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-938452157557465995_1039 src: /192.168.1.152:53963 dest: /192.168.1.152:50010
2017-05-18 15:01:51,123 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-938452157557465995_1039 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:01:51,123 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:01:51,304 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3887416225186969447_1043 src: /192.168.1.151:39182 dest: /192.168.1.151:50010
2017-05-18 15:01:51,304 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3887416225186969447_1043 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:01:51,304 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:01:51,312 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.151
2017-05-18 15:01:54,122 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4810433813933037647_1041 src: /192.168.1.152:53964 dest: /192.168.1.152:50010
2017-05-18 15:01:54,123 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4810433813933037647_1041 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:01:54,123 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:01:54,243 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_147865244614920032_1040 src: /192.168.1.150:41138 dest: /192.168.1.150:50010
2017-05-18 15:01:54,243 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_147865244614920032_1040 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:01:54,243 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:01:54,305 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-938452157557465995_1039 src: /192.168.1.151:39185 dest: /192.168.1.151:50010
2017-05-18 15:01:54,306 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-938452157557465995_1039 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:01:54,306 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:01:57,245 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-938452157557465995_1039 src: /192.168.1.150:41145 dest: /192.168.1.150:50010
2017-05-18 15:01:57,247 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-938452157557465995_1039 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:01:57,260 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:02:00,246 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-938452157557465995_1039 src: /192.168.1.150:41147 dest: /192.168.1.150:50010
2017-05-18 15:02:00,247 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-938452157557465995_1039 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:02:00,247 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:02:03,316 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-938452157557465995_1039 src: /192.168.1.151:39193 dest: /192.168.1.151:50010
2017-05-18 15:02:03,320 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-938452157557465995_1039 src: /192.168.1.151:39193 dest: /192.168.1.151:50010 of size 91176
2017-05-18 15:02:08,967 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.150
2017-05-18 15:02:09,740 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 15:02:18,270 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.151
2017-05-18 15:02:29,125 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.150
2017-05-18 15:02:29,627 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 15:02:36,678 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7972400381619806669_1001 to /192.168.1.153
2017-05-18 15:03:00,266 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7025587471326082516_1047 src: /192.168.1.150:41186 dest: /192.168.1.150:50010
2017-05-18 15:03:00,273 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7025587471326082516_1047 src: /192.168.1.150:41186 dest: /192.168.1.150:50010 of size 40564
2017-05-18 15:03:03,243 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-938452157557465995_1039 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-938452157557465995
2017-05-18 15:03:12,275 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1228255667399231331_1049 src: /192.168.1.151:39237 dest: /192.168.1.151:50010
2017-05-18 15:03:12,276 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1228255667399231331_1049 src: /192.168.1.151:39237 dest: /192.168.1.151:50010 of size 3877
2017-05-18 15:03:15,271 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3470014336829731338_1050 src: /192.168.1.150:41195 dest: /192.168.1.150:50010
2017-05-18 15:03:15,272 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3470014336829731338_1050 src: /192.168.1.150:41195 dest: /192.168.1.150:50010 of size 13553
2017-05-18 15:03:18,239 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_3470014336829731338_1050 to 192.168.1.151:50010
2017-05-18 15:03:18,242 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_3470014336829731338_1050 to /192.168.1.151:50010
2017-05-18 15:03:18,273 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6228421409283703476_1048 src: /192.168.1.150:41198 dest: /192.168.1.150:50010
2017-05-18 15:03:18,280 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6228421409283703476_1048 src: /192.168.1.150:41198 dest: /192.168.1.150:50010 of size 91176
2017-05-18 15:03:21,279 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7700518832645604883_1052 src: /192.168.1.150:41202 dest: /192.168.1.150:50010
2017-05-18 15:03:21,280 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7700518832645604883_1052 src: /192.168.1.150:41202 dest: /192.168.1.150:50010 of size 13539
2017-05-18 15:03:21,282 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7700518832645604883_1052 src: /192.168.1.150:41203 dest: /192.168.1.150:50010
2017-05-18 15:03:21,282 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7700518832645604883_1052 received exception java.io.IOException: Block blk_7700518832645604883_1052 is valid, and cannot be written to.
2017-05-18 15:03:21,282 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7700518832645604883_1052 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:03:24,241 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7700518832645604883_1052 to 192.168.1.151:50010, 192.168.1.152:50010
2017-05-18 15:03:24,244 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_7700518832645604883_1052 to /192.168.1.151:50010
2017-05-18 15:03:26,722 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 15:03:40,372 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 15:03:53,913 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 15:04:00,283 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 15:04:07,171 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7972400381619806669_1001 to /192.168.1.153
2017-05-18 15:04:30,307 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2743557119629954133_1056 src: /192.168.1.152:54057 dest: /192.168.1.152:50010
2017-05-18 15:04:30,307 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_2743557119629954133_1056 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:04:30,309 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:04:33,302 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2743557119629954133_1056 src: /192.168.1.150:41249 dest: /192.168.1.150:50010
2017-05-18 15:04:33,302 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_2743557119629954133_1056 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:04:33,302 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:04:36,267 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1228255667399231331_1049 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1228255667399231331
2017-05-18 15:04:36,268 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3470014336829731338_1050 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3470014336829731338
2017-05-18 15:04:36,269 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6228421409283703476_1048 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6228421409283703476
2017-05-18 15:04:36,269 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7700518832645604883_1052 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7700518832645604883
2017-05-18 15:32:12,862 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 4 msecs
2017-05-18 15:38:07,144 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 15:38:19,936 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 15:38:20,133 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 15:38:20,134 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 15:38:20,136 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 15:38:20,199 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 15:38:20,255 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 15:38:20,256 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 15:38:20,256 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 15:38:20,489 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-18 15:38:20,522 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 15:38:20,525 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 15:38:20,525 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-18 15:38:20,530 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 15:38:20,550 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 15:38:20,555 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 15:38:20,557 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 15:38:20,557 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 15:38:20,557 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 15:38:20,557 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 15:38:20,557 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 15:38:20,560 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 15:38:20,560 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 15:38:20,567 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 15:38:20,596 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-7025587471326082516_1047
2017-05-18 15:38:23,566 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 5 msecs
2017-05-18 15:38:56,581 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7025587471326082516_1047 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7025587471326082516
2017-05-18 15:39:32,540 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7465640310375632398_1059 src: /192.168.1.152:54072 dest: /192.168.1.152:50010
2017-05-18 15:39:32,549 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7465640310375632398_1059 src: /192.168.1.152:54072 dest: /192.168.1.152:50010 of size 13553
2017-05-18 15:39:35,536 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-199584613234972779_1058 src: /192.168.1.152:54074 dest: /192.168.1.152:50010
2017-05-18 15:39:35,537 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-199584613234972779_1058 src: /192.168.1.152:54074 dest: /192.168.1.152:50010 of size 3877
2017-05-18 15:39:35,606 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_718785043456012104_1061 src: /192.168.1.150:41266 dest: /192.168.1.150:50010
2017-05-18 15:39:35,607 INFO org.apache.hadoop.dfs.DataNode: Received block blk_718785043456012104_1061 src: /192.168.1.150:41266 dest: /192.168.1.150:50010 of size 13539
2017-05-18 15:39:41,609 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3075264526501050881_1057 src: /192.168.1.150:41277 dest: /192.168.1.150:50010
2017-05-18 15:39:41,612 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3075264526501050881_1057 src: /192.168.1.150:41277 dest: /192.168.1.150:50010 of size 91176
2017-05-18 15:39:43,172 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.153
2017-05-18 15:39:49,948 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.153
2017-05-18 15:39:51,043 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.151
2017-05-18 15:40:20,611 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-693123921925023466_1062 src: /192.168.1.151:39330 dest: /192.168.1.151:50010
2017-05-18 15:40:20,638 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4496162552424984881_1063 src: /192.168.1.150:41304 dest: /192.168.1.150:50010
2017-05-18 15:40:21,319 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-693123921925023466_1062 src: /192.168.1.151:39330 dest: /192.168.1.151:50010 of size 31964396
2017-05-18 15:40:21,472 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4496162552424984881_1063 src: /192.168.1.150:41304 dest: /192.168.1.150:50010 of size 31976695
2017-05-18 15:40:26,609 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7465640310375632398_1059 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7465640310375632398
2017-05-18 15:40:26,622 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4496162552424984881_1063 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4496162552424984881
2017-05-18 15:40:26,631 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-693123921925023466_1062 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-693123921925023466
2017-05-18 15:40:26,631 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-199584613234972779_1058 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-199584613234972779
2017-05-18 15:40:26,631 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_718785043456012104_1061 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_718785043456012104
2017-05-18 15:40:26,632 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3075264526501050881_1057 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3075264526501050881
2017-05-18 15:40:38,637 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6839758842529320551_1066 src: /192.168.1.150:41313 dest: /192.168.1.150:50010
2017-05-18 15:40:38,643 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Exception writing block blk_-6839758842529320551_1066 to mirror 192.168.1.151:50010
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:94)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:450)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receivePacket(DataNode.java:2601)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2698)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:40:38,643 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6839758842529320551_1066 src: /192.168.1.150:41313 dest: /192.168.1.150:50010 of size 91176
2017-05-18 15:40:41,614 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6839758842529320551_1066 to 192.168.1.152:50010, 192.168.1.151:50010
2017-05-18 15:40:41,621 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-6839758842529320551_1066 to /192.168.1.152:50010
2017-05-18 15:40:44,560 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5246982627784026550_1070 src: /192.168.1.152:54126 dest: /192.168.1.152:50010
2017-05-18 15:40:44,563 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5246982627784026550_1070 src: /192.168.1.152:54126 dest: /192.168.1.152:50010 of size 13539
2017-05-18 15:40:44,564 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.153
2017-05-18 15:40:44,614 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6839758842529320551_1066 to 192.168.1.151:50010
2017-05-18 15:40:44,617 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-6839758842529320551_1066 to /192.168.1.151:50010
2017-05-18 15:40:44,634 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4020677769119710787_1068 src: /192.168.1.150:41325 dest: /192.168.1.150:50010
2017-05-18 15:40:44,636 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4020677769119710787_1068 src: /192.168.1.150:41325 dest: /192.168.1.150:50010 of size 13553
2017-05-18 15:40:47,615 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6839758842529320551_1066 to 192.168.1.151:50010
2017-05-18 15:40:47,618 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-6839758842529320551_1066 to /192.168.1.151:50010
2017-05-18 15:40:47,634 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1252962454282743448_1067 src: /192.168.1.150:41329 dest: /192.168.1.150:50010
2017-05-18 15:40:47,634 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1252962454282743448_1067 src: /192.168.1.150:41329 dest: /192.168.1.150:50010 of size 3877
2017-05-18 15:40:51,703 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 15:40:56,618 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6839758842529320551_1066 to 192.168.1.151:50010
2017-05-18 15:40:56,621 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-6839758842529320551_1066 to /192.168.1.151:50010
2017-05-18 15:40:58,500 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 15:41:05,043 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 15:41:05,578 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7972400381619806669_1001 to /192.168.1.153
2017-05-18 15:41:32,663 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1012702170174854200_1074 src: /192.168.1.151:39374 dest: /192.168.1.151:50010
2017-05-18 15:41:32,664 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-1012702170174854200_1074 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:41:32,664 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:41:35,634 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6839758842529320551_1066 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6839758842529320551
2017-05-18 15:41:35,635 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5246982627784026550_1070 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5246982627784026550
2017-05-18 15:41:35,635 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4020677769119710787_1068 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4020677769119710787
2017-05-18 15:41:35,636 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1252962454282743448_1067 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1252962454282743448
2017-05-18 15:41:47,664 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4336763646240258391_1076 src: /192.168.1.151:39384 dest: /192.168.1.151:50010
2017-05-18 15:41:47,665 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-4336763646240258391_1076 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:41:47,666 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:41:50,645 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4336763646240258391_1076 src: /192.168.1.151:39387 dest: /192.168.1.151:50010
2017-05-18 15:41:50,645 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-4336763646240258391_1076 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:41:50,645 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:41:53,565 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 15:41:53,647 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2734563580320746841_1079 src: /192.168.1.151:39392 dest: /192.168.1.151:50010
2017-05-18 15:41:53,647 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2734563580320746841_1079 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:41:53,647 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:41:53,665 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3576685170498252394_1077 src: /192.168.1.150:41377 dest: /192.168.1.150:50010
2017-05-18 15:41:53,665 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3576685170498252394_1077 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:41:53,665 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:41:59,649 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7298309332320117966_1075 src: /192.168.1.151:39399 dest: /192.168.1.151:50010
2017-05-18 15:41:59,650 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7298309332320117966_1075 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:41:59,650 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:41:59,668 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3576685170498252394_1077 src: /192.168.1.151:39400 dest: /192.168.1.151:50010
2017-05-18 15:41:59,669 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3576685170498252394_1077 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:41:59,669 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:42:00,987 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 15:42:02,669 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7298309332320117966_1075 src: /192.168.1.150:41395 dest: /192.168.1.150:50010
2017-05-18 15:42:02,669 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7298309332320117966_1075 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:42:02,669 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:42:05,651 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7298309332320117966_1075 src: /192.168.1.151:39409 dest: /192.168.1.151:50010
2017-05-18 15:42:05,651 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7298309332320117966_1075 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:42:05,651 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:42:07,830 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 15:42:08,671 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7298309332320117966_1075 src: /192.168.1.152:54204 dest: /192.168.1.152:50010
2017-05-18 15:42:08,672 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7298309332320117966_1075 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:42:08,672 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:42:11,660 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7298309332320117966_1075 src: /192.168.1.151:39416 dest: /192.168.1.151:50010
2017-05-18 15:42:11,660 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7298309332320117966_1075 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:42:11,660 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:42:14,669 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7298309332320117966_1075 src: /192.168.1.150:41409 dest: /192.168.1.150:50010
2017-05-18 15:42:14,670 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7298309332320117966_1075 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:42:14,670 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:42:14,923 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7972400381619806669_1001 to /192.168.1.153
2017-05-18 15:42:17,677 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7298309332320117966_1075 src: /192.168.1.150:41410 dest: /192.168.1.150:50010
2017-05-18 15:42:17,679 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7298309332320117966_1075 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:42:17,679 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:42:20,610 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7298309332320117966_1075 src: /192.168.1.152:54209 dest: /192.168.1.152:50010
2017-05-18 15:42:20,611 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7298309332320117966_1075 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:42:20,611 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:42:23,601 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7298309332320117966_1075 src: /192.168.1.152:54210 dest: /192.168.1.152:50010
2017-05-18 15:42:23,601 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7298309332320117966_1075 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:42:23,601 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:42:26,677 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7298309332320117966_1075 src: /192.168.1.150:41414 dest: /192.168.1.150:50010
2017-05-18 15:42:26,677 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7298309332320117966_1075 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:42:26,677 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:42:29,603 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7298309332320117966_1075 src: /192.168.1.152:54212 dest: /192.168.1.152:50010
2017-05-18 15:42:29,603 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7298309332320117966_1075 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:42:29,604 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:42:32,604 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7298309332320117966_1075 src: /192.168.1.152:54213 dest: /192.168.1.152:50010
2017-05-18 15:42:32,604 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7298309332320117966_1075 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:42:32,605 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:42:35,680 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3521825971738863232_1083 src: /192.168.1.150:41416 dest: /192.168.1.150:50010
2017-05-18 15:42:35,680 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3521825971738863232_1083 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:42:35,681 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:42:47,623 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 15:43:00,448 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 15:43:00,643 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 15:43:00,645 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 15:43:00,646 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 15:43:00,716 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 15:43:00,773 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 15:43:00,774 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 15:43:00,774 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 15:43:01,012 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@14a8af0
2017-05-18 15:43:01,048 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 15:43:01,052 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 15:43:01,052 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-18 15:43:01,056 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 15:43:01,076 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 15:43:01,081 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 15:43:01,082 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 15:43:01,083 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 15:43:01,083 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 15:43:01,083 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 15:43:01,083 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 15:43:01,086 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 15:43:01,086 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 15:43:01,094 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 15:43:04,092 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-05-18 15:44:10,162 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7151427198012713328_1084 src: /192.168.1.150:41419 dest: /192.168.1.150:50010
2017-05-18 15:44:10,177 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7151427198012713328_1084 src: /192.168.1.150:41419 dest: /192.168.1.150:50010 of size 91176
2017-05-18 15:44:10,312 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-7151427198012713328_1084 to /192.168.1.153
2017-05-18 15:44:10,368 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-7151427198012713328_1084 to /192.168.1.151
2017-05-18 15:44:11,238 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.152
2017-05-18 15:44:13,135 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7151427198012713328_1084 to 192.168.1.151:50010
2017-05-18 15:44:13,142 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5153076695202833543_1086 src: /192.168.1.150:41430 dest: /192.168.1.150:50010
2017-05-18 15:44:13,143 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5153076695202833543_1086 src: /192.168.1.150:41430 dest: /192.168.1.150:50010 of size 13553
2017-05-18 15:44:13,152 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-7151427198012713328_1084 to /192.168.1.151:50010
2017-05-18 15:44:16,128 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4334603794073590694_1088 src: /192.168.1.150:41434 dest: /192.168.1.150:50010
2017-05-18 15:44:16,132 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4334603794073590694_1088 src: /192.168.1.150:41434 dest: /192.168.1.150:50010 of size 13539
2017-05-18 15:44:20,176 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 15:44:22,076 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4799527281057132008_1085 src: /192.168.1.152:54234 dest: /192.168.1.152:50010
2017-05-18 15:44:22,082 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4799527281057132008_1085 src: /192.168.1.152:54234 dest: /192.168.1.152:50010 of size 1941
2017-05-18 15:44:23,090 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.150
2017-05-18 15:44:24,994 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.150
2017-05-18 15:44:32,848 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 15:44:34,909 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7972400381619806669_1001 to /192.168.1.153
2017-05-18 15:45:01,156 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7151427198012713328_1084 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7151427198012713328
2017-05-18 15:45:01,156 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5153076695202833543_1086 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5153076695202833543
2017-05-18 15:45:01,157 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4334603794073590694_1088 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4334603794073590694
2017-05-18 15:45:01,157 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4799527281057132008_1085 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4799527281057132008
2017-05-18 15:45:13,162 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2240217478706936402_1095 src: /192.168.1.151:39473 dest: /192.168.1.151:50010
2017-05-18 15:45:13,163 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2240217478706936402_1095 src: /192.168.1.151:39473 dest: /192.168.1.151:50010 of size 13553
2017-05-18 15:45:18,650 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.153
2017-05-18 15:45:19,091 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3392539947736357052_1097 src: /192.168.1.152:54264 dest: /192.168.1.152:50010
2017-05-18 15:45:19,092 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3392539947736357052_1097 src: /192.168.1.152:54264 dest: /192.168.1.152:50010 of size 13539
2017-05-18 15:45:20,820 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 15:45:21,994 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 15:45:22,171 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7277465660880584833_1093 src: /192.168.1.150:41475 dest: /192.168.1.150:50010
2017-05-18 15:45:22,172 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7277465660880584833_1093 src: /192.168.1.150:41475 dest: /192.168.1.150:50010 of size 91176
2017-05-18 15:45:22,183 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6558143429349400267_1094 src: /192.168.1.151:39479 dest: /192.168.1.151:50010
2017-05-18 15:45:22,184 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6558143429349400267_1094 src: /192.168.1.151:39479 dest: /192.168.1.151:50010 of size 1941
2017-05-18 15:45:33,152 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 15:45:49,180 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8509268050272654893_1099 src: /192.168.1.150:41496 dest: /192.168.1.150:50010
2017-05-18 15:45:49,550 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Exception writing block blk_8509268050272654893_1099 to mirror 192.168.1.151:50010
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:94)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:450)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receivePacket(DataNode.java:2601)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2698)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:45:49,836 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8509268050272654893_1099 src: /192.168.1.150:41496 dest: /192.168.1.150:50010 of size 31976695
2017-05-18 15:45:55,165 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8509268050272654893_1099 to 192.168.1.151:50010
2017-05-18 15:45:55,171 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Failed to transfer blk_8509268050272654893_1099 to 192.168.1.151:50010 got java.net.SocketException: Original Exception : java.io.IOException: Broken pipe
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:420)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:552)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:199)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1873)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataNode$DataTransfer.run(DataNode.java:2855)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Broken pipe
	... 8 more

2017-05-18 15:45:55,177 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8169931253851145500_1099 src: /192.168.1.150:41499 dest: /192.168.1.150:50010
2017-05-18 15:45:55,690 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8169931253851145500_1099 src: /192.168.1.150:41499 dest: /192.168.1.150:50010 of size 31981189
2017-05-18 15:45:58,201 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4835165428179417838_1101 src: /192.168.1.152:54284 dest: /192.168.1.152:50010
2017-05-18 15:45:58,890 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4835165428179417838_1101 src: /192.168.1.152:54284 dest: /192.168.1.152:50010 of size 31964396
2017-05-18 15:46:01,186 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4835165428179417838_1101 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4835165428179417838
2017-05-18 15:46:01,187 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2240217478706936402_1095 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2240217478706936402
2017-05-18 15:46:01,188 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3392539947736357052_1097 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3392539947736357052
2017-05-18 15:46:01,188 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6558143429349400267_1094 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6558143429349400267
2017-05-18 15:46:01,188 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7277465660880584833_1093 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7277465660880584833
2017-05-18 15:46:01,195 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8169931253851145500_1099 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8169931253851145500
2017-05-18 15:46:01,196 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-876333837407057924_1101 src: /192.168.1.150:41501 dest: /192.168.1.150:50010
2017-05-18 15:46:01,200 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8509268050272654893_1099 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8509268050272654893
2017-05-18 15:46:01,724 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-876333837407057924_1101 src: /192.168.1.150:41501 dest: /192.168.1.150:50010 of size 31980463
2017-05-18 15:46:11,253 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.151
2017-05-18 15:46:13,182 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_258987537236263100_1104 src: /192.168.1.151:39509 dest: /192.168.1.151:50010
2017-05-18 15:46:13,185 INFO org.apache.hadoop.dfs.DataNode: Received block blk_258987537236263100_1104 src: /192.168.1.151:39509 dest: /192.168.1.151:50010 of size 13553
2017-05-18 15:46:16,182 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2157925839630548663_1102 src: /192.168.1.150:41513 dest: /192.168.1.150:50010
2017-05-18 15:46:16,187 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2157925839630548663_1102 src: /192.168.1.150:41513 dest: /192.168.1.150:50010 of size 91176
2017-05-18 15:46:19,172 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_2157925839630548663_1102 to 192.168.1.152:50010
2017-05-18 15:46:19,175 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_2157925839630548663_1102 to /192.168.1.152:50010
2017-05-18 15:46:19,183 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2197712325611039627_1103 src: /192.168.1.150:41517 dest: /192.168.1.150:50010
2017-05-18 15:46:19,185 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2197712325611039627_1103 src: /192.168.1.150:41517 dest: /192.168.1.150:50010 of size 1941
2017-05-18 15:46:20,219 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 15:46:24,652 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 15:46:25,183 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6105771312846792895_1106 src: /192.168.1.150:41522 dest: /192.168.1.150:50010
2017-05-18 15:46:25,187 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6105771312846792895_1106 src: /192.168.1.150:41522 dest: /192.168.1.150:50010 of size 13539
2017-05-18 15:46:25,614 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.150
2017-05-18 15:46:32,763 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 15:46:38,986 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 15:47:19,264 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_2197712325611039627_1103
2017-05-18 15:47:49,215 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3316647471571855296_1111 src: /192.168.1.150:41567 dest: /192.168.1.150:50010
2017-05-18 15:47:49,216 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3316647471571855296_1111 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 15:47:49,217 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 15:47:52,214 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_258987537236263100_1104 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_258987537236263100
2017-05-18 15:47:52,215 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2157925839630548663_1102 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2157925839630548663
2017-05-18 15:47:52,215 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2197712325611039627_1103 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2197712325611039627
2017-05-18 15:47:52,215 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6105771312846792895_1106 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6105771312846792895
2017-05-18 15:51:42,747 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 15:51:57,987 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 15:51:58,181 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 15:51:58,182 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 15:51:58,184 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 15:51:58,246 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 15:51:58,303 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 15:51:58,303 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 15:51:58,303 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 15:51:58,543 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-05-18 15:51:58,580 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 15:51:58,583 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 15:51:58,583 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-18 15:51:58,588 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 15:51:58,605 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 15:51:58,611 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 15:51:58,611 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 15:51:58,614 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 15:51:58,615 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 15:51:58,616 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 15:51:58,616 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 15:51:58,617 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 15:51:58,618 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 15:51:58,626 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 15:52:01,624 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 6 msecs
2017-05-18 15:52:27,388 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-876333837407057924_1101
2017-05-18 15:52:34,649 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-876333837407057924_1101 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-876333837407057924
2017-05-18 15:58:22,804 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6641154721016382116_1114 src: /192.168.1.150:41571 dest: /192.168.1.150:50010
2017-05-18 15:58:22,821 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6641154721016382116_1114 src: /192.168.1.150:41571 dest: /192.168.1.150:50010 of size 13553
2017-05-18 15:58:23,139 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-6641154721016382116_1114 to /192.168.1.153
2017-05-18 15:58:25,791 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3095444249210362926_1116 src: /192.168.1.150:41581 dest: /192.168.1.150:50010
2017-05-18 15:58:25,796 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3095444249210362926_1116 src: /192.168.1.150:41581 dest: /192.168.1.150:50010 of size 13539
2017-05-18 15:58:28,797 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2178884263434335622_1112 src: /192.168.1.151:39558 dest: /192.168.1.151:50010
2017-05-18 15:58:28,802 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2178884263434335622_1112 src: /192.168.1.151:39558 dest: /192.168.1.151:50010 of size 91176
2017-05-18 15:58:32,561 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.153
2017-05-18 15:58:35,036 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7441681135029123448_1113 src: /192.168.1.151:39564 dest: /192.168.1.151:50010
2017-05-18 15:58:35,038 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7441681135029123448_1113 src: /192.168.1.151:39564 dest: /192.168.1.151:50010 of size 1941
2017-05-18 15:58:35,898 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 15:58:36,139 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.151
2017-05-18 15:58:47,420 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7972400381619806669_1001 to /192.168.1.153
2017-05-18 15:59:10,813 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8786316209733211313_1120 src: /192.168.1.151:39584 dest: /192.168.1.151:50010
2017-05-18 15:59:10,815 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8786316209733211313_1120 src: /192.168.1.151:39584 dest: /192.168.1.151:50010 of size 23045
2017-05-18 15:59:16,775 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6641154721016382116_1114 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6641154721016382116
2017-05-18 15:59:16,775 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3095444249210362926_1116 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3095444249210362926
2017-05-18 15:59:16,776 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2178884263434335622_1112 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2178884263434335622
2017-05-18 15:59:16,776 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7441681135029123448_1113 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7441681135029123448
2017-05-18 15:59:16,777 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8786316209733211313_1120 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8786316209733211313
2017-05-18 16:26:05,359 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 4 msecs
2017-05-18 17:26:06,626 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 17:53:48,158 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 17:54:01,012 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 17:54:01,206 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 17:54:01,208 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 17:54:01,209 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 17:54:01,281 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 17:54:01,342 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 17:54:01,344 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 17:54:01,344 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 17:54:01,585 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-18 17:54:01,622 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 17:54:01,625 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 17:54:01,625 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-18 17:54:01,631 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 17:54:01,648 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 17:54:01,653 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 17:54:01,653 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 17:54:01,655 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 17:54:01,655 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 17:54:01,656 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 17:54:01,656 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 17:54:01,659 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 17:54:01,659 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 17:54:01,666 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 17:54:04,665 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-05-18 17:55:13,680 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5803372923066975718_1125 src: /192.168.1.152:54382 dest: /192.168.1.152:50010
2017-05-18 17:55:13,692 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5803372923066975718_1125 src: /192.168.1.152:54382 dest: /192.168.1.152:50010 of size 13537
2017-05-18 17:55:16,637 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-598487690871618142_1121 src: /192.168.1.150:41627 dest: /192.168.1.150:50010
2017-05-18 17:55:16,645 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-598487690871618142_1121 src: /192.168.1.150:41627 dest: /192.168.1.150:50010 of size 91176
2017-05-18 17:55:16,682 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4214164250803656764_1123 src: /192.168.1.152:54389 dest: /192.168.1.152:50010
2017-05-18 17:55:16,684 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4214164250803656764_1123 src: /192.168.1.152:54389 dest: /192.168.1.152:50010 of size 13551
2017-05-18 17:55:19,641 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9032482616656806133_1122 src: /192.168.1.150:41643 dest: /192.168.1.150:50010
2017-05-18 17:55:19,642 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9032482616656806133_1122 src: /192.168.1.150:41643 dest: /192.168.1.150:50010 of size 7749
2017-05-18 17:55:19,654 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 17:55:19,692 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-598487690871618142_1121 to 192.168.1.151:50010
2017-05-18 17:55:19,696 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-598487690871618142_1121 to /192.168.1.151:50010
2017-05-18 17:55:27,647 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 17:55:29,802 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 17:55:35,123 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.153
2017-05-18 17:55:38,408 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 17:57:22,734 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5803372923066975718_1125 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5803372923066975718
2017-05-18 17:57:22,735 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4214164250803656764_1123 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4214164250803656764
2017-05-18 17:57:22,735 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-598487690871618142_1121 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-598487690871618142
2017-05-18 17:57:22,735 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9032482616656806133_1122 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9032482616656806133
2017-05-18 17:57:31,681 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2948440987300018864_1134 src: /192.168.1.150:41690 dest: /192.168.1.150:50010
2017-05-18 17:57:31,682 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2948440987300018864_1134 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 17:57:31,683 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 17:57:39,754 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.151
2017-05-18 17:57:39,858 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.153
2017-05-18 17:57:39,949 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 17:57:43,683 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2948440987300018864_1134 src: /192.168.1.150:41715 dest: /192.168.1.150:50010
2017-05-18 17:57:43,683 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2948440987300018864_1134 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 17:57:43,683 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 17:57:52,685 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2218523541098848552_1131 src: /192.168.1.150:41738 dest: /192.168.1.150:50010
2017-05-18 17:57:52,694 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2218523541098848552_1131 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 17:57:52,694 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 17:57:55,687 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2948440987300018864_1134 src: /192.168.1.150:41743 dest: /192.168.1.150:50010
2017-05-18 17:57:55,687 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2948440987300018864_1134 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 17:57:55,688 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 17:57:56,851 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 17:58:04,689 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2218523541098848552_1131 src: /192.168.1.150:41769 dest: /192.168.1.150:50010
2017-05-18 17:58:04,690 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2218523541098848552_1131 src: /192.168.1.150:41769 dest: /192.168.1.150:50010 of size 7749
2017-05-18 17:58:04,691 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2948440987300018864_1134 src: /192.168.1.150:41770 dest: /192.168.1.150:50010
2017-05-18 17:58:04,692 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2948440987300018864_1134 src: /192.168.1.150:41770 dest: /192.168.1.150:50010 of size 13537
2017-05-18 17:58:07,749 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2948440987300018864_1134 to 192.168.1.152:50010, 192.168.1.151:50010
2017-05-18 17:58:07,754 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-2948440987300018864_1134 to /192.168.1.152:50010
2017-05-18 17:58:10,695 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5336672463115659839_1132 src: /192.168.1.150:41774 dest: /192.168.1.150:50010
2017-05-18 17:58:10,697 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5336672463115659839_1132 src: /192.168.1.150:41774 dest: /192.168.1.150:50010 of size 13551
2017-05-18 17:58:10,750 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2218523541098848552_1131 to 192.168.1.151:50010
2017-05-18 17:58:10,751 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2218523541098848552_1131 to 192.168.1.151:50010
2017-05-18 17:58:10,753 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-2218523541098848552_1131 to /192.168.1.151:50010
2017-05-18 17:58:10,755 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-2218523541098848552_1131 to /192.168.1.151:50010
2017-05-18 17:58:10,859 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4668584768627663331_1130 src: /192.168.1.151:39717 dest: /192.168.1.151:50010
2017-05-18 17:58:10,861 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4668584768627663331_1130 src: /192.168.1.151:39717 dest: /192.168.1.151:50010 of size 91176
2017-05-18 17:59:34,721 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4867858545692227723_1137 src: /192.168.1.150:41794 dest: /192.168.1.150:50010
2017-05-18 17:59:34,725 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4867858545692227723_1137 src: /192.168.1.150:41794 dest: /192.168.1.150:50010 of size 75732
2017-05-18 17:59:37,779 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2948440987300018864_1134 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2948440987300018864
2017-05-18 17:59:37,780 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2218523541098848552_1131 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2218523541098848552
2017-05-18 17:59:37,780 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4668584768627663331_1130 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4668584768627663331
2017-05-18 17:59:37,780 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5336672463115659839_1132 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5336672463115659839
2017-05-18 17:59:49,723 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5049553277814170285_1141 src: /192.168.1.150:41805 dest: /192.168.1.150:50010
2017-05-18 17:59:49,730 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5049553277814170285_1141 src: /192.168.1.150:41805 dest: /192.168.1.150:50010 of size 7749
2017-05-18 17:59:49,774 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5472361928141406808_1144 src: /192.168.1.152:54512 dest: /192.168.1.152:50010
2017-05-18 17:59:49,776 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5472361928141406808_1144 src: /192.168.1.152:54512 dest: /192.168.1.152:50010 of size 13537
2017-05-18 17:59:52,732 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2746660554480921589_1140 src: /192.168.1.152:54519 dest: /192.168.1.152:50010
2017-05-18 17:59:52,735 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2746660554480921589_1140 src: /192.168.1.152:54519 dest: /192.168.1.152:50010 of size 91176
2017-05-18 17:59:52,785 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-5049553277814170285_1141 to 192.168.1.151:50010
2017-05-18 17:59:52,791 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-5049553277814170285_1141 to /192.168.1.151:50010
2017-05-18 17:59:54,285 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.153
2017-05-18 17:59:55,725 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8964690177507095411_1142 src: /192.168.1.150:41818 dest: /192.168.1.150:50010
2017-05-18 17:59:55,726 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8964690177507095411_1142 src: /192.168.1.150:41818 dest: /192.168.1.150:50010 of size 13551
2017-05-18 17:59:57,779 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 18:00:04,620 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 18:00:13,004 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 18:00:15,466 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 18:01:55,826 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5472361928141406808_1144 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5472361928141406808
2017-05-18 18:01:55,827 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5049553277814170285_1141 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5049553277814170285
2017-05-18 18:01:55,827 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2746660554480921589_1140 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2746660554480921589
2017-05-18 18:01:55,827 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8964690177507095411_1142 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8964690177507095411
2017-05-18 18:02:03,355 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 18:02:16,193 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 18:02:16,379 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 18:02:16,380 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 18:02:16,382 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 18:02:16,452 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 18:02:16,507 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 18:02:16,508 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 18:02:16,508 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 18:02:16,734 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-18 18:02:16,765 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 18:02:16,768 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 18:02:16,768 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-18 18:02:16,772 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 18:02:16,789 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 18:02:16,794 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 18:02:16,794 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 18:02:16,796 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 18:02:16,796 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 18:02:16,797 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 18:02:16,797 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 18:02:16,799 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 18:02:16,800 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 18:02:16,806 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 18:02:16,835 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-4867858545692227723_1137
2017-05-18 18:02:19,807 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 4 msecs
2017-05-18 18:02:52,817 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4867858545692227723_1137 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4867858545692227723
2017-05-18 18:03:25,828 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6442959016315312431_1150 src: /192.168.1.150:41886 dest: /192.168.1.150:50010
2017-05-18 18:03:25,850 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6442959016315312431_1150 src: /192.168.1.150:41886 dest: /192.168.1.150:50010 of size 91176
2017-05-18 18:03:26,117 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-6442959016315312431_1150 to /192.168.1.153
2017-05-18 18:03:26,118 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-6442959016315312431_1150 to /192.168.1.152
2017-05-18 18:03:27,133 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.151
2017-05-18 18:03:28,809 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3419984240020398654_1151 src: /192.168.1.150:41897 dest: /192.168.1.150:50010
2017-05-18 18:03:28,810 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3419984240020398654_1151 src: /192.168.1.150:41897 dest: /192.168.1.150:50010 of size 3877
2017-05-18 18:03:28,827 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6442959016315312431_1150 to 192.168.1.152:50010
2017-05-18 18:03:28,839 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-6442959016315312431_1150 to /192.168.1.152:50010
2017-05-18 18:03:32,251 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 18:03:34,818 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-506558790355756364_1154 src: /192.168.1.152:54587 dest: /192.168.1.152:50010
2017-05-18 18:03:34,819 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-506558790355756364_1154 src: /192.168.1.152:54587 dest: /192.168.1.152:50010 of size 13539
2017-05-18 18:03:36,036 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.150
2017-05-18 18:03:37,814 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5750160748241923053_1152 src: /192.168.1.152:54592 dest: /192.168.1.152:50010
2017-05-18 18:03:37,815 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5750160748241923053_1152 src: /192.168.1.152:54592 dest: /192.168.1.152:50010 of size 13553
2017-05-18 18:03:39,993 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 18:03:47,721 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 18:04:04,841 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4395523770586544786_1155 src: /192.168.1.151:39827 dest: /192.168.1.151:50010
2017-05-18 18:04:05,550 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4395523770586544786_1155 src: /192.168.1.151:39827 dest: /192.168.1.151:50010 of size 31981189
2017-05-18 18:04:07,843 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-4395523770586544786_1155 to 192.168.1.152:50010
2017-05-18 18:04:08,960 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-4395523770586544786_1155 to /192.168.1.152:50010
2017-05-18 18:04:10,829 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8320923920653440012_1158 src: /192.168.1.150:41936 dest: /192.168.1.150:50010
2017-05-18 18:04:10,835 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8320923920653440012_1158 src: /192.168.1.150:41936 dest: /192.168.1.150:50010 of size 40564
2017-05-18 18:04:13,829 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7308779174796536383_1158 src: /192.168.1.150:41937 dest: /192.168.1.150:50010
2017-05-18 18:04:13,845 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6442959016315312431_1150 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6442959016315312431
2017-05-18 18:04:13,856 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4395523770586544786_1155 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4395523770586544786
2017-05-18 18:04:13,856 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3419984240020398654_1151 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3419984240020398654
2017-05-18 18:04:13,856 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-506558790355756364_1154 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-506558790355756364
2017-05-18 18:04:13,857 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5750160748241923053_1152 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5750160748241923053
2017-05-18 18:04:14,456 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7308779174796536383_1158 src: /192.168.1.150:41937 dest: /192.168.1.150:50010 of size 31976695
2017-05-18 18:04:24,137 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.152
2017-05-18 18:04:25,832 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2675150287637252841_1161 src: /192.168.1.150:41944 dest: /192.168.1.150:50010
2017-05-18 18:04:25,835 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2675150287637252841_1161 src: /192.168.1.150:41944 dest: /192.168.1.150:50010 of size 13553
2017-05-18 18:04:28,852 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2675150287637252841_1161 to 192.168.1.151:50010
2017-05-18 18:04:28,855 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-2675150287637252841_1161 to /192.168.1.151:50010
2017-05-18 18:04:29,120 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 18:04:31,947 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2252538990799225033_1160 src: /192.168.1.151:39844 dest: /192.168.1.151:50010
2017-05-18 18:04:31,948 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2252538990799225033_1160 src: /192.168.1.151:39844 dest: /192.168.1.151:50010 of size 3877
2017-05-18 18:04:34,971 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2345756028825934827_1163 src: /192.168.1.151:39851 dest: /192.168.1.151:50010
2017-05-18 18:04:34,973 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2345756028825934827_1163 src: /192.168.1.151:39851 dest: /192.168.1.151:50010 of size 13539
2017-05-18 18:04:36,268 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.153
2017-05-18 18:04:37,834 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8131926545817873127_1159 src: /192.168.1.150:41973 dest: /192.168.1.150:50010
2017-05-18 18:04:37,838 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8131926545817873127_1159 src: /192.168.1.150:41973 dest: /192.168.1.150:50010 of size 91176
2017-05-18 18:04:38,603 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 18:05:04,848 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7986097883219414539_1164 src: /192.168.1.150:41986 dest: /192.168.1.150:50010
2017-05-18 18:05:05,492 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7986097883219414539_1164 src: /192.168.1.150:41986 dest: /192.168.1.150:50010 of size 31981189
2017-05-18 18:05:07,858 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4633468304238701411_1167 src: /192.168.1.150:41987 dest: /192.168.1.150:50010
2017-05-18 18:05:07,860 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1596651188725088010_1167 src: /192.168.1.150:41988 dest: /192.168.1.150:50010
2017-05-18 18:05:07,862 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1596651188725088010_1167 src: /192.168.1.150:41988 dest: /192.168.1.150:50010 of size 40564
2017-05-18 18:05:08,318 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4633468304238701411_1167 src: /192.168.1.150:41987 dest: /192.168.1.150:50010 of size 31980463
2017-05-18 18:05:10,852 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5885335428020147078_1165 src: /192.168.1.150:41989 dest: /192.168.1.150:50010
2017-05-18 18:05:11,400 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5885335428020147078_1165 src: /192.168.1.150:41989 dest: /192.168.1.150:50010 of size 31964396
2017-05-18 18:05:13,883 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7986097883219414539_1164 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7986097883219414539
2017-05-18 18:05:13,890 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4633468304238701411_1167 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4633468304238701411
2017-05-18 18:05:13,890 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2675150287637252841_1161 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2675150287637252841
2017-05-18 18:05:13,891 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1596651188725088010_1167 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1596651188725088010
2017-05-18 18:05:13,891 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2252538990799225033_1160 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2252538990799225033
2017-05-18 18:05:13,891 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2345756028825934827_1163 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2345756028825934827
2017-05-18 18:05:13,891 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8131926545817873127_1159 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8131926545817873127
2017-05-18 18:05:25,855 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8448152604814391399_1170 src: /192.168.1.152:54659 dest: /192.168.1.152:50010
2017-05-18 18:05:25,857 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8448152604814391399_1170 src: /192.168.1.152:54659 dest: /192.168.1.152:50010 of size 13553
2017-05-18 18:05:27,118 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.151
2017-05-18 18:05:28,853 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4900849140343216499_1169 src: /192.168.1.150:42003 dest: /192.168.1.150:50010
2017-05-18 18:05:28,877 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4900849140343216499_1169 src: /192.168.1.150:42003 dest: /192.168.1.150:50010 of size 3877
2017-05-18 18:05:31,878 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4900849140343216499_1169 to 192.168.1.152:50010
2017-05-18 18:05:31,880 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_4900849140343216499_1169 to /192.168.1.152:50010
2017-05-18 18:05:34,516 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.150
2017-05-18 18:05:35,001 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5596516693396532606_1168 src: /192.168.1.151:39892 dest: /192.168.1.151:50010
2017-05-18 18:05:35,004 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5596516693396532606_1168 src: /192.168.1.151:39892 dest: /192.168.1.151:50010 of size 91176
2017-05-18 18:05:35,667 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 18:05:37,856 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7208354850309112541_1172 src: /192.168.1.152:54673 dest: /192.168.1.152:50010
2017-05-18 18:05:37,857 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7208354850309112541_1172 src: /192.168.1.152:54673 dest: /192.168.1.152:50010 of size 13539
2017-05-18 18:05:39,978 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.151
2017-05-18 18:05:42,306 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 18:05:43,558 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.153
2017-05-18 18:06:31,899 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8448152604814391399_1170 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8448152604814391399
2017-05-18 18:06:31,900 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4900849140343216499_1169 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4900849140343216499
2017-05-18 18:06:31,900 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5596516693396532606_1168 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5596516693396532606
2017-05-18 18:06:31,900 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7208354850309112541_1172 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7208354850309112541
2017-05-18 18:06:39,732 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 18:06:52,589 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 18:06:52,791 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 18:06:52,793 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 18:06:52,794 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 18:06:52,858 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 18:06:52,914 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 18:06:52,915 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 18:06:52,915 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 18:06:53,147 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@e7b92e
2017-05-18 18:06:53,184 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 18:06:53,187 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 18:06:53,187 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-18 18:06:53,191 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 18:06:53,209 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 18:06:53,214 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 18:06:53,214 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 18:06:53,215 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 18:06:53,216 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 18:06:53,216 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 18:06:53,216 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 18:06:53,218 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 18:06:53,219 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 18:06:53,227 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 18:06:53,252 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-8320923920653440012_1158
2017-05-18 18:06:56,233 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 11 blocks got processed in 11 msecs
2017-05-18 18:07:29,243 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8320923920653440012_1158 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8320923920653440012
2017-05-18 18:07:29,255 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7308779174796536383_1158 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7308779174796536383
2017-05-18 18:07:29,262 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5885335428020147078_1165 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5885335428020147078
2017-05-18 18:08:02,290 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8872458896866394223_1178 src: /192.168.1.151:39912 dest: /192.168.1.151:50010
2017-05-18 18:08:02,308 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8872458896866394223_1178 src: /192.168.1.151:39912 dest: /192.168.1.151:50010 of size 1941
2017-05-18 18:08:03,563 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.151
2017-05-18 18:08:03,573 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 18:08:08,262 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3199938568593643359_1181 src: /192.168.1.151:39926 dest: /192.168.1.151:50010
2017-05-18 18:08:08,263 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3199938568593643359_1181 src: /192.168.1.151:39926 dest: /192.168.1.151:50010 of size 13539
2017-05-18 18:08:08,632 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 18:08:08,792 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.150
2017-05-18 18:08:11,267 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2329605104285711376_1177 src: /192.168.1.152:54714 dest: /192.168.1.152:50010
2017-05-18 18:08:11,475 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2329605104285711376_1177 src: /192.168.1.152:54714 dest: /192.168.1.152:50010 of size 91176
2017-05-18 18:08:14,275 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8188810689797550181_1179 src: /192.168.1.152:54716 dest: /192.168.1.152:50010
2017-05-18 18:08:14,276 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8188810689797550181_1179 src: /192.168.1.152:54716 dest: /192.168.1.152:50010 of size 13553
2017-05-18 18:08:54,140 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 18:09:35,286 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8872458896866394223_1178 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8872458896866394223
2017-05-18 18:09:35,287 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3199938568593643359_1181 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3199938568593643359
2017-05-18 18:09:35,287 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2329605104285711376_1177 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2329605104285711376
2017-05-18 18:09:35,287 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8188810689797550181_1179 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8188810689797550181
2017-05-18 18:09:44,285 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8430294582977967279_1188 src: /192.168.1.150:42099 dest: /192.168.1.150:50010
2017-05-18 18:09:44,288 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8430294582977967279_1188 src: /192.168.1.150:42099 dest: /192.168.1.150:50010 of size 1941
2017-05-18 18:09:47,290 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8430294582977967279_1188 to 192.168.1.152:50010, 192.168.1.151:50010
2017-05-18 18:09:47,302 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Failed to transfer blk_-8430294582977967279_1188 to 192.168.1.152:50010 got java.net.SocketException: Original Exception : java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:420)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:552)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:199)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1873)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataNode$DataTransfer.run(DataNode.java:2855)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	... 8 more

2017-05-18 18:09:47,945 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 18:09:48,606 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.150
2017-05-18 18:09:50,285 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7179929275411922804_1189 src: /192.168.1.150:42108 dest: /192.168.1.150:50010
2017-05-18 18:09:50,293 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7179929275411922804_1189 src: /192.168.1.150:42108 dest: /192.168.1.150:50010 of size 13553
2017-05-18 18:09:53,291 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7435544377223987098_1187 src: /192.168.1.150:42109 dest: /192.168.1.150:50010
2017-05-18 18:09:53,305 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7435544377223987098_1187 src: /192.168.1.150:42109 dest: /192.168.1.150:50010 of size 91176
2017-05-18 18:09:53,306 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7179929275411922804_1189 to 192.168.1.151:50010, 192.168.1.152:50010
2017-05-18 18:09:53,308 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_7179929275411922804_1189 to /192.168.1.151:50010
2017-05-18 18:09:55,947 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 18:10:00,496 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 18:10:35,327 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5562708585138033955_1195 src: /192.168.1.152:54767 dest: /192.168.1.152:50010
2017-05-18 18:10:35,329 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5562708585138033955_1195 src: /192.168.1.152:54767 dest: /192.168.1.152:50010 of size 23045
2017-05-18 18:10:38,315 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8430294582977967279_1188 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8430294582977967279
2017-05-18 18:10:38,316 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7179929275411922804_1189 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7179929275411922804
2017-05-18 18:10:38,316 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7435544377223987098_1187 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7435544377223987098
2017-05-18 18:10:47,310 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7894093887315443427_1196 src: /192.168.1.150:42135 dest: /192.168.1.150:50010
2017-05-18 18:10:47,334 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7894093887315443427_1196 src: /192.168.1.150:42135 dest: /192.168.1.150:50010 of size 91176
2017-05-18 18:10:48,563 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-7894093887315443427_1196 to /192.168.1.153
2017-05-18 18:10:50,328 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7894093887315443427_1196 to 192.168.1.152:50010
2017-05-18 18:10:50,332 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_-7894093887315443427_1196 to /192.168.1.152:50010
2017-05-18 18:10:53,327 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3105783340676473103_1200 src: /192.168.1.150:42145 dest: /192.168.1.150:50010
2017-05-18 18:10:53,340 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3105783340676473103_1200 src: /192.168.1.150:42145 dest: /192.168.1.150:50010 of size 13539
2017-05-18 18:10:53,347 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-175398159467032847_1197 src: /192.168.1.151:40005 dest: /192.168.1.151:50010
2017-05-18 18:10:53,347 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-175398159467032847_1197 src: /192.168.1.151:40005 dest: /192.168.1.151:50010 of size 1941
2017-05-18 18:10:58,504 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.153
2017-05-18 18:10:58,651 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 18:10:59,312 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4345898367037981075_1198 src: /192.168.1.150:42150 dest: /192.168.1.150:50010
2017-05-18 18:10:59,320 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4345898367037981075_1198 src: /192.168.1.150:42150 dest: /192.168.1.150:50010 of size 13553
2017-05-18 18:11:01,766 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 18:11:02,108 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.150
2017-05-18 18:11:03,744 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.153
2017-05-18 18:11:29,344 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-85922594328716969_1204 src: /192.168.1.152:54800 dest: /192.168.1.152:50010
2017-05-18 18:11:29,346 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-85922594328716969_1204 src: /192.168.1.152:54800 dest: /192.168.1.152:50010 of size 23045
2017-05-18 18:11:32,343 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7894093887315443427_1196 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7894093887315443427
2017-05-18 18:11:32,343 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-175398159467032847_1197 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-175398159467032847
2017-05-18 18:11:32,344 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3105783340676473103_1200 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3105783340676473103
2017-05-18 18:11:32,344 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4345898367037981075_1198 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4345898367037981075
2017-05-18 18:29:29,432 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 18:29:42,302 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 18:29:42,507 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 18:29:42,509 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 18:29:42,510 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 18:29:42,574 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 18:29:42,631 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 18:29:42,632 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 18:29:42,632 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 18:29:42,886 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-18 18:29:42,921 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 18:29:42,924 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 18:29:42,924 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-18 18:29:42,930 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 18:29:42,947 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 18:29:42,953 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 18:29:42,953 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 18:29:42,955 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 18:29:42,955 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 18:29:42,956 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 18:29:42,956 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 18:29:42,958 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 18:29:42,959 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 18:29:42,968 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 18:29:42,996 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-5562708585138033955_1195
2017-05-18 18:29:45,968 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 10 blocks got processed in 6 msecs
2017-05-18 18:30:18,976 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5562708585138033955_1195 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5562708585138033955
2017-05-18 18:30:18,976 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-85922594328716969_1204 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-85922594328716969
2017-05-18 18:30:54,963 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1972918758748673528_1209 src: /192.168.1.151:40032 dest: /192.168.1.151:50010
2017-05-18 18:30:54,972 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1972918758748673528_1209 src: /192.168.1.151:40032 dest: /192.168.1.151:50010 of size 13539
2017-05-18 18:30:57,940 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7360703815054034980_1206 src: /192.168.1.150:42179 dest: /192.168.1.150:50010
2017-05-18 18:30:57,941 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7360703815054034980_1206 src: /192.168.1.150:42179 dest: /192.168.1.150:50010 of size 3877
2017-05-18 18:30:58,027 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5933470606429384952_1205 src: /192.168.1.151:40036 dest: /192.168.1.151:50010
2017-05-18 18:30:58,028 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5933470606429384952_1205 src: /192.168.1.151:40036 dest: /192.168.1.151:50010 of size 91176
2017-05-18 18:31:00,942 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7529581966843520504_1207 src: /192.168.1.150:42187 dest: /192.168.1.150:50010
2017-05-18 18:31:00,944 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7529581966843520504_1207 src: /192.168.1.150:42187 dest: /192.168.1.150:50010 of size 13553
2017-05-18 18:31:00,945 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7529581966843520504_1207 src: /192.168.1.150:42188 dest: /192.168.1.150:50010
2017-05-18 18:31:00,946 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7529581966843520504_1207 received exception java.io.IOException: Block blk_7529581966843520504_1207 is valid, and cannot be written to.
2017-05-18 18:31:00,947 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7529581966843520504_1207 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 18:31:00,992 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7360703815054034980_1206 to 192.168.1.152:50010
2017-05-18 18:31:00,994 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_7360703815054034980_1206 to /192.168.1.152:50010
2017-05-18 18:31:03,987 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_7529581966843520504_1207 to 192.168.1.151:50010, 192.168.1.152:50010
2017-05-18 18:31:03,990 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_7529581966843520504_1207 to /192.168.1.151:50010
2017-05-18 18:31:06,057 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.151
2017-05-18 18:31:30,961 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8622352832778912923_1210 src: /192.168.1.152:54847 dest: /192.168.1.152:50010
2017-05-18 18:31:31,786 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8622352832778912923_1210 src: /192.168.1.152:54847 dest: /192.168.1.152:50010 of size 31980463
2017-05-18 18:31:33,959 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_405033812612168269_1211 src: /192.168.1.151:40065 dest: /192.168.1.151:50010
2017-05-18 18:31:34,007 INFO org.apache.hadoop.dfs.DataNode: Exception in receiveBlock for block blk_405033812612168269_1211 org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
2017-05-18 18:31:34,008 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_405033812612168269_1211 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
2017-05-18 18:31:34,010 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
	at org.apache.hadoop.dfs.DataNode.checkDiskError(DataNode.java:595)
	at org.apache.hadoop.dfs.DataNode.access$1500(DataNode.java:83)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receivePacket(DataNode.java:2645)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2698)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 18:31:43,012 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1972918758748673528_1209 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1972918758748673528
2017-05-18 18:31:43,012 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5933470606429384952_1205 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5933470606429384952
2017-05-18 18:31:43,012 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7360703815054034980_1206 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7360703815054034980
2017-05-18 18:31:43,013 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7529581966843520504_1207 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7529581966843520504
2017-05-18 18:31:43,022 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8622352832778912923_1210 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8622352832778912923
2017-05-18 18:43:13,667 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 18:43:26,538 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 18:43:26,728 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 18:43:26,729 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 18:43:26,731 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 18:43:26,802 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 18:43:26,858 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 18:43:26,858 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 18:43:26,859 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 18:43:27,090 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-18 18:43:27,127 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 18:43:27,130 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 18:43:27,130 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-18 18:43:27,136 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 18:43:27,153 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 18:43:27,158 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 18:43:27,159 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 18:43:27,160 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 18:43:27,160 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 18:43:27,161 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 18:43:27,161 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 18:43:27,164 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 18:43:27,164 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 18:43:27,171 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 18:43:27,203 WARN org.apache.hadoop.dfs.DataNode:  Could not read or failed to veirfy checksum for data at offset 983040 for block blk_405033812612168269_1211 got : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 18:43:27,203 WARN org.apache.hadoop.dfs.DataBlockScanner: First Verification failed for blk_405033812612168269_1211. Exception : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 18:43:27,208 WARN org.apache.hadoop.dfs.DataNode:  Could not read or failed to veirfy checksum for data at offset 983040 for block blk_405033812612168269_1211 got : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 18:43:27,208 WARN org.apache.hadoop.dfs.DataBlockScanner: Second Verification failed for blk_405033812612168269_1211. Exception : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 18:43:27,208 INFO org.apache.hadoop.dfs.DataBlockScanner: Reporting bad block blk_405033812612168269_1211 to namenode.
2017-05-18 18:43:30,169 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 5 msecs
2017-05-18 18:44:03,186 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_405033812612168269_1211 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_405033812612168269
2017-05-18 18:44:36,117 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8658031400477953753_1215 src: /192.168.1.150:42217 dest: /192.168.1.150:50010
2017-05-18 18:44:36,126 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8658031400477953753_1215 src: /192.168.1.150:42217 dest: /192.168.1.150:50010 of size 1941
2017-05-18 18:44:42,105 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-402754038931479357_1216 src: /192.168.1.151:40078 dest: /192.168.1.151:50010
2017-05-18 18:44:42,106 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-402754038931479357_1216 src: /192.168.1.151:40078 dest: /192.168.1.151:50010 of size 13560
2017-05-18 18:44:42,569 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.151
2017-05-18 18:44:42,601 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.150
2017-05-18 18:44:45,112 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4951034580721288213_1218 src: /192.168.1.150:42237 dest: /192.168.1.150:50010
2017-05-18 18:44:45,113 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4951034580721288213_1218 src: /192.168.1.150:42237 dest: /192.168.1.150:50010 of size 13546
2017-05-18 18:44:46,305 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.153
2017-05-18 18:44:48,143 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.153
2017-05-18 18:44:51,109 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4344177332134915798_1214 src: /192.168.1.151:40093 dest: /192.168.1.151:50010
2017-05-18 18:44:51,116 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4344177332134915798_1214 src: /192.168.1.151:40093 dest: /192.168.1.151:50010 of size 91176
2017-05-18 18:44:51,884 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.153
2017-05-18 18:44:58,886 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7972400381619806669_1001 to /192.168.1.153
2017-05-18 18:45:15,120 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4133039242185302575_1219 src: /192.168.1.150:42252 dest: /192.168.1.150:50010
2017-05-18 18:45:16,007 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4133039242185302575_1219 src: /192.168.1.150:42252 dest: /192.168.1.150:50010 of size 31976695
2017-05-18 18:45:21,212 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8658031400477953753_1215 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8658031400477953753
2017-05-18 18:45:21,213 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4951034580721288213_1218 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4951034580721288213
2017-05-18 18:45:21,225 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4133039242185302575_1219 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4133039242185302575
2017-05-18 18:45:21,226 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-402754038931479357_1216 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-402754038931479357
2017-05-18 18:45:21,227 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4344177332134915798_1214 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4344177332134915798
2017-05-18 18:45:32,216 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.152
2017-05-18 18:45:36,359 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8662613431765159338_1224 src: /192.168.1.151:40113 dest: /192.168.1.151:50010
2017-05-18 18:45:36,359 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8662613431765159338_1224 src: /192.168.1.151:40113 dest: /192.168.1.151:50010 of size 1941
2017-05-18 18:45:37,148 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.150
2017-05-18 18:45:37,568 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.151
2017-05-18 18:45:39,122 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6141822045976836569_1223 src: /192.168.1.150:42273 dest: /192.168.1.150:50010
2017-05-18 18:45:39,125 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6141822045976836569_1223 src: /192.168.1.150:42273 dest: /192.168.1.150:50010 of size 91176
2017-05-18 18:45:39,374 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7305770572360273890_1225 src: /192.168.1.152:54891 dest: /192.168.1.152:50010
2017-05-18 18:45:39,374 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7305770572360273890_1225 src: /192.168.1.152:54891 dest: /192.168.1.152:50010 of size 13560
2017-05-18 18:45:41,999 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 18:45:42,810 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.153
2017-05-18 18:45:45,188 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2858710911696153005_1227 src: /192.168.1.152:54895 dest: /192.168.1.152:50010
2017-05-18 18:45:45,189 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2858710911696153005_1227 src: /192.168.1.152:54895 dest: /192.168.1.152:50010 of size 13546
2017-05-18 18:45:46,688 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.153
2017-05-18 18:46:08,077 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7972400381619806669_1001 to /192.168.1.153
2017-05-18 18:46:57,155 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5041762397192592582_1231 src: /192.168.1.150:42306 dest: /192.168.1.150:50010
2017-05-18 18:46:57,156 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-5041762397192592582_1231 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 18:46:57,157 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 18:47:00,250 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8662613431765159338_1224 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8662613431765159338
2017-05-18 18:47:00,250 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7305770572360273890_1225 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7305770572360273890
2017-05-18 18:47:00,251 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6141822045976836569_1223 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6141822045976836569
2017-05-18 18:47:00,251 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2858710911696153005_1227 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2858710911696153005
2017-05-18 18:47:18,174 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6882278130237246628_1233 src: /192.168.1.150:42326 dest: /192.168.1.150:50010
2017-05-18 18:47:18,176 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-6882278130237246628_1233 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 18:47:18,178 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 18:47:24,165 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6882278130237246628_1233 src: /192.168.1.150:42330 dest: /192.168.1.150:50010
2017-05-18 18:47:24,165 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-6882278130237246628_1233 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 18:47:24,165 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 18:47:33,237 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8609958741249002773_1234 src: /192.168.1.151:40139 dest: /192.168.1.151:50010
2017-05-18 18:47:33,238 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8609958741249002773_1234 src: /192.168.1.151:40139 dest: /192.168.1.151:50010 of size 13560
2017-05-18 18:47:33,434 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6882278130237246628_1233 src: /192.168.1.152:54919 dest: /192.168.1.152:50010
2017-05-18 18:47:33,435 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6882278130237246628_1233 src: /192.168.1.152:54919 dest: /192.168.1.152:50010 of size 1941
2017-05-18 18:47:36,169 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6487135244673226156_1232 src: /192.168.1.150:42348 dest: /192.168.1.150:50010
2017-05-18 18:47:36,171 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6487135244673226156_1232 src: /192.168.1.150:42348 dest: /192.168.1.150:50010 of size 91176
2017-05-18 18:47:36,200 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8609958741249002773_1234 to /192.168.1.153
2017-05-18 18:47:36,224 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_6487135244673226156_1232 to /192.168.1.153
2017-05-18 18:47:36,428 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6512841445447242817_1236 src: /192.168.1.151:40148 dest: /192.168.1.151:50010
2017-05-18 18:47:36,430 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6512841445447242817_1236 src: /192.168.1.151:40148 dest: /192.168.1.151:50010 of size 13546
2017-05-18 18:47:37,494 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.153
2017-05-18 18:47:39,260 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_6487135244673226156_1232 to 192.168.1.151:50010
2017-05-18 18:47:39,272 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_6487135244673226156_1232 to /192.168.1.151:50010
2017-05-18 18:47:45,551 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.153
2017-05-18 18:48:33,194 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5824049566273319088_1241 src: /192.168.1.150:42374 dest: /192.168.1.150:50010
2017-05-18 18:48:33,200 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Exception writing block blk_5824049566273319088_1241 to mirror 192.168.1.152:50010
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:94)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:450)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)
	at java.io.DataOutputStream.flush(DataOutputStream.java:123)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2704)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 18:48:33,200 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5824049566273319088_1241 src: /192.168.1.150:42374 dest: /192.168.1.150:50010 of size 23871
2017-05-18 18:48:36,282 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_5824049566273319088_1241 to 192.168.1.152:50010, 192.168.1.151:50010
2017-05-18 18:48:36,288 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Transmitted block blk_5824049566273319088_1241 to /192.168.1.152:50010
2017-05-18 18:48:39,283 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8609958741249002773_1234 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8609958741249002773
2017-05-18 18:48:39,284 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6882278130237246628_1233 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6882278130237246628
2017-05-18 18:48:39,284 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6512841445447242817_1236 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6512841445447242817
2017-05-18 18:48:39,284 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5824049566273319088_1241 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5824049566273319088
2017-05-18 18:48:39,285 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6487135244673226156_1232 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6487135244673226156
2017-05-18 18:52:39,363 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 19:02:07,615 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 19:02:16,037 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 19:02:16,211 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 19:02:16,213 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 19:02:16,215 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 19:02:16,280 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 19:02:16,337 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 19:02:16,338 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 19:02:16,338 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 19:02:16,563 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-18 19:02:16,597 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 19:02:16,600 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 19:02:16,600 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-18 19:02:16,605 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 19:02:16,622 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 19:02:16,626 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 19:02:16,634 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 19:02:16,636 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 19:02:16,636 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 19:02:16,636 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 19:02:16,637 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 19:02:16,639 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 19:02:16,639 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 19:02:16,647 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 19:02:19,644 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-18 19:06:38,211 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 19:06:44,200 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 19:06:44,386 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 19:06:44,388 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 19:06:44,390 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 19:06:44,453 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 19:06:44,499 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 19:06:44,500 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 19:06:44,500 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 19:06:44,700 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-18 19:06:44,730 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 19:06:44,732 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 19:06:44,732 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-18 19:06:44,736 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 19:06:44,753 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 19:06:44,757 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 19:06:44,758 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 19:06:44,759 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 19:06:44,760 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 19:06:44,760 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 19:06:44,761 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 19:06:44,763 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 19:06:44,764 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 19:06:44,773 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 19:06:47,772 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-18 19:08:10,266 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 19:08:23,097 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 19:08:23,277 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 19:08:23,279 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 19:08:23,280 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 19:08:23,345 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 19:08:23,401 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 19:08:23,401 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 19:08:23,401 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 19:08:23,619 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-18 19:08:23,655 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 19:08:23,657 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 19:08:23,657 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-18 19:08:23,661 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 19:08:23,675 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 19:08:23,679 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 19:08:23,680 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 19:08:23,681 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 19:08:23,682 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 19:08:23,682 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)
2017-05-18 19:08:23,682 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 19:08:23,688 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 19:08:23,689 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 19:08:23,699 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 19:08:26,700 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 8 msecs
2017-05-18 19:09:32,767 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6317601661172590793_1244 src: /192.168.1.150:42417 dest: /192.168.1.150:50010
2017-05-18 19:09:32,782 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6317601661172590793_1244 src: /192.168.1.150:42417 dest: /192.168.1.150:50010 of size 13560
2017-05-18 19:09:33,050 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-6317601661172590793_1244 to /192.168.1.153
2017-05-18 19:09:34,108 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 19:09:34,139 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_4706039197501890837_1001 to /192.168.1.151
2017-05-18 19:09:38,732 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4737301526707610038_1243 src: /192.168.1.150:42429 dest: /192.168.1.150:50010
2017-05-18 19:09:38,734 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4737301526707610038_1243 src: /192.168.1.150:42429 dest: /192.168.1.150:50010 of size 1941
2017-05-18 19:09:39,240 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 19:09:39,253 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-8136925468644615539_1001 to /192.168.1.150
2017-05-18 19:09:44,740 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2822136074465972415_1246 src: /192.168.1.151:40197 dest: /192.168.1.151:50010
2017-05-18 19:09:44,742 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2822136074465972415_1246 src: /192.168.1.151:40197 dest: /192.168.1.151:50010 of size 13546
2017-05-18 19:09:44,813 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-2176010241761529046_1001 to /192.168.1.153
2017-05-18 19:09:46,931 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 19:09:47,738 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-125211425812195367_1242 src: /192.168.1.150:42443 dest: /192.168.1.150:50010
2017-05-18 19:09:47,740 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-125211425812195367_1242 src: /192.168.1.150:42443 dest: /192.168.1.150:50010 of size 91176
2017-05-18 19:10:11,840 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1846054978455200906_1249 src: /192.168.1.151:40211 dest: /192.168.1.151:50010
2017-05-18 19:10:12,409 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1846054978455200906_1249 src: /192.168.1.151:40211 dest: /192.168.1.151:50010 of size 31981189
2017-05-18 19:10:14,760 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6481672114015388500_1247 src: /192.168.1.150:42455 dest: /192.168.1.150:50010
2017-05-18 19:10:15,444 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6481672114015388500_1247 src: /192.168.1.150:42455 dest: /192.168.1.150:50010 of size 31976695
2017-05-18 19:10:17,766 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1291926949564505114_1249 src: /192.168.1.150:42456 dest: /192.168.1.150:50010
2017-05-18 19:10:17,767 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2022838886132360364_1250 src: /192.168.1.150:42457 dest: /192.168.1.150:50010
2017-05-18 19:10:18,215 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1291926949564505114_1249 src: /192.168.1.150:42456 dest: /192.168.1.150:50010 of size 31980463
2017-05-18 19:10:18,712 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2022838886132360364_1250 src: /192.168.1.150:42457 dest: /192.168.1.150:50010 of size 31964396
2017-05-18 19:10:23,757 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6481672114015388500_1247 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6481672114015388500
2017-05-18 19:10:23,757 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6317601661172590793_1244 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6317601661172590793
2017-05-18 19:10:23,758 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4737301526707610038_1243 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4737301526707610038
2017-05-18 19:10:23,765 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2022838886132360364_1250 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2022838886132360364
2017-05-18 19:10:23,771 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1846054978455200906_1249 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1846054978455200906
2017-05-18 19:10:23,777 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1291926949564505114_1249 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1291926949564505114
2017-05-18 19:10:23,778 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-125211425812195367_1242 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-125211425812195367
2017-05-18 19:10:23,778 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2822136074465972415_1246 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2822136074465972415
2017-05-18 19:10:35,772 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4627623777592740609_1251 src: /192.168.1.152:54984 dest: /192.168.1.152:50010
2017-05-18 19:10:35,774 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4627623777592740609_1251 src: /192.168.1.152:54984 dest: /192.168.1.152:50010 of size 91176
2017-05-18 19:10:36,254 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-4627623777592740609_1251 to /192.168.1.153
2017-05-18 19:10:37,180 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_2466807231137463792_1001 to /192.168.1.153
2017-05-18 19:10:41,858 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5009280471694296357_1253 src: /192.168.1.151:40227 dest: /192.168.1.151:50010
2017-05-18 19:10:41,873 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5009280471694296357_1253 src: /192.168.1.151:40227 dest: /192.168.1.151:50010 of size 13560
2017-05-18 19:10:44,859 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7498629700116265470_1255 src: /192.168.1.151:40229 dest: /192.168.1.151:50010
2017-05-18 19:10:44,860 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7498629700116265470_1255 src: /192.168.1.151:40229 dest: /192.168.1.151:50010 of size 13546
2017-05-18 19:10:45,593 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_830771838363386275_1001 to /192.168.1.153
2017-05-18 19:10:47,846 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7675481682831826149_1252 src: /192.168.1.152:55001 dest: /192.168.1.152:50010
2017-05-18 19:10:47,871 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7675481682831826149_1252 src: /192.168.1.152:55001 dest: /192.168.1.152:50010 of size 1941
2017-05-18 19:10:50,584 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_-1716342580866869033_1001 to /192.168.1.153
2017-05-18 19:11:04,914 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Served block blk_7582974860746948614_1001 to /192.168.1.153
2017-05-18 19:12:02,796 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3909211497765254886_1260 src: /192.168.1.150:42517 dest: /192.168.1.150:50010
2017-05-18 19:12:02,801 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3909211497765254886_1260 src: /192.168.1.150:42517 dest: /192.168.1.150:50010 of size 25233
2017-05-18 19:12:05,779 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_3909211497765254886_1260 to 192.168.1.152:50010
2017-05-18 19:12:05,788 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-179625278-192.168.1.153-50010-1495042665476, infoPort=50075, ipcPort=50020):Failed to transfer blk_3909211497765254886_1260 to 192.168.1.152:50010 got java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:94)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:450)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82)
	at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140)
	at java.io.DataOutputStream.flush(DataOutputStream.java:123)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1975)
	at org.apache.hadoop.dfs.DataNode$DataTransfer.run(DataNode.java:2855)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:12:08,780 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4627623777592740609_1251 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4627623777592740609
2017-05-18 19:12:08,781 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5009280471694296357_1253 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5009280471694296357
2017-05-18 19:12:08,781 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7675481682831826149_1252 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7675481682831826149
2017-05-18 19:12:26,806 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-747034111171122068_1256 src: /192.168.1.150:42518 dest: /192.168.1.150:50010
2017-05-18 19:12:27,306 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-747034111171122068_1256 src: /192.168.1.150:42518 dest: /192.168.1.150:50010 of size 31980463
2017-05-18 19:12:29,807 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-691681661224899134_1259 src: /192.168.1.150:42519 dest: /192.168.1.150:50010
2017-05-18 19:12:30,257 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-691681661224899134_1259 src: /192.168.1.150:42519 dest: /192.168.1.150:50010 of size 31981189
2017-05-18 19:12:32,813 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3586358587949628056_1257 src: /192.168.1.150:42520 dest: /192.168.1.150:50010
2017-05-18 19:12:33,316 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3586358587949628056_1257 src: /192.168.1.150:42520 dest: /192.168.1.150:50010 of size 31964396
2017-05-18 19:12:35,811 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5306499951541505098_1258 src: /192.168.1.150:42521 dest: /192.168.1.150:50010
2017-05-18 19:12:37,230 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5306499951541505098_1258 src: /192.168.1.150:42521 dest: /192.168.1.150:50010 of size 31976695
2017-05-18 19:15:23,859 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DF.parseExecResult(DF.java:109)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:179)
	at org.apache.hadoop.util.Shell.run(Shell.java:134)
	at org.apache.hadoop.fs.DF.getCapacity(DF.java:63)
	at org.apache.hadoop.dfs.FSDataset$FSVolume.getCapacity(FSDataset.java:337)
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getCapacity(FSDataset.java:492)
	at org.apache.hadoop.dfs.FSDataset.getCapacity(FSDataset.java:690)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:16:23,878 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DF.parseExecResult(DF.java:109)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:179)
	at org.apache.hadoop.util.Shell.run(Shell.java:134)
	at org.apache.hadoop.fs.DF.getCapacity(DF.java:63)
	at org.apache.hadoop.dfs.FSDataset$FSVolume.getCapacity(FSDataset.java:337)
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getCapacity(FSDataset.java:492)
	at org.apache.hadoop.dfs.FSDataset.getCapacity(FSDataset.java:690)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:17:23,904 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Expecting a line not the end of stream
	at org.apache.hadoop.fs.DF.parseExecResult(DF.java:109)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:179)
	at org.apache.hadoop.util.Shell.run(Shell.java:134)
	at org.apache.hadoop.fs.DF.getCapacity(DF.java:63)
	at org.apache.hadoop.dfs.FSDataset$FSVolume.getCapacity(FSDataset.java:337)
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getCapacity(FSDataset.java:492)
	at org.apache.hadoop.dfs.FSDataset.getCapacity(FSDataset.java:690)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:17:27,894 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 19:17:40,890 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 19:17:41,075 INFO org.apache.hadoop.dfs.Storage: Storage directory /home/ubuntu/old_hadoop_temp/dfs/data is not formatted.
2017-05-18 19:17:41,075 INFO org.apache.hadoop.dfs.Storage: Formatting ...
2017-05-18 19:17:41,138 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 19:17:41,140 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 19:17:41,141 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 19:17:41,208 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 19:17:41,265 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 19:17:41,266 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 19:17:41,266 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 19:17:41,497 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@1eecfa7
2017-05-18 19:17:41,529 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 19:17:41,531 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 19:17:41,531 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d60c28
2017-05-18 19:17:41,536 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 19:17:41,550 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 19:17:41,555 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 19:17:41,555 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 19:17:41,556 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 19:17:41,556 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 19:17:41,557 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=, infoPort=50075, ipcPort=50020)
2017-05-18 19:17:41,557 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 19:18:16,963 INFO org.apache.hadoop.dfs.DataNode: New storage id DS-660144682-192.168.1.153-50010-1495127896953 is assigned to data-node 192.168.1.153:50010
2017-05-18 19:18:16,965 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 19:18:16,965 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 19:18:16,992 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 19:18:19,970 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 0 blocks got processed in 5 msecs
2017-05-18 19:18:46,285 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1462691181008144801_1001 src: /192.168.1.152:55016 dest: /192.168.1.152:50010
2017-05-18 19:18:48,383 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1462691181008144801_1001 of size 67108864 from /192.168.1.152
2017-05-18 19:18:48,384 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-1462691181008144801_1001 terminating
2017-05-18 19:18:48,403 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4082302689928169498_1001 src: /192.168.1.151:40254 dest: /192.168.1.151:50010
2017-05-18 19:18:50,869 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4082302689928169498_1001 of size 67108864 from /192.168.1.151
2017-05-18 19:18:50,869 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_4082302689928169498_1001 terminating
2017-05-18 19:18:50,891 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7742655286214540843_1001 src: /192.168.1.152:55017 dest: /192.168.1.152:50010
2017-05-18 19:18:53,480 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7742655286214540843_1001 of size 67108864 from /192.168.1.152
2017-05-18 19:18:53,480 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-7742655286214540843_1001 terminating
2017-05-18 19:18:53,496 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5966040669444194256_1001 src: /192.168.1.152:55018 dest: /192.168.1.152:50010
2017-05-18 19:18:56,228 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5966040669444194256_1001 of size 67108864 from /192.168.1.152
2017-05-18 19:18:56,229 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_5966040669444194256_1001 terminating
2017-05-18 19:18:56,247 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6241282822132550768_1001 src: /192.168.1.150:42527 dest: /192.168.1.150:50010
2017-05-18 19:18:59,044 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6241282822132550768_1001 of size 67108864 from /192.168.1.150
2017-05-18 19:18:59,045 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_-6241282822132550768_1001 terminating
2017-05-18 19:18:59,063 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-302239605532529116_1001 src: /192.168.1.150:42528 dest: /192.168.1.150:50010
2017-05-18 19:19:01,715 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-302239605532529116_1001 of size 67108864 from /192.168.1.150
2017-05-18 19:19:01,716 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_-302239605532529116_1001 terminating
2017-05-18 19:19:01,740 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5879298181291053563_1001 src: /192.168.1.152:55019 dest: /192.168.1.152:50010
2017-05-18 19:19:04,321 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5879298181291053563_1001 of size 67108864 from /192.168.1.152
2017-05-18 19:19:04,321 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_5879298181291053563_1001 terminating
2017-05-18 19:19:04,338 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-419086854078323934_1001 src: /192.168.1.152:55020 dest: /192.168.1.152:50010
2017-05-18 19:19:06,726 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-419086854078323934_1001 of size 67103998 from /192.168.1.152
2017-05-18 19:19:06,727 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_-419086854078323934_1001 terminating
2017-05-18 19:21:38,855 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_4082302689928169498_1001
2017-05-18 19:25:09,727 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at rivervm5/192.168.1.153
************************************************************/
2017-05-18 19:25:22,586 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = rivervm5/192.168.1.153
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-18 19:25:22,789 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-18 19:25:22,793 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-18 19:25:22,796 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-18 19:25:22,859 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-18 19:25:22,925 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-18 19:25:22,926 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-18 19:25:22,926 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-18 19:25:23,168 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-18 19:25:23,212 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-18 19:25:23,215 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-18 19:25:23,215 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-18 19:25:23,220 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-18 19:25:23,242 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-18 19:25:23,245 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-18 19:25:23,246 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-18 19:25:23,247 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-18 19:25:23,247 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-18 19:25:23,248 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(rivervm5:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020)
2017-05-18 19:25:23,248 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-18 19:25:23,250 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-18 19:25:23,251 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-18 19:25:23,258 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-18 19:25:26,254 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 19:26:25,800 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_5966040669444194256_1001
2017-05-18 19:26:32,286 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_48418177985736444_1002 src: /192.168.1.152:55023 dest: /192.168.1.152:50010
2017-05-18 19:26:32,305 INFO org.apache.hadoop.dfs.DataNode: Received block blk_48418177985736444_1002 src: /192.168.1.152:55023 dest: /192.168.1.152:50010 of size 91176
2017-05-18 19:26:32,532 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_48418177985736444_1002 to /192.168.1.153
2017-05-18 19:26:33,547 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_-1462691181008144801_1001 to /192.168.1.153
2017-05-18 19:26:33,573 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_-7742655286214540843_1001 to /192.168.1.153
2017-05-18 19:26:35,238 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_613216842950085434_1006 src: /192.168.1.152:55033 dest: /192.168.1.152:50010
2017-05-18 19:26:35,241 INFO org.apache.hadoop.dfs.DataNode: Received block blk_613216842950085434_1006 src: /192.168.1.152:55033 dest: /192.168.1.152:50010 of size 13546
2017-05-18 19:26:35,280 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_48418177985736444_1002 to 192.168.1.151:50010
2017-05-18 19:26:35,286 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):Transmitted block blk_48418177985736444_1002 to /192.168.1.151:50010
2017-05-18 19:26:38,236 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2282980617169441083_1004 src: /192.168.1.150:42546 dest: /192.168.1.150:50010
2017-05-18 19:26:38,237 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2282980617169441083_1004 src: /192.168.1.150:42546 dest: /192.168.1.150:50010 of size 13560
2017-05-18 19:26:38,604 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_-6241282822132550768_1001 to /192.168.1.153
2017-05-18 19:26:41,239 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6423634116546107099_1003 src: /192.168.1.152:55040 dest: /192.168.1.152:50010
2017-05-18 19:26:41,240 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6423634116546107099_1003 src: /192.168.1.152:55040 dest: /192.168.1.152:50010 of size 2085
2017-05-18 19:26:54,540 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_-419086854078323934_1001 to /192.168.1.153
2017-05-18 19:27:08,261 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3529551077347596184_1007 src: /192.168.1.152:55056 dest: /192.168.1.152:50010
2017-05-18 19:27:09,104 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3529551077347596184_1007 src: /192.168.1.152:55056 dest: /192.168.1.152:50010 of size 31976695
2017-05-18 19:27:11,261 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4556093068971431475_1009 src: /192.168.1.150:42566 dest: /192.168.1.150:50010
2017-05-18 19:27:11,264 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4556093068971431475_1009 src: /192.168.1.150:42567 dest: /192.168.1.150:50010
2017-05-18 19:27:11,268 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4556093068971431475_1009 received exception java.io.IOException: Block blk_4556093068971431475_1009 has already been started (though not completed), and thus cannot be created.
2017-05-18 19:27:11,277 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_4556093068971431475_1009 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:27:11,295 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_3529551077347596184_1007 to 192.168.1.151:50010
2017-05-18 19:27:11,814 INFO org.apache.hadoop.dfs.DataNode: Exception in receiveBlock for block blk_4556093068971431475_1009 org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
2017-05-18 19:27:11,816 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4556093068971431475_1009 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
2017-05-18 19:27:11,816 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
	at org.apache.hadoop.dfs.DataNode.chec2017-05-18 19:27:17,253 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1878523941699279752_1010 src: /192.168.1.150:42570 dest: /192.168.1.150:50010
2017-05-18 19:27:17,255 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1878523941699279752_1010 src: /192.168.1.150:42570 dest: /192.168.1.150:50010 of size 23377
2017-05-18 19:27:23,310 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6423634116546107099_1003 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6423634116546107099
2017-05-18 19:27:23,310 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_48418177985736444_1002 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_48418177985736444
2017-05-18 19:27:23,311 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_613216842950085434_1006 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_613216842950085434
2017-05-18 19:27:23,311 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1878523941699279752_1010 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1878523941699279752
2017-05-18 19:27:23,311 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2282980617169441083_1004 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2282980617169441083
2017-05-18 19:27:23,320 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3529551077347596184_1007 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3529551077347596184
2017-05-18 19:27:32,259 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3681235498471583524_1015 src: /192.168.1.151:40298 dest: /192.168.1.151:50010
2017-05-18 19:27:32,260 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3681235498471583524_1015 src: /192.168.1.151:40298 dest: /192.168.1.151:50010 of size 13546
2017-05-18 19:27:33,319 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_-7742655286214540843_1001 to /192.168.1.153
2017-05-18 19:27:35,268 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2717296044820252299_1013 src: /192.168.1.150:42583 dest: /192.168.1.150:50010
2017-05-18 19:27:35,269 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2717296044820252299_1013 src: /192.168.1.150:42583 dest: /192.168.1.150:50010 of size 13560
2017-05-18 19:27:35,302 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-3681235498471583524_1015 to 192.168.1.152:50010
2017-05-18 19:27:35,307 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):Transmitted block blk_-3681235498471583524_1015 to /192.168.1.152:50010
2017-05-18 19:27:38,303 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_2717296044820252299_1013 to 192.168.1.151:50010
2017-05-18 19:27:38,305 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):Transmitted block blk_2717296044820252299_1013 to /192.168.1.151:50010
2017-05-18 19:27:41,291 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4480056203410460235_1011 src: /192.168.1.152:55074 dest: /192.168.1.152:50010
2017-05-18 19:27:41,295 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4480056203410460235_1011 src: /192.168.1.152:55074 dest: /192.168.1.152:50010 of size 91176
2017-05-18 19:27:43,164 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_5966040669444194256_1001 to /192.168.1.153
2017-05-18 19:27:44,394 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9134647397428670725_1012 src: /192.168.1.151:40309 dest: /192.168.1.151:50010
2017-05-18 19:27:44,395 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9134647397428670725_1012 src: /192.168.1.151:40309 dest: /192.168.1.151:50010 of size 2085
2017-05-18 19:27:46,977 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_-302239605532529116_1001 to /192.168.1.153
2017-05-18 19:27:54,615 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_-419086854078323934_1001 to /192.168.1.153
2017-05-18 19:28:09,137 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_5879298181291053563_1001 to /192.168.1.153
2017-05-18 19:28:16,178 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_5879298181291053563_1001 to /192.168.1.153
2017-05-18 19:28:35,325 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3681235498471583524_1015 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3681235498471583524
2017-05-18 19:28:35,326 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2717296044820252299_1013 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2717296044820252299
2017-05-18 19:28:35,327 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4480056203410460235_1011 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4480056203410460235
2017-05-18 19:28:35,327 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9134647397428670725_1012 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9134647397428670725
2017-05-18 19:28:47,278 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8794343660807445222_1016 src: /192.168.1.150:42615 dest: /192.168.1.150:50010
2017-05-18 19:28:47,278 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8794343660807445222_1016 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:28:47,279 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:28:51,673 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_-1462691181008144801_1001 to /192.168.1.153
2017-05-18 19:28:52,429 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_4082302689928169498_1001 to /192.168.1.153
2017-05-18 19:28:53,284 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8794343660807445222_1016 src: /192.168.1.150:42624 dest: /192.168.1.150:50010
2017-05-18 19:28:53,284 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8794343660807445222_1016 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:28:53,285 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:28:55,603 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_-6241282822132550768_1001 to /192.168.1.153
2017-05-18 19:28:56,073 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_-302239605532529116_1001 to /192.168.1.153
2017-05-18 19:28:56,863 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020) Served block blk_5879298181291053563_1001 to /192.168.1.153
2017-05-18 19:28:59,283 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8794343660807445222_1016 src: /192.168.1.150:42628 dest: /192.168.1.150:50010
2017-05-18 19:28:59,283 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8794343660807445222_1016 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:28:59,283 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:29:05,289 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9123181895683493447_1017 src: /192.168.1.150:42636 dest: /192.168.1.150:50010
2017-05-18 19:29:05,289 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-9123181895683493447_1017 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:29:05,290 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:29:08,287 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9123181895683493447_1017 src: /192.168.1.150:42637 dest: /192.168.1.150:50010
2017-05-18 19:29:08,289 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-9123181895683493447_1017 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:29:08,289 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:29:17,291 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8794343660807445222_1016 src: /192.168.1.150:42646 dest: /192.168.1.150:50010
2017-05-18 19:29:17,292 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8794343660807445222_1016 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:29:17,292 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:29:23,307 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9123181895683493447_1017 src: /192.168.1.150:42650 dest: /192.168.1.150:50010
2017-05-18 19:29:23,307 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-9123181895683493447_1017 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:29:23,308 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:29:35,298 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8794343660807445222_1016 src: /192.168.1.150:42656 dest: /192.168.1.150:50010
2017-05-18 19:29:35,298 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8794343660807445222_1016 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:29:35,299 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:29:38,297 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9123181895683493447_1017 src: /192.168.1.150:42658 dest: /192.168.1.150:50010
2017-05-18 19:29:38,298 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-9123181895683493447_1017 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:29:38,298 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:29:41,300 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9123181895683493447_1017 src: /192.168.1.150:42660 dest: /192.168.1.150:50010
2017-05-18 19:29:41,300 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-9123181895683493447_1017 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:29:41,300 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:29:50,303 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9123181895683493447_1017 src: /192.168.1.150:42666 dest: /192.168.1.150:50010
2017-05-18 19:29:50,303 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-9123181895683493447_1017 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:29:50,303 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:29:53,308 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8794343660807445222_1016 src: /192.168.1.150:42668 dest: /192.168.1.150:50010
2017-05-18 19:29:53,309 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8794343660807445222_1016 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:29:53,309 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9123181895683493447_1017 src: /192.168.1.150:42669 dest: /192.168.1.150:50010
2017-05-18 19:29:53,310 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:29:53,311 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-9123181895683493447_1017 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:29:53,311 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:29:56,304 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8410310083399997232_1020 src: /192.168.1.150:42676 dest: /192.168.1.150:50010
2017-05-18 19:29:56,305 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8410310083399997232_1020 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:29:56,305 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:29:59,306 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8410310083399997232_1020 src: /192.168.1.150:42678 dest: /192.168.1.150:50010
2017-05-18 19:29:59,306 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8410310083399997232_1020 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:29:59,307 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:30:02,307 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8410310083399997232_1020 src: /192.168.1.150:42680 dest: /192.168.1.150:50010
2017-05-18 19:30:02,307 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8410310083399997232_1020 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:30:02,307 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:30:08,308 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8410310083399997232_1020 src: /192.168.1.150:42691 dest: /192.168.1.150:50010
2017-05-18 19:30:08,308 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8410310083399997232_1020 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-18 19:30:08,308 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.153:50010, storageID=DS-660144682-192.168.1.153-50010-1495127896953, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-18 19:30:29,318 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8410310083399997232_1020 src: /192.168.1.150:42712 dest: /192.168.1.150:50010
2017-05-18 19:30:29,320 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8410310083399997232_1020 src: /192.168.1.150:42712 dest: /192.168.1.150:50010 of size 13546
2017-05-18 19:30:29,465 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7623697979232494584_1018 src: /192.168.1.151:40353 dest: /192.168.1.151:50010
2017-05-18 19:30:29,467 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7623697979232494584_1018 src: /192.168.1.151:40353 dest: /192.168.1.151:50010 of size 13560
2017-05-18 19:30:35,334 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9123181895683493447_1017 src: /192.168.1.152:55125 dest: /192.168.1.152:50010
2017-05-18 19:30:35,335 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9123181895683493447_1017 src: /192.168.1.152:55125 dest: /192.168.1.152:50010 of size 2085
2017-05-18 19:30:38,323 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8794343660807445222_1016 src: /192.168.1.150:42717 dest: /192.168.1.150:50010
2017-05-18 19:30:38,332 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8794343660807445222_1016 src: /192.168.1.150:42717 dest: /192.168.1.150:50010 of size 91176
2017-05-18 19:30:41,324 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2697093336362453787_1024 src: /192.168.1.150:42719 dest: /192.168.1.150:50010
2017-05-18 19:30:41,328 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2697093336362453787_1024 src: /192.168.1.150:42719 dest: /192.168.1.150:50010 of size 25977
2017-05-18 19:30:47,383 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9123181895683493447_1017 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9123181895683493447
2017-05-18 19:30:47,385 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7623697979232494584_1018 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7623697979232494584
2017-05-18 19:30:47,385 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8410310083399997232_1020 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8410310083399997232
2017-05-18 19:36:28,426 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_5879298181291053563_1001
2017-05-18 19:46:27,946 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-7742655286214540843_1001
2017-05-18 19:56:28,466 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-419086854078323934_1001
2017-05-18 19:58:48,497 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-8794343660807445222_1016
2017-05-18 20:06:27,987 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-1462691181008144801_1001
2017-05-18 20:16:28,510 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-302239605532529116_1001
2017-05-18 20:16:45,382 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 10 blocks got processed in 4 msecs
2017-05-18 20:16:48,379 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8794343660807445222_1016 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8794343660807445222
2017-05-18 20:16:48,379 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2697093336362453787_1024 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2697093336362453787
2017-05-18 20:26:28,066 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-6241282822132550768_1001
2017-05-18 21:16:46,661 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-18 22:16:47,940 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 4 msecs
2017-05-18 23:16:49,215 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
