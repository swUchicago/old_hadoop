2017-06-19 18:54:00,295 INFO org.apache.hadoop.mapred.JobTracker: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting JobTracker
STARTUP_MSG:   host = secondvm1/192.168.1.155
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-06-19 18:54:00,394 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=JobTracker, port=9001
2017-06-19 18:54:00,399 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-06-19 18:54:00,400 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9001: starting
2017-06-19 18:54:00,401 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 9001: starting
2017-06-19 18:54:00,402 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 9001: starting
2017-06-19 18:54:00,409 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 9001: starting
2017-06-19 18:54:00,410 INFO org.apache.hadoop.ipc.Server: IPC Server handler 4 on 9001: starting
2017-06-19 18:54:00,410 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 9001: starting
2017-06-19 18:54:00,410 INFO org.apache.hadoop.ipc.Server: IPC Server handler 5 on 9001: starting
2017-06-19 18:54:00,411 INFO org.apache.hadoop.ipc.Server: IPC Server handler 6 on 9001: starting
2017-06-19 18:54:00,411 INFO org.apache.hadoop.ipc.Server: IPC Server handler 7 on 9001: starting
2017-06-19 18:54:00,412 INFO org.apache.hadoop.ipc.Server: IPC Server handler 8 on 9001: starting
2017-06-19 18:54:00,412 INFO org.apache.hadoop.ipc.Server: IPC Server handler 9 on 9001: starting
2017-06-19 18:54:00,458 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-06-19 18:54:00,539 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-06-19 18:54:00,539 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-06-19 18:54:00,539 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-06-19 18:54:00,821 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@62ed3a
2017-06-19 18:54:00,875 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-06-19 18:54:00,877 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50030
2017-06-19 18:54:00,877 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1e47e38
2017-06-19 18:54:00,879 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
2017-06-19 18:54:00,880 INFO org.apache.hadoop.mapred.JobTracker: JobTracker up at: 9001
2017-06-19 18:54:00,880 INFO org.apache.hadoop.mapred.JobTracker: JobTracker webserver: 50030
2017-06-19 18:54:01,018 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://secondvm1:9000/home/ubuntu/old_hadoop_temp/mapred/system
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.dfs.SafeModeException: Cannot delete /home/ubuntu/old_hadoop_temp/mapred/system. Name node is in safe mode.
The ratio of reported blocks 0.0000 has not reached the threshold 0.9990. Safe mode will be turned off automatically.
	at org.apache.hadoop.dfs.FSNamesystem.deleteInternal(FSNamesystem.java:1494)
	at org.apache.hadoop.dfs.FSNamesystem.delete(FSNamesystem.java:1466)
	at org.apache.hadoop.dfs.NameNode.delete(NameNode.java:425)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)

	at org.apache.hadoop.ipc.Client.call(Client.java:715)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at org.apache.hadoop.dfs.$Proxy4.delete(Unknown Source)
	at org.apache.hadoop.dfs.DFSClient.delete(DFSClient.java:529)
	at org.apache.hadoop.dfs.DistributedFileSystem.delete(DistributedFileSystem.java:192)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:715)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:132)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:2426)
2017-06-19 18:54:11,026 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://secondvm1:9000/home/ubuntu/old_hadoop_temp/mapred/system
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.dfs.SafeModeException: Cannot delete /home/ubuntu/old_hadoop_temp/mapred/system. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 20 seconds.
	at org.apache.hadoop.dfs.FSNamesystem.deleteInternal(FSNamesystem.java:1494)
	at org.apache.hadoop.dfs.FSNamesystem.delete(FSNamesystem.java:1466)
	at org.apache.hadoop.dfs.NameNode.delete(NameNode.java:425)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)

	at org.apache.hadoop.ipc.Client.call(Client.java:715)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at org.apache.hadoop.dfs.$Proxy4.delete(Unknown Source)
	at org.apache.hadoop.dfs.DFSClient.delete(DFSClient.java:529)
	at org.apache.hadoop.dfs.DistributedFileSystem.delete(DistributedFileSystem.java:192)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:715)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:132)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:2426)
2017-06-19 18:54:21,033 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://secondvm1:9000/home/ubuntu/old_hadoop_temp/mapred/system
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.dfs.SafeModeException: Cannot delete /home/ubuntu/old_hadoop_temp/mapred/system. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 10 seconds.
	at org.apache.hadoop.dfs.FSNamesystem.deleteInternal(FSNamesystem.java:1494)
	at org.apache.hadoop.dfs.FSNamesystem.delete(FSNamesystem.java:1466)
	at org.apache.hadoop.dfs.NameNode.delete(NameNode.java:425)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)

	at org.apache.hadoop.ipc.Client.call(Client.java:715)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at org.apache.hadoop.dfs.$Proxy4.delete(Unknown Source)
	at org.apache.hadoop.dfs.DFSClient.delete(DFSClient.java:529)
	at org.apache.hadoop.dfs.DistributedFileSystem.delete(DistributedFileSystem.java:192)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:715)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:132)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:2426)
2017-06-19 18:54:31,040 INFO org.apache.hadoop.mapred.JobTracker: problem cleaning system directory: hdfs://secondvm1:9000/home/ubuntu/old_hadoop_temp/mapred/system
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.dfs.SafeModeException: Cannot delete /home/ubuntu/old_hadoop_temp/mapred/system. Name node is in safe mode.
The ratio of reported blocks 1.0000 has reached the threshold 0.9990. Safe mode will be turned off automatically in 0 seconds.
	at org.apache.hadoop.dfs.FSNamesystem.deleteInternal(FSNamesystem.java:1494)
	at org.apache.hadoop.dfs.FSNamesystem.delete(FSNamesystem.java:1466)
	at org.apache.hadoop.dfs.NameNode.delete(NameNode.java:425)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:452)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:888)

	at org.apache.hadoop.ipc.Client.call(Client.java:715)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.delete(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:82)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:59)
	at org.apache.hadoop.dfs.$Proxy4.delete(Unknown Source)
	at org.apache.hadoop.dfs.DFSClient.delete(DFSClient.java:529)
	at org.apache.hadoop.dfs.DistributedFileSystem.delete(DistributedFileSystem.java:192)
	at org.apache.hadoop.mapred.JobTracker.<init>(JobTracker.java:715)
	at org.apache.hadoop.mapred.JobTracker.startTracker(JobTracker.java:132)
	at org.apache.hadoop.mapred.JobTracker.main(JobTracker.java:2426)
2017-06-19 18:54:41,113 INFO org.apache.hadoop.mapred.JobTracker: Starting RUNNING
2017-06-19 18:54:41,120 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/secondvm2
2017-06-19 18:54:41,120 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/secondvm4
2017-06-19 18:54:41,121 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/secondvm5
2017-06-19 18:54:41,121 INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/secondvm3
2017-06-19 18:56:46,080 INFO org.apache.hadoop.mapred.JobTracker: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down JobTracker at secondvm1/192.168.1.155
************************************************************/
