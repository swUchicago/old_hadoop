2017-05-20 00:06:52,037 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 01:06:54,606 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 02:06:55,452 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 2 msecs
2017-05-20 03:06:58,021 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 2 msecs
2017-05-20 04:06:58,452 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 04:55:02,681 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 04:55:15,495 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 04:55:15,677 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 04:55:15,679 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 04:55:15,680 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 04:55:15,747 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 04:55:15,804 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 04:55:15,805 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 04:55:15,805 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 04:55:16,039 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 04:55:16,075 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 04:55:16,078 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 04:55:16,078 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 04:55:16,083 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 04:55:16,106 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 04:55:16,111 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 04:55:16,112 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 04:55:16,113 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 04:55:16,114 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 04:55:16,114 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 04:55:16,114 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 04:55:16,117 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 04:55:16,117 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 04:55:16,124 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 04:55:19,125 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 4 msecs
2017-05-20 05:42:48,912 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 06:42:51,562 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 07:42:54,432 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 08:42:57,419 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 09:43:00,281 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 2 msecs
2017-05-20 10:43:02,904 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 11:43:05,837 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 12:18:44,892 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 12:18:57,688 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 12:18:57,897 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 12:18:57,898 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 12:18:57,899 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 12:18:57,964 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 12:18:58,020 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 12:18:58,021 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 12:18:58,021 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 12:18:58,246 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 12:18:58,282 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 12:18:58,284 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 12:18:58,284 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 12:18:58,289 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 12:18:58,309 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 12:18:58,313 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 12:18:58,314 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 12:18:58,315 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 12:18:58,316 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 12:18:58,316 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 12:18:58,316 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 12:18:58,318 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 12:18:58,318 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 12:18:58,327 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 12:19:01,323 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 12:20:07,457 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_181626941223272713_1137 src: /192.168.1.156:41650 dest: /192.168.1.156:50010
2017-05-20 12:20:07,473 INFO org.apache.hadoop.dfs.DataNode: Received block blk_181626941223272713_1137 src: /192.168.1.156:41650 dest: /192.168.1.156:50010 of size 91176
2017-05-20 12:20:07,677 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_181626941223272713_1137 to /192.168.1.159
2017-05-20 12:20:08,840 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 12:20:13,375 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_241019978563681128_1138 src: /192.168.1.157:34205 dest: /192.168.1.157:50010
2017-05-20 12:20:13,376 INFO org.apache.hadoop.dfs.DataNode: Received block blk_241019978563681128_1138 src: /192.168.1.157:34205 dest: /192.168.1.157:50010 of size 4325
2017-05-20 12:20:13,420 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1787040691135207822_1139 src: /192.168.1.156:41663 dest: /192.168.1.156:50010
2017-05-20 12:20:13,422 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1787040691135207822_1139 src: /192.168.1.156:41663 dest: /192.168.1.156:50010 of size 13560
2017-05-20 12:20:13,765 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 12:20:14,023 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 12:20:19,352 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2878772907845516522_1141 src: /192.168.1.157:34220 dest: /192.168.1.157:50010
2017-05-20 12:20:19,354 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2878772907845516522_1141 src: /192.168.1.157:34220 dest: /192.168.1.157:50010 of size 13545
2017-05-20 12:20:21,528 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 12:20:22,962 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 12:20:46,444 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2399090265777526561_1142 src: /192.168.1.157:34237 dest: /192.168.1.157:50010
2017-05-20 12:20:47,218 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2399090265777526561_1142 src: /192.168.1.157:34237 dest: /192.168.1.157:50010 of size 31976695
2017-05-20 12:20:52,365 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_133965054667142205_1143 src: /192.168.1.157:34239 dest: /192.168.1.157:50010
2017-05-20 12:20:53,098 INFO org.apache.hadoop.dfs.DataNode: Received block blk_133965054667142205_1143 src: /192.168.1.157:34239 dest: /192.168.1.157:50010 of size 31981189
2017-05-20 12:20:58,416 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_181626941223272713_1137 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_181626941223272713
2017-05-20 12:20:58,416 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_241019978563681128_1138 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_241019978563681128
2017-05-20 12:20:58,417 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1787040691135207822_1139 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1787040691135207822
2017-05-20 12:20:58,427 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2399090265777526561_1142 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2399090265777526561
2017-05-20 12:20:58,427 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2878772907845516522_1141 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2878772907845516522
2017-05-20 12:30:09,740 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 12:30:22,580 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 12:30:22,770 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 12:30:22,772 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 12:30:22,774 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 12:30:22,845 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 12:30:22,902 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 12:30:22,903 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 12:30:22,903 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 12:30:23,133 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-05-20 12:30:23,175 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 12:30:23,179 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 12:30:23,179 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 12:30:23,186 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 12:30:23,206 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 12:30:23,211 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 12:30:23,212 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 12:30:23,213 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 12:30:23,213 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 12:30:23,213 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 12:30:23,213 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 12:30:23,222 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 12:30:23,222 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 12:30:23,235 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 12:30:26,237 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 15 msecs
2017-05-20 12:30:51,981 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_133965054667142205_1143
2017-05-20 12:31:02,334 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_133965054667142205_1143 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_133965054667142205
2017-05-20 12:31:32,299 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7414481094795792586_1148 src: /192.168.1.158:52649 dest: /192.168.1.158:50010
2017-05-20 12:31:32,312 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7414481094795792586_1148 src: /192.168.1.158:52649 dest: /192.168.1.158:50010 of size 13558
2017-05-20 12:31:32,562 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-7414481094795792586_1148 to /192.168.1.157
2017-05-20 12:31:32,568 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-7414481094795792586_1148 to /192.168.1.159
2017-05-20 12:31:38,258 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2115906652238842699_1150 src: /192.168.1.156:41716 dest: /192.168.1.156:50010
2017-05-20 12:31:38,261 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2115906652238842699_1150 src: /192.168.1.156:41716 dest: /192.168.1.156:50010 of size 13543
2017-05-20 12:31:38,311 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1993863761132730537_1147 src: /192.168.1.158:52663 dest: /192.168.1.158:50010
2017-05-20 12:31:38,311 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1993863761132730537_1147 src: /192.168.1.158:52663 dest: /192.168.1.158:50010 of size 8645
2017-05-20 12:31:38,322 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 12:31:47,312 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4413866655152262446_1146 src: /192.168.1.157:34275 dest: /192.168.1.157:50010
2017-05-20 12:31:47,315 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4413866655152262446_1146 src: /192.168.1.157:34275 dest: /192.168.1.157:50010 of size 91176
2017-05-20 12:31:50,089 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 12:31:59,723 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 12:32:47,295 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4067521715971819888_1154 src: /192.168.1.156:41777 dest: /192.168.1.156:50010
2017-05-20 12:32:47,303 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4067521715971819888_1154 src: /192.168.1.156:41777 dest: /192.168.1.156:50010 of size 77147
2017-05-20 12:32:50,409 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-4067521715971819888_1154 to 192.168.1.157:50010, 192.168.1.158:50010
2017-05-20 12:32:50,420 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Failed to transfer blk_-4067521715971819888_1154 to 192.168.1.157:50010 got java.net.SocketException: Original Exception : java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:420)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:552)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:199)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1873)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataNode$DataTransfer.run(DataNode.java:2855)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	... 8 more

2017-05-20 12:32:56,412 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7414481094795792586_1148 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7414481094795792586
2017-05-20 12:32:56,412 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4067521715971819888_1154 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4067521715971819888
2017-05-20 12:32:56,413 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1993863761132730537_1147 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1993863761132730537
2017-05-20 12:32:56,413 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2115906652238842699_1150 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2115906652238842699
2017-05-20 12:32:56,414 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4413866655152262446_1146 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4413866655152262446
2017-05-20 12:32:58,430 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 12:33:11,195 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 12:33:11,377 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 12:33:11,379 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 12:33:11,380 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 12:33:11,438 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 12:33:11,485 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 12:33:11,485 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 12:33:11,485 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 12:33:11,699 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 12:33:11,736 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 12:33:11,739 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 12:33:11,739 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 12:33:11,745 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 12:33:11,762 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 12:33:11,767 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 12:33:11,768 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 12:33:11,769 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 12:33:11,770 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 12:33:11,770 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 12:33:11,770 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 12:33:11,786 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 12:33:11,787 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 12:33:11,801 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 12:33:14,802 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 12 msecs
2017-05-20 12:34:21,082 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3759912347566316842_1156 src: /192.168.1.156:41781 dest: /192.168.1.156:50010
2017-05-20 12:34:21,096 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3759912347566316842_1156 src: /192.168.1.156:41781 dest: /192.168.1.156:50010 of size 8645
2017-05-20 12:34:26,937 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1029598467930940621_1157 src: /192.168.1.157:34337 dest: /192.168.1.157:50010
2017-05-20 12:34:26,938 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1029598467930940621_1157 src: /192.168.1.157:34337 dest: /192.168.1.157:50010 of size 13558
2017-05-20 12:34:27,051 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7717942224091928988_1155 src: /192.168.1.156:41797 dest: /192.168.1.156:50010
2017-05-20 12:34:27,058 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7717942224091928988_1155 src: /192.168.1.156:41797 dest: /192.168.1.156:50010 of size 91176
2017-05-20 12:34:28,156 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 12:34:30,052 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8361055264578690597_1159 src: /192.168.1.156:41804 dest: /192.168.1.156:50010
2017-05-20 12:34:30,053 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8361055264578690597_1159 src: /192.168.1.156:41804 dest: /192.168.1.156:50010 of size 13543
2017-05-20 12:34:37,182 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 12:34:38,634 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 12:34:48,966 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 12:36:21,018 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3759912347566316842_1156 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3759912347566316842
2017-05-20 12:36:21,018 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1029598467930940621_1157 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1029598467930940621
2017-05-20 12:36:21,019 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7717942224091928988_1155 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7717942224091928988
2017-05-20 12:36:21,019 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8361055264578690597_1159 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8361055264578690597
2017-05-20 12:36:25,206 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 12:36:37,906 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 12:36:38,083 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 12:36:38,085 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 12:36:38,087 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 12:36:38,157 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 12:36:38,215 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 12:36:38,216 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 12:36:38,216 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 12:36:38,461 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 12:36:38,497 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 12:36:38,499 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 12:36:38,499 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 12:36:38,504 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 12:36:38,521 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 12:36:38,525 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 12:36:38,526 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 12:36:38,528 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 12:36:38,528 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 12:36:38,528 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 12:36:38,528 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 12:36:38,550 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 12:36:38,551 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 12:36:38,564 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 12:36:41,562 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 11 msecs
2017-05-20 12:37:47,821 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9040308850495331857_1166 src: /192.168.1.158:52797 dest: /192.168.1.158:50010
2017-05-20 12:37:47,834 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9040308850495331857_1166 src: /192.168.1.158:52797 dest: /192.168.1.158:50010 of size 8645
2017-05-20 12:37:50,776 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_746353327539217542_1165 src: /192.168.1.156:41875 dest: /192.168.1.156:50010
2017-05-20 12:37:50,776 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_746353327539217542_1165 src: /192.168.1.156:41874 dest: /192.168.1.156:50010
2017-05-20 12:37:50,776 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_746353327539217542_1165 received exception java.io.IOException: Block blk_746353327539217542_1165 has already been started (though not completed), and thus cannot be created.
2017-05-20 12:37:50,777 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_746353327539217542_1165 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 12:37:50,988 INFO org.apache.hadoop.dfs.DataNode: Received block blk_746353327539217542_1165 src: /192.168.1.156:41875 dest: /192.168.1.156:50010 of size 91176
2017-05-20 12:37:53,645 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_746353327539217542_1165 to 192.168.1.158:50010, 192.168.1.157:50010
2017-05-20 12:37:53,654 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_746353327539217542_1165 to /192.168.1.158:50010
2017-05-20 12:37:53,772 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5111823945623101319_1169 src: /192.168.1.156:41882 dest: /192.168.1.156:50010
2017-05-20 12:37:53,774 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5111823945623101319_1169 src: /192.168.1.156:41882 dest: /192.168.1.156:50010 of size 13543
2017-05-20 12:37:56,772 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8240940865073804011_1167 src: /192.168.1.156:41888 dest: /192.168.1.156:50010
2017-05-20 12:37:56,773 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8240940865073804011_1167 src: /192.168.1.156:41888 dest: /192.168.1.156:50010 of size 13558
2017-05-20 12:37:58,605 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 12:38:02,421 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 12:38:08,231 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 12:38:12,407 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 12:39:11,675 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9040308850495331857_1166 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9040308850495331857
2017-05-20 12:39:11,675 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_746353327539217542_1165 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_746353327539217542
2017-05-20 12:39:11,675 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5111823945623101319_1169 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5111823945623101319
2017-05-20 12:39:11,676 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8240940865073804011_1167 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8240940865073804011
2017-05-20 12:39:17,336 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 12:39:30,150 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 12:39:30,340 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 12:39:30,341 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 12:39:30,343 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 12:39:30,405 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 12:39:30,453 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 12:39:30,454 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 12:39:30,454 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 12:39:30,665 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 12:39:30,697 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 12:39:30,700 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 12:39:30,700 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 12:39:30,704 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 12:39:30,720 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 12:39:30,724 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 12:39:30,724 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 12:39:30,726 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 12:39:30,726 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 12:39:30,726 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 12:39:30,726 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 12:39:30,738 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 12:39:30,739 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 12:39:30,751 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 12:39:33,749 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 10 msecs
2017-05-20 12:40:39,901 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9218834529918275085_1175 src: /192.168.1.156:41947 dest: /192.168.1.156:50010
2017-05-20 12:40:39,918 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9218834529918275085_1175 src: /192.168.1.156:41947 dest: /192.168.1.156:50010 of size 4325
2017-05-20 12:40:42,871 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5546110940882542820_1174 src: /192.168.1.156:41957 dest: /192.168.1.156:50010
2017-05-20 12:40:42,886 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5546110940882542820_1174 src: /192.168.1.156:41957 dest: /192.168.1.156:50010 of size 91176
2017-05-20 12:40:42,888 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5546110940882542820_1174 src: /192.168.1.156:41958 dest: /192.168.1.156:50010
2017-05-20 12:40:42,889 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-5546110940882542820_1174 received exception java.io.IOException: Block blk_-5546110940882542820_1174 is valid, and cannot be written to.
2017-05-20 12:40:42,890 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-5546110940882542820_1174 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 12:40:48,868 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8541669268121070_1176 src: /192.168.1.156:41972 dest: /192.168.1.156:50010
2017-05-20 12:40:48,869 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8541669268121070_1176 src: /192.168.1.156:41972 dest: /192.168.1.156:50010 of size 13560
2017-05-20 12:40:51,734 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 12:40:51,830 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8541669268121070_1176 to 192.168.1.157:50010
2017-05-20 12:40:51,834 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_8541669268121070_1176 to /192.168.1.157:50010
2017-05-20 12:40:51,880 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2655327512959424079_1178 src: /192.168.1.158:52884 dest: /192.168.1.158:50010
2017-05-20 12:40:51,881 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2655327512959424079_1178 src: /192.168.1.158:52884 dest: /192.168.1.158:50010 of size 13545
2017-05-20 12:40:54,218 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 12:40:54,681 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 12:40:55,563 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 12:41:18,889 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9156936142312431361_1180 src: /192.168.1.156:41994 dest: /192.168.1.156:50010
2017-05-20 12:41:19,550 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9156936142312431361_1180 src: /192.168.1.156:41994 dest: /192.168.1.156:50010 of size 31976695
2017-05-20 12:41:24,890 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3909307185091771882_1182 src: /192.168.1.156:41997 dest: /192.168.1.156:50010
2017-05-20 12:41:24,894 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3909307185091771882_1182 src: /192.168.1.156:41997 dest: /192.168.1.156:50010 of size 41464
2017-05-20 12:41:27,879 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1617120953514712205_1179 src: /192.168.1.158:52906 dest: /192.168.1.158:50010
2017-05-20 12:41:28,563 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1617120953514712205_1179 src: /192.168.1.158:52906 dest: /192.168.1.158:50010 of size 31981189
2017-05-20 12:41:33,850 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9218834529918275085_1175 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9218834529918275085
2017-05-20 12:41:33,851 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5546110940882542820_1174 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5546110940882542820
2017-05-20 12:41:33,851 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3909307185091771882_1182 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3909307185091771882
2017-05-20 12:41:33,852 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8541669268121070_1176 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8541669268121070
2017-05-20 12:41:33,852 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2655327512959424079_1178 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2655327512959424079
2017-05-20 12:41:33,863 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9156936142312431361_1180 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9156936142312431361
2017-05-20 12:41:36,026 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 12:41:48,883 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 12:41:49,070 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 12:41:49,072 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 12:41:49,073 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 12:41:49,138 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 12:41:49,185 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 12:41:49,185 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 12:41:49,185 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 12:41:49,402 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 12:41:49,439 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 12:41:49,442 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 12:41:49,442 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 12:41:49,447 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 12:41:49,465 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 12:41:49,471 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 12:41:49,472 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 12:41:49,473 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 12:41:49,473 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 12:41:49,474 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 12:41:49,474 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 12:41:49,487 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 12:41:49,488 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 12:41:49,512 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 12:41:52,501 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 13 msecs
2017-05-20 12:42:18,281 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-1617120953514712205_1179
2017-05-20 12:42:25,527 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1617120953514712205_1179 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1617120953514712205
2017-05-20 12:42:58,591 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9180711583352181502_1187 src: /192.168.1.156:42002 dest: /192.168.1.156:50010
2017-05-20 12:42:58,612 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9180711583352181502_1187 src: /192.168.1.156:42002 dest: /192.168.1.156:50010 of size 13545
2017-05-20 12:43:01,582 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8903787637240487027_1183 src: /192.168.1.156:42012 dest: /192.168.1.156:50010
2017-05-20 12:43:01,584 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8903787637240487027_1183 src: /192.168.1.156:42013 dest: /192.168.1.156:50010
2017-05-20 12:43:01,584 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8903787637240487027_1183 received exception java.io.IOException: Block blk_-8903787637240487027_1183 has already been started (though not completed), and thus cannot be created.
2017-05-20 12:43:01,585 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-8903787637240487027_1183 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 12:43:01,586 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8903787637240487027_1183 src: /192.168.1.156:42012 dest: /192.168.1.156:50010 of size 91176
2017-05-20 12:43:04,542 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8903787637240487027_1183 to 192.168.1.158:50010, 192.168.1.157:50010
2017-05-20 12:43:04,547 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-8903787637240487027_1183 to /192.168.1.158:50010
2017-05-20 12:43:04,577 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8115894856999281430_1185 src: /192.168.1.156:42014 dest: /192.168.1.156:50010
2017-05-20 12:43:04,578 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8115894856999281430_1185 src: /192.168.1.156:42014 dest: /192.168.1.156:50010 of size 13560
2017-05-20 12:43:04,858 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 12:43:05,372 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 12:43:07,542 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8115894856999281430_1185 to 192.168.1.157:50010
2017-05-20 12:43:07,544 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-8115894856999281430_1185 to /192.168.1.157:50010
2017-05-20 12:43:09,032 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 12:43:10,034 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 12:43:10,328 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 12:43:10,579 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2334952602467381964_1184 src: /192.168.1.156:42030 dest: /192.168.1.156:50010
2017-05-20 12:43:10,580 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2334952602467381964_1184 src: /192.168.1.156:42030 dest: /192.168.1.156:50010 of size 4325
2017-05-20 12:43:13,065 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 12:43:37,607 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1048614692780126768_1190 src: /192.168.1.157:34532 dest: /192.168.1.157:50010
2017-05-20 12:43:37,925 INFO org.apache.hadoop.dfs.DataNode: Exception in receiveBlock for block blk_1048614692780126768_1190 org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
2017-05-20 12:43:37,925 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1048614692780126768_1190 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
2017-05-20 12:43:37,926 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
	at org.apache.hadoop.dfs.DataNode.checkDiskError(DataNode.java:595)
	at org.apache.hadoop.dfs.DataNode.access$1500(DataNode.java:83)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receivePacket(DataNode.java:2645)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2698)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 12:43:52,560 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9180711583352181502_1187 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9180711583352181502
2017-05-20 12:43:52,560 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8903787637240487027_1183 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8903787637240487027
2017-05-20 12:43:52,560 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8115894856999281430_1185 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8115894856999281430
2017-05-20 12:43:52,561 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2334952602467381964_1184 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2334952602467381964
2017-05-20 12:43:56,821 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 12:44:09,616 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 12:44:09,809 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 12:44:09,810 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 12:44:09,812 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 12:44:09,875 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 12:44:09,932 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 12:44:09,933 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 12:44:09,933 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 12:44:10,181 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 12:44:10,223 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 12:44:10,227 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 12:44:10,227 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-20 12:44:10,232 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 12:44:10,250 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 12:44:10,255 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 12:44:10,256 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 12:44:10,257 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 12:44:10,258 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 12:44:10,259 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 12:44:10,259 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 12:44:10,271 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 12:44:10,272 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 12:44:10,284 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 12:44:13,284 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 12 msecs
2017-05-20 12:44:20,221 WARN org.apache.hadoop.dfs.DataNode:  Could not read or failed to veirfy checksum for data at offset 12451840 for block blk_1048614692780126768_1190 got : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 12:44:20,222 WARN org.apache.hadoop.dfs.DataBlockScanner: First Verification failed for blk_1048614692780126768_1190. Exception : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 12:44:32,219 WARN org.apache.hadoop.dfs.DataNode:  Could not read or failed to veirfy checksum for data at offset 12451840 for block blk_1048614692780126768_1190 got : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 12:44:32,219 WARN org.apache.hadoop.dfs.DataBlockScanner: Second Verification failed for blk_1048614692780126768_1190. Exception : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 12:44:32,220 INFO org.apache.hadoop.dfs.DataBlockScanner: Reporting bad block blk_1048614692780126768_1190 to namenode.
2017-05-20 12:44:49,309 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1048614692780126768_1190 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1048614692780126768
2017-05-20 12:45:22,318 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9057878651116964152_1192 src: /192.168.1.157:34547 dest: /192.168.1.157:50010
2017-05-20 12:45:22,326 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9057878651116964152_1192 src: /192.168.1.157:34547 dest: /192.168.1.157:50010 of size 91176
2017-05-20 12:45:25,346 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1618911755584337763_1194 src: /192.168.1.156:42072 dest: /192.168.1.156:50010
2017-05-20 12:45:25,352 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1618911755584337763_1194 src: /192.168.1.156:42072 dest: /192.168.1.156:50010 of size 13560
2017-05-20 12:45:25,368 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6808211329865628387_1193 src: /192.168.1.158:52960 dest: /192.168.1.158:50010
2017-05-20 12:45:25,369 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6808211329865628387_1193 src: /192.168.1.158:52960 dest: /192.168.1.158:50010 of size 4325
2017-05-20 12:45:25,797 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 12:45:31,337 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1371130333425245819_1196 src: /192.168.1.156:42087 dest: /192.168.1.156:50010
2017-05-20 12:45:31,339 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1371130333425245819_1196 src: /192.168.1.156:42087 dest: /192.168.1.156:50010 of size 13545
2017-05-20 12:45:38,814 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 12:46:01,351 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5706818918704357859_1198 src: /192.168.1.156:42098 dest: /192.168.1.156:50010
2017-05-20 12:46:02,017 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5706818918704357859_1198 src: /192.168.1.156:42098 dest: /192.168.1.156:50010 of size 31976695
2017-05-20 12:46:10,363 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9057878651116964152_1192 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9057878651116964152
2017-05-20 12:46:10,363 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6808211329865628387_1193 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6808211329865628387
2017-05-20 12:46:10,376 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5706818918704357859_1198 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5706818918704357859
2017-05-20 12:46:10,377 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1618911755584337763_1194 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1618911755584337763
2017-05-20 12:46:10,377 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1371130333425245819_1196 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1371130333425245819
2017-05-20 12:46:14,947 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 12:46:27,710 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 12:46:27,892 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 12:46:27,894 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 12:46:27,895 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 12:46:27,962 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 12:46:28,020 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 12:46:28,021 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 12:46:28,021 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 12:46:28,263 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 12:46:28,296 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 12:46:28,299 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 12:46:28,299 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-20 12:46:28,304 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 12:46:28,325 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 12:46:28,332 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 12:46:28,333 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 12:46:28,333 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 12:46:28,333 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 12:46:28,333 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 12:46:28,333 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 12:46:28,337 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 12:46:28,337 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 12:46:28,345 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 12:46:31,344 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 4 msecs
2017-05-20 12:47:38,614 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 12:47:38,639 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 12:47:40,290 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8431028378405737353_1202 src: /192.168.1.158:53004 dest: /192.168.1.158:50010
2017-05-20 12:47:40,302 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8431028378405737353_1202 src: /192.168.1.158:53004 dest: /192.168.1.158:50010 of size 2165
2017-05-20 12:47:40,380 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7520323630413999980_1201 src: /192.168.1.156:42114 dest: /192.168.1.156:50010
2017-05-20 12:47:40,391 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7520323630413999980_1201 src: /192.168.1.156:42114 dest: /192.168.1.156:50010 of size 91176
2017-05-20 12:47:43,393 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7520323630413999980_1201 to 192.168.1.157:50010
2017-05-20 12:47:43,397 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-7520323630413999980_1201 to /192.168.1.157:50010
2017-05-20 12:47:43,652 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 12:47:44,089 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 12:47:46,412 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6573087680823364010_1203 src: /192.168.1.157:34601 dest: /192.168.1.157:50010
2017-05-20 12:47:46,414 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6573087680823364010_1203 src: /192.168.1.157:34601 dest: /192.168.1.157:50010 of size 13560
2017-05-20 12:47:49,376 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2416537593116340412_1205 src: /192.168.1.156:42127 dest: /192.168.1.156:50010
2017-05-20 12:47:49,378 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2416537593116340412_1205 src: /192.168.1.156:42127 dest: /192.168.1.156:50010 of size 13545
2017-05-20 12:48:13,406 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2746071512435465747_1208 src: /192.168.1.157:34613 dest: /192.168.1.157:50010
2017-05-20 12:48:14,097 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2746071512435465747_1208 src: /192.168.1.157:34613 dest: /192.168.1.157:50010 of size 31964396
2017-05-20 12:48:16,398 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1533376755119853726_1208 src: /192.168.1.156:42141 dest: /192.168.1.156:50010
2017-05-20 12:48:16,891 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1533376755119853726_1208 src: /192.168.1.156:42141 dest: /192.168.1.156:50010 of size 31980463
2017-05-20 12:48:19,403 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2874123130982772006_1209 src: /192.168.1.157:34614 dest: /192.168.1.157:50010
2017-05-20 12:48:19,413 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2746071512435465747_1208 to 192.168.1.158:50010
2017-05-20 12:48:19,414 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1533376755119853726_1208 to 192.168.1.157:50010
2017-05-20 12:48:20,177 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-2746071512435465747_1208 to /192.168.1.158:50010
2017-05-20 12:48:20,398 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-1533376755119853726_1208 to /192.168.1.157:50010
2017-05-20 12:48:20,619 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2874123130982772006_1209 src: /192.168.1.157:34614 dest: /192.168.1.157:50010 of size 31976695
2017-05-20 12:48:22,405 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5395906375395331687_1206 src: /192.168.1.156:42144 dest: /192.168.1.156:50010
2017-05-20 12:48:23,197 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5395906375395331687_1206 src: /192.168.1.156:42144 dest: /192.168.1.156:50010 of size 31981189
2017-05-20 12:48:28,434 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8431028378405737353_1202 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8431028378405737353
2017-05-20 12:48:28,434 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7520323630413999980_1201 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7520323630413999980
2017-05-20 12:48:28,434 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6573087680823364010_1203 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6573087680823364010
2017-05-20 12:48:28,442 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2874123130982772006_1209 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2874123130982772006
2017-05-20 12:48:28,449 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2746071512435465747_1208 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2746071512435465747
2017-05-20 12:48:28,450 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2416537593116340412_1205 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2416537593116340412
2017-05-20 12:48:28,456 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1533376755119853726_1208 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1533376755119853726
2017-05-20 12:48:32,478 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 12:48:45,262 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 12:48:45,454 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 12:48:45,456 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 12:48:45,458 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 12:48:45,521 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 12:48:45,570 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 12:48:45,571 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 12:48:45,571 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 12:48:45,791 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 12:48:45,827 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 12:48:45,829 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 12:48:45,829 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 12:48:45,834 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 12:48:45,856 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 12:48:45,861 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 12:48:45,862 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 12:48:45,863 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 12:48:45,863 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 12:48:45,864 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 12:48:45,864 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 12:48:45,866 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 12:48:45,867 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 12:48:45,878 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 12:48:48,878 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 11 msecs
2017-05-20 12:49:14,667 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-5395906375395331687_1206
2017-05-20 12:49:21,907 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5395906375395331687_1206 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5395906375395331687
2017-05-20 12:49:55,002 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7445486344387040429_1210 src: /192.168.1.158:53025 dest: /192.168.1.158:50010
2017-05-20 12:49:55,016 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7445486344387040429_1210 src: /192.168.1.158:53025 dest: /192.168.1.158:50010 of size 91176
2017-05-20 12:49:55,190 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-7445486344387040429_1210 to /192.168.1.159
2017-05-20 12:49:55,191 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-7445486344387040429_1210 to /192.168.1.157
2017-05-20 12:49:56,242 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 12:50:00,908 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6593603360348242137_1211 src: /192.168.1.157:34629 dest: /192.168.1.157:50010
2017-05-20 12:50:00,910 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6593603360348242137_1211 src: /192.168.1.157:34629 dest: /192.168.1.157:50010 of size 2165
2017-05-20 12:50:03,908 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4367454934007555383_1212 src: /192.168.1.157:34638 dest: /192.168.1.157:50010
2017-05-20 12:50:03,909 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4367454934007555383_1212 src: /192.168.1.157:34638 dest: /192.168.1.157:50010 of size 13560
2017-05-20 12:50:03,961 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6470592937962978127_1214 src: /192.168.1.156:42171 dest: /192.168.1.156:50010
2017-05-20 12:50:03,982 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6470592937962978127_1214 src: /192.168.1.156:42171 dest: /192.168.1.156:50010 of size 13545
2017-05-20 12:50:05,980 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 12:50:06,911 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_6470592937962978127_1214 to 192.168.1.158:50010
2017-05-20 12:50:06,913 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_6470592937962978127_1214 to /192.168.1.158:50010
2017-05-20 12:50:11,219 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-7542597023824073767_1001 to /192.168.1.159
2017-05-20 12:50:11,590 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 12:50:30,972 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5900643348198671408_1216 src: /192.168.1.156:42182 dest: /192.168.1.156:50010
2017-05-20 12:50:31,781 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5900643348198671408_1216 src: /192.168.1.156:42182 dest: /192.168.1.156:50010 of size 31980463
2017-05-20 12:50:33,921 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-5900643348198671408_1216 to 192.168.1.158:50010
2017-05-20 12:50:34,439 WARN org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Failed to transfer blk_-5900643348198671408_1216 to 192.168.1.158:50010 got java.net.SocketException: Original Exception : java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileChannelImpl.transferTo0(Native Method)
	at sun.nio.ch.FileChannelImpl.transferToDirectly(FileChannelImpl.java:420)
	at sun.nio.ch.FileChannelImpl.transferTo(FileChannelImpl.java:552)
	at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:199)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1873)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataNode$DataTransfer.run(DataNode.java:2855)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	... 8 more

2017-05-20 12:50:36,976 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7815214483248403507_1215 src: /192.168.1.156:42184 dest: /192.168.1.156:50010
2017-05-20 12:50:37,591 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7815214483248403507_1215 src: /192.168.1.156:42184 dest: /192.168.1.156:50010 of size 31981189
2017-05-20 12:50:45,945 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7815214483248403507_1215 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7815214483248403507
2017-05-20 12:50:45,946 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7445486344387040429_1210 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7445486344387040429
2017-05-20 12:50:45,946 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6593603360348242137_1211 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6593603360348242137
2017-05-20 12:50:45,952 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5900643348198671408_1216 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5900643348198671408
2017-05-20 12:50:45,953 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4367454934007555383_1212 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4367454934007555383
2017-05-20 12:50:45,953 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6470592937962978127_1214 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6470592937962978127
2017-05-20 12:50:49,951 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 12:51:02,688 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 12:51:02,880 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 12:51:02,881 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 12:51:02,883 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 12:51:02,944 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 12:51:02,990 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 12:51:02,991 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 12:51:02,991 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 12:51:03,208 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 12:51:03,245 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 12:51:03,247 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 12:51:03,247 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 12:51:03,252 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 12:51:03,269 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 12:51:03,273 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 12:51:03,274 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 12:51:03,275 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 12:51:03,276 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 12:51:03,276 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 12:51:03,276 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 12:51:03,295 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 12:51:03,295 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 12:51:03,308 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 12:51:06,309 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 13 msecs
2017-05-20 12:52:00,340 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 4 msecs
2017-05-20 12:52:15,382 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8772961784092044195_1219 src: /192.168.1.157:34664 dest: /192.168.1.157:50010
2017-05-20 12:52:15,401 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8772961784092044195_1219 src: /192.168.1.157:34664 dest: /192.168.1.157:50010 of size 91176
2017-05-20 12:52:15,480 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3188912769611281817_1221 src: /192.168.1.156:42203 dest: /192.168.1.156:50010
2017-05-20 12:52:15,481 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3188912769611281817_1221 src: /192.168.1.156:42203 dest: /192.168.1.156:50010 of size 13560
2017-05-20 12:52:18,349 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-3188912769611281817_1221 to 192.168.1.158:50010
2017-05-20 12:52:18,352 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-3188912769611281817_1221 to /192.168.1.158:50010
2017-05-20 12:52:18,484 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1513104618154673050_1223 src: /192.168.1.158:53065 dest: /192.168.1.158:50010
2017-05-20 12:52:18,484 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1513104618154673050_1223 src: /192.168.1.158:53065 dest: /192.168.1.158:50010 of size 13545
2017-05-20 12:52:18,815 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 12:52:21,349 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1513104618154673050_1223 to 192.168.1.157:50010
2017-05-20 12:52:21,351 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-1513104618154673050_1223 to /192.168.1.157:50010
2017-05-20 12:52:23,208 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 12:52:24,383 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2474811253940046269_1220 src: /192.168.1.157:34675 dest: /192.168.1.157:50010
2017-05-20 12:52:24,383 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2474811253940046269_1220 src: /192.168.1.157:34675 dest: /192.168.1.157:50010 of size 2165
2017-05-20 12:52:25,438 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 12:52:28,797 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 12:52:48,504 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7156505690241516821_1227 src: /192.168.1.158:53085 dest: /192.168.1.158:50010
2017-05-20 12:52:49,274 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7156505690241516821_1227 src: /192.168.1.158:53085 dest: /192.168.1.158:50010 of size 31964396
2017-05-20 12:52:51,362 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7156505690241516821_1227 to 192.168.1.157:50010
2017-05-20 12:52:51,973 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-7156505690241516821_1227 to /192.168.1.157:50010
2017-05-20 12:52:54,354 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3272519396087901780_1227 src: /192.168.1.157:34684 dest: /192.168.1.157:50010
2017-05-20 12:52:54,514 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7589581141175605254_1227 src: /192.168.1.158:53087 dest: /192.168.1.158:50010
2017-05-20 12:52:55,176 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3272519396087901780_1227 src: /192.168.1.157:34684 dest: /192.168.1.157:50010 of size 31981189
2017-05-20 12:52:55,552 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7589581141175605254_1227 src: /192.168.1.158:53087 dest: /192.168.1.158:50010 of size 31976695
2017-05-20 12:53:00,365 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8772961784092044195_1219 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8772961784092044195
2017-05-20 12:53:00,373 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7156505690241516821_1227 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7156505690241516821
2017-05-20 12:53:00,373 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3188912769611281817_1221 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3188912769611281817
2017-05-20 12:53:00,373 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1513104618154673050_1223 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1513104618154673050
2017-05-20 12:53:00,374 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2474811253940046269_1220 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2474811253940046269
2017-05-20 13:52:00,478 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 10 blocks got processed in 4 msecs
2017-05-20 13:52:03,486 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7589581141175605254_1227 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7589581141175605254
2017-05-20 13:52:03,495 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3272519396087901780_1227 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3272519396087901780
2017-05-20 14:52:02,711 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 15:28:14,653 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 15:28:27,477 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 15:28:27,673 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 15:28:27,674 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 15:28:27,676 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 15:28:27,748 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 15:28:27,805 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 15:28:27,806 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 15:28:27,806 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 15:28:28,043 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 15:28:28,079 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 15:28:28,082 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 15:28:28,082 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 15:28:28,087 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 15:28:28,104 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 15:28:28,108 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 15:28:28,109 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 15:28:28,110 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 15:28:28,111 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 15:28:28,111 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 15:28:28,111 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 15:28:28,114 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 15:28:28,114 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 15:28:28,121 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 15:28:31,120 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 15:28:37,125 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 4 msecs
2017-05-20 15:29:37,219 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5769381053227297805_1232 src: /192.168.1.156:42230 dest: /192.168.1.156:50010
2017-05-20 15:29:37,235 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5769381053227297805_1232 src: /192.168.1.156:42230 dest: /192.168.1.156:50010 of size 13545
2017-05-20 15:29:40,175 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-5769381053227297805_1232 to 192.168.1.157:50010
2017-05-20 15:29:40,183 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-5769381053227297805_1232 to /192.168.1.157:50010
2017-05-20 15:29:43,127 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4890295802189794743_1229 src: /192.168.1.158:53099 dest: /192.168.1.158:50010
2017-05-20 15:29:43,128 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4890295802189794743_1229 src: /192.168.1.158:53099 dest: /192.168.1.158:50010 of size 2165
2017-05-20 15:29:43,195 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_385642091513209318_1228 src: /192.168.1.157:34697 dest: /192.168.1.157:50010
2017-05-20 15:29:43,197 INFO org.apache.hadoop.dfs.DataNode: Received block blk_385642091513209318_1228 src: /192.168.1.157:34697 dest: /192.168.1.157:50010 of size 91176
2017-05-20 15:29:46,175 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_385642091513209318_1228 to 192.168.1.158:50010
2017-05-20 15:29:46,179 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_385642091513209318_1228 to /192.168.1.158:50010
2017-05-20 15:29:46,186 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8702014088362674328_1230 src: /192.168.1.156:42251 dest: /192.168.1.156:50010
2017-05-20 15:29:46,187 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8702014088362674328_1230 src: /192.168.1.156:42251 dest: /192.168.1.156:50010 of size 13560
2017-05-20 15:29:47,755 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 15:29:48,370 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 15:29:51,394 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 15:29:52,586 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 15:30:01,550 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-7542597023824073767_1001 to /192.168.1.159
2017-05-20 15:30:22,218 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5222571328589274924_1233 src: /192.168.1.158:53119 dest: /192.168.1.158:50010
2017-05-20 15:30:23,012 INFO org.apache.hadoop.dfs.DataNode: Exception in receiveBlock for block blk_5222571328589274924_1233 org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
2017-05-20 15:30:23,013 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5222571328589274924_1233 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
2017-05-20 15:30:23,015 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
	at org.apache.hadoop.dfs.DataNode.checkDiskError(DataNode.java:595)
	at org.apache.hadoop.dfs.DataNode.access$1500(DataNode.java:83)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receivePacket(DataNode.java:2645)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2698)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 15:30:25,205 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5222571328589274924_1233 src: /192.168.1.156:42270 dest: /192.168.1.156:50010
2017-05-20 15:30:25,205 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5222571328589274924_1233 received exception java.io.IOException: Block blk_5222571328589274924_1233 has already been started (though not completed), and thus cannot be created.
2017-05-20 15:30:25,206 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_5222571328589274924_1233 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 15:30:37,204 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5769381053227297805_1232 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5769381053227297805
2017-05-20 15:30:37,206 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4890295802189794743_1229 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4890295802189794743
2017-05-20 15:30:37,206 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_385642091513209318_1228 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_385642091513209318
2017-05-20 15:30:37,206 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8702014088362674328_1230 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8702014088362674328
2017-05-20 15:30:39,299 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 15:30:52,054 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 15:30:52,238 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 15:30:52,239 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 15:30:52,241 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 15:30:52,303 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 15:30:52,351 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 15:30:52,351 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 15:30:52,351 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 15:30:52,561 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 15:30:52,593 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 15:30:52,595 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 15:30:52,595 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-20 15:30:52,600 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 15:30:52,614 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 15:30:52,618 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 15:30:52,619 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 15:30:52,620 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 15:30:52,621 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 15:30:52,621 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 15:30:52,621 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 15:30:52,639 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 15:30:52,640 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 15:30:52,650 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 15:30:55,653 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 13 msecs
2017-05-20 15:31:17,650 WARN org.apache.hadoop.dfs.DataNode:  Could not read or failed to veirfy checksum for data at offset 28049408 for block blk_5222571328589274924_1233 got : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 15:31:17,651 WARN org.apache.hadoop.dfs.DataBlockScanner: First Verification failed for blk_5222571328589274924_1233. Exception : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 15:31:31,743 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5222571328589274924_1233 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5222571328589274924
2017-05-20 15:31:44,648 WARN org.apache.hadoop.dfs.DataNode:  Could not read or failed to veirfy checksum for data at offset 28049408 for block blk_5222571328589274924_1233 got : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 15:31:44,658 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification failed for blk_5222571328589274924_1233. Its ok since it not in datanode dataset anymore.
2017-05-20 15:32:01,749 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4470793424324442009_1238 src: /192.168.1.156:42276 dest: /192.168.1.156:50010
2017-05-20 15:32:01,766 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4470793424324442009_1238 src: /192.168.1.156:42276 dest: /192.168.1.156:50010 of size 2165
2017-05-20 15:32:02,997 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 15:32:07,733 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_773281780994906013_1239 src: /192.168.1.156:42289 dest: /192.168.1.156:50010
2017-05-20 15:32:07,738 INFO org.apache.hadoop.dfs.DataNode: Received block blk_773281780994906013_1239 src: /192.168.1.156:42289 dest: /192.168.1.156:50010 of size 13560
2017-05-20 15:32:07,747 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4257240529744812283_1237 src: /192.168.1.158:53135 dest: /192.168.1.158:50010
2017-05-20 15:32:07,750 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4257240529744812283_1237 src: /192.168.1.158:53135 dest: /192.168.1.158:50010 of size 91176
2017-05-20 15:32:08,194 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 15:32:10,809 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_773281780994906013_1239 to 192.168.1.158:50010
2017-05-20 15:32:10,813 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_773281780994906013_1239 to /192.168.1.158:50010
2017-05-20 15:32:13,718 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7954708121658996491_1241 src: /192.168.1.157:34732 dest: /192.168.1.157:50010
2017-05-20 15:32:13,719 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7954708121658996491_1241 src: /192.168.1.157:34732 dest: /192.168.1.157:50010 of size 13545
2017-05-20 15:32:46,755 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7669161022236743539_1242 src: /192.168.1.156:42313 dest: /192.168.1.156:50010
2017-05-20 15:32:47,395 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7669161022236743539_1242 src: /192.168.1.156:42313 dest: /192.168.1.156:50010 of size 31976695
2017-05-20 15:32:49,762 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-817997057879097636_1243 src: /192.168.1.158:53154 dest: /192.168.1.158:50010
2017-05-20 15:32:50,408 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-817997057879097636_1243 src: /192.168.1.158:53154 dest: /192.168.1.158:50010 of size 31980463
2017-05-20 15:32:52,835 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-817997057879097636_1243 to 192.168.1.157:50010
2017-05-20 15:32:53,739 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-817997057879097636_1243 to /192.168.1.157:50010
2017-05-20 15:32:55,756 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1340883963173191429_1245 src: /192.168.1.156:42317 dest: /192.168.1.156:50010
2017-05-20 15:32:55,760 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1340883963173191429_1245 src: /192.168.1.156:42317 dest: /192.168.1.156:50010 of size 23481
2017-05-20 15:33:01,828 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4470793424324442009_1238 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4470793424324442009
2017-05-20 15:33:01,828 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4257240529744812283_1237 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4257240529744812283
2017-05-20 15:33:01,841 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-817997057879097636_1243 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-817997057879097636
2017-05-20 15:33:01,841 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_773281780994906013_1239 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_773281780994906013
2017-05-20 15:33:01,846 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7669161022236743539_1242 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7669161022236743539
2017-05-20 15:33:01,846 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7954708121658996491_1241 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7954708121658996491
2017-05-20 15:33:04,768 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 15:33:17,595 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 15:33:17,779 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 15:33:17,781 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 15:33:17,782 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 15:33:17,848 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 15:33:17,905 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 15:33:17,906 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 15:33:17,906 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 15:33:18,141 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 15:33:18,178 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 15:33:18,180 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 15:33:18,180 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@5876a5
2017-05-20 15:33:18,186 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 15:33:18,202 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 15:33:18,208 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 15:33:18,209 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 15:33:18,210 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 15:33:18,211 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 15:33:18,211 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 15:33:18,212 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 15:33:18,223 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 15:33:18,224 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 15:33:18,238 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 15:33:18,264 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_1340883963173191429_1245
2017-05-20 15:33:21,237 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 12 msecs
2017-05-20 15:33:54,284 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1340883963173191429_1245 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1340883963173191429
2017-05-20 15:34:27,337 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6769226047844736999_1247 src: /192.168.1.157:34754 dest: /192.168.1.157:50010
2017-05-20 15:34:27,354 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6769226047844736999_1247 src: /192.168.1.157:34754 dest: /192.168.1.157:50010 of size 2165
2017-05-20 15:34:28,648 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 15:34:30,300 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6769226047844736999_1247 to 192.168.1.158:50010
2017-05-20 15:34:30,306 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-6769226047844736999_1247 to /192.168.1.158:50010
2017-05-20 15:34:30,309 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1364220210759458503_1246 src: /192.168.1.156:42330 dest: /192.168.1.156:50010
2017-05-20 15:34:30,313 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1364220210759458503_1246 src: /192.168.1.156:42330 dest: /192.168.1.156:50010 of size 91176
2017-05-20 15:34:36,290 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3802672631631044965_1248 src: /192.168.1.157:34772 dest: /192.168.1.157:50010
2017-05-20 15:34:36,292 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3802672631631044965_1248 src: /192.168.1.157:34772 dest: /192.168.1.157:50010 of size 13560
2017-05-20 15:34:36,304 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3963304096024526460_1250 src: /192.168.1.156:42338 dest: /192.168.1.156:50010
2017-05-20 15:34:36,304 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3963304096024526460_1250 src: /192.168.1.156:42338 dest: /192.168.1.156:50010 of size 13545
2017-05-20 15:34:38,092 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 15:34:41,371 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 15:34:42,737 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 15:35:03,320 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1294257847575853809_1251 src: /192.168.1.156:42359 dest: /192.168.1.156:50010
2017-05-20 15:35:04,026 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1294257847575853809_1251 src: /192.168.1.156:42359 dest: /192.168.1.156:50010 of size 31981189
2017-05-20 15:35:06,324 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_1294257847575853809_1251 to 192.168.1.157:50010
2017-05-20 15:35:07,230 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_1294257847575853809_1251 to /192.168.1.157:50010
2017-05-20 15:35:09,317 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6070115685333914752_1253 src: /192.168.1.156:42362 dest: /192.168.1.156:50010
2017-05-20 15:35:10,072 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6070115685333914752_1253 src: /192.168.1.156:42362 dest: /192.168.1.156:50010 of size 31964396
2017-05-20 15:35:12,319 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7871633748215053874_1252 src: /192.168.1.156:42363 dest: /192.168.1.156:50010
2017-05-20 15:35:12,864 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7871633748215053874_1252 src: /192.168.1.156:42363 dest: /192.168.1.156:50010 of size 31980463
2017-05-20 15:35:18,342 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6769226047844736999_1247 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6769226047844736999
2017-05-20 15:35:18,352 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6070115685333914752_1253 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6070115685333914752
2017-05-20 15:35:18,352 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1364220210759458503_1246 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1364220210759458503
2017-05-20 15:35:18,358 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1294257847575853809_1251 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1294257847575853809
2017-05-20 15:35:18,358 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3802672631631044965_1248 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3802672631631044965
2017-05-20 15:35:18,358 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3963304096024526460_1250 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3963304096024526460
2017-05-20 15:35:22,413 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 15:35:35,183 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 15:35:35,363 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 15:35:35,365 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 15:35:35,367 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 15:35:35,436 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 15:35:35,494 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 15:35:35,495 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 15:35:35,495 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 15:35:35,715 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 15:35:35,747 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 15:35:35,749 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 15:35:35,749 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 15:35:35,754 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 15:35:35,769 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 15:35:35,773 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 15:35:35,774 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 15:35:35,775 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 15:35:35,776 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 15:35:35,776 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 15:35:35,776 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 15:35:35,810 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 15:35:35,810 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 15:35:35,820 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 15:35:38,829 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 19 msecs
2017-05-20 15:36:04,573 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_7871633748215053874_1252
2017-05-20 15:36:11,858 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7871633748215053874_1252 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7871633748215053874
2017-05-20 15:36:44,930 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2769190571222077523_1256 src: /192.168.1.158:53188 dest: /192.168.1.158:50010
2017-05-20 15:36:44,947 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2769190571222077523_1256 src: /192.168.1.158:53188 dest: /192.168.1.158:50010 of size 2165
2017-05-20 15:36:46,137 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 15:36:46,200 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 15:36:47,859 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2769190571222077523_1256 to 192.168.1.157:50010
2017-05-20 15:36:47,865 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-2769190571222077523_1256 to /192.168.1.157:50010
2017-05-20 15:36:50,861 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-631967989048498008_1257 src: /192.168.1.157:34798 dest: /192.168.1.157:50010
2017-05-20 15:36:50,861 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-631967989048498008_1257 src: /192.168.1.157:34798 dest: /192.168.1.157:50010 of size 13560
2017-05-20 15:36:50,894 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1305040229604653055_1255 src: /192.168.1.156:42379 dest: /192.168.1.156:50010
2017-05-20 15:36:50,898 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1305040229604653055_1255 src: /192.168.1.156:42379 dest: /192.168.1.156:50010 of size 91176
2017-05-20 15:36:51,321 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 15:36:53,859 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_1305040229604653055_1255 to 192.168.1.157:50010
2017-05-20 15:36:53,863 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_1305040229604653055_1255 to /192.168.1.157:50010
2017-05-20 15:36:56,857 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2019958679723975687_1259 src: /192.168.1.157:34804 dest: /192.168.1.157:50010
2017-05-20 15:36:56,863 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2019958679723975687_1259 src: /192.168.1.157:34804 dest: /192.168.1.157:50010 of size 13545
2017-05-20 15:37:07,681 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-7542597023824073767_1001 to /192.168.1.159
2017-05-20 15:37:20,913 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1774859080797615560_1262 src: /192.168.1.156:42401 dest: /192.168.1.156:50010
2017-05-20 15:37:21,536 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1774859080797615560_1262 src: /192.168.1.156:42401 dest: /192.168.1.156:50010 of size 31981189
2017-05-20 15:37:23,870 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1774859080797615560_1262 to 192.168.1.157:50010
2017-05-20 15:37:24,805 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-1774859080797615560_1262 to /192.168.1.157:50010
2017-05-20 15:37:29,872 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2769190571222077523_1256 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2769190571222077523
2017-05-20 15:37:29,884 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1774859080797615560_1262 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1774859080797615560
2017-05-20 15:37:29,885 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-631967989048498008_1257 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-631967989048498008
2017-05-20 15:37:29,885 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1305040229604653055_1255 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1305040229604653055
2017-05-20 15:37:29,885 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2019958679723975687_1259 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2019958679723975687
2017-05-20 15:37:34,039 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 15:37:46,908 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 15:37:47,107 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 15:37:47,109 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 15:37:47,110 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 15:37:47,167 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 15:37:47,217 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 15:37:47,217 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 15:37:47,217 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 15:37:47,435 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 15:37:47,476 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 15:37:47,488 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 15:37:47,488 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 15:37:47,494 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 15:37:47,513 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 15:37:47,517 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 15:37:47,518 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 15:37:47,519 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 15:37:47,520 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 15:37:47,520 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 15:37:47,520 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 15:37:47,522 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 15:37:47,523 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 15:37:47,530 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 15:37:50,529 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-05-20 15:38:56,507 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5228047250567860655_1265 src: /192.168.1.158:53221 dest: /192.168.1.158:50010
2017-05-20 15:38:56,520 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5228047250567860655_1265 src: /192.168.1.158:53221 dest: /192.168.1.158:50010 of size 2165
2017-05-20 15:38:57,792 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 15:38:59,456 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1776901883000222831_1264 src: /192.168.1.156:42417 dest: /192.168.1.156:50010
2017-05-20 15:38:59,464 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1776901883000222831_1264 src: /192.168.1.156:42418 dest: /192.168.1.156:50010
2017-05-20 15:38:59,464 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1776901883000222831_1264 received exception java.io.IOException: Block blk_1776901883000222831_1264 has already been started (though not completed), and thus cannot be created.
2017-05-20 15:38:59,465 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_1776901883000222831_1264 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 15:38:59,469 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1776901883000222831_1264 src: /192.168.1.156:42417 dest: /192.168.1.156:50010 of size 91176
2017-05-20 15:39:02,457 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4609342238503908421_1266 src: /192.168.1.157:34830 dest: /192.168.1.157:50010
2017-05-20 15:39:02,459 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4609342238503908421_1266 src: /192.168.1.157:34830 dest: /192.168.1.157:50010 of size 13560
2017-05-20 15:39:02,561 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_1776901883000222831_1264 to 192.168.1.158:50010, 192.168.1.157:50010
2017-05-20 15:39:02,565 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_1776901883000222831_1264 to /192.168.1.158:50010
2017-05-20 15:39:06,900 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 15:39:08,592 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4945292480877293974_1268 src: /192.168.1.157:34838 dest: /192.168.1.157:50010
2017-05-20 15:39:08,594 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4945292480877293974_1268 src: /192.168.1.157:34838 dest: /192.168.1.157:50010 of size 13545
2017-05-20 15:39:10,932 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 15:39:12,401 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 15:39:21,133 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-7542597023824073767_1001 to /192.168.1.159
2017-05-20 15:39:36,834 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_4609342238503908421_1266
2017-05-20 15:39:41,606 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3120973249717211131_1269 src: /192.168.1.157:34855 dest: /192.168.1.157:50010
2017-05-20 15:39:42,277 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3120973249717211131_1269 src: /192.168.1.157:34855 dest: /192.168.1.157:50010 of size 31980463
2017-05-20 15:39:44,491 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-901103418239703752_1270 src: /192.168.1.158:53246 dest: /192.168.1.158:50010
2017-05-20 15:39:45,244 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-901103418239703752_1270 src: /192.168.1.158:53246 dest: /192.168.1.158:50010 of size 31976695
2017-05-20 15:39:47,587 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-901103418239703752_1270 to 192.168.1.157:50010
2017-05-20 15:39:48,263 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-901103418239703752_1270 to /192.168.1.157:50010
2017-05-20 15:39:50,493 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5839813096690931073_1272 src: /192.168.1.158:53247 dest: /192.168.1.158:50010
2017-05-20 15:39:50,494 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5839813096690931073_1272 src: /192.168.1.158:53247 dest: /192.168.1.158:50010 of size 23481
2017-05-20 15:39:56,581 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5228047250567860655_1265 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5228047250567860655
2017-05-20 15:39:56,592 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-901103418239703752_1270 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-901103418239703752
2017-05-20 15:39:56,593 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1776901883000222831_1264 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1776901883000222831
2017-05-20 15:39:56,600 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3120973249717211131_1269 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3120973249717211131
2017-05-20 15:39:56,600 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4609342238503908421_1266 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4609342238503908421
2017-05-20 15:39:56,600 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4945292480877293974_1268 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4945292480877293974
2017-05-20 15:39:58,456 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 15:40:11,365 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 15:40:11,571 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 15:40:11,573 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 15:40:11,574 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 15:40:11,648 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 15:40:11,707 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 15:40:11,708 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 15:40:11,708 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 15:40:11,947 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@14a8af0
2017-05-20 15:40:11,983 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 15:40:11,985 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 15:40:11,985 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-20 15:40:11,991 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 15:40:12,014 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 15:40:12,019 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 15:40:12,020 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 15:40:12,020 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 15:40:12,020 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 15:40:12,021 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 15:40:12,021 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 15:40:12,023 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 15:40:12,023 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 15:40:12,031 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 15:40:12,056 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_5839813096690931073_1272
2017-05-20 15:40:15,028 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 5 msecs
2017-05-20 15:40:48,050 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5839813096690931073_1272 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5839813096690931073
2017-05-20 15:41:21,092 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2963120909827108731_1275 src: /192.168.1.156:42446 dest: /192.168.1.156:50010
2017-05-20 15:41:21,110 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2963120909827108731_1275 src: /192.168.1.156:42446 dest: /192.168.1.156:50010 of size 13560
2017-05-20 15:41:21,306 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-2963120909827108731_1275 to /192.168.1.159
2017-05-20 15:41:22,336 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 15:41:22,354 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 15:41:24,067 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2963120909827108731_1275 to 192.168.1.157:50010
2017-05-20 15:41:24,073 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-2963120909827108731_1275 to /192.168.1.157:50010
2017-05-20 15:41:27,053 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-394027270644869280_1274 src: /192.168.1.158:53261 dest: /192.168.1.158:50010
2017-05-20 15:41:27,054 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-394027270644869280_1274 src: /192.168.1.158:53261 dest: /192.168.1.158:50010 of size 2165
2017-05-20 15:41:27,076 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_49257505777026265_1273 src: /192.168.1.156:42458 dest: /192.168.1.156:50010
2017-05-20 15:41:27,080 INFO org.apache.hadoop.dfs.DataNode: Received block blk_49257505777026265_1273 src: /192.168.1.156:42458 dest: /192.168.1.156:50010 of size 91176
2017-05-20 15:41:27,400 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 15:41:30,078 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8056882357214193701_1277 src: /192.168.1.156:42465 dest: /192.168.1.156:50010
2017-05-20 15:41:30,088 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8056882357214193701_1277 src: /192.168.1.156:42465 dest: /192.168.1.156:50010 of size 13545
2017-05-20 15:41:43,734 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 15:42:00,074 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8610859372234363607_1278 src: /192.168.1.158:53279 dest: /192.168.1.158:50010
2017-05-20 15:42:00,796 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8610859372234363607_1278 src: /192.168.1.158:53279 dest: /192.168.1.158:50010 of size 31980463
2017-05-20 15:42:06,073 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_583046443154994905_1279 src: /192.168.1.158:53281 dest: /192.168.1.158:50010
2017-05-20 15:42:06,099 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_583046443154994905_1279 src: /192.168.1.156:42485 dest: /192.168.1.156:50010
2017-05-20 15:42:06,100 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_583046443154994905_1279 received exception java.io.IOException: Block blk_583046443154994905_1279 has already been started (though not completed), and thus cannot be created.
2017-05-20 15:42:06,102 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_583046443154994905_1279 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 15:42:06,814 INFO org.apache.hadoop.dfs.DataNode: Received block blk_583046443154994905_1279 src: /192.168.1.158:53281 dest: /192.168.1.158:50010 of size 31976695
2017-05-20 15:42:09,108 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4120050914971116238_1281 src: /192.168.1.157:34890 dest: /192.168.1.157:50010
2017-05-20 15:42:09,899 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4120050914971116238_1281 src: /192.168.1.157:34890 dest: /192.168.1.157:50010 of size 31981189
2017-05-20 15:42:15,100 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2963120909827108731_1275 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2963120909827108731
2017-05-20 15:42:15,101 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-394027270644869280_1274 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-394027270644869280
2017-05-20 15:42:15,101 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_49257505777026265_1273 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_49257505777026265
2017-05-20 15:42:15,111 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_583046443154994905_1279 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_583046443154994905
2017-05-20 15:42:15,111 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8056882357214193701_1277 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8056882357214193701
2017-05-20 15:42:15,118 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8610859372234363607_1278 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8610859372234363607
2017-05-20 15:58:18,709 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 4 msecs
2017-05-20 16:10:02,534 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_4120050914971116238_1281
2017-05-20 16:17:05,347 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 16:17:18,176 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 16:17:18,364 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 16:17:18,365 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 16:17:18,367 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 16:17:18,436 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 16:17:18,493 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 16:17:18,494 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 16:17:18,494 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 16:17:18,725 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 16:17:18,760 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 16:17:18,763 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 16:17:18,763 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 16:17:18,768 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 16:17:18,785 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 16:17:18,790 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 16:17:18,791 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 16:17:18,792 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 16:17:18,792 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 16:17:18,792 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 16:17:18,792 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 16:17:18,800 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 16:17:18,800 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 16:17:18,812 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 16:17:21,817 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 13 msecs
2017-05-20 16:17:57,830 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4120050914971116238_1281 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4120050914971116238
2017-05-20 16:18:29,166 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 16:18:30,908 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7413905864957538438_1283 src: /192.168.1.157:34902 dest: /192.168.1.157:50010
2017-05-20 16:18:30,933 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7413905864957538438_1283 src: /192.168.1.157:34902 dest: /192.168.1.157:50010 of size 2165
2017-05-20 16:18:33,880 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5986954183014352903_1286 src: /192.168.1.158:53292 dest: /192.168.1.158:50010
2017-05-20 16:18:33,883 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5986954183014352903_1286 src: /192.168.1.158:53292 dest: /192.168.1.158:50010 of size 13545
2017-05-20 16:18:33,907 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1690674926461064520_1284 src: /192.168.1.157:34903 dest: /192.168.1.157:50010
2017-05-20 16:18:33,907 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1690674926461064520_1284 src: /192.168.1.157:34903 dest: /192.168.1.157:50010 of size 13560
2017-05-20 16:18:36,841 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_1690674926461064520_1284 to 192.168.1.158:50010
2017-05-20 16:18:36,846 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_1690674926461064520_1284 to /192.168.1.158:50010
2017-05-20 16:18:39,880 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9137515758177848000_1282 src: /192.168.1.158:53293 dest: /192.168.1.158:50010
2017-05-20 16:18:39,885 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9137515758177848000_1282 src: /192.168.1.158:53293 dest: /192.168.1.158:50010 of size 91176
2017-05-20 16:18:50,278 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 16:19:01,795 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 16:19:13,772 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 16:19:42,876 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7413905864957538438_1283 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7413905864957538438
2017-05-20 16:19:42,877 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5986954183014352903_1286 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5986954183014352903
2017-05-20 16:19:42,877 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1690674926461064520_1284 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1690674926461064520
2017-05-20 16:19:42,877 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9137515758177848000_1282 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9137515758177848000
2017-05-20 16:19:45,889 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-20 16:19:45,953 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 16:19:58,777 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 16:19:58,964 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 16:19:58,965 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 16:19:58,967 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 16:19:59,038 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 16:19:59,095 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 16:19:59,096 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 16:19:59,096 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 16:19:59,324 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@14a8af0
2017-05-20 16:19:59,361 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 16:19:59,364 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 16:19:59,364 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-20 16:19:59,369 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 16:19:59,385 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 16:19:59,390 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 16:19:59,390 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 16:19:59,391 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 16:19:59,392 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 16:19:59,392 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 16:19:59,392 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 16:19:59,394 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 16:19:59,395 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 16:19:59,401 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 16:20:02,400 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 16:21:08,559 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6559299257875775186_1291 src: /192.168.1.158:53336 dest: /192.168.1.158:50010
2017-05-20 16:21:08,572 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6559299257875775186_1291 src: /192.168.1.158:53336 dest: /192.168.1.158:50010 of size 91176
2017-05-20 16:21:08,825 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-6559299257875775186_1291 to /192.168.1.159
2017-05-20 16:21:11,431 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6559299257875775186_1291 to 192.168.1.157:50010
2017-05-20 16:21:11,440 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-6559299257875775186_1291 to /192.168.1.157:50010
2017-05-20 16:21:11,497 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6390542806508344102_1293 src: /192.168.1.156:42551 dest: /192.168.1.156:50010
2017-05-20 16:21:11,498 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6390542806508344102_1293 src: /192.168.1.156:42552 dest: /192.168.1.156:50010
2017-05-20 16:21:11,498 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-6390542806508344102_1293 received exception java.io.IOException: Block blk_-6390542806508344102_1293 has already been started (though not completed), and thus cannot be created.
2017-05-20 16:21:11,499 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6390542806508344102_1293 src: /192.168.1.156:42551 dest: /192.168.1.156:50010 of size 13560
2017-05-20 16:21:11,500 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-6390542806508344102_1293 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 16:21:14,430 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6390542806508344102_1293 to 192.168.1.157:50010, 192.168.1.158:50010
2017-05-20 16:21:14,432 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-6390542806508344102_1293 to /192.168.1.157:50010
2017-05-20 16:21:14,503 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2528492161049344265_1292 src: /192.168.1.157:34949 dest: /192.168.1.157:50010
2017-05-20 16:21:14,504 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2528492161049344265_1292 src: /192.168.1.157:34949 dest: /192.168.1.157:50010 of size 2165
2017-05-20 16:21:18,222 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 16:21:20,504 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6231099380561582196_1295 src: /192.168.1.156:42556 dest: /192.168.1.156:50010
2017-05-20 16:21:20,506 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6231099380561582196_1295 src: /192.168.1.156:42556 dest: /192.168.1.156:50010 of size 13545
2017-05-20 16:21:21,527 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 16:21:33,313 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 16:21:45,067 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 16:22:20,530 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4707502655279323868_1299 src: /192.168.1.156:42589 dest: /192.168.1.156:50010
2017-05-20 16:22:20,535 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4707502655279323868_1299 src: /192.168.1.156:42589 dest: /192.168.1.156:50010 of size 23481
2017-05-20 16:22:26,470 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6559299257875775186_1291 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6559299257875775186
2017-05-20 16:22:26,470 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6390542806508344102_1293 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6390542806508344102
2017-05-20 16:22:26,470 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2528492161049344265_1292 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2528492161049344265
2017-05-20 16:22:26,471 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6231099380561582196_1295 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6231099380561582196
2017-05-20 16:22:28,588 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 16:22:41,297 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 16:22:41,484 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 16:22:41,486 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 16:22:41,487 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 16:22:41,540 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 16:22:41,588 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 16:22:41,589 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 16:22:41,589 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 16:22:41,802 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 16:22:41,839 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 16:22:41,841 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 16:22:41,842 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 16:22:41,846 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 16:22:41,864 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 16:22:41,869 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 16:22:41,869 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 16:22:41,871 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 16:22:41,872 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 16:22:41,872 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 16:22:41,872 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 16:22:41,890 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 16:22:41,890 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 16:22:41,903 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 16:22:41,932 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-4707502655279323868_1299
2017-05-20 16:22:44,903 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 13 msecs
2017-05-20 16:23:17,944 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4707502655279323868_1299 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4707502655279323868
2017-05-20 16:23:53,999 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1043296544143579061_1302 src: /192.168.1.156:42601 dest: /192.168.1.156:50010
2017-05-20 16:23:54,013 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1043296544143579061_1302 src: /192.168.1.156:42601 dest: /192.168.1.156:50010 of size 13560
2017-05-20 16:23:54,041 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6265415660609894081_1301 src: /192.168.1.158:53389 dest: /192.168.1.158:50010
2017-05-20 16:23:54,042 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6265415660609894081_1301 src: /192.168.1.158:53389 dest: /192.168.1.158:50010 of size 2165
2017-05-20 16:24:00,074 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1309926591437431568_1304 src: /192.168.1.157:34996 dest: /192.168.1.157:50010
2017-05-20 16:24:00,075 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1309926591437431568_1304 src: /192.168.1.157:34996 dest: /192.168.1.157:50010 of size 13545
2017-05-20 16:24:03,041 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5546293747251373926_1300 src: /192.168.1.158:53392 dest: /192.168.1.158:50010
2017-05-20 16:24:03,043 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5546293747251373926_1300 src: /192.168.1.158:53392 dest: /192.168.1.158:50010 of size 91176
2017-05-20 16:24:13,609 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 16:24:24,986 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 16:24:36,876 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 16:25:00,045 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2783219059686994351_1308 src: /192.168.1.157:35029 dest: /192.168.1.157:50010
2017-05-20 16:25:00,046 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2783219059686994351_1308 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-20 16:25:00,048 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 16:25:03,103 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2783219059686994351_1308 src: /192.168.1.158:53432 dest: /192.168.1.158:50010
2017-05-20 16:25:03,104 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2783219059686994351_1308 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-20 16:25:03,104 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 16:25:08,996 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6265415660609894081_1301 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6265415660609894081
2017-05-20 16:25:08,997 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1043296544143579061_1302 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1043296544143579061
2017-05-20 16:25:08,998 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1309926591437431568_1304 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1309926591437431568
2017-05-20 16:25:08,998 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5546293747251373926_1300 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5546293747251373926
2017-05-20 16:25:12,833 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 16:25:25,678 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 16:25:25,865 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 16:25:25,866 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 16:25:25,868 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 16:25:25,933 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 16:25:25,989 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 16:25:25,990 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 16:25:25,990 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 16:25:26,230 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 16:25:26,268 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 16:25:26,271 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 16:25:26,271 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 16:25:26,275 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 16:25:26,293 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 16:25:26,297 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 16:25:26,297 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 16:25:26,299 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 16:25:26,299 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 16:25:26,300 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 16:25:26,300 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 16:25:26,318 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 16:25:26,318 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 16:25:26,330 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 16:25:29,331 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 13 msecs
2017-05-20 16:26:38,361 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7904623006806857493_1309 src: /192.168.1.157:35042 dest: /192.168.1.157:50010
2017-05-20 16:26:38,377 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7904623006806857493_1309 src: /192.168.1.157:35042 dest: /192.168.1.157:50010 of size 91176
2017-05-20 16:26:38,401 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6267171080422398902_1313 src: /192.168.1.156:42650 dest: /192.168.1.156:50010
2017-05-20 16:26:38,402 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6267171080422398902_1313 src: /192.168.1.156:42650 dest: /192.168.1.156:50010 of size 13552
2017-05-20 16:26:41,403 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1581813367289821882_1310 src: /192.168.1.156:42652 dest: /192.168.1.156:50010
2017-05-20 16:26:41,406 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1581813367289821882_1310 src: /192.168.1.156:42652 dest: /192.168.1.156:50010 of size 2165
2017-05-20 16:26:44,379 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1581813367289821882_1310 to 192.168.1.157:50010
2017-05-20 16:26:44,385 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-1581813367289821882_1310 to /192.168.1.157:50010
2017-05-20 16:26:44,413 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2414410254596761946_1311 src: /192.168.1.156:42653 dest: /192.168.1.156:50010
2017-05-20 16:26:44,414 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2414410254596761946_1311 src: /192.168.1.156:42653 dest: /192.168.1.156:50010 of size 13567
2017-05-20 16:26:45,255 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 16:26:57,476 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 16:27:09,181 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 16:27:20,332 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 16:27:44,437 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3533482220922694689_1317 src: /192.168.1.157:35075 dest: /192.168.1.157:50010
2017-05-20 16:27:44,438 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3533482220922694689_1317 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-20 16:27:44,440 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 16:27:50,414 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7904623006806857493_1309 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7904623006806857493
2017-05-20 16:27:50,414 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6267171080422398902_1313 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6267171080422398902
2017-05-20 16:27:50,415 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1581813367289821882_1310 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1581813367289821882
2017-05-20 16:27:50,415 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2414410254596761946_1311 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2414410254596761946
2017-05-20 16:27:53,411 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 16:27:53,417 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-20 16:28:06,297 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 16:28:06,491 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 16:28:06,492 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 16:28:06,494 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 16:28:06,562 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 16:28:06,619 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 16:28:06,621 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 16:28:06,621 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 16:28:06,856 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 16:28:06,895 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 16:28:06,898 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 16:28:06,898 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 16:28:06,903 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 16:28:06,921 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 16:28:06,926 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 16:28:06,927 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 16:28:06,928 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 16:28:06,929 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 16:28:06,929 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 16:28:06,929 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 16:28:06,932 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 16:28:06,932 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 16:28:06,940 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 16:28:09,940 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 16:29:18,893 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4359572067704619678_1319 src: /192.168.1.157:35086 dest: /192.168.1.157:50010
2017-05-20 16:29:18,904 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4359572067704619678_1319 src: /192.168.1.157:35086 dest: /192.168.1.157:50010 of size 2165
2017-05-20 16:29:19,056 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5183667125424305504_1322 src: /192.168.1.156:42700 dest: /192.168.1.156:50010
2017-05-20 16:29:19,058 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5183667125424305504_1322 src: /192.168.1.156:42700 dest: /192.168.1.156:50010 of size 13552
2017-05-20 16:29:22,058 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6090453114515780098_1318 src: /192.168.1.156:42701 dest: /192.168.1.156:50010
2017-05-20 16:29:22,064 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6090453114515780098_1318 src: /192.168.1.156:42701 dest: /192.168.1.156:50010 of size 91176
2017-05-20 16:29:25,058 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7335999350477506037_1320 src: /192.168.1.156:42702 dest: /192.168.1.156:50010
2017-05-20 16:29:25,059 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7335999350477506037_1320 src: /192.168.1.156:42702 dest: /192.168.1.156:50010 of size 13567
2017-05-20 16:29:30,857 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 16:29:42,251 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 16:30:02,135 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-7542597023824073767_1001 to /192.168.1.159
2017-05-20 16:30:28,094 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8059054929655319696_1326 src: /192.168.1.156:42746 dest: /192.168.1.156:50010
2017-05-20 16:30:28,095 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8059054929655319696_1326 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-20 16:30:28,097 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 16:30:34,010 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4359572067704619678_1319 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4359572067704619678
2017-05-20 16:30:34,010 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5183667125424305504_1322 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5183667125424305504
2017-05-20 16:30:34,011 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6090453114515780098_1318 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6090453114515780098
2017-05-20 16:30:34,011 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7335999350477506037_1320 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7335999350477506037
2017-05-20 16:30:36,100 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 16:30:48,949 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 16:30:49,135 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 16:30:49,137 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 16:30:49,138 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 16:30:49,208 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 16:30:49,265 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 16:30:49,266 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 16:30:49,266 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 16:30:49,505 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 16:30:49,547 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 16:30:49,550 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 16:30:49,550 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 16:30:49,555 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 16:30:49,574 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 16:30:49,579 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 16:30:49,580 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 16:30:49,581 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 16:30:49,582 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 16:30:49,582 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 16:30:49,582 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 16:30:49,585 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 16:30:49,586 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 16:30:49,594 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 16:30:52,595 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-05-20 16:31:58,754 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2334393795139642795_1327 src: /192.168.1.156:42749 dest: /192.168.1.156:50010
2017-05-20 16:31:58,772 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2334393795139642795_1327 src: /192.168.1.156:42749 dest: /192.168.1.156:50010 of size 91176
2017-05-20 16:31:58,998 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-2334393795139642795_1327 to /192.168.1.159
2017-05-20 16:32:01,700 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2334393795139642795_1327 to 192.168.1.157:50010
2017-05-20 16:32:01,707 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-2334393795139642795_1327 to /192.168.1.157:50010
2017-05-20 16:32:04,540 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1627354633063646913_1329 src: /192.168.1.158:53535 dest: /192.168.1.158:50010
2017-05-20 16:32:04,542 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1627354633063646913_1329 src: /192.168.1.158:53535 dest: /192.168.1.158:50010 of size 13567
2017-05-20 16:32:04,719 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4986200398885359915_1331 src: /192.168.1.156:42760 dest: /192.168.1.156:50010
2017-05-20 16:32:04,722 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4986200398885359915_1331 src: /192.168.1.156:42760 dest: /192.168.1.156:50010 of size 13552
2017-05-20 16:32:07,700 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4986200398885359915_1331 to 192.168.1.157:50010
2017-05-20 16:32:07,706 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_4986200398885359915_1331 to /192.168.1.157:50010
2017-05-20 16:32:07,720 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8880914893449963050_1328 src: /192.168.1.156:42761 dest: /192.168.1.156:50010
2017-05-20 16:32:07,721 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8880914893449963050_1328 src: /192.168.1.156:42761 dest: /192.168.1.156:50010 of size 2165
2017-05-20 16:32:08,770 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 16:32:12,699 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 16:32:24,482 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 16:32:36,243 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 16:33:16,729 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2334393795139642795_1327 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2334393795139642795
2017-05-20 16:33:16,730 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1627354633063646913_1329 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1627354633063646913
2017-05-20 16:33:16,730 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4986200398885359915_1331 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4986200398885359915
2017-05-20 16:33:16,730 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8880914893449963050_1328 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8880914893449963050
2017-05-20 16:33:20,437 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 16:33:33,221 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 16:33:33,408 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 16:33:33,410 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 16:33:33,412 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 16:33:33,472 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 16:33:33,520 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 16:33:33,521 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 16:33:33,521 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 16:33:33,733 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 16:33:33,766 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 16:33:33,769 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 16:33:33,769 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 16:33:33,773 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 16:33:33,790 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 16:33:33,795 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 16:33:33,796 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 16:33:33,797 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 16:33:33,798 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 16:33:33,798 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 16:33:33,806 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 16:33:33,822 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 16:33:33,822 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 16:33:33,835 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 16:33:36,838 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 12 msecs
2017-05-20 16:34:43,066 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8591966197169711211_1337 src: /192.168.1.158:53570 dest: /192.168.1.158:50010
2017-05-20 16:34:43,080 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8591966197169711211_1337 src: /192.168.1.158:53570 dest: /192.168.1.158:50010 of size 2165
2017-05-20 16:34:46,008 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3828433745160800539_1338 src: /192.168.1.156:42818 dest: /192.168.1.156:50010
2017-05-20 16:34:46,010 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3828433745160800539_1338 src: /192.168.1.156:42818 dest: /192.168.1.156:50010 of size 13568
2017-05-20 16:34:48,920 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-3828433745160800539_1338 to 192.168.1.158:50010
2017-05-20 16:34:48,933 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-3828433745160800539_1338 to /192.168.1.158:50010
2017-05-20 16:34:49,012 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6807063379679827115_1340 src: /192.168.1.157:35174 dest: /192.168.1.157:50010
2017-05-20 16:34:49,012 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6807063379679827115_1340 src: /192.168.1.157:35174 dest: /192.168.1.157:50010 of size 13553
2017-05-20 16:34:52,011 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7884402762554099095_1336 src: /192.168.1.156:42821 dest: /192.168.1.156:50010
2017-05-20 16:34:52,019 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7884402762554099095_1336 src: /192.168.1.156:42820 dest: /192.168.1.156:50010
2017-05-20 16:34:52,020 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7884402762554099095_1336 received exception java.io.IOException: Block blk_7884402762554099095_1336 has already been started (though not completed), and thus cannot be created.
2017-05-20 16:34:52,021 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7884402762554099095_1336 src: /192.168.1.156:42821 dest: /192.168.1.156:50010 of size 91176
2017-05-20 16:34:52,021 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7884402762554099095_1336 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 16:34:53,066 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 16:35:05,279 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 16:35:08,813 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 16:35:20,535 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 16:36:00,961 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8591966197169711211_1337 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8591966197169711211
2017-05-20 16:36:00,962 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3828433745160800539_1338 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3828433745160800539
2017-05-20 16:36:00,963 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6807063379679827115_1340 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6807063379679827115
2017-05-20 16:36:00,963 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7884402762554099095_1336 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7884402762554099095
2017-05-20 16:36:02,958 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 16:36:15,788 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 16:36:16,011 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 16:36:16,012 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 16:36:16,014 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 16:36:16,080 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 16:36:16,143 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 16:36:16,144 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 16:36:16,145 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 16:36:16,383 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 16:36:16,418 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 16:36:16,421 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 16:36:16,421 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 16:36:16,427 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 16:36:16,449 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 16:36:16,454 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 16:36:16,455 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 16:36:16,456 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 16:36:16,457 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 16:36:16,457 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 16:36:16,457 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 16:36:16,461 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 16:36:16,461 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 16:36:16,469 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 16:36:19,468 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 4 msecs
2017-05-20 16:37:25,502 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6945219348613365581_1345 src: /192.168.1.158:53614 dest: /192.168.1.158:50010
2017-05-20 16:37:25,515 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6945219348613365581_1345 src: /192.168.1.158:53614 dest: /192.168.1.158:50010 of size 91176
2017-05-20 16:37:25,833 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-6945219348613365581_1345 to /192.168.1.159
2017-05-20 16:37:25,836 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-6945219348613365581_1345 to /192.168.1.157
2017-05-20 16:37:26,761 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 16:37:28,493 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6945219348613365581_1345 to 192.168.1.157:50010
2017-05-20 16:37:28,497 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-6945219348613365581_1345 to /192.168.1.157:50010
2017-05-20 16:37:31,411 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6055424384038918620_1349 src: /192.168.1.158:53623 dest: /192.168.1.158:50010
2017-05-20 16:37:31,413 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6055424384038918620_1349 src: /192.168.1.158:53623 dest: /192.168.1.158:50010 of size 13553
2017-05-20 16:37:31,427 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-435297526674315086_1347 src: /192.168.1.156:42869 dest: /192.168.1.156:50010
2017-05-20 16:37:31,430 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-435297526674315086_1347 src: /192.168.1.156:42869 dest: /192.168.1.156:50010 of size 13568
2017-05-20 16:37:34,429 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4705237981142433499_1346 src: /192.168.1.156:42871 dest: /192.168.1.156:50010
2017-05-20 16:37:34,430 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4705237981142433499_1346 src: /192.168.1.156:42871 dest: /192.168.1.156:50010 of size 2165
2017-05-20 16:37:34,493 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-435297526674315086_1347 to 192.168.1.158:50010
2017-05-20 16:37:34,495 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-435297526674315086_1347 to /192.168.1.158:50010
2017-05-20 16:37:37,495 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4705237981142433499_1346 to 192.168.1.157:50010
2017-05-20 16:37:37,498 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_4705237981142433499_1346 to /192.168.1.157:50010
2017-05-20 16:37:48,938 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 16:38:00,018 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 16:38:12,326 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-7542597023824073767_1001 to /192.168.1.159
2017-05-20 16:38:40,456 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4179454078869303663_1353 src: /192.168.1.156:42914 dest: /192.168.1.156:50010
2017-05-20 16:38:40,463 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4179454078869303663_1353 src: /192.168.1.156:42914 dest: /192.168.1.156:50010 of size 23896
2017-05-20 16:38:49,542 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6945219348613365581_1345 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6945219348613365581
2017-05-20 16:38:49,543 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6055424384038918620_1349 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6055424384038918620
2017-05-20 16:38:49,543 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4179454078869303663_1353 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4179454078869303663
2017-05-20 16:38:49,544 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-435297526674315086_1347 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-435297526674315086
2017-05-20 16:38:49,544 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4705237981142433499_1346 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4705237981142433499
2017-05-20 16:38:51,622 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 16:39:04,357 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 16:39:04,542 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 16:39:04,544 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 16:39:04,546 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 16:39:04,616 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 16:39:04,673 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 16:39:04,674 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 16:39:04,674 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 16:39:04,918 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 16:39:04,958 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 16:39:04,960 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 16:39:04,960 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 16:39:04,965 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 16:39:04,986 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 16:39:04,992 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 16:39:04,993 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 16:39:04,994 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 16:39:04,995 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 16:39:05,003 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 16:39:05,003 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 16:39:05,025 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 16:39:05,025 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 16:39:05,038 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 16:39:08,040 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 12 msecs
2017-05-20 16:40:14,231 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3436339616407076879_1356 src: /192.168.1.157:35255 dest: /192.168.1.157:50010
2017-05-20 16:40:14,245 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3436339616407076879_1356 src: /192.168.1.157:35255 dest: /192.168.1.157:50010 of size 13568
2017-05-20 16:40:14,374 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-3436339616407076879_1356 to /192.168.1.159
2017-05-20 16:40:17,080 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-3436339616407076879_1356 to 192.168.1.158:50010
2017-05-20 16:40:17,086 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-3436339616407076879_1356 to /192.168.1.158:50010
2017-05-20 16:40:17,167 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_70179162194752921_1354 src: /192.168.1.156:42926 dest: /192.168.1.156:50010
2017-05-20 16:40:17,169 INFO org.apache.hadoop.dfs.DataNode: Received block blk_70179162194752921_1354 src: /192.168.1.156:42926 dest: /192.168.1.156:50010 of size 91176
2017-05-20 16:40:17,169 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7476478091900577148_1358 src: /192.168.1.156:42927 dest: /192.168.1.156:50010
2017-05-20 16:40:17,170 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7476478091900577148_1358 src: /192.168.1.156:42927 dest: /192.168.1.156:50010 of size 13553
2017-05-20 16:40:20,078 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7476478091900577148_1358 to 192.168.1.158:50010, 192.168.1.157:50010
2017-05-20 16:40:20,080 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-7476478091900577148_1358 to /192.168.1.158:50010
2017-05-20 16:40:23,088 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_264015316695780804_1355 src: /192.168.1.157:35264 dest: /192.168.1.157:50010
2017-05-20 16:40:23,090 INFO org.apache.hadoop.dfs.DataNode: Received block blk_264015316695780804_1355 src: /192.168.1.157:35264 dest: /192.168.1.157:50010 of size 2165
2017-05-20 16:40:24,156 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 16:40:26,080 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_70179162194752921_1354 to 192.168.1.158:50010, 192.168.1.157:50010
2017-05-20 16:40:26,085 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_70179162194752921_1354 to /192.168.1.158:50010
2017-05-20 16:40:36,781 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 16:40:48,144 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 16:40:59,522 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 16:41:23,197 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7065078395728952364_1362 src: /192.168.1.157:35297 dest: /192.168.1.157:50010
2017-05-20 16:41:23,197 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7065078395728952364_1362 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-20 16:41:23,199 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 16:41:26,189 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7065078395728952364_1362 src: /192.168.1.156:42973 dest: /192.168.1.156:50010
2017-05-20 16:41:26,189 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7065078395728952364_1362 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-20 16:41:26,189 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 16:41:32,123 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7476478091900577148_1358 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7476478091900577148
2017-05-20 16:41:32,124 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3436339616407076879_1356 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3436339616407076879
2017-05-20 16:41:32,124 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_70179162194752921_1354 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_70179162194752921
2017-05-20 16:41:32,125 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_264015316695780804_1355 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_264015316695780804
2017-05-20 17:26:27,736 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 17:26:40,597 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 17:26:40,786 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 17:26:40,788 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 17:26:40,790 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 17:26:40,855 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 17:26:40,903 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 17:26:40,904 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 17:26:40,904 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 17:26:41,123 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 17:26:41,162 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 17:26:41,165 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 17:26:41,165 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-20 17:26:41,170 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 17:26:41,192 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 17:26:41,200 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 17:26:41,200 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 17:26:41,202 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 17:26:41,202 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 17:26:41,203 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 17:26:41,203 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 17:26:41,213 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 17:26:41,214 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 17:26:41,224 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 17:26:44,230 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 16 msecs
2017-05-20 17:27:53,305 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4299291697841655940_1365 src: /192.168.1.158:53711 dest: /192.168.1.158:50010
2017-05-20 17:27:53,321 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4299291697841655940_1365 src: /192.168.1.158:53711 dest: /192.168.1.158:50010 of size 13560
2017-05-20 17:27:56,264 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3137177639852641530_1367 src: /192.168.1.157:35310 dest: /192.168.1.157:50010
2017-05-20 17:27:56,267 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3137177639852641530_1367 src: /192.168.1.157:35310 dest: /192.168.1.157:50010 of size 13545
2017-05-20 17:27:56,314 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3087522530919597866_1364 src: /192.168.1.156:42987 dest: /192.168.1.156:50010
2017-05-20 17:27:56,316 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3087522530919597866_1364 src: /192.168.1.156:42987 dest: /192.168.1.156:50010 of size 2165
2017-05-20 17:27:59,312 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5833035965508046745_1363 src: /192.168.1.156:42989 dest: /192.168.1.156:50010
2017-05-20 17:27:59,319 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5833035965508046745_1363 src: /192.168.1.156:42989 dest: /192.168.1.156:50010 of size 91176
2017-05-20 17:27:59,368 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-3087522530919597866_1364 to 192.168.1.157:50010
2017-05-20 17:27:59,373 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-3087522530919597866_1364 to /192.168.1.157:50010
2017-05-20 17:27:59,890 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 17:28:03,272 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 17:28:23,465 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 17:28:34,576 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 17:29:05,401 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4299291697841655940_1365 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4299291697841655940
2017-05-20 17:29:05,401 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3137177639852641530_1367 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3137177639852641530
2017-05-20 17:29:05,402 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3087522530919597866_1364 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3087522530919597866
2017-05-20 17:29:05,402 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5833035965508046745_1363 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5833035965508046745
2017-05-20 17:29:09,352 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 17:29:22,190 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 17:29:22,370 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 17:29:22,372 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 17:29:22,373 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 17:29:22,434 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 17:29:22,483 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 17:29:22,483 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 17:29:22,483 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 17:29:22,697 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 17:29:22,728 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 17:29:22,731 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 17:29:22,731 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 17:29:22,735 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 17:29:22,751 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 17:29:22,757 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 17:29:22,757 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 17:29:22,758 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 17:29:22,759 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 17:29:22,760 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 17:29:22,760 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 17:29:22,786 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 17:29:22,786 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 17:29:22,796 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 17:29:25,799 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 13 msecs
2017-05-20 17:30:31,966 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8077156181866545451_1373 src: /192.168.1.158:53747 dest: /192.168.1.158:50010
2017-05-20 17:30:31,979 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8077156181866545451_1373 src: /192.168.1.158:53747 dest: /192.168.1.158:50010 of size 2165
2017-05-20 17:30:37,870 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3109575219449573166_1374 src: /192.168.1.158:53758 dest: /192.168.1.158:50010
2017-05-20 17:30:37,872 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3109575219449573166_1374 src: /192.168.1.158:53758 dest: /192.168.1.158:50010 of size 13560
2017-05-20 17:30:40,872 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1137053335397965218_1376 src: /192.168.1.158:53760 dest: /192.168.1.158:50010
2017-05-20 17:30:40,873 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1137053335397965218_1376 src: /192.168.1.158:53760 dest: /192.168.1.158:50010 of size 13545
2017-05-20 17:30:42,090 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 17:30:43,880 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7645644676292411416_1372 src: /192.168.1.158:53761 dest: /192.168.1.158:50010
2017-05-20 17:30:43,886 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7645644676292411416_1372 src: /192.168.1.158:53761 dest: /192.168.1.158:50010 of size 91176
2017-05-20 17:30:54,343 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 17:31:06,433 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 17:31:10,581 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 17:31:49,893 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8077156181866545451_1373 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8077156181866545451
2017-05-20 17:31:49,894 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3109575219449573166_1374 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3109575219449573166
2017-05-20 17:31:49,894 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1137053335397965218_1376 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1137053335397965218
2017-05-20 17:31:49,894 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7645644676292411416_1372 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7645644676292411416
2017-05-20 17:31:52,027 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 17:32:04,864 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 17:32:05,063 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 17:32:05,064 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 17:32:05,066 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 17:32:05,139 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 17:32:05,198 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 17:32:05,199 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 17:32:05,199 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 17:32:05,420 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 17:32:05,455 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 17:32:05,458 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 17:32:05,458 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 17:32:05,463 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 17:32:05,485 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 17:32:05,490 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 17:32:05,491 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 17:32:05,491 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 17:32:05,491 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 17:32:05,491 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 17:32:05,492 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 17:32:05,493 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 17:32:05,494 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 17:32:05,501 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 17:32:08,499 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 17:33:14,600 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7966282623208545248_1382 src: /192.168.1.156:43084 dest: /192.168.1.156:50010
2017-05-20 17:33:14,616 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7966282623208545248_1382 src: /192.168.1.156:43084 dest: /192.168.1.156:50010 of size 2165
2017-05-20 17:33:17,569 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4454878091439017314_1381 src: /192.168.1.156:43095 dest: /192.168.1.156:50010
2017-05-20 17:33:17,570 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4454878091439017314_1381 src: /192.168.1.156:43095 dest: /192.168.1.156:50010 of size 91176
2017-05-20 17:33:17,579 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7966282623208545248_1382 to 192.168.1.158:50010
2017-05-20 17:33:17,586 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-7966282623208545248_1382 to /192.168.1.158:50010
2017-05-20 17:33:20,580 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4454878091439017314_1381 to 192.168.1.158:50010
2017-05-20 17:33:20,585 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_4454878091439017314_1381 to /192.168.1.158:50010
2017-05-20 17:33:23,555 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4492527933675661518_1385 src: /192.168.1.158:53805 dest: /192.168.1.158:50010
2017-05-20 17:33:23,556 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4492527933675661518_1385 src: /192.168.1.158:53805 dest: /192.168.1.158:50010 of size 13545
2017-05-20 17:33:23,568 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5204010868458826731_1383 src: /192.168.1.156:43098 dest: /192.168.1.156:50010
2017-05-20 17:33:23,570 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5204010868458826731_1383 src: /192.168.1.156:43098 dest: /192.168.1.156:50010 of size 13560
2017-05-20 17:33:23,937 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 17:33:27,664 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 17:33:39,466 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 17:33:51,145 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 17:34:32,610 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7966282623208545248_1382 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7966282623208545248
2017-05-20 17:34:32,610 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4454878091439017314_1381 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4454878091439017314
2017-05-20 17:34:32,610 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4492527933675661518_1385 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4492527933675661518
2017-05-20 17:34:32,611 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5204010868458826731_1383 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5204010868458826731
2017-05-20 17:34:36,428 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 17:34:49,284 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 17:34:49,483 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 17:34:49,485 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 17:34:49,486 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 17:34:49,553 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 17:34:49,610 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 17:34:49,610 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 17:34:49,610 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 17:34:49,830 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 17:34:49,862 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 17:34:49,865 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 17:34:49,865 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 17:34:49,870 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 17:34:49,886 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 17:34:49,891 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 17:34:49,891 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 17:34:49,892 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 17:34:49,892 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 17:34:49,892 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 17:34:49,893 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 17:34:49,902 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 17:34:49,902 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 17:34:49,915 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 17:34:52,911 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 9 msecs
2017-05-20 17:35:59,068 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6093305322736997568_1394 src: /192.168.1.157:35439 dest: /192.168.1.157:50010
2017-05-20 17:35:59,080 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6093305322736997568_1394 src: /192.168.1.157:35439 dest: /192.168.1.157:50010 of size 13552
2017-05-20 17:36:01,998 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3088636388232508897_1391 src: /192.168.1.156:43154 dest: /192.168.1.156:50010
2017-05-20 17:36:01,999 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3088636388232508897_1391 src: /192.168.1.156:43154 dest: /192.168.1.156:50010 of size 2165
2017-05-20 17:36:07,993 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6152899687194485152_1390 src: /192.168.1.157:35448 dest: /192.168.1.157:50010
2017-05-20 17:36:07,998 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6152899687194485152_1390 src: /192.168.1.157:35448 dest: /192.168.1.157:50010 of size 91176
2017-05-20 17:36:08,000 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7424298040315444912_1392 src: /192.168.1.156:43158 dest: /192.168.1.156:50010
2017-05-20 17:36:08,001 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7424298040315444912_1392 src: /192.168.1.156:43158 dest: /192.168.1.156:50010 of size 13567
2017-05-20 17:36:08,948 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 17:36:20,750 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 17:36:24,681 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 17:36:36,475 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 17:37:17,013 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6093305322736997568_1394 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6093305322736997568
2017-05-20 17:37:17,014 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3088636388232508897_1391 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3088636388232508897
2017-05-20 17:37:17,014 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6152899687194485152_1390 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6152899687194485152
2017-05-20 17:37:17,015 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7424298040315444912_1392 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7424298040315444912
2017-05-20 17:37:19,008 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 17:37:31,946 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 17:37:32,139 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 17:37:32,141 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 17:37:32,142 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 17:37:32,201 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 17:37:32,247 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 17:37:32,247 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 17:37:32,248 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 17:37:32,450 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 17:37:32,480 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 17:37:32,495 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 17:37:32,495 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 17:37:32,500 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 17:37:32,521 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 17:37:32,526 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 17:37:32,527 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 17:37:32,527 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 17:37:32,527 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 17:37:32,527 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 17:37:32,527 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 17:37:32,551 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 17:37:32,552 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 17:37:32,565 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 17:37:35,564 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 12 msecs
2017-05-20 17:38:44,649 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9068914757862692088_1401 src: /192.168.1.158:53896 dest: /192.168.1.158:50010
2017-05-20 17:38:44,658 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9068914757862692088_1401 src: /192.168.1.158:53896 dest: /192.168.1.158:50010 of size 13567
2017-05-20 17:38:47,649 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4174662664592287131_1400 src: /192.168.1.158:53897 dest: /192.168.1.158:50010
2017-05-20 17:38:47,650 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4174662664592287131_1400 src: /192.168.1.158:53897 dest: /192.168.1.158:50010 of size 2165
2017-05-20 17:38:47,691 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1189936470524837172_1399 src: /192.168.1.156:43214 dest: /192.168.1.156:50010
2017-05-20 17:38:47,698 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1189936470524837172_1399 src: /192.168.1.156:43214 dest: /192.168.1.156:50010 of size 91176
2017-05-20 17:38:50,631 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_1189936470524837172_1399 to 192.168.1.157:50010
2017-05-20 17:38:50,637 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_1189936470524837172_1399 to /192.168.1.157:50010
2017-05-20 17:38:52,741 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 17:38:53,693 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7318860059249783892_1403 src: /192.168.1.156:43217 dest: /192.168.1.156:50010
2017-05-20 17:38:53,695 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7318860059249783892_1403 src: /192.168.1.156:43217 dest: /192.168.1.156:50010 of size 13552
2017-05-20 17:38:56,510 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 17:39:07,939 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 17:39:16,716 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-9068914757862692088_1401
2017-05-20 17:39:27,883 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-7542597023824073767_1001 to /192.168.1.159
2017-05-20 17:40:02,724 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4460882161347561889_1407 src: /192.168.1.156:43260 dest: /192.168.1.156:50010
2017-05-20 17:40:02,725 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4460882161347561889_1407 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-20 17:40:02,726 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 17:40:08,691 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9068914757862692088_1401 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9068914757862692088
2017-05-20 17:40:08,691 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4174662664592287131_1400 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4174662664592287131
2017-05-20 17:40:08,692 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1189936470524837172_1399 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1189936470524837172
2017-05-20 17:40:08,692 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7318860059249783892_1403 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7318860059249783892
2017-05-20 17:40:11,656 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 17:40:24,513 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 17:40:24,723 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 17:40:24,725 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 17:40:24,726 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 17:40:24,795 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 17:40:24,852 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 17:40:24,853 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 17:40:24,853 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 17:40:25,088 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 17:40:25,124 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 17:40:25,126 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 17:40:25,127 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 17:40:25,133 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 17:40:25,150 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 17:40:25,155 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 17:40:25,156 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 17:40:25,157 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 17:40:25,158 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 17:40:25,158 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 17:40:25,158 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 17:40:25,162 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 17:40:25,163 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 17:40:25,171 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 17:40:28,171 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 17:41:34,216 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4340731896318199677_1410 src: /192.168.1.156:43263 dest: /192.168.1.156:50010
2017-05-20 17:41:34,233 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4340731896318199677_1410 src: /192.168.1.156:43263 dest: /192.168.1.156:50010 of size 13567
2017-05-20 17:41:34,475 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4340731896318199677_1410 to /192.168.1.159
2017-05-20 17:41:35,504 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 17:41:37,188 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2508458049499060092_1409 src: /192.168.1.156:43272 dest: /192.168.1.156:50010
2017-05-20 17:41:37,188 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2508458049499060092_1409 src: /192.168.1.156:43273 dest: /192.168.1.156:50010
2017-05-20 17:41:37,190 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2508458049499060092_1409 received exception java.io.IOException: Block blk_-2508458049499060092_1409 has already been started (though not completed), and thus cannot be created.
2017-05-20 17:41:37,190 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2508458049499060092_1409 src: /192.168.1.156:43272 dest: /192.168.1.156:50010 of size 2165
2017-05-20 17:41:37,193 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-2508458049499060092_1409 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 17:41:37,252 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-4340731896318199677_1410 to 192.168.1.157:50010
2017-05-20 17:41:37,257 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-4340731896318199677_1410 to /192.168.1.157:50010
2017-05-20 17:41:40,183 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-343725968732603573_1412 src: /192.168.1.156:43274 dest: /192.168.1.156:50010
2017-05-20 17:41:40,185 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-343725968732603573_1412 src: /192.168.1.156:43274 dest: /192.168.1.156:50010 of size 13552
2017-05-20 17:41:40,252 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2508458049499060092_1409 to 192.168.1.157:50010, 192.168.1.158:50010
2017-05-20 17:41:40,254 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-2508458049499060092_1409 to /192.168.1.157:50010
2017-05-20 17:41:43,253 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-343725968732603573_1412 to 192.168.1.158:50010
2017-05-20 17:41:43,255 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-343725968732603573_1412 to /192.168.1.158:50010
2017-05-20 17:41:46,114 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-96359100962575307_1408 src: /192.168.1.158:53941 dest: /192.168.1.158:50010
2017-05-20 17:41:46,117 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-96359100962575307_1408 src: /192.168.1.158:53941 dest: /192.168.1.158:50010 of size 91176
2017-05-20 17:41:49,249 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 17:42:00,538 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 17:42:11,322 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 17:42:43,208 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6761666491318358799_1416 src: /192.168.1.156:43309 dest: /192.168.1.156:50010
2017-05-20 17:42:43,212 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6761666491318358799_1416 src: /192.168.1.156:43309 dest: /192.168.1.156:50010 of size 23481
2017-05-20 17:42:49,291 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4340731896318199677_1410 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4340731896318199677
2017-05-20 17:42:49,291 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2508458049499060092_1409 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2508458049499060092
2017-05-20 17:42:49,292 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-343725968732603573_1412 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-343725968732603573
2017-05-20 17:42:49,292 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-96359100962575307_1408 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-96359100962575307
2017-05-20 17:42:49,293 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6761666491318358799_1416 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6761666491318358799
2017-05-20 17:42:54,965 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 17:43:07,782 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 17:43:07,970 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 17:43:07,972 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 17:43:07,974 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 17:43:08,033 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 17:43:08,081 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 17:43:08,081 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 17:43:08,081 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 17:43:08,304 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 17:43:08,339 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 17:43:08,342 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 17:43:08,342 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 17:43:08,347 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 17:43:08,369 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 17:43:08,377 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 17:43:08,378 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 17:43:08,378 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 17:43:08,378 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 17:43:08,378 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 17:43:08,379 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 17:43:08,397 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 17:43:08,397 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 17:43:08,410 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 17:43:11,409 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 12 msecs
2017-05-20 17:44:17,610 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6142450892401536956_1419 src: /192.168.1.157:35568 dest: /192.168.1.157:50010
2017-05-20 17:44:17,623 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6142450892401536956_1419 src: /192.168.1.157:35568 dest: /192.168.1.157:50010 of size 13568
2017-05-20 17:44:17,783 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-6142450892401536956_1419 to /192.168.1.159
2017-05-20 17:44:20,481 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-6142450892401536956_1419 to 192.168.1.158:50010
2017-05-20 17:44:20,486 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-6142450892401536956_1419 to /192.168.1.158:50010
2017-05-20 17:44:20,534 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4905572831373582838_1421 src: /192.168.1.156:43321 dest: /192.168.1.156:50010
2017-05-20 17:44:20,535 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4905572831373582838_1421 src: /192.168.1.156:43322 dest: /192.168.1.156:50010
2017-05-20 17:44:20,535 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4905572831373582838_1421 src: /192.168.1.156:43321 dest: /192.168.1.156:50010 of size 13553
2017-05-20 17:44:20,537 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-4905572831373582838_1421 received exception java.io.IOException: Block blk_-4905572831373582838_1421 is valid, and cannot be written to.
2017-05-20 17:44:20,538 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-4905572831373582838_1421 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 17:44:23,480 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-4905572831373582838_1421 to 192.168.1.157:50010, 192.168.1.158:50010
2017-05-20 17:44:23,483 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_-4905572831373582838_1421 to /192.168.1.157:50010
2017-05-20 17:44:23,536 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1491671093755944715_1417 src: /192.168.1.156:43323 dest: /192.168.1.156:50010
2017-05-20 17:44:23,541 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1491671093755944715_1417 src: /192.168.1.156:43323 dest: /192.168.1.156:50010 of size 91176
2017-05-20 17:44:26,481 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_1491671093755944715_1417 to 192.168.1.157:50010
2017-05-20 17:44:26,486 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_1491671093755944715_1417 to /192.168.1.157:50010
2017-05-20 17:44:26,538 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6391580979616401376_1418 src: /192.168.1.156:43325 dest: /192.168.1.156:50010
2017-05-20 17:44:26,539 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6391580979616401376_1418 src: /192.168.1.156:43325 dest: /192.168.1.156:50010 of size 2165
2017-05-20 17:44:27,435 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8748616289663248105_1001 to /192.168.1.159
2017-05-20 17:44:29,482 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_6391580979616401376_1418 to 192.168.1.158:50010
2017-05-20 17:44:29,485 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_6391580979616401376_1418 to /192.168.1.158:50010
2017-05-20 17:44:39,706 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 17:44:51,630 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 17:45:03,367 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1740804589725075408_1001 to /192.168.1.159
2017-05-20 17:45:41,569 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7341367881824916594_1425 src: /192.168.1.156:43370 dest: /192.168.1.156:50010
2017-05-20 17:45:41,570 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7341367881824916594_1425 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-20 17:45:41,570 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 17:45:47,536 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6142450892401536956_1419 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6142450892401536956
2017-05-20 17:45:47,537 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4905572831373582838_1421 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4905572831373582838
2017-05-20 17:45:47,537 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1491671093755944715_1417 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1491671093755944715
2017-05-20 17:45:47,538 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6391580979616401376_1418 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6391580979616401376
2017-05-20 17:45:49,610 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 17:46:02,420 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 17:46:02,615 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 17:46:02,617 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 17:46:02,618 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 17:46:02,686 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 17:46:02,743 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 17:46:02,744 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 17:46:02,744 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 17:46:02,982 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 17:46:03,020 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 17:46:03,023 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 17:46:03,023 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 17:46:03,028 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 17:46:03,045 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 17:46:03,050 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 17:46:03,051 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 17:46:03,052 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 17:46:03,053 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 17:46:03,053 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 17:46:03,054 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 17:46:03,056 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 17:46:03,056 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 17:46:03,063 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 17:46:06,064 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 17:47:12,173 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8530417440000623252_1426 src: /192.168.1.156:43373 dest: /192.168.1.156:50010
2017-05-20 17:47:12,188 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8530417440000623252_1426 src: /192.168.1.156:43373 dest: /192.168.1.156:50010 of size 91176
2017-05-20 17:47:12,405 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-8530417440000623252_1426 to /192.168.1.159
2017-05-20 17:47:15,141 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2283795074368349894_1427 src: /192.168.1.156:43383 dest: /192.168.1.156:50010
2017-05-20 17:47:15,143 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2283795074368349894_1427 src: /192.168.1.156:43383 dest: /192.168.1.156:50010 of size 2165
2017-05-20 17:47:18,085 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_2283795074368349894_1427 to 192.168.1.158:50010
2017-05-20 17:47:18,089 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_2283795074368349894_1427 to /192.168.1.158:50010
2017-05-20 17:47:18,140 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4027645184862325869_1430 src: /192.168.1.156:43384 dest: /192.168.1.156:50010
2017-05-20 17:47:18,142 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4027645184862325869_1430 src: /192.168.1.156:43384 dest: /192.168.1.156:50010 of size 13553
2017-05-20 17:47:21,086 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4027645184862325869_1430 to 192.168.1.157:50010
2017-05-20 17:47:21,088 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020):Transmitted block blk_4027645184862325869_1430 to /192.168.1.157:50010
2017-05-20 17:47:21,138 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7987562611194957904_1428 src: /192.168.1.156:43385 dest: /192.168.1.156:50010
2017-05-20 17:47:21,138 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7987562611194957904_1428 src: /192.168.1.156:43385 dest: /192.168.1.156:50010 of size 13568
2017-05-20 17:47:23,281 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 17:47:27,185 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 17:47:38,929 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4913922051368690606_1001 to /192.168.1.159
2017-05-20 17:47:59,633 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-7542597023824073767_1001 to /192.168.1.159
2017-05-20 17:48:24,135 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6898573179164080031_1434 src: /192.168.1.158:54062 dest: /192.168.1.158:50010
2017-05-20 17:48:24,137 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6898573179164080031_1434 src: /192.168.1.158:54062 dest: /192.168.1.158:50010 of size 23481
2017-05-20 17:48:30,135 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8530417440000623252_1426 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8530417440000623252
2017-05-20 17:48:30,135 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2283795074368349894_1427 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2283795074368349894
2017-05-20 17:48:30,136 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4027645184862325869_1430 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4027645184862325869
2017-05-20 17:48:30,136 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7987562611194957904_1428 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7987562611194957904
2017-05-20 17:48:32,129 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 17:48:44,959 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 17:48:45,165 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 17:48:45,166 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 17:48:45,168 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 17:48:45,224 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 17:48:45,273 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 17:48:45,274 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 17:48:45,274 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 17:48:45,486 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 17:48:45,518 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 17:48:45,520 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 17:48:45,521 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 17:48:45,526 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 17:48:45,543 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 17:48:45,547 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 17:48:45,548 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 17:48:45,548 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 17:48:45,549 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 17:48:45,549 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)
2017-05-20 17:48:45,549 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 17:48:45,571 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 17:48:45,571 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 17:48:45,584 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 17:48:45,614 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_6898573179164080031_1434
2017-05-20 17:48:48,581 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 10 msecs
2017-05-20 17:49:21,625 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6898573179164080031_1434 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6898573179164080031
2017-05-20 17:49:54,678 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7364979583066366104_1436 src: /192.168.1.158:54065 dest: /192.168.1.158:50010
2017-05-20 17:49:54,692 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7364979583066366104_1436 src: /192.168.1.158:54065 dest: /192.168.1.158:50010 of size 2165
2017-05-20 17:49:55,893 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_449473293360089298_1001 to /192.168.1.159
2017-05-20 17:50:00,650 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6491295917467686417_1435 src: /192.168.1.157:35663 dest: /192.168.1.157:50010
2017-05-20 17:50:00,653 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6491295917467686417_1435 src: /192.168.1.157:35663 dest: /192.168.1.157:50010 of size 91176
2017-05-20 17:50:03,622 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7901883857487301367_1437 src: /192.168.1.156:43445 dest: /192.168.1.156:50010
2017-05-20 17:50:03,623 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7901883857487301367_1437 src: /192.168.1.156:43445 dest: /192.168.1.156:50010 of size 13568
2017-05-20 17:50:03,673 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7856795739024880346_1439 src: /192.168.1.157:35664 dest: /192.168.1.157:50010
2017-05-20 17:50:03,674 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7856795739024880346_1439 src: /192.168.1.157:35664 dest: /192.168.1.157:50010 of size 13553
2017-05-20 17:50:16,597 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-4587846993946844194_1001 to /192.168.1.159
2017-05-20 17:50:20,345 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_1131307284753285062_1001 to /192.168.1.159
2017-05-20 17:50:32,182 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-1368366973-192.168.1.159-50010-1495207677668, infoPort=50075, ipcPort=50020) Served block blk_-1240561215457262067_1001 to /192.168.1.159
2017-05-20 17:51:09,693 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7901883857487301367_1437 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7901883857487301367
2017-05-20 17:51:09,694 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7856795739024880346_1439 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7856795739024880346
2017-05-20 17:51:09,694 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7364979583066366104_1436 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7364979583066366104
2017-05-20 17:51:09,694 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6491295917467686417_1435 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6491295917467686417
2017-05-20 17:54:24,885 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 4 msecs
2017-05-20 18:01:58,042 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:04:38,393 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:04:38,539 INFO org.apache.hadoop.dfs.Storage: Storage directory /home/ubuntu/old_hadoop_temp/dfs/data is not formatted.
2017-05-20 18:04:38,540 INFO org.apache.hadoop.dfs.Storage: Formatting ...
2017-05-20 18:04:38,591 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:04:38,593 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:04:38,595 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:04:38,654 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:04:38,700 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:04:38,701 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:04:38,701 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:04:38,912 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@169d193
2017-05-20 18:04:38,948 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:04:38,950 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:04:38,950 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d60c28
2017-05-20 18:04:38,955 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:04:38,971 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:04:38,975 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:04:38,976 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:04:38,976 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:04:38,976 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:04:38,977 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:04:38,977 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=, infoPort=50075, ipcPort=50020)
2017-05-20 18:04:39,001 INFO org.apache.hadoop.dfs.DataNode: New storage id DS-2051926727-192.168.1.159-50010-1495296278987 is assigned to data-node 192.168.1.159:50010
2017-05-20 18:04:39,002 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:04:39,002 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:04:39,015 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:04:42,009 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 0 blocks got processed in 6 msecs
2017-05-20 18:05:36,348 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5765559863906286956_1001 src: /192.168.1.155:36637 dest: /192.168.1.155:50010
2017-05-20 18:05:38,549 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5765559863906286956_1001 of size 67108864 from /192.168.1.155
2017-05-20 18:05:38,550 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_5765559863906286956_1001 terminating
2017-05-20 18:05:38,574 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8960126721114299935_1001 src: /192.168.1.156:43482 dest: /192.168.1.156:50010
2017-05-20 18:05:41,060 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8960126721114299935_1001 of size 67108864 from /192.168.1.156
2017-05-20 18:05:41,061 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-8960126721114299935_1001 terminating
2017-05-20 18:05:41,074 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6828596650668451241_1001 src: /192.168.1.157:35701 dest: /192.168.1.157:50010
2017-05-20 18:05:43,648 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6828596650668451241_1001 of size 67108864 from /192.168.1.157
2017-05-20 18:05:43,649 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_6828596650668451241_1001 terminating
2017-05-20 18:05:43,663 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6261442317249549109_1001 src: /192.168.1.156:43483 dest: /192.168.1.156:50010
2017-05-20 18:05:46,092 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6261442317249549109_1001 of size 67108864 from /192.168.1.156
2017-05-20 18:05:46,092 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_-6261442317249549109_1001 terminating
2017-05-20 18:05:46,106 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1989889279775532485_1001 src: /192.168.1.155:36641 dest: /192.168.1.155:50010
2017-05-20 18:05:48,124 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1989889279775532485_1001 of size 67108864 from /192.168.1.155
2017-05-20 18:05:48,125 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_1989889279775532485_1001 terminating
2017-05-20 18:05:48,140 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8274412040191428808_1001 src: /192.168.1.155:36642 dest: /192.168.1.155:50010
2017-05-20 18:05:50,451 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8274412040191428808_1001 of size 67108864 from /192.168.1.155
2017-05-20 18:05:50,452 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 2 for block blk_8274412040191428808_1001 terminating
2017-05-20 18:05:50,461 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5714383415080207311_1001 src: /192.168.1.156:43484 dest: /192.168.1.156:50010
2017-05-20 18:05:52,419 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5714383415080207311_1001 of size 67108864 from /192.168.1.156
2017-05-20 18:05:52,419 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 1 for block blk_-5714383415080207311_1001 terminating
2017-05-20 18:05:52,435 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3343421719657974443_1001 src: /192.168.1.157:35705 dest: /192.168.1.157:50010
2017-05-20 18:05:54,892 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3343421719657974443_1001 of size 67103998 from /192.168.1.157
2017-05-20 18:05:54,893 INFO org.apache.hadoop.dfs.DataNode: PacketResponder 0 for block blk_3343421719657974443_1001 terminating
2017-05-20 18:05:57,077 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_3343421719657974443_1001 to 192.168.1.158:50010
2017-05-20 18:05:57,080 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_5765559863906286956_1001 to 192.168.1.158:50010
2017-05-20 18:06:01,312 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_5765559863906286956_1001 to /192.168.1.158:50010
2017-05-20 18:06:03,357 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_3343421719657974443_1001 to /192.168.1.158:50010
2017-05-20 18:06:09,085 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_6828596650668451241_1001 to 192.168.1.158:50010
2017-05-20 18:06:10,885 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_6828596650668451241_1001 to /192.168.1.158:50010
2017-05-20 18:09:46,220 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:09:59,109 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:09:59,304 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:09:59,306 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:09:59,308 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:09:59,376 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:09:59,435 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:09:59,436 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:09:59,436 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:09:59,654 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 18:09:59,687 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:09:59,689 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:09:59,689 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 18:09:59,694 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:09:59,710 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:09:59,715 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:09:59,716 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:09:59,717 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:09:59,718 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:09:59,718 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:09:59,718 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:09:59,721 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:09:59,721 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:09:59,730 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:10:02,727 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-05-20 18:11:02,317 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-8960126721114299935_1001
2017-05-20 18:11:08,689 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-341555671019868843_1002 src: /192.168.1.157:35711 dest: /192.168.1.157:50010
2017-05-20 18:11:08,712 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-341555671019868843_1002 src: /192.168.1.157:35711 dest: /192.168.1.157:50010 of size 91176
2017-05-20 18:11:08,785 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8706444252772910495_1003 src: /192.168.1.158:54114 dest: /192.168.1.158:50010
2017-05-20 18:11:08,787 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8706444252772910495_1003 src: /192.168.1.158:54114 dest: /192.168.1.158:50010 of size 4325
2017-05-20 18:11:09,063 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-341555671019868843_1002 to /192.168.1.159
2017-05-20 18:11:11,672 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1364770472399961564_1006 src: /192.168.1.158:54123 dest: /192.168.1.158:50010
2017-05-20 18:11:11,674 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1364770472399961564_1006 src: /192.168.1.158:54123 dest: /192.168.1.158:50010 of size 13545
2017-05-20 18:11:14,778 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2529622562193633477_1004 src: /192.168.1.158:54124 dest: /192.168.1.158:50010
2017-05-20 18:11:14,779 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2529622562193633477_1004 src: /192.168.1.158:54124 dest: /192.168.1.158:50010 of size 13560
2017-05-20 18:11:24,528 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 18:11:44,776 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 18:11:51,514 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 18:11:58,302 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 18:12:20,703 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6686808411793508191_1010 src: /192.168.1.158:54165 dest: /192.168.1.158:50010
2017-05-20 18:12:20,705 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6686808411793508191_1010 src: /192.168.1.158:54165 dest: /192.168.1.158:50010 of size 41464
2017-05-20 18:12:23,854 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8706444252772910495_1003 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8706444252772910495
2017-05-20 18:12:23,854 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6686808411793508191_1010 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6686808411793508191
2017-05-20 18:12:23,855 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-341555671019868843_1002 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-341555671019868843
2017-05-20 18:12:23,855 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1364770472399961564_1006 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1364770472399961564
2017-05-20 18:12:23,856 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2529622562193633477_1004 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2529622562193633477
2017-05-20 18:12:30,858 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:12:43,648 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:12:43,852 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:12:43,853 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:12:43,855 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:12:43,920 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:12:43,976 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:12:43,977 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:12:43,978 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:12:44,212 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 18:12:44,250 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:12:44,253 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:12:44,253 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 18:12:44,259 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:12:44,276 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:12:44,281 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:12:44,282 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:12:44,283 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:12:44,284 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:12:44,284 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:12:44,285 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:12:44,287 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:12:44,287 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:12:44,297 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:12:47,294 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 18:13:35,354 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-05-20 18:13:46,862 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_1989889279775532485_1001
2017-05-20 18:13:53,259 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1700614804323917826_1011 src: /192.168.1.156:43557 dest: /192.168.1.156:50010
2017-05-20 18:13:53,279 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1700614804323917826_1011 src: /192.168.1.156:43557 dest: /192.168.1.156:50010 of size 91176
2017-05-20 18:13:53,309 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2199716462899564507_1013 src: /192.168.1.157:35768 dest: /192.168.1.157:50010
2017-05-20 18:13:53,313 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2199716462899564507_1013 src: /192.168.1.157:35768 dest: /192.168.1.157:50010 of size 13560
2017-05-20 18:13:53,609 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-2199716462899564507_1013 to /192.168.1.159
2017-05-20 18:13:53,650 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-1700614804323917826_1011 to /192.168.1.159
2017-05-20 18:13:56,242 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1948789480193621057_1015 src: /192.168.1.156:43566 dest: /192.168.1.156:50010
2017-05-20 18:13:56,252 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1948789480193621057_1015 src: /192.168.1.156:43566 dest: /192.168.1.156:50010 of size 13545
2017-05-20 18:13:56,309 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1948789480193621057_1015 src: /192.168.1.157:35778 dest: /192.168.1.157:50010
2017-05-20 18:13:56,310 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-1948789480193621057_1015 received exception java.io.IOException: Block blk_-1948789480193621057_1015 is valid, and cannot be written to.
2017-05-20 18:13:56,311 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-1948789480193621057_1015 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:13:59,343 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1329816109970031423_1012 src: /192.168.1.158:54176 dest: /192.168.1.158:50010
2017-05-20 18:13:59,344 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1329816109970031423_1012 src: /192.168.1.158:54176 dest: /192.168.1.158:50010 of size 4325
2017-05-20 18:14:06,761 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 18:15:08,277 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6862974622856804057_1019 src: /192.168.1.158:54223 dest: /192.168.1.158:50010
2017-05-20 18:15:08,279 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6862974622856804057_1019 src: /192.168.1.158:54223 dest: /192.168.1.158:50010 of size 41464
2017-05-20 18:15:11,390 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2199716462899564507_1013 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2199716462899564507
2017-05-20 18:15:11,390 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1700614804323917826_1011 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1700614804323917826
2017-05-20 18:15:11,391 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1329816109970031423_1012 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1329816109970031423
2017-05-20 18:15:14,387 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1948789480193621057_1015 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1948789480193621057
2017-05-20 18:15:14,389 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6862974622856804057_1019 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6862974622856804057
2017-05-20 18:15:19,413 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:15:32,209 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:15:32,401 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:15:32,403 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:15:32,404 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:15:32,470 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:15:32,519 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:15:32,520 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:15:32,520 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:15:32,751 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 18:15:32,789 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:15:32,792 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:15:32,792 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 18:15:32,798 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:15:32,815 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:15:32,821 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:15:32,821 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:15:32,823 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:15:32,823 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:15:32,824 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:15:32,824 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:15:32,826 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:15:32,826 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:15:32,835 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:15:35,832 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 18:16:35,412 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_6828596650668451241_1001
2017-05-20 18:16:41,880 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5526129311833255096_1020 src: /192.168.1.156:43623 dest: /192.168.1.156:50010
2017-05-20 18:16:41,899 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5526129311833255096_1020 src: /192.168.1.156:43623 dest: /192.168.1.156:50010 of size 91176
2017-05-20 18:16:41,927 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3794998518481491965_1022 src: /192.168.1.157:35835 dest: /192.168.1.157:50010
2017-05-20 18:16:41,931 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3794998518481491965_1022 src: /192.168.1.157:35835 dest: /192.168.1.157:50010 of size 13560
2017-05-20 18:16:42,016 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3794998518481491965_1022 to /192.168.1.159
2017-05-20 18:16:42,058 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5526129311833255096_1020 to /192.168.1.159
2017-05-20 18:16:44,869 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_840217245701534988_1024 src: /192.168.1.156:43633 dest: /192.168.1.156:50010
2017-05-20 18:16:44,870 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6692078551248554754_1021 src: /192.168.1.156:43632 dest: /192.168.1.156:50010
2017-05-20 18:16:44,871 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6692078551248554754_1021 src: /192.168.1.156:43632 dest: /192.168.1.156:50010 of size 4325
2017-05-20 18:16:44,871 INFO org.apache.hadoop.dfs.DataNode: Received block blk_840217245701534988_1024 src: /192.168.1.156:43633 dest: /192.168.1.156:50010 of size 13545
2017-05-20 18:16:44,921 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_840217245701534988_1024 src: /192.168.1.157:35844 dest: /192.168.1.157:50010
2017-05-20 18:16:44,922 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_840217245701534988_1024 received exception java.io.IOException: Block blk_840217245701534988_1024 is valid, and cannot be written to.
2017-05-20 18:16:44,924 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_840217245701534988_1024 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:16:50,671 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 18:17:02,451 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 18:17:56,916 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4734885724015171481_1028 src: /192.168.1.158:54283 dest: /192.168.1.158:50010
2017-05-20 18:17:56,916 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4734885724015171481_1028 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-20 18:17:56,917 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:17:59,928 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5526129311833255096_1020 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5526129311833255096
2017-05-20 18:17:59,929 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3794998518481491965_1022 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3794998518481491965
2017-05-20 18:17:59,930 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_840217245701534988_1024 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_840217245701534988
2017-05-20 18:17:59,930 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6692078551248554754_1021 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6692078551248554754
2017-05-20 18:18:09,565 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:18:22,468 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:18:22,660 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:18:22,662 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:18:22,664 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:18:22,735 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:18:22,792 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:18:22,793 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:18:22,793 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:18:23,042 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 18:18:23,077 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:18:23,080 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:18:23,080 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 18:18:23,089 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:18:23,106 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:18:23,110 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:18:23,110 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:18:23,112 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:18:23,113 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:18:23,113 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:18:23,113 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:18:23,117 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:18:23,117 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:18:23,126 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:18:26,122 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 18:19:25,671 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-6261442317249549109_1001
2017-05-20 18:19:32,076 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-702727948796981217_1029 src: /192.168.1.157:35900 dest: /192.168.1.157:50010
2017-05-20 18:19:32,098 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-702727948796981217_1029 src: /192.168.1.157:35900 dest: /192.168.1.157:50010 of size 91176
2017-05-20 18:19:32,207 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5975994830349165320_1031 src: /192.168.1.158:54286 dest: /192.168.1.158:50010
2017-05-20 18:19:32,209 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5975994830349165320_1031 src: /192.168.1.158:54286 dest: /192.168.1.158:50010 of size 13560
2017-05-20 18:19:32,376 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5975994830349165320_1031 to /192.168.1.159
2017-05-20 18:19:32,409 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-702727948796981217_1029 to /192.168.1.159
2017-05-20 18:19:35,199 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6170008234003699756_1030 src: /192.168.1.156:43697 dest: /192.168.1.156:50010
2017-05-20 18:19:35,201 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6170008234003699756_1030 src: /192.168.1.156:43697 dest: /192.168.1.156:50010 of size 2165
2017-05-20 18:19:38,094 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5124168367570947434_1033 src: /192.168.1.158:54296 dest: /192.168.1.158:50010
2017-05-20 18:19:38,096 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5124168367570947434_1033 src: /192.168.1.158:54296 dest: /192.168.1.158:50010 of size 13545
2017-05-20 18:19:41,551 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 18:19:45,176 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 18:19:56,958 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 18:20:09,674 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 18:20:38,083 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2056984910228775235_1037 src: /192.168.1.157:35955 dest: /192.168.1.157:50010
2017-05-20 18:20:38,088 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2056984910228775235_1037 src: /192.168.1.157:35955 dest: /192.168.1.157:50010 of size 23481
2017-05-20 18:20:41,204 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-702727948796981217_1029 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-702727948796981217
2017-05-20 18:20:41,204 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5975994830349165320_1031 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5975994830349165320
2017-05-20 18:20:41,205 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6170008234003699756_1030 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6170008234003699756
2017-05-20 18:20:44,202 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5124168367570947434_1033 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5124168367570947434
2017-05-20 18:20:44,203 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2056984910228775235_1037 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2056984910228775235
2017-05-20 18:20:50,201 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:21:03,047 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:21:03,234 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:21:03,235 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:21:03,237 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:21:03,299 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:21:03,345 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:21:03,346 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:21:03,346 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:21:03,557 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-20 18:21:03,594 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:21:03,596 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:21:03,596 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 18:21:03,601 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:21:03,622 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:21:03,625 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:21:03,626 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:21:03,626 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:21:03,626 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:21:03,626 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:21:03,626 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:21:03,632 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:21:03,632 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:21:03,644 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:21:06,648 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 12 msecs
2017-05-20 18:22:06,244 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-5714383415080207311_1001
2017-05-20 18:22:12,730 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3795009347514280798_1042 src: /192.168.1.156:43735 dest: /192.168.1.156:50010
2017-05-20 18:22:12,748 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3795009347514280798_1042 src: /192.168.1.156:43735 dest: /192.168.1.156:50010 of size 13545
2017-05-20 18:22:12,751 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2226977055388164698_1038 src: /192.168.1.157:35961 dest: /192.168.1.157:50010
2017-05-20 18:22:12,758 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2226977055388164698_1038 src: /192.168.1.157:35961 dest: /192.168.1.157:50010 of size 91176
2017-05-20 18:22:13,130 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-2226977055388164698_1038 to /192.168.1.159
2017-05-20 18:22:15,717 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8615116141367552535_1039 src: /192.168.1.156:43745 dest: /192.168.1.156:50010
2017-05-20 18:22:15,718 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8615116141367552535_1039 src: /192.168.1.156:43745 dest: /192.168.1.156:50010 of size 2165
2017-05-20 18:22:15,746 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4741877897858491484_1040 src: /192.168.1.157:35970 dest: /192.168.1.157:50010
2017-05-20 18:22:15,748 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4741877897858491484_1040 src: /192.168.1.157:35970 dest: /192.168.1.157:50010 of size 13560
2017-05-20 18:22:23,056 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 18:22:35,171 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 18:22:38,658 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 18:22:59,191 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-20 18:23:18,746 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3414837301128297694_1046 src: /192.168.1.156:43782 dest: /192.168.1.156:50010
2017-05-20 18:23:18,750 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3414837301128297694_1046 src: /192.168.1.156:43782 dest: /192.168.1.156:50010 of size 23481
2017-05-20 18:23:21,702 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2226977055388164698_1038 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2226977055388164698
2017-05-20 18:23:21,702 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4741877897858491484_1040 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4741877897858491484
2017-05-20 18:23:21,703 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8615116141367552535_1039 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8615116141367552535
2017-05-20 18:23:24,700 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3414837301128297694_1046 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3414837301128297694
2017-05-20 18:23:24,700 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3795009347514280798_1042 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3795009347514280798
2017-05-20 18:23:29,841 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:23:42,629 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:23:42,817 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:23:42,819 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:23:42,820 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:23:42,888 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:23:42,944 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:23:42,945 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:23:42,945 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:23:43,180 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-20 18:23:43,219 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:23:43,221 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:23:43,221 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 18:23:43,225 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:23:43,240 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:23:43,245 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:23:43,246 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:23:43,247 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:23:43,248 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:23:43,248 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:23:43,248 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:23:43,250 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:23:43,251 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:23:43,259 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:23:46,255 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 4 msecs
2017-05-20 18:24:45,828 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_8274412040191428808_1001
2017-05-20 18:24:52,300 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-452659020301593064_1047 src: /192.168.1.156:43788 dest: /192.168.1.156:50010
2017-05-20 18:24:52,320 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-452659020301593064_1047 src: /192.168.1.156:43788 dest: /192.168.1.156:50010 of size 91176
2017-05-20 18:24:52,330 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7520780235706880559_1048 src: /192.168.1.157:36016 dest: /192.168.1.157:50010
2017-05-20 18:24:52,333 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7520780235706880559_1048 src: /192.168.1.157:36016 dest: /192.168.1.157:50010 of size 2165
2017-05-20 18:24:52,580 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-452659020301593064_1047 to /192.168.1.159
2017-05-20 18:24:53,536 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 18:24:55,328 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4651210740380350651_1049 src: /192.168.1.157:36025 dest: /192.168.1.157:50010
2017-05-20 18:24:55,333 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4651210740380350651_1049 src: /192.168.1.157:36025 dest: /192.168.1.157:50010 of size 13560
2017-05-20 18:24:55,335 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4651210740380350651_1049 src: /192.168.1.157:36026 dest: /192.168.1.157:50010
2017-05-20 18:24:55,335 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-4651210740380350651_1049 received exception java.io.IOException: Block blk_-4651210740380350651_1049 is valid, and cannot be written to.
2017-05-20 18:24:55,337 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-4651210740380350651_1049 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:24:58,330 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2661340142493920207_1051 src: /192.168.1.157:36028 dest: /192.168.1.157:50010
2017-05-20 18:24:58,331 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2661340142493920207_1051 src: /192.168.1.157:36028 dest: /192.168.1.157:50010 of size 13545
2017-05-20 18:25:14,560 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 18:25:26,356 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 18:25:37,846 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 18:26:01,359 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5866260327027445183_1055 src: /192.168.1.157:36063 dest: /192.168.1.157:50010
2017-05-20 18:26:01,365 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5866260327027445183_1055 src: /192.168.1.157:36063 dest: /192.168.1.157:50010 of size 23481
2017-05-20 18:26:04,356 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7520780235706880559_1048 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7520780235706880559
2017-05-20 18:26:04,357 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4651210740380350651_1049 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4651210740380350651
2017-05-20 18:26:04,357 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-452659020301593064_1047 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-452659020301593064
2017-05-20 18:26:04,358 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2661340142493920207_1051 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2661340142493920207
2017-05-20 18:26:12,107 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:26:24,840 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:26:25,059 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:26:25,061 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:26:25,063 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:26:25,132 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:26:25,190 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:26:25,191 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:26:25,191 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:26:25,411 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 18:26:25,443 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:26:25,446 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:26:25,446 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 18:26:25,452 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:26:25,467 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:26:25,472 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:26:25,472 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:26:25,474 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:26:25,474 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:26:25,475 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:26:25,475 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:26:25,477 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:26:25,477 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:26:25,485 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:26:25,508 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-5866260327027445183_1055
2017-05-20 18:26:28,487 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 7 msecs
2017-05-20 18:27:01,523 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5866260327027445183_1055 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5866260327027445183
2017-05-20 18:27:34,520 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5363129567263702465_1056 src: /192.168.1.158:54417 dest: /192.168.1.158:50010
2017-05-20 18:27:34,537 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5363129567263702465_1056 src: /192.168.1.158:54417 dest: /192.168.1.158:50010 of size 91176
2017-05-20 18:27:34,643 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1594926887030876493_1057 src: /192.168.1.158:54418 dest: /192.168.1.158:50010
2017-05-20 18:27:34,645 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1594926887030876493_1057 src: /192.168.1.158:54418 dest: /192.168.1.158:50010 of size 2165
2017-05-20 18:27:34,871 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5363129567263702465_1056 to /192.168.1.159
2017-05-20 18:27:37,479 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1824200093736723287_1060 src: /192.168.1.157:36078 dest: /192.168.1.157:50010
2017-05-20 18:27:37,480 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1824200093736723287_1060 src: /192.168.1.157:36078 dest: /192.168.1.157:50010 of size 13552
2017-05-20 18:27:37,639 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6516022275133875960_1058 src: /192.168.1.156:43856 dest: /192.168.1.156:50010
2017-05-20 18:27:37,640 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6516022275133875960_1058 src: /192.168.1.156:43857 dest: /192.168.1.156:50010
2017-05-20 18:27:37,640 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6516022275133875960_1058 received exception java.io.IOException: Block blk_6516022275133875960_1058 has already been started (though not completed), and thus cannot be created.
2017-05-20 18:27:37,641 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_6516022275133875960_1058 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:27:37,642 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6516022275133875960_1058 src: /192.168.1.156:43856 dest: /192.168.1.156:50010 of size 13567
2017-05-20 18:27:40,545 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_6516022275133875960_1058 to 192.168.1.158:50010
2017-05-20 18:27:40,551 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_6516022275133875960_1058 to /192.168.1.158:50010
2017-05-20 18:27:44,320 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 18:27:56,707 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 18:28:08,704 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 18:28:20,368 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 18:28:40,504 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5099961120954003948_1064 src: /192.168.1.157:36122 dest: /192.168.1.157:50010
2017-05-20 18:28:40,510 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5099961120954003948_1064 src: /192.168.1.157:36122 dest: /192.168.1.157:50010 of size 23481
2017-05-20 18:28:43,572 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5363129567263702465_1056 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5363129567263702465
2017-05-20 18:28:43,573 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1594926887030876493_1057 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1594926887030876493
2017-05-20 18:28:43,573 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6516022275133875960_1058 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6516022275133875960
2017-05-20 18:28:46,573 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5099961120954003948_1064 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5099961120954003948
2017-05-20 18:28:46,574 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1824200093736723287_1060 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1824200093736723287
2017-05-20 18:28:52,672 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-20 18:28:52,688 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:29:05,401 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:29:05,586 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:29:05,588 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:29:05,590 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:29:05,661 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:29:05,718 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:29:05,719 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:29:05,719 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:29:05,957 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 18:29:05,992 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:29:05,995 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:29:05,996 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 18:29:06,001 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:29:06,018 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:29:06,022 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:29:06,023 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:29:06,024 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:29:06,025 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:29:06,025 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:29:06,026 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:29:06,036 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:29:06,037 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:29:06,048 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:29:09,050 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 13 msecs
2017-05-20 18:30:08,597 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_5765559863906286956_1001
2017-05-20 18:30:15,180 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1903396978967549070_1066 src: /192.168.1.157:36127 dest: /192.168.1.157:50010
2017-05-20 18:30:15,198 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1903396978967549070_1066 src: /192.168.1.157:36127 dest: /192.168.1.157:50010 of size 2165
2017-05-20 18:30:15,207 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3800201478705313291_1065 src: /192.168.1.156:43894 dest: /192.168.1.156:50010
2017-05-20 18:30:15,219 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3800201478705313291_1065 src: /192.168.1.156:43894 dest: /192.168.1.156:50010 of size 91176
2017-05-20 18:30:15,531 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3800201478705313291_1065 to /192.168.1.159
2017-05-20 18:30:16,497 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 18:30:18,170 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6217182100690126668_1069 src: /192.168.1.157:36137 dest: /192.168.1.157:50010
2017-05-20 18:30:18,171 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6217182100690126668_1069 src: /192.168.1.157:36137 dest: /192.168.1.157:50010 of size 13552
2017-05-20 18:30:18,212 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3539357121429466649_1067 src: /192.168.1.156:43903 dest: /192.168.1.156:50010
2017-05-20 18:30:18,213 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3539357121429466649_1067 src: /192.168.1.156:43903 dest: /192.168.1.156:50010 of size 13567
2017-05-20 18:30:18,214 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3539357121429466649_1067 src: /192.168.1.156:43904 dest: /192.168.1.156:50010
2017-05-20 18:30:18,214 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3539357121429466649_1067 received exception java.io.IOException: Block blk_-3539357121429466649_1067 is valid, and cannot be written to.
2017-05-20 18:30:18,215 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-3539357121429466649_1067 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:30:37,598 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 18:30:49,701 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 18:30:53,858 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 18:31:24,143 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3539357121429466649_1067 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3539357121429466649
2017-05-20 18:31:24,144 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1903396978967549070_1066 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1903396978967549070
2017-05-20 18:31:24,145 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3800201478705313291_1065 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3800201478705313291
2017-05-20 18:31:27,142 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6217182100690126668_1069 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6217182100690126668
2017-05-20 18:31:32,357 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:31:45,101 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:31:45,296 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:31:45,299 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:31:45,302 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:31:45,370 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:31:45,426 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:31:45,427 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:31:45,427 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:31:45,657 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 18:31:45,692 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:31:45,695 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:31:45,695 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 18:31:45,700 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:31:45,717 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:31:45,721 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:31:45,722 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:31:45,723 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:31:45,724 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:31:45,724 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:31:45,724 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:31:45,750 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:31:45,750 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:31:45,762 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:31:48,760 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 10 msecs
2017-05-20 18:32:33,855 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 18:32:48,311 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_3343421719657974443_1001
2017-05-20 18:32:54,848 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8604031742913090048_1074 src: /192.168.1.156:43951 dest: /192.168.1.156:50010
2017-05-20 18:32:54,872 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8604031742913090048_1074 src: /192.168.1.156:43951 dest: /192.168.1.156:50010 of size 91176
2017-05-20 18:32:54,921 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7574162907653786471_1076 src: /192.168.1.158:54503 dest: /192.168.1.158:50010
2017-05-20 18:32:54,923 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7574162907653786471_1076 src: /192.168.1.158:54503 dest: /192.168.1.158:50010 of size 13567
2017-05-20 18:32:55,105 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-7574162907653786471_1076 to /192.168.1.159
2017-05-20 18:32:55,157 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8604031742913090048_1074 to /192.168.1.159
2017-05-20 18:32:56,127 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 18:32:57,917 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6057134768983828499_1075 src: /192.168.1.157:36190 dest: /192.168.1.157:50010
2017-05-20 18:32:57,931 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9134417592343064703_1078 src: /192.168.1.157:36191 dest: /192.168.1.157:50010
2017-05-20 18:32:57,932 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6057134768983828499_1075 src: /192.168.1.157:36190 dest: /192.168.1.157:50010 of size 2165
2017-05-20 18:32:57,932 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9134417592343064703_1078 src: /192.168.1.157:36191 dest: /192.168.1.157:50010 of size 13552
2017-05-20 18:33:16,646 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 18:33:28,667 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 18:33:40,417 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 18:34:00,919 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9134417592343064703_1078 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9134417592343064703
2017-05-20 18:34:00,920 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8604031742913090048_1074 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8604031742913090048
2017-05-20 18:34:00,920 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7574162907653786471_1076 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7574162907653786471
2017-05-20 18:34:00,920 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6057134768983828499_1075 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6057134768983828499
2017-05-20 18:34:09,524 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:34:22,410 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:34:22,638 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:34:22,640 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:34:22,642 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:34:22,711 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:34:22,769 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:34:22,770 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:34:22,770 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:34:23,007 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 18:34:23,046 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:34:23,049 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:34:23,049 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-20 18:34:23,055 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:34:23,073 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:34:23,078 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:34:23,079 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:34:23,080 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:34:23,081 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:34:23,081 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:34:23,081 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:34:23,086 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:34:23,086 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:34:23,094 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:34:26,092 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-05-20 18:35:32,089 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3154669505021208843_1087 src: /192.168.1.157:36229 dest: /192.168.1.157:50010
2017-05-20 18:35:32,103 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3154669505021208843_1087 src: /192.168.1.157:36229 dest: /192.168.1.157:50010 of size 13544
2017-05-20 18:35:32,130 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3140111103834076507_1083 src: /192.168.1.156:44002 dest: /192.168.1.156:50010
2017-05-20 18:35:32,145 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3140111103834076507_1083 src: /192.168.1.156:44002 dest: /192.168.1.156:50010 of size 91176
2017-05-20 18:35:32,316 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3140111103834076507_1083 to /192.168.1.159
2017-05-20 18:35:33,280 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 18:35:35,128 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8091946375240979743_1085 src: /192.168.1.156:44013 dest: /192.168.1.156:50010
2017-05-20 18:35:35,130 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8091946375240979743_1085 src: /192.168.1.156:44013 dest: /192.168.1.156:50010 of size 13559
2017-05-20 18:35:38,131 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6301195639119825934_1084 src: /192.168.1.156:44014 dest: /192.168.1.156:50010
2017-05-20 18:35:38,132 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6301195639119825934_1084 src: /192.168.1.156:44014 dest: /192.168.1.156:50010 of size 1085
2017-05-20 18:35:50,113 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 18:35:56,037 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 18:36:12,287 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 18:36:31,093 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 18:37:17,214 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3140111103834076507_1083 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3140111103834076507
2017-05-20 18:37:17,214 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6301195639119825934_1084 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6301195639119825934
2017-05-20 18:37:17,215 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8091946375240979743_1085 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8091946375240979743
2017-05-20 18:37:20,212 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3154669505021208843_1087 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3154669505021208843
2017-05-20 18:37:27,088 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:37:39,904 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:37:40,092 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:37:40,094 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:37:40,096 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:37:40,162 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:37:40,220 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:37:40,221 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:37:40,221 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:37:40,454 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 18:37:40,489 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:37:40,492 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:37:40,492 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 18:37:40,497 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:37:40,514 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:37:40,519 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:37:40,520 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:37:40,529 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:37:40,529 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:37:40,530 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:37:40,530 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:37:40,560 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:37:40,561 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:37:40,571 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:37:43,574 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 13 msecs
2017-05-20 18:38:49,630 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1605783122667216464_1096 src: /192.168.1.157:36274 dest: /192.168.1.157:50010
2017-05-20 18:38:49,647 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1605783122667216464_1096 src: /192.168.1.157:36274 dest: /192.168.1.157:50010 of size 13544
2017-05-20 18:38:49,668 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3723374183452630093_1092 src: /192.168.1.156:44050 dest: /192.168.1.156:50010
2017-05-20 18:38:49,675 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3723374183452630093_1092 src: /192.168.1.156:44050 dest: /192.168.1.156:50010 of size 91176
2017-05-20 18:38:49,876 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3723374183452630093_1092 to /192.168.1.159
2017-05-20 18:38:52,600 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1465105047459479395_1093 src: /192.168.1.157:36284 dest: /192.168.1.157:50010
2017-05-20 18:38:52,602 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1465105047459479395_1093 src: /192.168.1.157:36284 dest: /192.168.1.157:50010 of size 1085
2017-05-20 18:38:52,672 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6575419904060121367_1094 src: /192.168.1.156:44060 dest: /192.168.1.156:50010
2017-05-20 18:38:52,672 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6575419904060121367_1094 src: /192.168.1.156:44061 dest: /192.168.1.156:50010
2017-05-20 18:38:52,672 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-6575419904060121367_1094 received exception java.io.IOException: Block blk_-6575419904060121367_1094 has already been started (though not completed), and thus cannot be created.
2017-05-20 18:38:52,673 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6575419904060121367_1094 src: /192.168.1.156:44060 dest: /192.168.1.156:50010 of size 13559
2017-05-20 18:38:52,675 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-6575419904060121367_1094 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:39:09,597 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 18:39:16,718 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 18:39:33,018 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-20 18:40:16,630 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3242230128347847890_1100 src: /192.168.1.157:36311 dest: /192.168.1.157:50010
2017-05-20 18:40:16,635 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3242230128347847890_1100 src: /192.168.1.157:36311 dest: /192.168.1.157:50010 of size 15728
2017-05-20 18:40:19,712 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6575419904060121367_1094 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6575419904060121367
2017-05-20 18:40:19,712 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3723374183452630093_1092 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3723374183452630093
2017-05-20 18:40:19,712 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1605783122667216464_1096 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1605783122667216464
2017-05-20 18:40:19,713 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1465105047459479395_1093 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1465105047459479395
2017-05-20 18:40:25,670 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:40:38,510 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:40:38,698 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:40:38,700 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:40:38,702 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:40:38,758 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:40:38,815 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:40:38,816 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:40:38,816 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:40:39,032 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 18:40:39,064 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:40:39,067 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:40:39,067 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 18:40:39,072 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:40:39,089 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:40:39,093 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:40:39,094 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:40:39,096 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:40:39,096 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:40:39,096 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:40:39,097 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:40:39,112 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:40:39,113 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:40:39,123 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:40:39,151 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_3242230128347847890_1100
2017-05-20 18:40:42,126 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 10 msecs
2017-05-20 18:41:15,170 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3242230128347847890_1100 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3242230128347847890
2017-05-20 18:41:48,179 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4450225158746409442_1101 src: /192.168.1.157:36318 dest: /192.168.1.157:50010
2017-05-20 18:41:48,198 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4450225158746409442_1101 src: /192.168.1.157:36318 dest: /192.168.1.157:50010 of size 91176
2017-05-20 18:41:48,203 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_178285810884785559_1102 src: /192.168.1.158:54609 dest: /192.168.1.158:50010
2017-05-20 18:41:48,204 INFO org.apache.hadoop.dfs.DataNode: Received block blk_178285810884785559_1102 src: /192.168.1.158:54609 dest: /192.168.1.158:50010 of size 1085
2017-05-20 18:41:48,441 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4450225158746409442_1101 to /192.168.1.159
2017-05-20 18:41:49,429 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 18:41:51,165 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2202303530091116050_1103 src: /192.168.1.157:36328 dest: /192.168.1.157:50010
2017-05-20 18:41:51,166 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2202303530091116050_1103 src: /192.168.1.157:36328 dest: /192.168.1.157:50010 of size 13559
2017-05-20 18:41:54,172 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2331725489236391954_1105 src: /192.168.1.156:44100 dest: /192.168.1.156:50010
2017-05-20 18:41:54,174 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2331725489236391954_1105 src: /192.168.1.156:44100 dest: /192.168.1.156:50010 of size 13544
2017-05-20 18:42:05,287 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 18:42:11,153 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 18:42:26,493 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 18:42:49,497 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 18:43:12,202 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3794931052364767989_1109 src: /192.168.1.158:54633 dest: /192.168.1.158:50010
2017-05-20 18:43:12,204 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3794931052364767989_1109 src: /192.168.1.158:54633 dest: /192.168.1.158:50010 of size 15728
2017-05-20 18:43:15,261 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4450225158746409442_1101 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4450225158746409442
2017-05-20 18:43:15,261 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2202303530091116050_1103 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2202303530091116050
2017-05-20 18:43:15,262 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_178285810884785559_1102 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_178285810884785559
2017-05-20 18:43:18,261 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2331725489236391954_1105 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2331725489236391954
2017-05-20 18:43:18,262 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3794931052364767989_1109 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3794931052364767989
2017-05-20 18:43:24,876 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:43:37,703 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:43:37,885 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:43:37,887 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:43:37,888 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:43:37,961 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:43:38,019 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:43:38,020 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:43:38,020 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:43:38,246 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 18:43:38,282 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:43:38,284 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:43:38,285 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 18:43:38,290 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:43:38,306 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:43:38,312 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:43:38,312 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:43:38,313 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:43:38,314 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:43:38,314 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:43:38,314 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:43:38,320 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:43:38,321 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:43:38,333 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:43:41,335 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 10 msecs
2017-05-20 18:44:47,509 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-831600024155643051_1112 src: /192.168.1.156:44129 dest: /192.168.1.156:50010
2017-05-20 18:44:47,509 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_612862782431164871_1110 src: /192.168.1.157:36359 dest: /192.168.1.157:50010
2017-05-20 18:44:47,533 INFO org.apache.hadoop.dfs.DataNode: Received block blk_612862782431164871_1110 src: /192.168.1.157:36359 dest: /192.168.1.157:50010 of size 91176
2017-05-20 18:44:47,533 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-831600024155643051_1112 src: /192.168.1.156:44129 dest: /192.168.1.156:50010 of size 13567
2017-05-20 18:44:47,801 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-831600024155643051_1112 to /192.168.1.159
2017-05-20 18:44:47,843 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_612862782431164871_1110 to /192.168.1.159
2017-05-20 18:44:48,751 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 18:44:50,471 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_274245672377604005_1114 src: /192.168.1.157:36369 dest: /192.168.1.157:50010
2017-05-20 18:44:50,471 INFO org.apache.hadoop.dfs.DataNode: Received block blk_274245672377604005_1114 src: /192.168.1.157:36369 dest: /192.168.1.157:50010 of size 13552
2017-05-20 18:44:50,472 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5390715130556270959_1111 src: /192.168.1.157:36370 dest: /192.168.1.157:50010
2017-05-20 18:44:50,473 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5390715130556270959_1111 src: /192.168.1.157:36370 dest: /192.168.1.157:50010 of size 1085
2017-05-20 18:44:50,481 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5390715130556270959_1111 src: /192.168.1.156:44139 dest: /192.168.1.156:50010
2017-05-20 18:44:50,481 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5390715130556270959_1111 received exception java.io.IOException: Block blk_5390715130556270959_1111 is valid, and cannot be written to.
2017-05-20 18:44:50,482 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_5390715130556270959_1111 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:44:50,482 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_274245672377604005_1114 src: /192.168.1.156:44140 dest: /192.168.1.156:50010
2017-05-20 18:44:50,483 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_274245672377604005_1114 received exception java.io.IOException: Block blk_274245672377604005_1114 is valid, and cannot be written to.
2017-05-20 18:44:50,484 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_274245672377604005_1114 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:45:04,756 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 18:45:10,567 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 18:45:26,829 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 18:46:08,502 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7733303362295591611_1118 src: /192.168.1.157:36395 dest: /192.168.1.157:50010
2017-05-20 18:46:08,506 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7733303362295591611_1118 src: /192.168.1.157:36395 dest: /192.168.1.157:50010 of size 17069
2017-05-20 18:46:11,437 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-831600024155643051_1112 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-831600024155643051
2017-05-20 18:46:11,438 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_612862782431164871_1110 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_612862782431164871
2017-05-20 18:46:11,438 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5390715130556270959_1111 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5390715130556270959
2017-05-20 18:46:14,436 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_274245672377604005_1114 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_274245672377604005
2017-05-20 18:46:14,436 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7733303362295591611_1118 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7733303362295591611
2017-05-20 18:46:19,511 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:46:32,385 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:46:32,587 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:46:32,588 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:46:32,590 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:46:32,661 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:46:32,720 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:46:32,721 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:46:32,721 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:46:32,960 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 18:46:32,997 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:46:33,000 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:46:33,001 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 18:46:33,008 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:46:33,026 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:46:33,031 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:46:33,032 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:46:33,033 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:46:33,033 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:46:33,033 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:46:33,033 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:46:33,036 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:46:33,036 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:46:33,046 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:46:36,043 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 7 msecs
2017-05-20 18:47:42,131 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8946530266902425126_1120 src: /192.168.1.156:44171 dest: /192.168.1.156:50010
2017-05-20 18:47:42,143 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6059760728669638185_1119 src: /192.168.1.157:36400 dest: /192.168.1.157:50010
2017-05-20 18:47:42,148 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8946530266902425126_1120 src: /192.168.1.156:44171 dest: /192.168.1.156:50010 of size 1085
2017-05-20 18:47:42,149 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6059760728669638185_1119 src: /192.168.1.157:36400 dest: /192.168.1.157:50010 of size 91176
2017-05-20 18:47:42,314 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6059760728669638185_1119 to /192.168.1.159
2017-05-20 18:47:43,273 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 18:47:48,076 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1281156683827971563_1121 src: /192.168.1.158:54669 dest: /192.168.1.158:50010
2017-05-20 18:47:48,079 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1281156683827971563_1121 src: /192.168.1.158:54669 dest: /192.168.1.158:50010 of size 13567
2017-05-20 18:47:48,131 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8397373399838108651_1123 src: /192.168.1.156:44183 dest: /192.168.1.156:50010
2017-05-20 18:47:48,133 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8397373399838108651_1123 src: /192.168.1.156:44183 dest: /192.168.1.156:50010 of size 13552
2017-05-20 18:47:59,381 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 18:48:05,045 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 18:48:21,000 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 18:48:30,158 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 18:48:46,329 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-20 18:49:33,153 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4662722114504511008_1127 src: /192.168.1.158:54685 dest: /192.168.1.158:50010
2017-05-20 18:49:33,155 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4662722114504511008_1127 src: /192.168.1.158:54685 dest: /192.168.1.158:50010 of size 18278
2017-05-20 18:49:36,144 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8946530266902425126_1120 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8946530266902425126
2017-05-20 18:49:36,144 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6059760728669638185_1119 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6059760728669638185
2017-05-20 18:49:36,145 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1281156683827971563_1121 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1281156683827971563
2017-05-20 18:49:36,145 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8397373399838108651_1123 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8397373399838108651
2017-05-20 18:49:42,081 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:49:54,867 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:49:55,056 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:49:55,058 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:49:55,059 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:49:55,113 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:49:55,160 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:49:55,160 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:49:55,161 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:49:55,365 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 18:49:55,398 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:49:55,400 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:49:55,401 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 18:49:55,405 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:49:55,422 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:49:55,427 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:49:55,427 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:49:55,429 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:49:55,429 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:49:55,430 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:49:55,430 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:49:55,455 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:49:55,456 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:49:55,471 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:49:55,500 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_4662722114504511008_1127
2017-05-20 18:49:58,470 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 13 msecs
2017-05-20 18:50:31,510 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4662722114504511008_1127 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4662722114504511008
2017-05-20 18:51:04,620 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5923363475851870836_1128 src: /192.168.1.158:54689 dest: /192.168.1.158:50010
2017-05-20 18:51:04,620 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1803744006344015264_1132 src: /192.168.1.158:54688 dest: /192.168.1.158:50010
2017-05-20 18:51:04,636 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1803744006344015264_1132 src: /192.168.1.158:54688 dest: /192.168.1.158:50010 of size 13552
2017-05-20 18:51:04,636 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5923363475851870836_1128 src: /192.168.1.158:54689 dest: /192.168.1.158:50010 of size 91176
2017-05-20 18:51:04,870 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5923363475851870836_1128 to /192.168.1.159
2017-05-20 18:51:05,805 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 18:51:07,575 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2463453843406674641_1130 src: /192.168.1.156:44234 dest: /192.168.1.156:50010
2017-05-20 18:51:07,577 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2463453843406674641_1130 src: /192.168.1.156:44234 dest: /192.168.1.156:50010 of size 13567
2017-05-20 18:51:10,576 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4278852597544381169_1129 src: /192.168.1.156:44236 dest: /192.168.1.156:50010
2017-05-20 18:51:10,577 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4278852597544381169_1129 src: /192.168.1.156:44236 dest: /192.168.1.156:50010 of size 1085
2017-05-20 18:51:22,001 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 18:51:27,542 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 18:51:42,659 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 18:51:47,383 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 18:52:03,992 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 18:52:46,631 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7151749838111259903_1136 src: /192.168.1.158:54714 dest: /192.168.1.158:50010
2017-05-20 18:52:46,632 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7151749838111259903_1136 src: /192.168.1.158:54714 dest: /192.168.1.158:50010 of size 16131
2017-05-20 18:52:49,614 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5923363475851870836_1128 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5923363475851870836
2017-05-20 18:52:49,615 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4278852597544381169_1129 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4278852597544381169
2017-05-20 18:52:49,615 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1803744006344015264_1132 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1803744006344015264
2017-05-20 18:52:49,616 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2463453843406674641_1130 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2463453843406674641
2017-05-20 18:52:57,363 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:53:10,186 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:53:10,394 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:53:10,395 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:53:10,397 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:53:10,461 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:53:10,518 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:53:10,519 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:53:10,519 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:53:10,760 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 18:53:10,798 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:53:10,801 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:53:10,801 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 18:53:10,807 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:53:10,827 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:53:10,833 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:53:10,834 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:53:10,834 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:53:10,834 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:53:10,834 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:53:10,835 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:53:10,837 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:53:10,838 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:53:10,844 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:53:10,871 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-7151749838111259903_1136
2017-05-20 18:53:13,846 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 5 msecs
2017-05-20 18:53:46,862 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7151749838111259903_1136 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7151749838111259903
2017-05-20 18:54:19,870 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2577513064031040943_1139 src: /192.168.1.156:44273 dest: /192.168.1.156:50010
2017-05-20 18:54:19,889 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-670982133066425799_1137 src: /192.168.1.158:54717 dest: /192.168.1.158:50010
2017-05-20 18:54:19,889 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2577513064031040943_1139 src: /192.168.1.156:44273 dest: /192.168.1.156:50010 of size 13560
2017-05-20 18:54:19,897 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-670982133066425799_1137 src: /192.168.1.158:54717 dest: /192.168.1.158:50010 of size 91176
2017-05-20 18:54:20,121 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-2577513064031040943_1139 to /192.168.1.159
2017-05-20 18:54:20,160 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-670982133066425799_1137 to /192.168.1.159
2017-05-20 18:54:22,859 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1603210800497871375_1138 src: /192.168.1.157:36503 dest: /192.168.1.157:50010
2017-05-20 18:54:22,860 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1603210800497871375_1138 src: /192.168.1.157:36504 dest: /192.168.1.157:50010
2017-05-20 18:54:22,860 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-1603210800497871375_1138 received exception java.io.IOException: Block blk_-1603210800497871375_1138 has already been started (though not completed), and thus cannot be created.
2017-05-20 18:54:22,861 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8555968944373928939_1141 src: /192.168.1.156:44284 dest: /192.168.1.156:50010
2017-05-20 18:54:22,861 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1603210800497871375_1138 src: /192.168.1.157:36503 dest: /192.168.1.157:50010 of size 4325
2017-05-20 18:54:22,861 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8555968944373928939_1141 src: /192.168.1.156:44283 dest: /192.168.1.156:50010
2017-05-20 18:54:22,864 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8555968944373928939_1141 src: /192.168.1.156:44284 dest: /192.168.1.156:50010 of size 13545
2017-05-20 18:54:22,868 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-1603210800497871375_1138 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:54:22,868 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8555968944373928939_1141 received exception java.io.IOException: Block blk_8555968944373928939_1141 is valid, and cannot be written to.
2017-05-20 18:54:22,869 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8555968944373928939_1141 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:54:25,886 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8555968944373928939_1141 to 192.168.1.158:50010
2017-05-20 18:54:25,889 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_8555968944373928939_1141 to /192.168.1.158:50010
2017-05-20 18:54:33,487 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 18:54:34,433 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 18:54:40,478 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 18:54:47,647 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 18:55:10,887 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-710098546632461720_1145 src: /192.168.1.157:36543 dest: /192.168.1.157:50010
2017-05-20 18:55:10,902 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-710098546632461720_1145 src: /192.168.1.157:36543 dest: /192.168.1.157:50010 of size 41464
2017-05-20 18:55:16,910 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2577513064031040943_1139 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2577513064031040943
2017-05-20 18:55:16,911 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1603210800497871375_1138 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1603210800497871375
2017-05-20 18:55:16,911 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-710098546632461720_1145 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-710098546632461720
2017-05-20 18:55:16,912 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-670982133066425799_1137 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-670982133066425799
2017-05-20 18:55:16,912 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8555968944373928939_1141 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8555968944373928939
2017-05-20 18:55:22,932 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:55:35,791 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:55:35,987 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:55:35,988 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:55:35,989 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:55:36,056 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:55:36,112 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:55:36,113 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:55:36,113 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:55:36,358 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 18:55:36,396 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:55:36,398 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:55:36,398 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 18:55:36,403 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:55:36,420 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:55:36,425 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:55:36,426 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:55:36,427 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:55:36,434 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:55:36,434 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:55:36,434 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:55:36,437 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:55:36,438 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:55:36,446 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:55:39,444 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-05-20 18:56:45,492 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7657695105417788910_1147 src: /192.168.1.157:36550 dest: /192.168.1.157:50010
2017-05-20 18:56:45,508 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7657695105417788910_1147 src: /192.168.1.157:36550 dest: /192.168.1.157:50010 of size 4325
2017-05-20 18:56:45,533 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_563003792418146069_1146 src: /192.168.1.158:54761 dest: /192.168.1.158:50010
2017-05-20 18:56:45,540 INFO org.apache.hadoop.dfs.DataNode: Received block blk_563003792418146069_1146 src: /192.168.1.158:54761 dest: /192.168.1.158:50010 of size 91176
2017-05-20 18:56:45,873 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_563003792418146069_1146 to /192.168.1.159
2017-05-20 18:56:48,472 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_870402424932069049_1148 src: /192.168.1.157:36561 dest: /192.168.1.157:50010
2017-05-20 18:56:48,473 INFO org.apache.hadoop.dfs.DataNode: Received block blk_870402424932069049_1148 src: /192.168.1.157:36561 dest: /192.168.1.157:50010 of size 13560
2017-05-20 18:56:48,512 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1943477535588658196_1150 src: /192.168.1.156:44338 dest: /192.168.1.156:50010
2017-05-20 18:56:48,513 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1943477535588658196_1150 src: /192.168.1.156:44339 dest: /192.168.1.156:50010
2017-05-20 18:56:48,513 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1943477535588658196_1150 received exception java.io.IOException: Block blk_1943477535588658196_1150 has already been started (though not completed), and thus cannot be created.
2017-05-20 18:56:48,514 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1943477535588658196_1150 src: /192.168.1.156:44338 dest: /192.168.1.156:50010 of size 13545
2017-05-20 18:56:48,517 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_1943477535588658196_1150 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:56:51,339 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 18:56:51,471 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_1943477535588658196_1150 to 192.168.1.158:50010
2017-05-20 18:56:51,475 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_1943477535588658196_1150 to /192.168.1.158:50010
2017-05-20 18:56:52,094 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 18:56:54,778 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 18:57:00,321 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 18:57:12,762 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 18:57:33,535 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3108059914469806090_1152 src: /192.168.1.158:54807 dest: /192.168.1.158:50010
2017-05-20 18:57:33,995 INFO org.apache.hadoop.dfs.DataNode: Exception in receiveBlock for block blk_3108059914469806090_1152 java.io.EOFException: while trying to read 66073 bytes
2017-05-20 18:57:33,995 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3108059914469806090_1152 received exception java.io.EOFException: while trying to read 66073 bytes
2017-05-20 18:57:33,996 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.EOFException: while trying to read 66073 bytes
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.readToBuf(DataNode.java:2464)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.readNextPacket(DataNode.java:2508)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receivePacket(DataNode.java:2572)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2698)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:57:42,508 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7657695105417788910_1147 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7657695105417788910
2017-05-20 18:57:42,509 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_563003792418146069_1146 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_563003792418146069
2017-05-20 18:57:42,509 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_870402424932069049_1148 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_870402424932069049
2017-05-20 18:57:42,509 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1943477535588658196_1150 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1943477535588658196
2017-05-20 18:57:48,510 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-20 18:57:48,539 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 18:58:01,390 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 18:58:01,583 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 18:58:01,585 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 18:58:01,586 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 18:58:01,653 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 18:58:01,719 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 18:58:01,720 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 18:58:01,720 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 18:58:01,958 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 18:58:01,998 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 18:58:02,001 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 18:58:02,001 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 18:58:02,006 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 18:58:02,029 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 18:58:02,035 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 18:58:02,036 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 18:58:02,036 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 18:58:02,037 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 18:58:02,037 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 18:58:02,037 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 18:58:02,040 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 18:58:02,041 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 18:58:02,048 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 18:58:05,046 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 5 msecs
2017-05-20 18:58:14,993 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_3108059914469806090_1152
2017-05-20 18:58:38,096 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3108059914469806090_1152 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3108059914469806090
2017-05-20 18:59:11,061 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5130488444414659778_1156 src: /192.168.1.157:36605 dest: /192.168.1.157:50010
2017-05-20 18:59:11,082 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5130488444414659778_1156 src: /192.168.1.157:36605 dest: /192.168.1.157:50010 of size 4325
2017-05-20 18:59:11,119 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6157927820748167923_1155 src: /192.168.1.158:54810 dest: /192.168.1.158:50010
2017-05-20 18:59:11,126 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6157927820748167923_1155 src: /192.168.1.158:54810 dest: /192.168.1.158:50010 of size 91176
2017-05-20 18:59:11,338 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6157927820748167923_1155 to /192.168.1.159
2017-05-20 18:59:14,056 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8234166472312041235_1159 src: /192.168.1.157:36616 dest: /192.168.1.157:50010
2017-05-20 18:59:14,058 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8693329325786240404_1157 src: /192.168.1.157:36617 dest: /192.168.1.157:50010
2017-05-20 18:59:14,059 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8693329325786240404_1157 src: /192.168.1.157:36617 dest: /192.168.1.157:50010 of size 13560
2017-05-20 18:59:14,060 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8234166472312041235_1159 src: /192.168.1.157:36616 dest: /192.168.1.157:50010 of size 13545
2017-05-20 18:59:14,087 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8693329325786240404_1157 src: /192.168.1.156:44392 dest: /192.168.1.156:50010
2017-05-20 18:59:14,087 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8234166472312041235_1159 src: /192.168.1.156:44393 dest: /192.168.1.156:50010
2017-05-20 18:59:14,087 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8693329325786240404_1157 received exception java.io.IOException: Block blk_-8693329325786240404_1157 is valid, and cannot be written to.
2017-05-20 18:59:14,088 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8234166472312041235_1159 received exception java.io.IOException: Block blk_8234166472312041235_1159 is valid, and cannot be written to.
2017-05-20 18:59:14,089 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-8693329325786240404_1157 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:59:14,089 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8234166472312041235_1159 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 18:59:17,126 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-8693329325786240404_1157 to 192.168.1.158:50010
2017-05-20 18:59:17,128 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8234166472312041235_1159 to 192.168.1.158:50010
2017-05-20 18:59:17,136 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_8234166472312041235_1159 to /192.168.1.158:50010
2017-05-20 18:59:17,151 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-8693329325786240404_1157 to /192.168.1.158:50010
2017-05-20 18:59:28,039 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 18:59:39,096 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:00:02,115 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7142101155484772082_1163 src: /192.168.1.156:44432 dest: /192.168.1.156:50010
2017-05-20 19:00:02,121 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7142101155484772082_1163 src: /192.168.1.156:44432 dest: /192.168.1.156:50010 of size 41464
2017-05-20 19:00:05,158 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8693329325786240404_1157 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8693329325786240404
2017-05-20 19:00:05,159 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6157927820748167923_1155 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6157927820748167923
2017-05-20 19:00:05,159 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5130488444414659778_1156 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5130488444414659778
2017-05-20 19:00:08,160 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7142101155484772082_1163 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7142101155484772082
2017-05-20 19:00:08,160 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8234166472312041235_1159 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8234166472312041235
2017-05-20 19:00:14,791 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:00:27,583 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:00:27,790 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:00:27,792 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:00:27,794 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:00:27,852 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:00:27,901 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:00:27,902 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:00:27,902 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:00:28,122 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 19:00:28,160 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:00:28,162 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:00:28,162 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 19:00:28,167 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:00:28,188 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:00:28,194 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:00:28,195 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:00:28,195 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:00:28,195 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:00:28,196 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:00:28,195 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:00:28,198 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:00:28,198 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:00:28,205 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:00:31,205 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 7 msecs
2017-05-20 19:01:37,234 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4384529882831191057_1164 src: /192.168.1.157:36659 dest: /192.168.1.157:50010
2017-05-20 19:01:37,254 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4384529882831191057_1164 src: /192.168.1.157:36659 dest: /192.168.1.157:50010 of size 91176
2017-05-20 19:01:37,265 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4932524764245290835_1168 src: /192.168.1.158:54855 dest: /192.168.1.158:50010
2017-05-20 19:01:37,267 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4932524764245290835_1168 src: /192.168.1.158:54855 dest: /192.168.1.158:50010 of size 13545
2017-05-20 19:01:37,601 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4384529882831191057_1164 to /192.168.1.159
2017-05-20 19:01:38,606 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:01:40,209 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8402852131940242145_1165 src: /192.168.1.157:36671 dest: /192.168.1.157:50010
2017-05-20 19:01:40,215 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8402852131940242145_1165 src: /192.168.1.157:36671 dest: /192.168.1.157:50010 of size 2165
2017-05-20 19:01:40,232 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8402852131940242145_1165 src: /192.168.1.156:44449 dest: /192.168.1.156:50010
2017-05-20 19:01:40,232 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8402852131940242145_1165 received exception java.io.IOException: Block blk_8402852131940242145_1165 is valid, and cannot be written to.
2017-05-20 19:01:40,233 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5246651761644821934_1166 src: /192.168.1.156:44450 dest: /192.168.1.156:50010
2017-05-20 19:01:40,233 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5246651761644821934_1166 src: /192.168.1.156:44450 dest: /192.168.1.156:50010 of size 13560
2017-05-20 19:01:40,234 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8402852131940242145_1165 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:01:43,295 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8402852131940242145_1165 to 192.168.1.158:50010
2017-05-20 19:01:43,300 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_8402852131940242145_1165 to /192.168.1.158:50010
2017-05-20 19:01:47,372 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 19:01:51,396 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 19:01:58,909 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:02:19,316 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 12 blocks got processed in 4 msecs
2017-05-20 19:02:25,234 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5154588173978300173_1172 src: /192.168.1.158:54890 dest: /192.168.1.158:50010
2017-05-20 19:02:25,259 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4098241567722129742_1172 src: /192.168.1.156:44479 dest: /192.168.1.156:50010
2017-05-20 19:02:25,266 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4098241567722129742_1172 src: /192.168.1.156:44479 dest: /192.168.1.156:50010 of size 23481
2017-05-20 19:02:26,290 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5154588173978300173_1172 src: /192.168.1.158:54890 dest: /192.168.1.158:50010 of size 31964396
2017-05-20 19:02:28,244 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7235426959556671565_1172 src: /192.168.1.157:36696 dest: /192.168.1.157:50010
2017-05-20 19:02:28,336 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-4098241567722129742_1172 to 192.168.1.158:50010
2017-05-20 19:02:28,340 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-4098241567722129742_1172 to /192.168.1.158:50010
2017-05-20 19:02:28,983 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7235426959556671565_1172 src: /192.168.1.157:36696 dest: /192.168.1.157:50010 of size 31976695
2017-05-20 19:02:31,339 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5154588173978300173_1172 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5154588173978300173
2017-05-20 19:02:31,339 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4098241567722129742_1172 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4098241567722129742
2017-05-20 19:02:31,340 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4384529882831191057_1164 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4384529882831191057
2017-05-20 19:02:31,340 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4932524764245290835_1168 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4932524764245290835
2017-05-20 19:02:31,340 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5246651761644821934_1166 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5246651761644821934
2017-05-20 19:02:31,340 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8402852131940242145_1165 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8402852131940242145
2017-05-20 19:02:36,368 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:02:49,230 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:02:49,446 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:02:49,448 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:02:49,450 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:02:49,515 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:02:49,573 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:02:49,574 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:02:49,574 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:02:49,809 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-20 19:02:49,847 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:02:49,849 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:02:49,849 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 19:02:49,854 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:02:49,874 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:02:49,880 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:02:49,881 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:02:49,882 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:02:49,882 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:02:49,882 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:02:49,882 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:02:49,884 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:02:49,885 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:02:49,891 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:02:52,894 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 6 msecs
2017-05-20 19:03:18,657 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-7235426959556671565_1172
2017-05-20 19:03:25,914 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7235426959556671565_1172 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7235426959556671565
2017-05-20 19:03:58,913 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4309372627316946189_1175 src: /192.168.1.156:44483 dest: /192.168.1.156:50010
2017-05-20 19:03:58,924 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-126577660125126823_1173 src: /192.168.1.158:54894 dest: /192.168.1.158:50010
2017-05-20 19:03:58,932 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4309372627316946189_1175 src: /192.168.1.156:44483 dest: /192.168.1.156:50010 of size 13560
2017-05-20 19:03:58,932 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-126577660125126823_1173 src: /192.168.1.158:54894 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:03:59,113 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4309372627316946189_1175 to /192.168.1.159
2017-05-20 19:03:59,152 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-126577660125126823_1173 to /192.168.1.159
2017-05-20 19:04:01,889 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7155033776352414627_1174 src: /192.168.1.157:36714 dest: /192.168.1.157:50010
2017-05-20 19:04:01,890 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7155033776352414627_1174 src: /192.168.1.157:36714 dest: /192.168.1.157:50010 of size 2165
2017-05-20 19:04:01,896 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3210928740674122694_1177 src: /192.168.1.156:44494 dest: /192.168.1.156:50010
2017-05-20 19:04:01,903 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3210928740674122694_1177 src: /192.168.1.156:44494 dest: /192.168.1.156:50010 of size 13545
2017-05-20 19:04:08,283 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 19:04:11,921 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:04:23,828 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-20 19:04:46,895 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3185564640642148280_1179 src: /192.168.1.157:36742 dest: /192.168.1.157:50010
2017-05-20 19:04:46,934 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3301407578628385622_1178 src: /192.168.1.158:54929 dest: /192.168.1.158:50010
2017-05-20 19:04:48,094 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3301407578628385622_1178 src: /192.168.1.158:54929 dest: /192.168.1.158:50010 of size 31976695
2017-05-20 19:04:48,123 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3185564640642148280_1179 src: /192.168.1.157:36742 dest: /192.168.1.157:50010 of size 31981189
2017-05-20 19:04:49,904 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1163657069937469138_1181 src: /192.168.1.157:36743 dest: /192.168.1.157:50010
2017-05-20 19:04:49,905 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1163657069937469138_1181 src: /192.168.1.157:36743 dest: /192.168.1.157:50010 of size 23481
2017-05-20 19:04:49,946 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7155033776352414627_1174 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7155033776352414627
2017-05-20 19:04:49,946 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4309372627316946189_1175 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4309372627316946189
2017-05-20 19:04:49,947 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3210928740674122694_1177 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3210928740674122694
2017-05-20 19:04:49,948 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-126577660125126823_1173 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-126577660125126823
2017-05-20 19:04:57,791 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:05:10,663 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:05:10,892 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:05:10,893 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:05:10,895 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:05:10,966 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:05:11,026 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:05:11,027 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:05:11,027 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:05:11,255 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 19:05:11,290 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:05:11,292 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:05:11,292 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 19:05:11,297 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:05:11,315 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:05:11,319 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:05:11,322 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:05:11,323 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:05:11,324 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:05:11,325 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:05:11,325 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:05:11,328 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:05:11,328 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:05:11,336 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:05:11,363 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_1163657069937469138_1181
2017-05-20 19:05:14,335 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 11 blocks got processed in 7 msecs
2017-05-20 19:05:47,373 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3301407578628385622_1178 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3301407578628385622
2017-05-20 19:05:47,381 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3185564640642148280_1179 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3185564640642148280
2017-05-20 19:05:47,382 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1163657069937469138_1181 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1163657069937469138
2017-05-20 19:06:20,324 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7746375829115700298_1183 src: /192.168.1.156:44524 dest: /192.168.1.156:50010
2017-05-20 19:06:20,338 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7746700512452443208_1182 src: /192.168.1.158:54932 dest: /192.168.1.158:50010
2017-05-20 19:06:20,342 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7746700512452443208_1182 src: /192.168.1.158:54932 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:06:20,344 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7746375829115700298_1183 src: /192.168.1.156:44524 dest: /192.168.1.156:50010 of size 2165
2017-05-20 19:06:20,630 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-7746700512452443208_1182 to /192.168.1.159
2017-05-20 19:06:21,664 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:06:23,313 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4536950280193803191_1186 src: /192.168.1.156:44536 dest: /192.168.1.156:50010
2017-05-20 19:06:23,316 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4536950280193803191_1186 src: /192.168.1.156:44536 dest: /192.168.1.156:50010 of size 13545
2017-05-20 19:06:26,299 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-531007660645593337_1184 src: /192.168.1.157:36762 dest: /192.168.1.157:50010
2017-05-20 19:06:26,300 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-531007660645593337_1184 src: /192.168.1.157:36762 dest: /192.168.1.157:50010 of size 13560
2017-05-20 19:06:42,390 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:06:44,657 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-20 19:07:08,320 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2929195412992127011_1189 src: /192.168.1.157:36786 dest: /192.168.1.157:50010
2017-05-20 19:07:08,348 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5006915202002346517_1190 src: /192.168.1.158:54965 dest: /192.168.1.158:50010
2017-05-20 19:07:09,138 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2929195412992127011_1189 src: /192.168.1.157:36786 dest: /192.168.1.157:50010 of size 31980463
2017-05-20 19:07:09,576 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5006915202002346517_1190 src: /192.168.1.158:54965 dest: /192.168.1.158:50010 of size 31964396
2017-05-20 19:07:11,325 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8132262631154309438_1189 src: /192.168.1.157:36787 dest: /192.168.1.157:50010
2017-05-20 19:07:11,862 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8132262631154309438_1189 src: /192.168.1.157:36787 dest: /192.168.1.157:50010 of size 31981189
2017-05-20 19:07:14,408 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7746700512452443208_1182 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7746700512452443208
2017-05-20 19:07:14,420 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5006915202002346517_1190 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5006915202002346517
2017-05-20 19:07:14,421 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4536950280193803191_1186 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4536950280193803191
2017-05-20 19:07:14,428 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2929195412992127011_1189 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2929195412992127011
2017-05-20 19:07:14,428 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-531007660645593337_1184 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-531007660645593337
2017-05-20 19:07:14,428 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7746375829115700298_1183 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7746375829115700298
2017-05-20 19:07:21,277 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:07:34,084 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:07:34,275 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:07:34,277 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:07:34,278 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:07:34,347 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:07:34,404 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:07:34,405 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:07:34,405 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:07:34,641 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 19:07:34,680 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:07:34,682 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:07:34,683 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 19:07:34,693 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:07:34,711 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:07:34,717 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:07:34,717 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:07:34,719 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:07:34,720 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:07:34,720 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:07:34,720 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:07:34,722 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:07:34,723 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:07:34,729 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:07:37,732 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 5 msecs
2017-05-20 19:08:03,485 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_8132262631154309438_1189
2017-05-20 19:08:10,756 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8132262631154309438_1189 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8132262631154309438
2017-05-20 19:08:43,760 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4441730715583203362_1191 src: /192.168.1.156:44573 dest: /192.168.1.156:50010
2017-05-20 19:08:43,775 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4441730715583203362_1191 src: /192.168.1.156:44573 dest: /192.168.1.156:50010 of size 91176
2017-05-20 19:08:43,807 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3010492776966547368_1193 src: /192.168.1.158:54968 dest: /192.168.1.158:50010
2017-05-20 19:08:43,809 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3010492776966547368_1193 src: /192.168.1.158:54968 dest: /192.168.1.158:50010 of size 13559
2017-05-20 19:08:44,025 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3010492776966547368_1193 to /192.168.1.159
2017-05-20 19:08:44,067 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4441730715583203362_1191 to /192.168.1.159
2017-05-20 19:08:45,018 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:08:45,070 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:08:46,746 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4119169550297937994_1195 src: /192.168.1.156:44585 dest: /192.168.1.156:50010
2017-05-20 19:08:46,754 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4119169550297937994_1195 src: /192.168.1.156:44585 dest: /192.168.1.156:50010 of size 13544
2017-05-20 19:08:49,781 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2688218444035146547_1192 src: /192.168.1.158:54981 dest: /192.168.1.158:50010
2017-05-20 19:08:49,782 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2688218444035146547_1192 src: /192.168.1.158:54981 dest: /192.168.1.158:50010 of size 1085
2017-05-20 19:09:00,867 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 19:09:01,673 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-20 19:09:10,001 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:09:24,437 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 19:10:07,795 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7151412837337896640_1199 src: /192.168.1.158:54997 dest: /192.168.1.158:50010
2017-05-20 19:10:07,796 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7151412837337896640_1199 src: /192.168.1.158:54997 dest: /192.168.1.158:50010 of size 18360
2017-05-20 19:10:07,817 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4817606976483918569_1198 src: /192.168.1.157:36828 dest: /192.168.1.157:50010
2017-05-20 19:10:08,354 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4817606976483918569_1198 src: /192.168.1.157:36828 dest: /192.168.1.157:50010 of size 31964396
2017-05-20 19:10:10,795 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5082037146553385475_1197 src: /192.168.1.156:44614 dest: /192.168.1.156:50010
2017-05-20 19:10:11,236 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5082037146553385475_1197 src: /192.168.1.156:44614 dest: /192.168.1.156:50010 of size 31981189
2017-05-20 19:10:13,818 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4817606976483918569_1198 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4817606976483918569
2017-05-20 19:10:13,818 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4441730715583203362_1191 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4441730715583203362
2017-05-20 19:10:13,818 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4119169550297937994_1195 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4119169550297937994
2017-05-20 19:10:13,818 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3010492776966547368_1193 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3010492776966547368
2017-05-20 19:10:13,819 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2688218444035146547_1192 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2688218444035146547
2017-05-20 19:10:13,819 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7151412837337896640_1199 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7151412837337896640
2017-05-20 19:10:19,794 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:10:32,681 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:10:32,876 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:10:32,878 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:10:32,879 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:10:32,933 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:10:32,980 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:10:32,981 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:10:32,981 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:10:33,198 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 19:10:33,229 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:10:33,232 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:10:33,232 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 19:10:33,237 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:10:33,253 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:10:33,259 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:10:33,259 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:10:33,261 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:10:33,261 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:10:33,262 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:10:33,262 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:10:33,277 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:10:33,277 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:10:33,290 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:10:36,291 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 14 msecs
2017-05-20 19:11:02,086 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-5082037146553385475_1197
2017-05-20 19:11:09,372 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5082037146553385475_1197 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5082037146553385475
2017-05-20 19:11:42,344 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6140967217744784571_1202 src: /192.168.1.156:44619 dest: /192.168.1.156:50010
2017-05-20 19:11:42,361 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6140967217744784571_1202 src: /192.168.1.156:44619 dest: /192.168.1.156:50010 of size 13559
2017-05-20 19:11:42,364 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8711778877694145980_1200 src: /192.168.1.157:36833 dest: /192.168.1.157:50010
2017-05-20 19:11:42,372 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8711778877694145980_1200 src: /192.168.1.157:36833 dest: /192.168.1.157:50010 of size 91176
2017-05-20 19:11:42,571 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6140967217744784571_1202 to /192.168.1.159
2017-05-20 19:11:42,607 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8711778877694145980_1200 to /192.168.1.159
2017-05-20 19:11:43,606 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 19:11:43,615 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:11:45,332 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2932819718056490277_1204 src: /192.168.1.156:44631 dest: /192.168.1.156:50010
2017-05-20 19:11:45,340 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2932819718056490277_1204 src: /192.168.1.156:44631 dest: /192.168.1.156:50010 of size 13544
2017-05-20 19:11:45,362 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4184071105416644751_1201 src: /192.168.1.157:36845 dest: /192.168.1.157:50010
2017-05-20 19:11:45,364 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4184071105416644751_1201 src: /192.168.1.157:36845 dest: /192.168.1.157:50010 of size 1085
2017-05-20 19:11:45,366 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4184071105416644751_1201 src: /192.168.1.157:36846 dest: /192.168.1.157:50010
2017-05-20 19:11:45,366 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4184071105416644751_1201 received exception java.io.IOException: Block blk_4184071105416644751_1201 is valid, and cannot be written to.
2017-05-20 19:11:45,368 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_4184071105416644751_1201 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:11:59,770 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-20 19:12:00,390 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:12:51,418 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6140967217744784571_1202 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6140967217744784571
2017-05-20 19:12:51,419 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2932819718056490277_1204 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2932819718056490277
2017-05-20 19:12:51,419 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4184071105416644751_1201 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4184071105416644751
2017-05-20 19:12:51,420 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8711778877694145980_1200 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8711778877694145980
2017-05-20 19:12:59,300 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:13:12,105 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:13:12,304 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:13:12,306 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:13:12,308 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:13:12,366 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:13:12,413 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:13:12,413 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:13:12,413 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:13:12,630 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@3d9edf
2017-05-20 19:13:12,668 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:13:12,670 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:13:12,670 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 19:13:12,675 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:13:12,692 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:13:12,696 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:13:12,697 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:13:12,698 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:13:12,698 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:13:12,698 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:13:12,698 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:13:12,729 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:13:12,729 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:13:12,741 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:13:15,741 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 12 msecs
2017-05-20 19:14:21,900 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1672280299214569465_1213 src: /192.168.1.158:55028 dest: /192.168.1.158:50010
2017-05-20 19:14:21,900 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1919954120657658446_1209 src: /192.168.1.158:55029 dest: /192.168.1.158:50010
2017-05-20 19:14:21,922 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1672280299214569465_1213 src: /192.168.1.158:55028 dest: /192.168.1.158:50010 of size 13544
2017-05-20 19:14:21,922 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1919954120657658446_1209 src: /192.168.1.158:55029 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:14:22,169 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-1919954120657658446_1209 to /192.168.1.159
2017-05-20 19:14:23,154 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 19:14:23,220 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:14:24,824 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1859423289649164894_1210 src: /192.168.1.157:36883 dest: /192.168.1.157:50010
2017-05-20 19:14:24,828 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6531083303412904008_1211 src: /192.168.1.156:44674 dest: /192.168.1.156:50010
2017-05-20 19:14:24,830 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6531083303412904008_1211 src: /192.168.1.156:44674 dest: /192.168.1.156:50010 of size 13559
2017-05-20 19:14:24,836 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1859423289649164894_1210 src: /192.168.1.157:36883 dest: /192.168.1.157:50010 of size 1085
2017-05-20 19:14:39,853 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-20 19:14:41,827 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 19:14:57,892 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_1859423289649164894_1210
2017-05-20 19:15:24,865 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1900658738349875074_1217 src: /192.168.1.158:55051 dest: /192.168.1.158:50010
2017-05-20 19:15:24,867 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1900658738349875074_1217 src: /192.168.1.158:55051 dest: /192.168.1.158:50010 of size 15431
2017-05-20 19:15:27,821 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1919954120657658446_1209 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1919954120657658446
2017-05-20 19:15:27,821 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1672280299214569465_1213 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1672280299214569465
2017-05-20 19:15:27,822 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1859423289649164894_1210 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1859423289649164894
2017-05-20 19:15:27,822 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1900658738349875074_1217 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1900658738349875074
2017-05-20 19:15:27,822 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6531083303412904008_1211 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6531083303412904008
2017-05-20 19:15:36,692 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:15:49,509 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:15:49,719 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:15:49,721 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:15:49,723 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:15:49,794 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:15:49,854 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:15:49,855 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:15:49,855 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:15:50,097 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 19:15:50,134 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:15:50,137 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:15:50,137 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 19:15:50,142 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:15:50,159 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:15:50,164 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:15:50,165 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:15:50,166 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:15:50,167 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:15:50,168 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:15:50,168 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:15:50,170 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:15:50,170 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:15:50,179 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:15:53,177 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-05-20 19:16:59,237 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_317961720125141740_1220 src: /192.168.1.157:36908 dest: /192.168.1.157:50010
2017-05-20 19:16:59,252 INFO org.apache.hadoop.dfs.DataNode: Received block blk_317961720125141740_1220 src: /192.168.1.157:36908 dest: /192.168.1.157:50010 of size 13567
2017-05-20 19:16:59,293 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2786549138888986791_1218 src: /192.168.1.158:55054 dest: /192.168.1.158:50010
2017-05-20 19:16:59,299 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2786549138888986791_1218 src: /192.168.1.158:55054 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:16:59,413 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_317961720125141740_1220 to /192.168.1.159
2017-05-20 19:16:59,455 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_2786549138888986791_1218 to /192.168.1.159
2017-05-20 19:17:00,365 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 19:17:00,478 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 19:17:02,256 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-169518595108663999_1219 src: /192.168.1.156:44710 dest: /192.168.1.156:50010
2017-05-20 19:17:02,257 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-169518595108663999_1219 src: /192.168.1.156:44711 dest: /192.168.1.156:50010
2017-05-20 19:17:02,258 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-169518595108663999_1219 received exception java.io.IOException: Block blk_-169518595108663999_1219 has already been started (though not completed), and thus cannot be created.
2017-05-20 19:17:02,260 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-169518595108663999_1219 src: /192.168.1.156:44710 dest: /192.168.1.156:50010 of size 1085
2017-05-20 19:17:02,260 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-169518595108663999_1219 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:17:05,157 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6483355006625571595_1222 src: /192.168.1.158:55066 dest: /192.168.1.158:50010
2017-05-20 19:17:05,233 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6483355006625571595_1222 src: /192.168.1.158:55066 dest: /192.168.1.158:50010 of size 13552
2017-05-20 19:17:05,273 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-169518595108663999_1219 to 192.168.1.158:50010
2017-05-20 19:17:05,278 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-169518595108663999_1219 to /192.168.1.158:50010
2017-05-20 19:17:16,353 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:17:17,138 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:18:32,320 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-169518595108663999_1219 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-169518595108663999
2017-05-20 19:18:32,320 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_317961720125141740_1220 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_317961720125141740
2017-05-20 19:18:32,321 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2786549138888986791_1218 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2786549138888986791
2017-05-20 19:18:35,320 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6483355006625571595_1222 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6483355006625571595
2017-05-20 19:18:42,170 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:18:55,026 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:18:55,202 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:18:55,203 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:18:55,205 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:18:55,262 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:18:55,310 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:18:55,311 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:18:55,311 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:18:55,521 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 19:18:55,557 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:18:55,560 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:18:55,560 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 19:18:55,565 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:18:55,580 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:18:55,584 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:18:55,584 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:18:55,585 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:18:55,586 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:18:55,586 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:18:55,586 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:18:55,613 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:18:55,614 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:18:55,631 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:18:58,629 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 12 msecs
2017-05-20 19:20:04,789 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5911397034957719666_1228 src: /192.168.1.158:55078 dest: /192.168.1.158:50010
2017-05-20 19:20:04,790 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7687921564317602199_1227 src: /192.168.1.157:36955 dest: /192.168.1.157:50010
2017-05-20 19:20:04,811 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5911397034957719666_1228 src: /192.168.1.158:55078 dest: /192.168.1.158:50010 of size 1085
2017-05-20 19:20:04,812 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7687921564317602199_1227 src: /192.168.1.157:36955 dest: /192.168.1.157:50010 of size 91176
2017-05-20 19:20:05,022 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-7687921564317602199_1227 to /192.168.1.159
2017-05-20 19:20:06,007 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:20:06,074 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:20:07,723 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1857568351656182825_1229 src: /192.168.1.156:44746 dest: /192.168.1.156:50010
2017-05-20 19:20:07,727 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1857568351656182825_1229 src: /192.168.1.156:44746 dest: /192.168.1.156:50010 of size 13567
2017-05-20 19:20:07,783 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3077157089207312910_1231 src: /192.168.1.157:36966 dest: /192.168.1.157:50010
2017-05-20 19:20:07,788 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3077157089207312910_1231 src: /192.168.1.157:36966 dest: /192.168.1.157:50010 of size 13552
2017-05-20 19:20:21,755 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 19:20:22,217 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-20 19:20:30,983 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 19:21:31,826 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1906466029496234451_1232 src: /192.168.1.158:55106 dest: /192.168.1.158:50010
2017-05-20 19:21:32,586 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1906466029496234451_1232 src: /192.168.1.158:55106 dest: /192.168.1.158:50010 of size 31981189
2017-05-20 19:21:37,820 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4874948736063748185_1235 src: /192.168.1.157:37001 dest: /192.168.1.157:50010
2017-05-20 19:21:38,560 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4874948736063748185_1235 src: /192.168.1.157:37001 dest: /192.168.1.157:50010 of size 31964396
2017-05-20 19:21:40,770 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3433518172377013000_1235 src: /192.168.1.156:44777 dest: /192.168.1.156:50010
2017-05-20 19:21:40,774 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3433518172377013000_1235 src: /192.168.1.156:44777 dest: /192.168.1.156:50010 of size 19296
2017-05-20 19:21:43,795 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7687921564317602199_1227 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7687921564317602199
2017-05-20 19:21:43,796 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5911397034957719666_1228 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5911397034957719666
2017-05-20 19:21:43,805 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4874948736063748185_1235 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4874948736063748185
2017-05-20 19:21:43,811 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1906466029496234451_1232 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1906466029496234451
2017-05-20 19:21:43,812 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1857568351656182825_1229 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1857568351656182825
2017-05-20 19:21:43,812 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3077157089207312910_1231 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3077157089207312910
2017-05-20 19:21:49,814 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-20 19:21:49,821 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:22:02,676 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:22:02,869 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:22:02,871 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:22:02,873 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:22:02,938 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:22:02,985 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:22:02,986 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:22:02,986 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:22:03,200 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@14a8af0
2017-05-20 19:22:03,236 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:22:03,240 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:22:03,240 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 19:22:03,245 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:22:03,262 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:22:03,266 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:22:03,267 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:22:03,269 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:22:03,269 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:22:03,269 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:22:03,269 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:22:03,301 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:22:03,302 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:22:03,313 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:22:03,348 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-3433518172377013000_1235
2017-05-20 19:22:06,316 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 14 msecs
2017-05-20 19:22:39,366 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3433518172377013000_1235 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3433518172377013000
2017-05-20 19:23:12,375 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2500395786478410879_1238 src: /192.168.1.156:44782 dest: /192.168.1.156:50010
2017-05-20 19:23:12,395 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2500395786478410879_1238 src: /192.168.1.156:44782 dest: /192.168.1.156:50010 of size 13567
2017-05-20 19:23:12,429 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_827616904026514154_1236 src: /192.168.1.158:55109 dest: /192.168.1.158:50010
2017-05-20 19:23:12,431 INFO org.apache.hadoop.dfs.DataNode: Received block blk_827616904026514154_1236 src: /192.168.1.158:55109 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:23:12,607 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_2500395786478410879_1238 to /192.168.1.159
2017-05-20 19:23:12,649 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_827616904026514154_1236 to /192.168.1.159
2017-05-20 19:23:13,589 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 19:23:13,675 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:23:15,365 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-941737752687117387_1237 src: /192.168.1.156:44794 dest: /192.168.1.156:50010
2017-05-20 19:23:15,367 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-941737752687117387_1237 src: /192.168.1.156:44794 dest: /192.168.1.156:50010 of size 1085
2017-05-20 19:23:15,388 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-941737752687117387_1237 src: /192.168.1.157:37017 dest: /192.168.1.157:50010
2017-05-20 19:23:15,389 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-941737752687117387_1237 received exception java.io.IOException: Block blk_-941737752687117387_1237 is valid, and cannot be written to.
2017-05-20 19:23:15,391 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-941737752687117387_1237 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:23:15,392 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8267423389334025255_1240 src: /192.168.1.157:37018 dest: /192.168.1.157:50010
2017-05-20 19:23:15,393 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8267423389334025255_1240 src: /192.168.1.157:37018 dest: /192.168.1.157:50010 of size 13552
2017-05-20 19:23:18,399 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8267423389334025255_1240 to 192.168.1.158:50010
2017-05-20 19:23:18,408 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_8267423389334025255_1240 to /192.168.1.158:50010
2017-05-20 19:23:29,682 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 19:23:31,507 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 19:23:38,739 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 19:23:38,918 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 19:23:54,939 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:24:42,409 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_291760686532946587_1244 src: /192.168.1.156:44821 dest: /192.168.1.156:50010
2017-05-20 19:24:42,413 INFO org.apache.hadoop.dfs.DataNode: Received block blk_291760686532946587_1244 src: /192.168.1.156:44821 dest: /192.168.1.156:50010 of size 17149
2017-05-20 19:24:48,464 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-941737752687117387_1237 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-941737752687117387
2017-05-20 19:24:48,465 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_291760686532946587_1244 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_291760686532946587
2017-05-20 19:24:48,465 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_827616904026514154_1236 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_827616904026514154
2017-05-20 19:24:48,466 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2500395786478410879_1238 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2500395786478410879
2017-05-20 19:24:48,466 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8267423389334025255_1240 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8267423389334025255
2017-05-20 19:24:55,154 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:25:07,994 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:25:08,182 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:25:08,184 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:25:08,186 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:25:08,255 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:25:08,313 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:25:08,314 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:25:08,314 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:25:08,541 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 19:25:08,574 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:25:08,576 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:25:08,576 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-20 19:25:08,580 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:25:08,602 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:25:08,609 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:25:08,610 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:25:08,610 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:25:08,611 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:25:08,611 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:25:08,611 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:25:08,613 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:25:08,613 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:25:08,620 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:25:11,622 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 4 msecs
2017-05-20 19:26:17,694 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-877147993820581542_1245 src: /192.168.1.158:55134 dest: /192.168.1.158:50010
2017-05-20 19:26:17,708 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-877147993820581542_1245 src: /192.168.1.158:55134 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:26:17,729 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3990955601257692981_1247 src: /192.168.1.158:55135 dest: /192.168.1.158:50010
2017-05-20 19:26:17,731 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3990955601257692981_1247 src: /192.168.1.158:55135 dest: /192.168.1.158:50010 of size 13558
2017-05-20 19:26:17,924 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3990955601257692981_1247 to /192.168.1.159
2017-05-20 19:26:17,965 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-877147993820581542_1245 to /192.168.1.159
2017-05-20 19:26:20,641 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3276362975180707507_1246 src: /192.168.1.157:37066 dest: /192.168.1.157:50010
2017-05-20 19:26:20,643 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3276362975180707507_1246 src: /192.168.1.157:37066 dest: /192.168.1.157:50010 of size 8645
2017-05-20 19:26:21,687 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 19:26:23,637 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8406468012435500484_1249 src: /192.168.1.157:37071 dest: /192.168.1.157:50010
2017-05-20 19:26:23,638 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8406468012435500484_1249 src: /192.168.1.157:37071 dest: /192.168.1.157:50010 of size 13543
2017-05-20 19:26:33,248 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 19:26:42,859 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:27:32,698 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3990955601257692981_1247 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3990955601257692981
2017-05-20 19:27:32,698 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3276362975180707507_1246 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3276362975180707507
2017-05-20 19:27:32,699 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-877147993820581542_1245 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-877147993820581542
2017-05-20 19:27:35,693 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8406468012435500484_1249 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8406468012435500484
2017-05-20 19:27:42,690 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:27:55,438 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:27:55,616 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:27:55,618 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:27:55,620 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:27:55,682 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:27:55,727 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:27:55,728 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:27:55,728 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:27:55,935 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 19:27:55,973 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:27:55,976 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:27:55,976 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 19:27:55,981 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:27:55,998 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:27:56,006 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:27:56,007 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:27:56,008 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:27:56,008 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:27:56,009 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:27:56,009 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:27:56,024 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:27:56,025 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:27:56,036 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:27:59,037 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 12 msecs
2017-05-20 19:29:05,142 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2971638394173872139_1254 src: /192.168.1.157:37141 dest: /192.168.1.157:50010
2017-05-20 19:29:05,160 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2971638394173872139_1254 src: /192.168.1.157:37141 dest: /192.168.1.157:50010 of size 91176
2017-05-20 19:29:05,186 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6675412562056520475_1255 src: /192.168.1.156:44903 dest: /192.168.1.156:50010
2017-05-20 19:29:05,190 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6675412562056520475_1255 src: /192.168.1.156:44903 dest: /192.168.1.156:50010 of size 8645
2017-05-20 19:29:05,441 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_2971638394173872139_1254 to /192.168.1.159
2017-05-20 19:29:08,120 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3375615446456170649_1256 src: /192.168.1.157:37151 dest: /192.168.1.157:50010
2017-05-20 19:29:08,121 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8426885496344679433_1258 src: /192.168.1.157:37152 dest: /192.168.1.157:50010
2017-05-20 19:29:08,122 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8426885496344679433_1258 src: /192.168.1.157:37152 dest: /192.168.1.157:50010 of size 13543
2017-05-20 19:29:08,123 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3375615446456170649_1256 src: /192.168.1.157:37151 dest: /192.168.1.157:50010 of size 13558
2017-05-20 19:29:08,185 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3375615446456170649_1256 src: /192.168.1.156:44914 dest: /192.168.1.156:50010
2017-05-20 19:29:08,186 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3375615446456170649_1256 received exception java.io.IOException: Block blk_3375615446456170649_1256 is valid, and cannot be written to.
2017-05-20 19:29:08,188 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_3375615446456170649_1256 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:29:20,905 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 19:30:17,149 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8794860682813981857_1260 src: /192.168.1.157:37212 dest: /192.168.1.157:50010
2017-05-20 19:30:17,150 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8794860682813981857_1260 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-20 19:30:17,150 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:30:20,127 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2971638394173872139_1254 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2971638394173872139
2017-05-20 19:30:20,128 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3375615446456170649_1256 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3375615446456170649
2017-05-20 19:30:20,128 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6675412562056520475_1255 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6675412562056520475
2017-05-20 19:30:23,132 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8426885496344679433_1258 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8426885496344679433
2017-05-20 19:30:28,246 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:30:41,094 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:30:41,274 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:30:41,276 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:30:41,279 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:30:41,337 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:30:41,385 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:30:41,386 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:30:41,386 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:30:41,599 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 19:30:41,631 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:30:41,633 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:30:41,633 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 19:30:41,639 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:30:41,656 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:30:41,661 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:30:41,662 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:30:41,663 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:30:41,664 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:30:41,664 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:30:41,665 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:30:41,686 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:30:41,687 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:30:41,698 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:30:44,701 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 14 msecs
2017-05-20 19:31:50,799 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3904135476928918968_1263 src: /192.168.1.158:55285 dest: /192.168.1.158:50010
2017-05-20 19:31:50,813 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3904135476928918968_1263 src: /192.168.1.158:55285 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:31:50,819 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5168912440429829551_1265 src: /192.168.1.158:55286 dest: /192.168.1.158:50010
2017-05-20 19:31:50,820 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5168912440429829551_1265 src: /192.168.1.158:55286 dest: /192.168.1.158:50010 of size 13558
2017-05-20 19:31:50,947 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5168912440429829551_1265 to /192.168.1.159
2017-05-20 19:31:50,989 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3904135476928918968_1263 to /192.168.1.159
2017-05-20 19:31:56,730 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7824686323183696919_1264 src: /192.168.1.157:37232 dest: /192.168.1.157:50010
2017-05-20 19:31:56,732 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7824686323183696919_1264 src: /192.168.1.157:37232 dest: /192.168.1.157:50010 of size 8645
2017-05-20 19:31:56,817 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1094829421453348284_1267 src: /192.168.1.158:55303 dest: /192.168.1.158:50010
2017-05-20 19:31:56,818 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1094829421453348284_1267 src: /192.168.1.158:55303 dest: /192.168.1.158:50010 of size 13543
2017-05-20 19:31:58,071 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 19:32:02,790 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:32:07,735 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:32:10,593 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:32:12,618 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 19:33:23,796 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2603076674604663999_1268 src: /192.168.1.157:37291 dest: /192.168.1.157:50010
2017-05-20 19:33:23,802 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2603076674604663999_1268 src: /192.168.1.157:37291 dest: /192.168.1.157:50010 of size 77562
2017-05-20 19:33:26,836 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5168912440429829551_1265 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5168912440429829551
2017-05-20 19:33:26,837 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3904135476928918968_1263 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3904135476928918968
2017-05-20 19:33:26,837 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7824686323183696919_1264 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7824686323183696919
2017-05-20 19:33:29,834 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1094829421453348284_1267 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1094829421453348284
2017-05-20 19:33:29,835 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2603076674604663999_1268 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2603076674604663999
2017-05-20 19:33:36,542 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:33:49,412 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:33:49,589 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:33:49,591 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:33:49,593 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:33:49,659 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:33:49,717 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:33:49,718 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:33:49,718 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:33:49,955 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 19:33:49,991 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:33:49,994 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:33:49,994 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 19:33:49,999 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:33:50,017 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:33:50,022 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:33:50,023 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:33:50,024 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:33:50,025 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:33:50,025 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:33:50,025 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:33:50,028 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:33:50,029 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:33:50,035 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:33:53,035 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-05-20 19:34:59,056 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2277261992761099439_1272 src: /192.168.1.157:37296 dest: /192.168.1.157:50010
2017-05-20 19:34:59,078 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2277261992761099439_1272 src: /192.168.1.157:37296 dest: /192.168.1.157:50010 of size 91176
2017-05-20 19:34:59,171 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3952761395447793665_1274 src: /192.168.1.156:45072 dest: /192.168.1.156:50010
2017-05-20 19:34:59,174 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3952761395447793665_1274 src: /192.168.1.156:45072 dest: /192.168.1.156:50010 of size 13560
2017-05-20 19:34:59,282 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3952761395447793665_1274 to /192.168.1.159
2017-05-20 19:34:59,325 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-2277261992761099439_1272 to /192.168.1.159
2017-05-20 19:35:02,183 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2128579114971568437_1273 src: /192.168.1.156:45082 dest: /192.168.1.156:50010
2017-05-20 19:35:02,185 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2128579114971568437_1273 src: /192.168.1.156:45082 dest: /192.168.1.156:50010 of size 4325
2017-05-20 19:35:02,190 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2128579114971568437_1273 src: /192.168.1.156:45083 dest: /192.168.1.156:50010
2017-05-20 19:35:02,191 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2128579114971568437_1273 received exception java.io.IOException: Block blk_-2128579114971568437_1273 is valid, and cannot be written to.
2017-05-20 19:35:02,193 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-2128579114971568437_1273 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:35:04,924 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 19:35:05,024 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7174693062371866592_1276 src: /192.168.1.157:37310 dest: /192.168.1.157:50010
2017-05-20 19:35:05,025 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7174693062371866592_1276 src: /192.168.1.157:37310 dest: /192.168.1.157:50010 of size 13545
2017-05-20 19:35:10,346 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:35:13,246 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 19:35:17,106 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:35:38,039 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4172960370570876677_1279 src: /192.168.1.157:37347 dest: /192.168.1.157:50010
2017-05-20 19:35:38,775 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4172960370570876677_1279 src: /192.168.1.157:37347 dest: /192.168.1.157:50010 of size 31980463
2017-05-20 19:35:41,045 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2985791087010842819_1278 src: /192.168.1.158:55385 dest: /192.168.1.158:50010
2017-05-20 19:35:41,686 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2985791087010842819_1278 src: /192.168.1.158:55385 dest: /192.168.1.158:50010 of size 31964396
2017-05-20 19:35:44,045 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-194018017864500489_1280 src: /192.168.1.158:55386 dest: /192.168.1.158:50010
2017-05-20 19:35:44,056 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-194018017864500489_1280 src: /192.168.1.158:55386 dest: /192.168.1.158:50010 of size 41464
2017-05-20 19:35:47,054 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6456942668840127108_1277 src: /192.168.1.158:55387 dest: /192.168.1.158:50010
2017-05-20 19:35:47,775 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6456942668840127108_1277 src: /192.168.1.158:55387 dest: /192.168.1.158:50010 of size 31981189
2017-05-20 19:35:50,102 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7174693062371866592_1276 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7174693062371866592
2017-05-20 19:35:50,102 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3952761395447793665_1274 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3952761395447793665
2017-05-20 19:35:50,114 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2985791087010842819_1278 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2985791087010842819
2017-05-20 19:35:50,114 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2277261992761099439_1272 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2277261992761099439
2017-05-20 19:35:50,114 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2128579114971568437_1273 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2128579114971568437
2017-05-20 19:35:50,114 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-194018017864500489_1280 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-194018017864500489
2017-05-20 19:35:50,121 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4172960370570876677_1279 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4172960370570876677
2017-05-20 19:35:56,093 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-20 19:35:56,118 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:36:08,938 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:36:09,132 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:36:09,134 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:36:09,136 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:36:09,199 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:36:09,256 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:36:09,257 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:36:09,257 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:36:09,493 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 19:36:09,525 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:36:09,527 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:36:09,527 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 19:36:09,532 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:36:09,552 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:36:09,557 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:36:09,558 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:36:09,558 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:36:09,558 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:36:09,559 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:36:09,559 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:36:09,562 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:36:09,562 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:36:09,570 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:36:12,568 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 6 msecs
2017-05-20 19:36:38,341 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_6456942668840127108_1277
2017-05-20 19:36:45,600 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6456942668840127108_1277 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6456942668840127108
2017-05-20 19:37:18,544 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8901367073063071456_1282 src: /192.168.1.157:37355 dest: /192.168.1.157:50010
2017-05-20 19:37:18,561 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8901367073063071456_1282 src: /192.168.1.157:37355 dest: /192.168.1.157:50010 of size 4325
2017-05-20 19:37:18,607 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4049391094784511231_1281 src: /192.168.1.156:45123 dest: /192.168.1.156:50010
2017-05-20 19:37:18,614 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4049391094784511231_1281 src: /192.168.1.156:45123 dest: /192.168.1.156:50010 of size 91176
2017-05-20 19:37:18,835 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4049391094784511231_1281 to /192.168.1.159
2017-05-20 19:37:21,547 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6616941539811946031_1285 src: /192.168.1.158:55399 dest: /192.168.1.158:50010
2017-05-20 19:37:21,548 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6616941539811946031_1285 src: /192.168.1.158:55399 dest: /192.168.1.158:50010 of size 13545
2017-05-20 19:37:21,601 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8887407125702170522_1283 src: /192.168.1.156:45135 dest: /192.168.1.156:50010
2017-05-20 19:37:21,602 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8887407125702170522_1283 src: /192.168.1.156:45135 dest: /192.168.1.156:50010 of size 13560
2017-05-20 19:37:24,689 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 19:37:27,787 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:37:32,663 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:37:57,618 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6467722947133470264_1286 src: /192.168.1.156:45166 dest: /192.168.1.156:50010
2017-05-20 19:37:58,362 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6467722947133470264_1286 src: /192.168.1.156:45166 dest: /192.168.1.156:50010 of size 31980463
2017-05-20 19:38:00,564 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4549224768586399608_1289 src: /192.168.1.158:55429 dest: /192.168.1.158:50010
2017-05-20 19:38:00,619 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2902977249534098763_1289 src: /192.168.1.158:55430 dest: /192.168.1.158:50010
2017-05-20 19:38:00,622 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2902977249534098763_1289 src: /192.168.1.158:55430 dest: /192.168.1.158:50010 of size 41464
2017-05-20 19:38:01,159 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4549224768586399608_1289 src: /192.168.1.158:55429 dest: /192.168.1.158:50010 of size 31976695
2017-05-20 19:38:03,616 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6989245367815066043_1287 src: /192.168.1.156:45168 dest: /192.168.1.156:50010
2017-05-20 19:38:04,411 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6989245367815066043_1287 src: /192.168.1.156:45168 dest: /192.168.1.156:50010 of size 31964396
2017-05-20 19:38:06,618 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7715660855508520037_1288 src: /192.168.1.156:45169 dest: /192.168.1.156:50010
2017-05-20 19:38:06,624 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6616941539811946031_1285 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6616941539811946031
2017-05-20 19:38:06,625 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4049391094784511231_1281 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4049391094784511231
2017-05-20 19:38:06,625 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2902977249534098763_1289 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2902977249534098763
2017-05-20 19:38:06,637 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4549224768586399608_1289 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4549224768586399608
2017-05-20 19:38:06,643 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6467722947133470264_1286 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6467722947133470264
2017-05-20 19:38:06,643 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8887407125702170522_1283 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8887407125702170522
2017-05-20 19:38:06,644 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8901367073063071456_1282 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8901367073063071456
2017-05-20 19:38:07,102 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7715660855508520037_1288 src: /192.168.1.156:45169 dest: /192.168.1.156:50010 of size 31981189
2017-05-20 19:38:11,622 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:38:24,437 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:38:24,627 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:38:24,629 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:38:24,631 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:38:24,708 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:38:24,769 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:38:24,770 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:38:24,770 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:38:25,009 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-20 19:38:25,045 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:38:25,048 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:38:25,048 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 19:38:25,053 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:38:25,074 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:38:25,082 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:38:25,083 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:38:25,084 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:38:25,084 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:38:25,085 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:38:25,085 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:38:25,088 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:38:25,088 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:38:25,095 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:38:28,094 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 10 blocks got processed in 6 msecs
2017-05-20 19:38:53,837 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_7715660855508520037_1288
2017-05-20 19:39:01,140 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6989245367815066043_1287 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6989245367815066043
2017-05-20 19:39:01,147 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7715660855508520037_1288 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7715660855508520037
2017-05-20 19:39:13,133 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 19:39:34,094 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4001012511182686434_1290 src: /192.168.1.158:55433 dest: /192.168.1.158:50010
2017-05-20 19:39:34,110 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4001012511182686434_1290 src: /192.168.1.158:55433 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:39:34,114 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6024471624197552687_1291 src: /192.168.1.156:45174 dest: /192.168.1.156:50010
2017-05-20 19:39:34,116 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6024471624197552687_1291 src: /192.168.1.156:45174 dest: /192.168.1.156:50010 of size 4325
2017-05-20 19:39:34,338 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4001012511182686434_1290 to /192.168.1.159
2017-05-20 19:39:37,054 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6516227537290169205_1294 src: /192.168.1.157:37416 dest: /192.168.1.157:50010
2017-05-20 19:39:37,054 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6066358312743732026_1292 src: /192.168.1.157:37415 dest: /192.168.1.157:50010
2017-05-20 19:39:37,061 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6516227537290169205_1294 src: /192.168.1.157:37416 dest: /192.168.1.157:50010 of size 13545
2017-05-20 19:39:37,064 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6066358312743732026_1292 src: /192.168.1.157:37415 dest: /192.168.1.157:50010 of size 13560
2017-05-20 19:39:37,108 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6066358312743732026_1292 src: /192.168.1.156:45185 dest: /192.168.1.156:50010
2017-05-20 19:39:37,108 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-6066358312743732026_1292 received exception java.io.IOException: Block blk_-6066358312743732026_1292 is valid, and cannot be written to.
2017-05-20 19:39:37,110 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-6066358312743732026_1292 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:39:37,123 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6516227537290169205_1294 src: /192.168.1.156:45184 dest: /192.168.1.156:50010
2017-05-20 19:39:37,123 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6516227537290169205_1294 received exception java.io.IOException: Block blk_6516227537290169205_1294 is valid, and cannot be written to.
2017-05-20 19:39:37,124 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_6516227537290169205_1294 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:39:39,871 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 19:39:40,708 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 19:39:43,198 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 19:39:45,348 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:39:48,206 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:39:51,266 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:39:56,006 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:40:19,159 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6066358312743732026_1292 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6066358312743732026
2017-05-20 19:40:19,159 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4001012511182686434_1290 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4001012511182686434
2017-05-20 19:40:19,159 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6024471624197552687_1291 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6024471624197552687
2017-05-20 19:40:19,160 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6516227537290169205_1294 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6516227537290169205
2017-05-20 19:40:27,758 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:40:40,692 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:40:40,888 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:40:40,890 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:40:40,891 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:40:40,964 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:40:41,021 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:40:41,022 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:40:41,022 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:40:41,257 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 19:40:41,293 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:40:41,296 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:40:41,296 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 19:40:41,302 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:40:41,324 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:40:41,330 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:40:41,331 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:40:41,332 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:40:41,332 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:40:41,332 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:40:41,333 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:40:41,335 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:40:41,336 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:40:41,344 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:40:44,344 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 19:41:50,298 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7241421260591357051_1301 src: /192.168.1.157:37454 dest: /192.168.1.157:50010
2017-05-20 19:41:50,316 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7241421260591357051_1301 src: /192.168.1.157:37454 dest: /192.168.1.157:50010 of size 13560
2017-05-20 19:41:50,356 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2367591822445184555_1299 src: /192.168.1.158:55475 dest: /192.168.1.158:50010
2017-05-20 19:41:50,361 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2367591822445184555_1299 src: /192.168.1.158:55475 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:41:50,545 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_7241421260591357051_1301 to /192.168.1.159
2017-05-20 19:41:50,587 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_2367591822445184555_1299 to /192.168.1.159
2017-05-20 19:41:51,592 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 19:41:53,274 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7618259099874792863_1303 src: /192.168.1.157:37464 dest: /192.168.1.157:50010
2017-05-20 19:41:53,275 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7618259099874792863_1303 src: /192.168.1.157:37465 dest: /192.168.1.157:50010
2017-05-20 19:41:53,276 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7618259099874792863_1303 received exception java.io.IOException: Block blk_7618259099874792863_1303 has already been started (though not completed), and thus cannot be created.
2017-05-20 19:41:53,277 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7618259099874792863_1303 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:41:53,280 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7618259099874792863_1303 src: /192.168.1.157:37465 dest: /192.168.1.157:50010 of size 13545
2017-05-20 19:41:53,347 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1838739689154709262_1300 src: /192.168.1.156:45233 dest: /192.168.1.156:50010
2017-05-20 19:41:53,350 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1838739689154709262_1300 src: /192.168.1.156:45233 dest: /192.168.1.156:50010 of size 2165
2017-05-20 19:42:00,177 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 19:42:05,680 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 19:42:12,925 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:42:26,371 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6299628031788437443_1306 src: /192.168.1.158:55501 dest: /192.168.1.158:50010
2017-05-20 19:42:27,114 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6299628031788437443_1306 src: /192.168.1.158:55501 dest: /192.168.1.158:50010 of size 31964396
2017-05-20 19:42:29,287 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2945475415889106496_1307 src: /192.168.1.157:37488 dest: /192.168.1.157:50010
2017-05-20 19:42:29,292 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2945475415889106496_1307 src: /192.168.1.157:37488 dest: /192.168.1.157:50010 of size 23481
2017-05-20 19:42:29,363 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6732858199511021413_1306 src: /192.168.1.156:45255 dest: /192.168.1.156:50010
2017-05-20 19:42:30,007 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6732858199511021413_1306 src: /192.168.1.156:45255 dest: /192.168.1.156:50010 of size 31981189
2017-05-20 19:42:32,293 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4699285310464872377_1304 src: /192.168.1.158:55502 dest: /192.168.1.158:50010
2017-05-20 19:42:33,095 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4699285310464872377_1304 src: /192.168.1.158:55502 dest: /192.168.1.158:50010 of size 31980463
2017-05-20 19:42:35,398 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6732858199511021413_1306 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6732858199511021413
2017-05-20 19:42:35,405 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6299628031788437443_1306 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6299628031788437443
2017-05-20 19:42:35,405 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1838739689154709262_1300 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1838739689154709262
2017-05-20 19:42:35,406 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2367591822445184555_1299 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2367591822445184555
2017-05-20 19:42:35,406 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2945475415889106496_1307 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2945475415889106496
2017-05-20 19:42:35,406 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7241421260591357051_1301 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7241421260591357051
2017-05-20 19:42:35,406 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7618259099874792863_1303 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7618259099874792863
2017-05-20 19:42:40,324 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:42:53,145 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:42:53,352 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:42:53,354 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:42:53,356 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:42:53,410 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:42:53,456 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:42:53,456 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:42:53,456 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:42:53,668 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-05-20 19:42:53,696 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:42:53,698 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:42:53,698 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 19:42:53,702 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:42:53,719 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:42:53,725 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:42:53,726 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:42:53,727 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:42:53,727 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:42:53,727 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:42:53,727 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:42:53,737 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:42:53,738 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:42:53,750 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:42:56,753 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 12 msecs
2017-05-20 19:43:22,563 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-4699285310464872377_1304
2017-05-20 19:43:29,832 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4699285310464872377_1304 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4699285310464872377
2017-05-20 19:44:02,851 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5883839195544169240_1308 src: /192.168.1.158:55506 dest: /192.168.1.158:50010
2017-05-20 19:44:02,854 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6314243204537551281_1312 src: /192.168.1.158:55505 dest: /192.168.1.158:50010
2017-05-20 19:44:02,866 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6314243204537551281_1312 src: /192.168.1.158:55505 dest: /192.168.1.158:50010 of size 13545
2017-05-20 19:44:02,866 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5883839195544169240_1308 src: /192.168.1.158:55506 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:44:03,050 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5883839195544169240_1308 to /192.168.1.159
2017-05-20 19:44:03,998 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 19:44:04,067 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:44:05,806 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4025008337266306436_1309 src: /192.168.1.157:37507 dest: /192.168.1.157:50010
2017-05-20 19:44:05,806 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4025008337266306436_1309 src: /192.168.1.157:37507 dest: /192.168.1.157:50010 of size 2165
2017-05-20 19:44:05,815 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3730781583321689409_1310 src: /192.168.1.156:45269 dest: /192.168.1.156:50010
2017-05-20 19:44:05,820 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3730781583321689409_1310 src: /192.168.1.156:45269 dest: /192.168.1.156:50010 of size 13560
2017-05-20 19:44:09,180 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:44:25,807 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:44:26,909 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-20 19:44:44,821 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5508743413710237524_1313 src: /192.168.1.157:37528 dest: /192.168.1.157:50010
2017-05-20 19:44:45,468 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Exception writing block blk_-5508743413710237524_1313 to mirror 192.168.1.158:50010
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:94)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:450)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receivePacket(DataNode.java:2601)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2698)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-052017-05-20 19:44:50,829 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2141114528515785708_1315 src: /192.168.1.157:37529 dest: /192.168.1.157:50010
2017-05-20 19:44:51,512 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2141114528515785708_1315 src: /192.168.1.157:37529 dest: /192.168.1.157:50010 of size 31976695
2017-05-20 19:44:53,841 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4373064138500567983_1316 src: /192.168.1.158:55535 dest: /192.168.1.158:50010
2017-05-20 19:44:53,842 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4373064138500567983_1316 src: /192.168.1.158:55535 dest: /192.168.1.158:50010 of size 23481
2017-05-20 19:44:56,879 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6314243204537551281_1312 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6314243204537551281
2017-05-20 19:44:56,880 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5883839195544169240_1308 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5883839195544169240
2017-05-20 19:44:56,881 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4025008337266306436_1309 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4025008337266306436
2017-05-20 19:44:56,892 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2141114528515785708_1315 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2141114528515785708
2017-05-20 19:44:56,892 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3730781583321689409_1310 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3730781583321689409
2017-05-20 19:44:56,893 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4373064138500567983_1316 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4373064138500567983
2017-05-20 19:45:03,888 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:45:16,724 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:45:16,905 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:45:16,906 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:45:16,908 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:45:16,978 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:45:17,036 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:45:17,037 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:45:17,037 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:45:17,284 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 19:45:17,322 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:45:17,324 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:45:17,324 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-20 19:45:17,330 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:45:17,346 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:45:17,353 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:45:17,353 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:45:17,354 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:45:17,355 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:45:17,355 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:45:17,355 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:45:17,378 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:45:17,379 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:45:17,395 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:45:20,396 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 14 msecs
2017-05-20 19:45:40,516 WARN org.apache.hadoop.dfs.DataNode:  Could not read or failed to veirfy checksum for data at offset 26017792 for block blk_-5508743413710237524_1313 got : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:45:40,517 WARN org.apache.hadoop.dfs.DataBlockScanner: First Verification failed for blk_-5508743413710237524_1313. Exception : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:45:53,419 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5508743413710237524_1313 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5508743413710237524
2017-05-20 19:46:05,514 WARN org.apache.hadoop.dfs.DataNode:  Could not read or failed to veirfy checksum for data at offset 26017792 for block blk_-5508743413710237524_1313 got : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:46:05,524 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification failed for blk_-5508743413710237524_1313. Its ok since it not in datanode dataset anymore.
2017-05-20 19:46:26,473 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7739715590234967945_1317 src: /192.168.1.158:55538 dest: /192.168.1.158:50010
2017-05-20 19:46:26,475 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6112231245511164416_1318 src: /192.168.1.158:55539 dest: /192.168.1.158:50010
2017-05-20 19:46:26,494 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6112231245511164416_1318 src: /192.168.1.158:55539 dest: /192.168.1.158:50010 of size 2165
2017-05-20 19:46:26,494 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7739715590234967945_1317 src: /192.168.1.158:55538 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:46:26,774 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-7739715590234967945_1317 to /192.168.1.159
2017-05-20 19:46:27,777 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 19:46:27,792 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:46:29,424 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5085927568835167867_1319 src: /192.168.1.157:37546 dest: /192.168.1.157:50010
2017-05-20 19:46:29,432 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5085927568835167867_1319 src: /192.168.1.157:37546 dest: /192.168.1.157:50010 of size 13560
2017-05-20 19:46:29,455 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5085927568835167867_1319 src: /192.168.1.156:45307 dest: /192.168.1.156:50010
2017-05-20 19:46:29,456 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5085927568835167867_1319 received exception java.io.IOException: Block blk_5085927568835167867_1319 is valid, and cannot be written to.
2017-05-20 19:46:29,456 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_5085927568835167867_1319 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:46:32,456 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6632932753665196583_1321 src: /192.168.1.156:45308 dest: /192.168.1.156:50010
2017-05-20 19:46:32,459 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6632932753665196583_1321 src: /192.168.1.156:45308 dest: /192.168.1.156:50010 of size 13545
2017-05-20 19:46:32,916 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:46:40,662 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:47:02,476 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-473672389473022961_1323 src: /192.168.1.158:55568 dest: /192.168.1.158:50010
2017-05-20 19:47:03,203 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-473672389473022961_1323 src: /192.168.1.158:55568 dest: /192.168.1.158:50010 of size 31976695
2017-05-20 19:47:05,437 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1861506492526772408_1325 src: /192.168.1.157:37567 dest: /192.168.1.157:50010
2017-05-20 19:47:05,441 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1861506492526772408_1325 src: /192.168.1.157:37567 dest: /192.168.1.157:50010 of size 23481
2017-05-20 19:47:08,463 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7739715590234967945_1317 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7739715590234967945
2017-05-20 19:47:08,463 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6632932753665196583_1321 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6632932753665196583
2017-05-20 19:47:08,464 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6112231245511164416_1318 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6112231245511164416
2017-05-20 19:47:08,464 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1861506492526772408_1325 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1861506492526772408
2017-05-20 19:47:08,475 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-473672389473022961_1323 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-473672389473022961
2017-05-20 19:47:08,475 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5085927568835167867_1319 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5085927568835167867
2017-05-20 19:47:17,287 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:47:30,189 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:47:30,414 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:47:30,416 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:47:30,417 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:47:30,494 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:47:30,558 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:47:30,559 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:47:30,559 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:47:30,802 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 19:47:30,841 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:47:30,845 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:47:30,845 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 19:47:30,854 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:47:30,873 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:47:30,879 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:47:30,879 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:47:30,881 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:47:30,881 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:47:30,882 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:47:30,882 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:47:30,884 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:47:30,885 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:47:30,893 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:47:33,890 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 19:48:39,941 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2386330858894790692_1326 src: /192.168.1.158:55571 dest: /192.168.1.158:50010
2017-05-20 19:48:39,956 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2386330858894790692_1326 src: /192.168.1.158:55571 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:48:40,013 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8112001348727708650_1328 src: /192.168.1.158:55572 dest: /192.168.1.158:50010
2017-05-20 19:48:40,015 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8112001348727708650_1328 src: /192.168.1.158:55572 dest: /192.168.1.158:50010 of size 13558
2017-05-20 19:48:40,172 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8112001348727708650_1328 to /192.168.1.159
2017-05-20 19:48:40,214 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_2386330858894790692_1326 to /192.168.1.159
2017-05-20 19:48:42,880 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6535498959598879290_1327 src: /192.168.1.157:37582 dest: /192.168.1.157:50010
2017-05-20 19:48:42,887 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6535498959598879290_1327 src: /192.168.1.157:37582 dest: /192.168.1.157:50010 of size 8645
2017-05-20 19:48:43,004 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6535498959598879290_1327 src: /192.168.1.158:55582 dest: /192.168.1.158:50010
2017-05-20 19:48:43,006 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6535498959598879290_1327 received exception java.io.IOException: Block blk_6535498959598879290_1327 is valid, and cannot be written to.
2017-05-20 19:48:43,007 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_6535498959598879290_1327 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:48:46,002 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4822907323911890379_1330 src: /192.168.1.156:45351 dest: /192.168.1.156:50010
2017-05-20 19:48:46,004 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4822907323911890379_1330 src: /192.168.1.156:45351 dest: /192.168.1.156:50010 of size 13543
2017-05-20 19:48:46,064 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 19:48:56,948 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:48:59,818 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:49:51,964 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2386330858894790692_1326 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2386330858894790692
2017-05-20 19:49:51,965 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6535498959598879290_1327 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6535498959598879290
2017-05-20 19:49:51,965 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8112001348727708650_1328 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8112001348727708650
2017-05-20 19:49:54,973 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4822907323911890379_1330 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4822907323911890379
2017-05-20 19:49:59,984 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:50:12,810 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:50:13,003 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:50:13,005 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:50:13,006 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:50:13,074 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:50:13,130 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:50:13,130 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:50:13,130 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:50:13,368 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 19:50:13,404 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:50:13,407 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:50:13,407 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 19:50:13,411 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:50:13,428 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:50:13,432 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:50:13,433 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:50:13,434 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:50:13,435 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:50:13,435 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:50:13,436 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:50:13,455 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:50:13,456 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:50:13,468 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:50:16,471 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 15 msecs
2017-05-20 19:51:22,516 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7572592439313419774_1339 src: /192.168.1.157:37650 dest: /192.168.1.157:50010
2017-05-20 19:51:22,517 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9121512463909798908_1335 src: /192.168.1.156:45414 dest: /192.168.1.156:50010
2017-05-20 19:51:22,539 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7572592439313419774_1339 src: /192.168.1.157:37650 dest: /192.168.1.157:50010 of size 13543
2017-05-20 19:51:22,539 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9121512463909798908_1335 src: /192.168.1.156:45414 dest: /192.168.1.156:50010 of size 91176
2017-05-20 19:51:22,762 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-9121512463909798908_1335 to /192.168.1.159
2017-05-20 19:51:25,492 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5661041420423221294_1337 src: /192.168.1.157:37660 dest: /192.168.1.157:50010
2017-05-20 19:51:25,494 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5661041420423221294_1337 src: /192.168.1.157:37660 dest: /192.168.1.157:50010 of size 13558
2017-05-20 19:51:25,503 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8467913334703747285_1336 src: /192.168.1.156:45424 dest: /192.168.1.156:50010
2017-05-20 19:51:25,511 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8467913334703747285_1336 src: /192.168.1.156:45424 dest: /192.168.1.156:50010 of size 8645
2017-05-20 19:51:26,484 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 19:51:37,181 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 19:51:39,322 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:51:45,089 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 19:52:34,521 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8418752501157154096_1343 src: /192.168.1.157:37717 dest: /192.168.1.157:50010
2017-05-20 19:52:34,522 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-8418752501157154096_1343 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-20 19:52:34,524 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:52:37,572 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9121512463909798908_1335 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9121512463909798908
2017-05-20 19:52:37,572 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7572592439313419774_1339 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7572592439313419774
2017-05-20 19:52:37,572 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5661041420423221294_1337 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5661041420423221294
2017-05-20 19:52:37,573 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8467913334703747285_1336 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8467913334703747285
2017-05-20 19:52:44,526 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:52:57,328 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:52:57,530 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:52:57,532 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:52:57,533 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:52:57,597 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:52:57,654 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:52:57,655 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:52:57,655 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:52:57,888 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-20 19:52:57,919 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:52:57,921 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:52:57,921 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 19:52:57,926 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:52:57,940 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:52:57,944 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:52:57,944 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:52:57,945 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:52:57,946 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:52:57,946 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:52:57,946 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:52:57,960 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:52:57,961 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:52:57,969 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:53:00,969 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 19:54:07,051 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4845532842796087692_1345 src: /192.168.1.158:55710 dest: /192.168.1.158:50010
2017-05-20 19:54:07,064 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4845532842796087692_1345 src: /192.168.1.158:55710 dest: /192.168.1.158:50010 of size 8645
2017-05-20 19:54:07,076 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4068338116571641911_1344 src: /192.168.1.156:45492 dest: /192.168.1.156:50010
2017-05-20 19:54:07,086 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4068338116571641911_1344 src: /192.168.1.156:45492 dest: /192.168.1.156:50010 of size 91176
2017-05-20 19:54:07,313 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4068338116571641911_1344 to /192.168.1.159
2017-05-20 19:54:09,992 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1891913076774711112_1348 src: /192.168.1.158:55720 dest: /192.168.1.158:50010
2017-05-20 19:54:09,993 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1891913076774711112_1348 src: /192.168.1.158:55720 dest: /192.168.1.158:50010 of size 13543
2017-05-20 19:54:10,085 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5383864563967231742_1346 src: /192.168.1.156:45503 dest: /192.168.1.156:50010
2017-05-20 19:54:10,086 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5383864563967231742_1346 src: /192.168.1.156:45503 dest: /192.168.1.156:50010 of size 13558
2017-05-20 19:54:14,261 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 19:54:18,054 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:54:26,577 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:54:39,263 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-20 19:56:01,120 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4845532842796087692_1345 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4845532842796087692
2017-05-20 19:56:01,121 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4068338116571641911_1344 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4068338116571641911
2017-05-20 19:56:01,121 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5383864563967231742_1346 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5383864563967231742
2017-05-20 19:56:04,119 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1891913076774711112_1348 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1891913076774711112
2017-05-20 19:56:12,868 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:56:25,627 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:56:25,826 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:56:25,828 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:56:25,829 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:56:25,904 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:56:25,965 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:56:25,966 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:56:25,967 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:56:26,212 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 19:56:26,251 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:56:26,254 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:56:26,254 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 19:56:26,260 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:56:26,281 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:56:26,287 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:56:26,288 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:56:26,289 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:56:26,290 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:56:26,290 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:56:26,290 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:56:26,294 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:56:26,294 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:56:26,302 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:56:29,303 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 6 msecs
2017-05-20 19:57:35,282 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3572339105696408349_1356 src: /192.168.1.157:37807 dest: /192.168.1.157:50010
2017-05-20 19:57:35,297 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3572339105696408349_1356 src: /192.168.1.157:37807 dest: /192.168.1.157:50010 of size 13560
2017-05-20 19:57:35,344 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-777784402073290241_1354 src: /192.168.1.158:55772 dest: /192.168.1.158:50010
2017-05-20 19:57:35,346 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-777784402073290241_1354 src: /192.168.1.158:55772 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:57:35,529 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3572339105696408349_1356 to /192.168.1.159
2017-05-20 19:57:35,572 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-777784402073290241_1354 to /192.168.1.159
2017-05-20 19:57:38,252 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4990501728945195822_1355 src: /192.168.1.157:37817 dest: /192.168.1.157:50010
2017-05-20 19:57:38,254 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4990501728945195822_1355 src: /192.168.1.157:37817 dest: /192.168.1.157:50010 of size 4325
2017-05-20 19:57:38,310 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4990501728945195822_1355 src: /192.168.1.158:55782 dest: /192.168.1.158:50010
2017-05-20 19:57:38,310 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4990501728945195822_1355 received exception java.io.IOException: Block blk_4990501728945195822_1355 is valid, and cannot be written to.
2017-05-20 19:57:38,312 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_4990501728945195822_1355 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 19:57:41,085 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 19:57:41,305 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1264540650612453193_1358 src: /192.168.1.156:45581 dest: /192.168.1.156:50010
2017-05-20 19:57:41,307 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1264540650612453193_1358 src: /192.168.1.156:45581 dest: /192.168.1.156:50010 of size 13545
2017-05-20 19:57:41,665 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 19:57:47,198 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 19:57:47,206 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 19:57:49,849 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 19:57:49,863 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:57:54,819 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 19:58:14,274 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-911137717657147355_1360 src: /192.168.1.158:55809 dest: /192.168.1.158:50010
2017-05-20 19:58:15,219 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-911137717657147355_1360 src: /192.168.1.158:55809 dest: /192.168.1.158:50010 of size 31981189
2017-05-20 19:58:17,274 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5150887685547596310_1360 src: /192.168.1.158:55810 dest: /192.168.1.158:50010
2017-05-20 19:58:17,325 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4665090427759094640_1362 src: /192.168.1.156:45613 dest: /192.168.1.156:50010
2017-05-20 19:58:17,328 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4665090427759094640_1362 src: /192.168.1.156:45613 dest: /192.168.1.156:50010 of size 41464
2017-05-20 19:58:17,937 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5150887685547596310_1360 src: /192.168.1.158:55810 dest: /192.168.1.158:50010 of size 31976695
2017-05-20 19:58:20,380 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3572339105696408349_1356 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3572339105696408349
2017-05-20 19:58:20,390 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-911137717657147355_1360 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-911137717657147355
2017-05-20 19:58:20,390 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-777784402073290241_1354 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-777784402073290241
2017-05-20 19:58:20,390 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1264540650612453193_1358 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1264540650612453193
2017-05-20 19:58:20,391 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4990501728945195822_1355 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4990501728945195822
2017-05-20 19:58:26,277 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 19:58:39,143 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 19:58:39,348 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 19:58:39,350 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 19:58:39,351 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 19:58:39,407 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 19:58:39,455 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 19:58:39,456 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 19:58:39,456 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 19:58:39,677 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 19:58:39,717 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 19:58:39,720 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 19:58:39,720 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 19:58:39,725 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 19:58:39,743 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 19:58:39,747 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 19:58:39,748 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 19:58:39,749 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 19:58:39,749 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 19:58:39,749 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 19:58:39,750 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 19:58:39,752 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 19:58:39,753 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 19:58:39,760 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 19:58:39,798 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_4665090427759094640_1362
2017-05-20 19:58:42,760 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 10 blocks got processed in 4 msecs
2017-05-20 19:59:15,838 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5150887685547596310_1360 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5150887685547596310
2017-05-20 19:59:15,838 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4665090427759094640_1362 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4665090427759094640
2017-05-20 19:59:48,802 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1688195855510538810_1365 src: /192.168.1.157:37853 dest: /192.168.1.157:50010
2017-05-20 19:59:48,822 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1688195855510538810_1365 src: /192.168.1.157:37853 dest: /192.168.1.157:50010 of size 13560
2017-05-20 19:59:48,830 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4474345464421918759_1363 src: /192.168.1.158:55814 dest: /192.168.1.158:50010
2017-05-20 19:59:48,837 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4474345464421918759_1363 src: /192.168.1.158:55814 dest: /192.168.1.158:50010 of size 91176
2017-05-20 19:59:49,073 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-1688195855510538810_1365 to /192.168.1.159
2017-05-20 19:59:49,114 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4474345464421918759_1363 to /192.168.1.159
2017-05-20 19:59:51,787 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6790620528352197370_1367 src: /192.168.1.157:37863 dest: /192.168.1.157:50010
2017-05-20 19:59:51,788 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2262483846263314173_1364 src: /192.168.1.157:37864 dest: /192.168.1.157:50010
2017-05-20 19:59:51,799 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6790620528352197370_1367 src: /192.168.1.157:37863 dest: /192.168.1.157:50010 of size 13545
2017-05-20 19:59:51,800 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2262483846263314173_1364 src: /192.168.1.157:37864 dest: /192.168.1.157:50010 of size 4325
2017-05-20 20:00:03,227 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 20:00:09,563 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-20 20:00:27,815 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5126444040213927893_1368 src: /192.168.1.156:45665 dest: /192.168.1.156:50010
2017-05-20 20:00:28,402 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5126444040213927893_1368 src: /192.168.1.156:45665 dest: /192.168.1.156:50010 of size 31976695
2017-05-20 20:00:30,807 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_316044634463346357_1371 src: /192.168.1.158:55858 dest: /192.168.1.158:50010
2017-05-20 20:00:30,822 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6678775743239823833_1369 src: /192.168.1.156:45666 dest: /192.168.1.156:50010
2017-05-20 20:00:31,557 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6678775743239823833_1369 src: /192.168.1.156:45666 dest: /192.168.1.156:50010 of size 31980463
2017-05-20 20:00:32,036 INFO org.apache.hadoop.dfs.DataNode: Received block blk_316044634463346357_1371 src: /192.168.1.158:55858 dest: /192.168.1.158:50010 of size 31981189
2017-05-20 20:00:33,807 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1105645602435420078_1371 src: /192.168.1.157:37897 dest: /192.168.1.157:50010
2017-05-20 20:00:33,808 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1105645602435420078_1371 src: /192.168.1.157:37898 dest: /192.168.1.157:50010
2017-05-20 20:00:33,808 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1105645602435420078_1371 received exception java.io.IOException: Block blk_1105645602435420078_1371 has already been started (though not completed), and thus cannot be created.
2017-05-20 20:00:33,809 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1105645602435420078_1371 src: /192.168.1.157:37897 dest: /192.168.1.157:50010 of size 41464
2017-05-20 20:00:33,811 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_1105645602435420078_1371 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:00:36,876 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2262483846263314173_1364 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2262483846263314173
2017-05-20 20:00:36,876 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1688195855510538810_1365 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1688195855510538810
2017-05-20 20:00:36,887 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_316044634463346357_1371 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_316044634463346357
2017-05-20 20:00:36,887 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4474345464421918759_1363 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4474345464421918759
2017-05-20 20:00:36,894 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5126444040213927893_1368 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5126444040213927893
2017-05-20 20:00:36,901 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6678775743239823833_1369 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6678775743239823833
2017-05-20 20:00:36,901 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6790620528352197370_1367 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6790620528352197370
2017-05-20 20:00:41,986 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 20:00:54,767 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 20:00:54,965 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 20:00:54,967 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 20:00:54,969 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 20:00:55,038 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 20:00:55,098 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 20:00:55,099 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 20:00:55,099 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 20:00:55,343 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 20:00:55,383 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 20:00:55,386 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 20:00:55,386 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 20:00:55,391 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 20:00:55,408 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 20:00:55,413 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 20:00:55,413 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 20:00:55,415 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 20:00:55,415 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 20:00:55,416 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 20:00:55,416 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 20:00:55,418 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 20:00:55,418 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 20:00:55,428 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 20:00:55,459 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_1105645602435420078_1371
2017-05-20 20:00:58,425 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 6 msecs
2017-05-20 20:01:31,477 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1105645602435420078_1371 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1105645602435420078
2017-05-20 20:02:04,524 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7401808831303544388_1374 src: /192.168.1.157:37903 dest: /192.168.1.157:50010
2017-05-20 20:02:04,540 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7401808831303544388_1374 src: /192.168.1.157:37903 dest: /192.168.1.157:50010 of size 13560
2017-05-20 20:02:04,563 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7059271816276387318_1372 src: /192.168.1.158:55861 dest: /192.168.1.158:50010
2017-05-20 20:02:04,568 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7059271816276387318_1372 src: /192.168.1.158:55861 dest: /192.168.1.158:50010 of size 91176
2017-05-20 20:02:04,670 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-7401808831303544388_1374 to /192.168.1.159
2017-05-20 20:02:04,709 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-7059271816276387318_1372 to /192.168.1.159
2017-05-20 20:02:10,465 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1773889462370717603_1376 src: /192.168.1.158:55872 dest: /192.168.1.158:50010
2017-05-20 20:02:10,466 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1773889462370717603_1376 src: /192.168.1.158:55872 dest: /192.168.1.158:50010 of size 13545
2017-05-20 20:02:10,511 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1817010518305085014_1373 src: /192.168.1.156:45687 dest: /192.168.1.156:50010
2017-05-20 20:02:10,512 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1817010518305085014_1373 src: /192.168.1.156:45687 dest: /192.168.1.156:50010 of size 4325
2017-05-20 20:02:19,874 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 20:02:43,529 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7390154019757786240_1377 src: /192.168.1.157:37949 dest: /192.168.1.157:50010
2017-05-20 20:02:44,056 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7390154019757786240_1377 src: /192.168.1.157:37949 dest: /192.168.1.157:50010 of size 31976695
2017-05-20 20:02:46,543 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1010204390489831668_1380 src: /192.168.1.158:55907 dest: /192.168.1.158:50010
2017-05-20 20:02:46,543 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6442686254511825352_1379 src: /192.168.1.156:45716 dest: /192.168.1.156:50010
2017-05-20 20:02:46,548 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1010204390489831668_1380 src: /192.168.1.158:55907 dest: /192.168.1.158:50010 of size 41464
2017-05-20 20:02:46,998 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6442686254511825352_1379 src: /192.168.1.156:45716 dest: /192.168.1.156:50010 of size 31964396
2017-05-20 20:02:49,530 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5062465226402211902_1380 src: /192.168.1.157:37952 dest: /192.168.1.157:50010
2017-05-20 20:02:49,538 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5794240675327392185_1378 src: /192.168.1.156:45717 dest: /192.168.1.156:50010
2017-05-20 20:02:50,254 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5794240675327392185_1378 src: /192.168.1.156:45717 dest: /192.168.1.156:50010 of size 31980463
2017-05-20 20:02:50,788 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5062465226402211902_1380 src: /192.168.1.157:37952 dest: /192.168.1.157:50010 of size 31981189
2017-05-20 20:02:52,523 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7401808831303544388_1374 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7401808831303544388
2017-05-20 20:02:52,535 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7390154019757786240_1377 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7390154019757786240
2017-05-20 20:02:52,535 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7059271816276387318_1372 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7059271816276387318
2017-05-20 20:02:52,541 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6442686254511825352_1379 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6442686254511825352
2017-05-20 20:02:52,541 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1773889462370717603_1376 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1773889462370717603
2017-05-20 20:02:52,541 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1010204390489831668_1380 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1010204390489831668
2017-05-20 20:02:52,541 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1817010518305085014_1373 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1817010518305085014
2017-05-20 20:03:00,173 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 20:03:13,023 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 20:03:13,226 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 20:03:13,228 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 20:03:13,229 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 20:03:13,293 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 20:03:13,350 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 20:03:13,351 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 20:03:13,351 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 20:03:13,588 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 20:03:13,625 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 20:03:13,627 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 20:03:13,627 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@5876a5
2017-05-20 20:03:13,633 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 20:03:13,649 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 20:03:13,654 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 20:03:13,655 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 20:03:13,656 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 20:03:13,657 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 20:03:13,657 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 20:03:13,657 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 20:03:13,659 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 20:03:13,660 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 20:03:13,668 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 20:03:16,667 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 10 blocks got processed in 6 msecs
2017-05-20 20:03:42,435 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_5794240675327392185_1378
2017-05-20 20:03:49,697 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5062465226402211902_1380 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5062465226402211902
2017-05-20 20:03:49,705 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5794240675327392185_1378 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5794240675327392185
2017-05-20 20:04:22,764 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3459000466269626873_1381 src: /192.168.1.158:55910 dest: /192.168.1.158:50010
2017-05-20 20:04:22,764 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-879459183792626516_1383 src: /192.168.1.158:55911 dest: /192.168.1.158:50010
2017-05-20 20:04:22,783 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-879459183792626516_1383 src: /192.168.1.158:55911 dest: /192.168.1.158:50010 of size 13560
2017-05-20 20:04:22,783 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3459000466269626873_1381 src: /192.168.1.158:55910 dest: /192.168.1.158:50010 of size 91176
2017-05-20 20:04:22,947 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-879459183792626516_1383 to /192.168.1.159
2017-05-20 20:04:22,993 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3459000466269626873_1381 to /192.168.1.159
2017-05-20 20:04:25,707 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7093158735788351052_1382 src: /192.168.1.157:37968 dest: /192.168.1.157:50010
2017-05-20 20:04:25,710 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7093158735788351052_1382 src: /192.168.1.157:37968 dest: /192.168.1.157:50010 of size 2165
2017-05-20 20:04:25,756 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8874258077246315113_1385 src: /192.168.1.156:45733 dest: /192.168.1.156:50010
2017-05-20 20:04:25,757 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8874258077246315113_1385 src: /192.168.1.156:45734 dest: /192.168.1.156:50010
2017-05-20 20:04:25,758 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8874258077246315113_1385 received exception java.io.IOException: Block blk_8874258077246315113_1385 has already been started (though not completed), and thus cannot be created.
2017-05-20 20:04:25,759 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8874258077246315113_1385 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:04:25,760 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8874258077246315113_1385 src: /192.168.1.156:45733 dest: /192.168.1.156:50010 of size 13545
2017-05-20 20:04:28,741 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8874258077246315113_1385 to 192.168.1.158:50010
2017-05-20 20:04:28,745 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_8874258077246315113_1385 to /192.168.1.158:50010
2017-05-20 20:04:33,210 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 20:04:33,618 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 20:04:38,200 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 20:04:39,158 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-20 20:04:58,775 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3213233544306213142_1388 src: /192.168.1.156:45756 dest: /192.168.1.156:50010
2017-05-20 20:04:59,517 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3213233544306213142_1388 src: /192.168.1.156:45756 dest: /192.168.1.156:50010 of size 31980463
2017-05-20 20:05:01,725 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3611280749543489743_1389 src: /192.168.1.157:37990 dest: /192.168.1.157:50010
2017-05-20 20:05:01,729 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3611280749543489743_1389 src: /192.168.1.157:37990 dest: /192.168.1.157:50010 of size 23481
2017-05-20 20:05:01,780 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3776681302916632677_1386 src: /192.168.1.158:55941 dest: /192.168.1.158:50010
2017-05-20 20:05:02,533 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3776681302916632677_1386 src: /192.168.1.158:55941 dest: /192.168.1.158:50010 of size 31964396
2017-05-20 20:05:04,725 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5010754589365580727_1389 src: /192.168.1.157:37991 dest: /192.168.1.157:50010
2017-05-20 20:05:05,334 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5010754589365580727_1389 src: /192.168.1.157:37991 dest: /192.168.1.157:50010 of size 31981189
2017-05-20 20:05:07,771 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3776681302916632677_1386 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3776681302916632677
2017-05-20 20:05:07,771 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3459000466269626873_1381 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3459000466269626873
2017-05-20 20:05:07,772 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-879459183792626516_1383 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-879459183792626516
2017-05-20 20:05:07,779 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3213233544306213142_1388 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3213233544306213142
2017-05-20 20:05:07,779 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3611280749543489743_1389 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3611280749543489743
2017-05-20 20:05:07,779 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7093158735788351052_1382 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7093158735788351052
2017-05-20 20:05:07,779 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8874258077246315113_1385 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8874258077246315113
2017-05-20 20:05:12,868 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 20:05:25,656 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 20:05:25,850 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 20:05:25,852 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 20:05:25,853 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 20:05:25,926 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 20:05:25,982 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 20:05:25,983 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 20:05:25,983 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 20:05:26,224 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@14a8af0
2017-05-20 20:05:26,262 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 20:05:26,265 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 20:05:26,265 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 20:05:26,270 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 20:05:26,287 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 20:05:26,292 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 20:05:26,292 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 20:05:26,294 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 20:05:26,295 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 20:05:26,295 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 20:05:26,295 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 20:05:26,318 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 20:05:26,319 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 20:05:26,329 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 20:05:29,329 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 10 msecs
2017-05-20 20:05:55,060 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_5010754589365580727_1389
2017-05-20 20:06:02,361 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5010754589365580727_1389 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5010754589365580727
2017-05-20 20:06:35,381 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4233852500211953373_1394 src: /192.168.1.157:37997 dest: /192.168.1.157:50010
2017-05-20 20:06:35,388 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3575528017112933659_1390 src: /192.168.1.158:55944 dest: /192.168.1.158:50010
2017-05-20 20:06:35,399 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4233852500211953373_1394 src: /192.168.1.157:37997 dest: /192.168.1.157:50010 of size 13545
2017-05-20 20:06:35,400 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3575528017112933659_1390 src: /192.168.1.158:55944 dest: /192.168.1.158:50010 of size 91176
2017-05-20 20:06:35,617 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3575528017112933659_1390 to /192.168.1.159
2017-05-20 20:06:38,363 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2034547667821436462_1392 src: /192.168.1.156:45774 dest: /192.168.1.156:50010
2017-05-20 20:06:38,364 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7505319840519508753_1391 src: /192.168.1.156:45775 dest: /192.168.1.156:50010
2017-05-20 20:06:38,365 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7505319840519508753_1391 src: /192.168.1.156:45775 dest: /192.168.1.156:50010 of size 2165
2017-05-20 20:06:38,367 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2034547667821436462_1392 src: /192.168.1.156:45774 dest: /192.168.1.156:50010 of size 13560
2017-05-20 20:06:38,378 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2034547667821436462_1392 src: /192.168.1.157:38008 dest: /192.168.1.157:50010
2017-05-20 20:06:38,378 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2034547667821436462_1392 received exception java.io.IOException: Block blk_-2034547667821436462_1392 is valid, and cannot be written to.
2017-05-20 20:06:38,379 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-2034547667821436462_1392 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:06:46,162 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 20:06:48,581 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 20:06:52,051 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 20:06:52,105 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 20:07:14,383 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1073124338400261355_1397 src: /192.168.1.156:45796 dest: /192.168.1.156:50010
2017-05-20 20:07:15,171 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Exception writing block blk_-1073124338400261355_1397 to mirror 192.168.1.158:50010
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:94)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:450)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receivePacket(DataNode.java:2601)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2698)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:07:15,226 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1073124338400261355_1397 src: /192.168.1.156:45796 dest: /192.168.1.156:50010 of size 31976695
2017-05-20 20:07:17,381 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4385990946952661022_1395 src: /192.168.1.156:45798 dest: /192.168.1.156:50010
2017-05-20 20:07:17,834 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4385990946952661022_1395 src: /192.168.1.156:45798 dest: /192.168.1.156:50010 of size 31980463
2017-05-20 20:07:20,388 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2360846823056864803_1397 src: /192.168.1.156:45799 dest: /192.168.1.156:50010
2017-05-20 20:07:20,389 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5783965833190893396_1398 src: /192.168.1.156:45800 dest: /192.168.1.156:50010
2017-05-20 20:07:20,391 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5783965833190893396_1398 src: /192.168.1.156:45800 dest: /192.168.1.156:50010 of size 23481
2017-05-20 20:07:20,952 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2360846823056864803_1397 src: /192.168.1.156:45799 dest: /192.168.1.156:50010 of size 31981189
2017-05-20 20:07:23,395 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5841000185674172958_1398 src: /192.168.1.157:38033 dest: /192.168.1.157:50010
2017-05-20 20:07:23,965 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5841000185674172958_1398 src: /192.168.1.157:38033 dest: /192.168.1.157:50010 of size 31964396
2017-05-20 20:07:26,402 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5783965833190893396_1398 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5783965833190893396
2017-05-20 20:07:26,410 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4385990946952661022_1395 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4385990946952661022
2017-05-20 20:07:26,410 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4233852500211953373_1394 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4233852500211953373
2017-05-20 20:07:26,411 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3575528017112933659_1390 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3575528017112933659
2017-05-20 20:07:26,411 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2034547667821436462_1392 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2034547667821436462
2017-05-20 20:07:26,417 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1073124338400261355_1397 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1073124338400261355
2017-05-20 20:07:26,425 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2360846823056864803_1397 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2360846823056864803
2017-05-20 20:07:26,425 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7505319840519508753_1391 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7505319840519508753
2017-05-20 20:07:31,419 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 20:07:44,233 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 20:07:44,419 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 20:07:44,421 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 20:07:44,423 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 20:07:44,478 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 20:07:44,526 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 20:07:44,526 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 20:07:44,526 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 20:07:44,733 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-20 20:07:44,765 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 20:07:44,768 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 20:07:44,768 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 20:07:44,773 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 20:07:44,789 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 20:07:44,794 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 20:07:44,794 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 20:07:44,796 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 20:07:44,796 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 20:07:44,800 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 20:07:44,800 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 20:07:44,810 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 20:07:44,810 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 20:07:44,822 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 20:07:47,823 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 13 msecs
2017-05-20 20:08:13,630 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-5841000185674172958_1398
2017-05-20 20:08:20,877 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5841000185674172958_1398 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5841000185674172958
2017-05-20 20:08:53,939 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8057985047160173982_1399 src: /192.168.1.156:45808 dest: /192.168.1.156:50010
2017-05-20 20:08:53,939 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7456019544284340312_1400 src: /192.168.1.157:38037 dest: /192.168.1.157:50010
2017-05-20 20:08:53,956 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7456019544284340312_1400 src: /192.168.1.157:38037 dest: /192.168.1.157:50010 of size 2165
2017-05-20 20:08:53,960 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8057985047160173982_1399 src: /192.168.1.156:45808 dest: /192.168.1.156:50010 of size 91176
2017-05-20 20:08:54,203 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8057985047160173982_1399 to /192.168.1.159
2017-05-20 20:08:55,182 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 20:08:56,937 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8177846675472125235_1403 src: /192.168.1.158:55989 dest: /192.168.1.158:50010
2017-05-20 20:08:56,938 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8177846675472125235_1403 src: /192.168.1.158:55989 dest: /192.168.1.158:50010 of size 13545
2017-05-20 20:08:59,977 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5333298971965793648_1401 src: /192.168.1.158:55991 dest: /192.168.1.158:50010
2017-05-20 20:08:59,978 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5333298971965793648_1401 src: /192.168.1.158:55991 dest: /192.168.1.158:50010 of size 13560
2017-05-20 20:09:00,357 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 20:09:00,394 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 20:09:29,946 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6424907165158637615_1405 src: /192.168.1.158:56011 dest: /192.168.1.158:50010
2017-05-20 20:09:30,658 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6424907165158637615_1405 src: /192.168.1.158:56011 dest: /192.168.1.158:50010 of size 31976695
2017-05-20 20:09:32,938 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2425598616744529248_1405 src: /192.168.1.156:45844 dest: /192.168.1.156:50010
2017-05-20 20:09:33,080 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Exception writing block blk_2425598616744529248_1405 to mirror 192.168.1.158:50010
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.write0(Native Method)
	at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47)
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:94)
	at sun.nio.ch.IOUtil.write(IOUtil.java:65)
	at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:450)
	at org.apache.hadoop.net.SocketOutputStream$Writer.performIO(SocketOutputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:146)
	at org.apache.hadoop.net.SocketOutputStream.write(SocketOutputStream.java:107)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receivePacket(DataNode.java:2601)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2698)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:09:33,439 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2425598616744529248_1405 src: /192.168.1.156:45844 dest: /192.168.1.156:50010 of size 31981189
2017-05-20 20:09:38,951 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5553537222396345171_1407 src: /192.168.1.157:38072 dest: /192.168.1.157:50010
2017-05-20 20:09:38,954 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4795421548711761367_1407 src: /192.168.1.158:56012 dest: /192.168.1.158:50010
2017-05-20 20:09:38,957 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4795421548711761367_1407 src: /192.168.1.158:56012 dest: /192.168.1.158:50010 of size 23481
2017-05-20 20:09:39,558 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5553537222396345171_1407 src: /192.168.1.157:38072 dest: /192.168.1.157:50010 of size 31964396
2017-05-20 20:09:41,945 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9113534289350874160_1406 src: /192.168.1.157:38073 dest: /192.168.1.157:50010
2017-05-20 20:09:42,578 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9113534289350874160_1406 src: /192.168.1.157:38073 dest: /192.168.1.157:50010 of size 31980463
2017-05-20 20:09:44,921 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8177846675472125235_1403 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8177846675472125235
2017-05-20 20:09:44,922 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8057985047160173982_1399 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8057985047160173982
2017-05-20 20:09:44,932 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6424907165158637615_1405 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6424907165158637615
2017-05-20 20:09:44,941 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5553537222396345171_1407 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5553537222396345171
2017-05-20 20:09:44,941 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5333298971965793648_1401 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5333298971965793648
2017-05-20 20:09:44,942 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4795421548711761367_1407 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4795421548711761367
2017-05-20 20:09:44,948 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2425598616744529248_1405 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2425598616744529248
2017-05-20 20:09:44,948 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7456019544284340312_1400 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7456019544284340312
2017-05-20 20:09:51,748 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 20:10:04,523 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 20:10:04,711 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 20:10:04,713 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 20:10:04,715 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 20:10:04,782 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 20:10:04,838 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 20:10:04,839 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 20:10:04,839 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 20:10:05,073 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 20:10:05,108 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 20:10:05,111 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 20:10:05,111 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 20:10:05,117 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 20:10:05,135 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 20:10:05,140 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 20:10:05,141 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 20:10:05,142 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 20:10:05,142 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 20:10:05,142 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 20:10:05,143 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 20:10:05,146 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 20:10:05,146 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 20:10:05,153 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 20:10:08,155 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 6 msecs
2017-05-20 20:10:33,922 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_9113534289350874160_1406
2017-05-20 20:10:41,180 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9113534289350874160_1406 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9113534289350874160
2017-05-20 20:11:14,183 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1389213218911515643_1408 src: /192.168.1.158:56015 dest: /192.168.1.158:50010
2017-05-20 20:11:14,198 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1389213218911515643_1408 src: /192.168.1.158:56015 dest: /192.168.1.158:50010 of size 91176
2017-05-20 20:11:14,227 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5777696571194083156_1409 src: /192.168.1.158:56016 dest: /192.168.1.158:50010
2017-05-20 20:11:14,228 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5777696571194083156_1409 src: /192.168.1.158:56016 dest: /192.168.1.158:50010 of size 8645
2017-05-20 20:11:14,593 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-1389213218911515643_1408 to /192.168.1.159
2017-05-20 20:11:17,148 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3834838319096485307_1410 src: /192.168.1.157:38088 dest: /192.168.1.157:50010
2017-05-20 20:11:17,150 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3834838319096485307_1410 src: /192.168.1.157:38088 dest: /192.168.1.157:50010 of size 13558
2017-05-20 20:11:17,217 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1989979351829958090_1412 src: /192.168.1.156:45861 dest: /192.168.1.156:50010
2017-05-20 20:11:17,222 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1989979351829958090_1412 src: /192.168.1.156:45861 dest: /192.168.1.156:50010 of size 13543
2017-05-20 20:11:28,137 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 20:11:31,313 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 20:12:26,244 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3477702488542882801_1416 src: /192.168.1.156:45927 dest: /192.168.1.156:50010
2017-05-20 20:12:26,245 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3477702488542882801_1416 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-20 20:12:26,247 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:12:29,249 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5777696571194083156_1409 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5777696571194083156
2017-05-20 20:12:29,250 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1989979351829958090_1412 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1989979351829958090
2017-05-20 20:12:29,250 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1389213218911515643_1408 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1389213218911515643
2017-05-20 20:12:29,250 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3834838319096485307_1410 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3834838319096485307
2017-05-20 20:12:36,415 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 20:12:49,262 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 20:12:49,462 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 20:12:49,464 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 20:12:49,466 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 20:12:49,539 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 20:12:49,600 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 20:12:49,601 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 20:12:49,601 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 20:12:49,817 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 20:12:49,855 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 20:12:49,858 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 20:12:49,858 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 20:12:49,862 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 20:12:49,882 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 20:12:49,886 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 20:12:49,887 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 20:12:49,887 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 20:12:49,887 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 20:12:49,888 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 20:12:49,888 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 20:12:49,890 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 20:12:49,890 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 20:12:49,898 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 20:12:52,897 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 7 msecs
2017-05-20 20:13:58,981 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5285958767247526674_1417 src: /192.168.1.156:45931 dest: /192.168.1.156:50010
2017-05-20 20:13:58,997 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5285958767247526674_1417 src: /192.168.1.156:45931 dest: /192.168.1.156:50010 of size 91176
2017-05-20 20:13:59,003 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9175685728806051938_1418 src: /192.168.1.158:56082 dest: /192.168.1.158:50010
2017-05-20 20:13:59,004 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9175685728806051938_1418 src: /192.168.1.158:56082 dest: /192.168.1.158:50010 of size 8645
2017-05-20 20:13:59,231 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5285958767247526674_1417 to /192.168.1.159
2017-05-20 20:14:01,949 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5188894478780522200_1421 src: /192.168.1.156:45942 dest: /192.168.1.156:50010
2017-05-20 20:14:01,953 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5188894478780522200_1421 src: /192.168.1.156:45942 dest: /192.168.1.156:50010 of size 13543
2017-05-20 20:14:01,958 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_519427331906998753_1419 src: /192.168.1.157:38168 dest: /192.168.1.157:50010
2017-05-20 20:14:01,959 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_519427331906998753_1419 src: /192.168.1.157:38169 dest: /192.168.1.157:50010
2017-05-20 20:14:01,959 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_519427331906998753_1419 received exception java.io.IOException: Block blk_519427331906998753_1419 has already been started (though not completed), and thus cannot be created.
2017-05-20 20:14:01,960 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_519427331906998753_1419 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:14:01,961 INFO org.apache.hadoop.dfs.DataNode: Received block blk_519427331906998753_1419 src: /192.168.1.157:38168 dest: /192.168.1.157:50010 of size 13558
2017-05-20 20:14:13,796 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 20:14:18,429 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 20:14:22,217 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 20:14:23,610 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 20:15:43,995 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1083417049449204853_1424 src: /192.168.1.157:38239 dest: /192.168.1.157:50010
2017-05-20 20:15:43,996 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-1083417049449204853_1424 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-20 20:15:44,000 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:15:47,005 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9175685728806051938_1418 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9175685728806051938
2017-05-20 20:15:47,005 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_519427331906998753_1419 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_519427331906998753
2017-05-20 20:15:47,006 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5285958767247526674_1417 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5285958767247526674
2017-05-20 20:15:50,012 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5188894478780522200_1421 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5188894478780522200
2017-05-20 20:15:55,101 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 20:16:07,976 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 20:16:08,176 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 20:16:08,177 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 20:16:08,178 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 20:16:08,250 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 20:16:08,309 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 20:16:08,309 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 20:16:08,310 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 20:16:08,537 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-20 20:16:08,569 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 20:16:08,572 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 20:16:08,572 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 20:16:08,578 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 20:16:08,594 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 20:16:08,599 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 20:16:08,599 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 20:16:08,601 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 20:16:08,601 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 20:16:08,602 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 20:16:08,602 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 20:16:08,604 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 20:16:08,604 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 20:16:08,612 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 20:16:11,610 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 5 msecs
2017-05-20 20:17:17,700 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-688974582730053584_1426 src: /192.168.1.158:56148 dest: /192.168.1.158:50010
2017-05-20 20:17:17,713 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-688974582730053584_1426 src: /192.168.1.158:56148 dest: /192.168.1.158:50010 of size 91176
2017-05-20 20:17:17,728 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2161805077405774869_1427 src: /192.168.1.158:56149 dest: /192.168.1.158:50010
2017-05-20 20:17:17,729 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2161805077405774869_1427 src: /192.168.1.158:56149 dest: /192.168.1.158:50010 of size 8645
2017-05-20 20:17:18,095 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-688974582730053584_1426 to /192.168.1.159
2017-05-20 20:17:20,621 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6959946139565037495_1430 src: /192.168.1.157:38252 dest: /192.168.1.157:50010
2017-05-20 20:17:20,633 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6959946139565037495_1430 src: /192.168.1.157:38252 dest: /192.168.1.157:50010 of size 13543
2017-05-20 20:17:20,720 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7070093453791283832_1428 src: /192.168.1.156:46017 dest: /192.168.1.156:50010
2017-05-20 20:17:20,721 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7070093453791283832_1428 src: /192.168.1.156:46017 dest: /192.168.1.156:50010 of size 13558
2017-05-20 20:17:22,098 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 20:17:27,514 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 20:17:36,360 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 20:17:39,445 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 20:17:40,817 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 20:19:14,762 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-688974582730053584_1426 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-688974582730053584
2017-05-20 20:19:14,763 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2161805077405774869_1427 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2161805077405774869
2017-05-20 20:19:14,764 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7070093453791283832_1428 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7070093453791283832
2017-05-20 20:19:17,670 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4692545536708001473_1432 src: /192.168.1.157:38307 dest: /192.168.1.157:50010
2017-05-20 20:19:17,677 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4692545536708001473_1432 src: /192.168.1.157:38307 dest: /192.168.1.157:50010 of size 77977
2017-05-20 20:19:20,762 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6959946139565037495_1430 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6959946139565037495
2017-05-20 20:19:27,624 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 20:19:40,377 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 20:19:40,559 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 20:19:40,560 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 20:19:40,562 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 20:19:40,627 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 20:19:40,683 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 20:19:40,684 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 20:19:40,684 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 20:19:40,918 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 20:19:40,955 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 20:19:40,958 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 20:19:40,958 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 20:19:40,963 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 20:19:40,986 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 20:19:40,992 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 20:19:40,992 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 20:19:40,993 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 20:19:40,994 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 20:19:40,994 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 20:19:40,995 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 20:19:40,997 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 20:19:40,997 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 20:19:41,005 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 20:19:41,043 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-4692545536708001473_1432
2017-05-20 20:19:44,007 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 7 msecs
2017-05-20 20:20:17,022 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4692545536708001473_1432 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4692545536708001473
2017-05-20 20:20:50,112 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1200274784519429149_1435 src: /192.168.1.157:38311 dest: /192.168.1.157:50010
2017-05-20 20:20:50,118 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3133927442972338469_1437 src: /192.168.1.158:56215 dest: /192.168.1.158:50010
2017-05-20 20:20:50,130 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3133927442972338469_1437 src: /192.168.1.158:56215 dest: /192.168.1.158:50010 of size 13560
2017-05-20 20:20:50,135 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1200274784519429149_1435 src: /192.168.1.157:38311 dest: /192.168.1.157:50010 of size 91176
2017-05-20 20:20:50,331 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3133927442972338469_1437 to /192.168.1.159
2017-05-20 20:20:50,371 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-1200274784519429149_1435 to /192.168.1.159
2017-05-20 20:20:53,079 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2883672859958327655_1439 src: /192.168.1.156:46103 dest: /192.168.1.156:50010
2017-05-20 20:20:53,080 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4930395408536264411_1436 src: /192.168.1.156:46104 dest: /192.168.1.156:50010
2017-05-20 20:20:53,085 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2883672859958327655_1439 src: /192.168.1.156:46103 dest: /192.168.1.156:50010 of size 13545
2017-05-20 20:20:53,086 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4930395408536264411_1436 src: /192.168.1.156:46104 dest: /192.168.1.156:50010 of size 4325
2017-05-20 20:20:53,104 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2883672859958327655_1439 src: /192.168.1.157:38322 dest: /192.168.1.157:50010
2017-05-20 20:20:53,104 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_2883672859958327655_1439 received exception java.io.IOException: Block blk_2883672859958327655_1439 is valid, and cannot be written to.
2017-05-20 20:20:53,106 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_2883672859958327655_1439 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:20:56,795 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-20 20:20:59,194 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 20:21:04,604 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 20:21:04,636 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 20:21:29,112 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-307926004617565244_1441 src: /192.168.1.157:38360 dest: /192.168.1.157:50010
2017-05-20 20:21:29,851 INFO org.apache.hadoop.dfs.DataNode: Exception in receiveBlock for block blk_-307926004617565244_1441 org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
2017-05-20 20:21:29,851 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-307926004617565244_1441 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
2017-05-20 20:21:29,853 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
	at org.apache.hadoop.dfs.DataNode.checkDiskError(DataNode.java:595)
	at org.apache.hadoop.dfs.DataNode.access$1500(DataNode.java:83)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receivePacket(DataNode.java:2645)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2698)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:21:35,117 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3921568556816323332_1443 src: /192.168.1.157:38361 dest: /192.168.1.157:50010
2017-05-20 20:21:35,122 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3921568556816323332_1443 src: /192.168.1.157:38361 dest: /192.168.1.157:50010 of size 41464
2017-05-20 20:21:41,070 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3133927442972338469_1437 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3133927442972338469
2017-05-20 20:21:41,072 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1200274784519429149_1435 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1200274784519429149
2017-05-20 20:21:41,072 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2883672859958327655_1439 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2883672859958327655
2017-05-20 20:21:41,073 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3921568556816323332_1443 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3921568556816323332
2017-05-20 20:21:41,073 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4930395408536264411_1436 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4930395408536264411
2017-05-20 20:21:46,153 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 20:21:58,967 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 20:21:59,148 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 20:21:59,150 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 20:21:59,151 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 20:21:59,204 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 20:21:59,251 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 20:21:59,252 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 20:21:59,252 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 20:21:59,468 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-20 20:21:59,500 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 20:21:59,502 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 20:21:59,503 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 20:21:59,507 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 20:21:59,523 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 20:21:59,527 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 20:21:59,528 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 20:21:59,529 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 20:21:59,529 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 20:21:59,529 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 20:21:59,529 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 20:21:59,538 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 20:21:59,538 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 20:21:59,550 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 20:22:02,552 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 14 msecs
2017-05-20 20:22:25,558 WARN org.apache.hadoop.dfs.DataNode:  Could not read or failed to veirfy checksum for data at offset 28901376 for block blk_-307926004617565244_1441 got : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:22:25,559 WARN org.apache.hadoop.dfs.DataBlockScanner: First Verification failed for blk_-307926004617565244_1441. Exception : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:22:35,626 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-307926004617565244_1441 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-307926004617565244
2017-05-20 20:22:53,355 WARN org.apache.hadoop.dfs.DataNode:  Could not read or failed to veirfy checksum for data at offset 28901376 for block blk_-307926004617565244_1441 got : java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendChunks(DataNode.java:1821)
	at org.apache.hadoop.dfs.DataNode$BlockSender.sendBlock(DataNode.java:1967)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyBlock(DataBlockScanner.java:414)
	at org.apache.hadoop.dfs.DataBlockScanner.verifyFirstBlock(DataBlockScanner.java:474)
	at org.apache.hadoop.dfs.DataBlockScanner.run(DataBlockScanner.java:565)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:22:53,365 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification failed for blk_-307926004617565244_1441. Its ok since it not in datanode dataset anymore.
2017-05-20 20:23:08,653 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5805936902481151314_1448 src: /192.168.1.158:56250 dest: /192.168.1.158:50010
2017-05-20 20:23:08,659 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-116490435351374594_1444 src: /192.168.1.156:46139 dest: /192.168.1.156:50010
2017-05-20 20:23:08,677 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5805936902481151314_1448 src: /192.168.1.158:56250 dest: /192.168.1.158:50010 of size 13545
2017-05-20 20:23:08,686 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-116490435351374594_1444 src: /192.168.1.156:46139 dest: /192.168.1.156:50010 of size 91176
2017-05-20 20:23:08,964 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-116490435351374594_1444 to /192.168.1.159
2017-05-20 20:23:11,659 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1316151490780922547_1445 src: /192.168.1.156:46150 dest: /192.168.1.156:50010
2017-05-20 20:23:11,667 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1316151490780922547_1445 src: /192.168.1.156:46150 dest: /192.168.1.156:50010 of size 4325
2017-05-20 20:23:14,614 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2688061802058582803_1446 src: /192.168.1.157:38382 dest: /192.168.1.157:50010
2017-05-20 20:23:14,614 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2688061802058582803_1446 src: /192.168.1.157:38382 dest: /192.168.1.157:50010 of size 13560
2017-05-20 20:23:23,057 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 20:23:25,793 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-20 20:23:47,676 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4532651256663458722_1449 src: /192.168.1.158:56295 dest: /192.168.1.158:50010
2017-05-20 20:23:48,349 INFO org.apache.hadoop.dfs.DataNode: Exception in receiveBlock for block blk_4532651256663458722_1449 java.io.EOFException: while trying to read 66073 bytes
2017-05-20 20:23:48,349 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4532651256663458722_1449 received exception java.io.EOFException: while trying to read 66073 bytes
2017-05-20 20:23:48,349 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.EOFException: while trying to read 66073 bytes
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.readToBuf(DataNode.java:2464)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.readNextPacket(DataNode.java:2508)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receivePacket(DataNode.java:2572)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2698)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:23:50,673 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6026453087732545196_1452 src: /192.168.1.156:46182 dest: /192.168.1.156:50010
2017-05-20 20:23:51,131 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6026453087732545196_1452 src: /192.168.1.156:46182 dest: /192.168.1.156:50010 of size 31964396
2017-05-20 20:23:53,638 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1641756090487420869_1451 src: /192.168.1.157:38410 dest: /192.168.1.157:50010
2017-05-20 20:23:53,639 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3377351795155876102_1452 src: /192.168.1.157:38411 dest: /192.168.1.157:50010
2017-05-20 20:23:53,642 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3377351795155876102_1452 src: /192.168.1.157:38411 dest: /192.168.1.157:50010 of size 41464
2017-05-20 20:23:54,205 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1641756090487420869_1451 src: /192.168.1.157:38410 dest: /192.168.1.157:50010 of size 31980463
2017-05-20 20:23:56,705 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6026453087732545196_1452 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6026453087732545196
2017-05-20 20:23:56,705 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5805936902481151314_1448 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5805936902481151314
2017-05-20 20:23:56,706 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-116490435351374594_1444 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-116490435351374594
2017-05-20 20:23:56,706 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1316151490780922547_1445 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1316151490780922547
2017-05-20 20:23:56,706 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2688061802058582803_1446 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2688061802058582803
2017-05-20 20:24:02,772 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 20:24:15,646 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 20:24:15,836 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 20:24:15,838 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 20:24:15,840 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 20:24:15,893 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 20:24:15,940 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 20:24:15,941 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 20:24:15,941 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 20:24:16,155 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-20 20:24:16,191 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 20:24:16,206 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 20:24:16,206 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 20:24:16,215 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 20:24:16,233 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 20:24:16,237 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 20:24:16,238 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 20:24:16,239 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 20:24:16,240 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 20:24:16,240 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 20:24:16,241 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 20:24:16,243 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 20:24:16,243 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 20:24:16,250 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 20:24:19,248 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 11 blocks got processed in 5 msecs
2017-05-20 20:24:45,048 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_1641756090487420869_1451
2017-05-20 20:24:52,303 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3377351795155876102_1452 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3377351795155876102
2017-05-20 20:24:52,314 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1641756090487420869_1451 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1641756090487420869
2017-05-20 20:24:52,320 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4532651256663458722_1449 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4532651256663458722
2017-05-20 20:25:25,309 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5066690268495200415_1457 src: /192.168.1.158:56299 dest: /192.168.1.158:50010
2017-05-20 20:25:25,311 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3012246532263815991_1453 src: /192.168.1.158:56298 dest: /192.168.1.158:50010
2017-05-20 20:25:25,326 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5066690268495200415_1457 src: /192.168.1.158:56299 dest: /192.168.1.158:50010 of size 13545
2017-05-20 20:25:25,328 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3012246532263815991_1453 src: /192.168.1.158:56298 dest: /192.168.1.158:50010 of size 91176
2017-05-20 20:25:25,675 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3012246532263815991_1453 to /192.168.1.159
2017-05-20 20:25:28,262 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3541189604292461156_1455 src: /192.168.1.157:38427 dest: /192.168.1.157:50010
2017-05-20 20:25:28,263 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3541189604292461156_1455 src: /192.168.1.157:38427 dest: /192.168.1.157:50010 of size 13560
2017-05-20 20:25:28,288 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4561202556359542174_1454 src: /192.168.1.156:46198 dest: /192.168.1.156:50010
2017-05-20 20:25:28,289 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4561202556359542174_1454 src: /192.168.1.156:46199 dest: /192.168.1.156:50010
2017-05-20 20:25:28,289 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4561202556359542174_1454 received exception java.io.IOException: Block blk_4561202556359542174_1454 has already been started (though not completed), and thus cannot be created.
2017-05-20 20:25:28,291 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4561202556359542174_1454 src: /192.168.1.156:46198 dest: /192.168.1.156:50010 of size 4325
2017-05-20 20:25:28,291 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_4561202556359542174_1454 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:25:31,363 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4561202556359542174_1454 to 192.168.1.158:50010
2017-05-20 20:25:31,365 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_4561202556359542174_1454 to /192.168.1.158:50010
2017-05-20 20:26:04,309 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2954955652432845590_1458 src: /192.168.1.156:46234 dest: /192.168.1.156:50010
2017-05-20 20:26:05,206 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2954955652432845590_1458 src: /192.168.1.156:46234 dest: /192.168.1.156:50010 of size 31976695
2017-05-20 20:26:07,284 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8803193431495912594_1461 src: /192.168.1.158:56341 dest: /192.168.1.158:50010
2017-05-20 20:26:07,285 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8803193431495912594_1461 src: /192.168.1.158:56341 dest: /192.168.1.158:50010 of size 41464
2017-05-20 20:26:07,309 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4063557458224009986_1461 src: /192.168.1.158:56342 dest: /192.168.1.158:50010
2017-05-20 20:26:08,157 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4063557458224009986_1461 src: /192.168.1.158:56342 dest: /192.168.1.158:50010 of size 31964396
2017-05-20 20:26:10,277 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8402319783456865184_1460 src: /192.168.1.157:38462 dest: /192.168.1.157:50010
2017-05-20 20:26:10,875 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8402319783456865184_1460 src: /192.168.1.157:38462 dest: /192.168.1.157:50010 of size 31980463
2017-05-20 20:26:13,389 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5066690268495200415_1457 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5066690268495200415
2017-05-20 20:26:13,391 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3541189604292461156_1455 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3541189604292461156
2017-05-20 20:26:13,401 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2954955652432845590_1458 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2954955652432845590
2017-05-20 20:26:13,401 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3012246532263815991_1453 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3012246532263815991
2017-05-20 20:26:13,408 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4063557458224009986_1461 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4063557458224009986
2017-05-20 20:26:13,409 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4561202556359542174_1454 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4561202556359542174
2017-05-20 20:26:13,409 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8803193431495912594_1461 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8803193431495912594
2017-05-20 20:26:20,203 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 20:26:32,958 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 20:26:33,142 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 20:26:33,143 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 20:26:33,145 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 20:26:33,212 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 20:26:33,259 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 20:26:33,260 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 20:26:33,260 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 20:26:33,494 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-20 20:26:33,531 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 20:26:33,533 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 20:26:33,533 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 20:26:33,539 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 20:26:33,556 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 20:26:33,561 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 20:26:33,561 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 20:26:33,563 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 20:26:33,564 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 20:26:33,564 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 20:26:33,564 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 20:26:33,584 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 20:26:33,585 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 20:26:33,596 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 20:26:36,596 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 11 msecs
2017-05-20 20:27:02,351 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_8402319783456865184_1460
2017-05-20 20:27:09,640 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8402319783456865184_1460 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8402319783456865184
2017-05-20 20:27:42,742 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5113956664176967070_1462 src: /192.168.1.157:38466 dest: /192.168.1.157:50010
2017-05-20 20:27:42,759 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5113956664176967070_1462 src: /192.168.1.157:38466 dest: /192.168.1.157:50010 of size 91176
2017-05-20 20:27:42,763 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3253812372041420806_1466 src: /192.168.1.156:46243 dest: /192.168.1.156:50010
2017-05-20 20:27:42,765 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3253812372041420806_1466 src: /192.168.1.156:46243 dest: /192.168.1.156:50010 of size 13545
2017-05-20 20:27:42,962 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5113956664176967070_1462 to /192.168.1.159
2017-05-20 20:27:44,040 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 20:27:45,756 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6886757584366728946_1463 src: /192.168.1.156:46255 dest: /192.168.1.156:50010
2017-05-20 20:27:45,765 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6886757584366728946_1463 src: /192.168.1.156:46255 dest: /192.168.1.156:50010 of size 2165
2017-05-20 20:27:48,723 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3211109813365927940_1464 src: /192.168.1.158:56355 dest: /192.168.1.158:50010
2017-05-20 20:27:48,724 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3211109813365927940_1464 src: /192.168.1.158:56355 dest: /192.168.1.158:50010 of size 13560
2017-05-20 20:27:49,081 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 20:27:49,168 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 20:27:54,379 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 20:28:18,778 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-372549495342931759_1469 src: /192.168.1.158:56373 dest: /192.168.1.158:50010
2017-05-20 20:28:19,514 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-372549495342931759_1469 src: /192.168.1.158:56373 dest: /192.168.1.158:50010 of size 31964396
2017-05-20 20:28:21,742 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4275200237364783891_1470 src: /192.168.1.157:38499 dest: /192.168.1.157:50010
2017-05-20 20:28:21,772 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5406341539050280574_1468 src: /192.168.1.156:46277 dest: /192.168.1.156:50010
2017-05-20 20:28:22,934 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4275200237364783891_1470 src: /192.168.1.157:38499 dest: /192.168.1.157:50010 of size 31980463
2017-05-20 20:28:23,000 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5406341539050280574_1468 src: /192.168.1.156:46277 dest: /192.168.1.156:50010 of size 31976695
2017-05-20 20:28:24,748 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1039229860929880639_1470 src: /192.168.1.158:56374 dest: /192.168.1.158:50010
2017-05-20 20:28:24,749 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1039229860929880639_1470 src: /192.168.1.158:56374 dest: /192.168.1.158:50010 of size 23481
2017-05-20 20:28:27,688 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6886757584366728946_1463 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6886757584366728946
2017-05-20 20:28:27,700 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5406341539050280574_1468 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5406341539050280574
2017-05-20 20:28:27,701 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5113956664176967070_1462 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5113956664176967070
2017-05-20 20:28:27,708 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4275200237364783891_1470 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4275200237364783891
2017-05-20 20:28:27,709 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3253812372041420806_1466 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3253812372041420806
2017-05-20 20:28:27,715 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-372549495342931759_1469 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-372549495342931759
2017-05-20 20:28:27,715 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3211109813365927940_1464 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3211109813365927940
2017-05-20 20:28:33,752 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 20:28:46,582 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 20:28:46,765 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 20:28:46,767 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 20:28:46,769 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 20:28:46,837 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 20:28:46,893 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 20:28:46,894 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 20:28:46,894 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 20:28:47,125 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-20 20:28:47,163 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 20:28:47,167 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 20:28:47,167 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-20 20:28:47,172 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 20:28:47,190 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 20:28:47,195 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 20:28:47,196 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 20:28:47,197 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 20:28:47,198 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 20:28:47,198 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 20:28:47,198 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 20:28:47,208 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 20:28:47,209 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 20:28:47,220 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 20:28:47,256 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-1039229860929880639_1470
2017-05-20 20:28:50,225 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 12 msecs
2017-05-20 20:29:23,280 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1039229860929880639_1470 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1039229860929880639
2017-05-20 20:29:26,280 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 20:29:56,272 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-516189048380153183_1472 src: /192.168.1.157:38505 dest: /192.168.1.157:50010
2017-05-20 20:29:56,292 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-516189048380153183_1472 src: /192.168.1.157:38505 dest: /192.168.1.157:50010 of size 2165
2017-05-20 20:29:56,390 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7721851855015491655_1471 src: /192.168.1.156:46283 dest: /192.168.1.156:50010
2017-05-20 20:29:56,398 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7721851855015491655_1471 src: /192.168.1.156:46283 dest: /192.168.1.156:50010 of size 91176
2017-05-20 20:29:56,553 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-7721851855015491655_1471 to /192.168.1.159
2017-05-20 20:29:57,596 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 20:29:59,385 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-12490829322730309_1473 src: /192.168.1.156:46293 dest: /192.168.1.156:50010
2017-05-20 20:29:59,391 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-12490829322730309_1473 src: /192.168.1.156:46293 dest: /192.168.1.156:50010 of size 13560
2017-05-20 20:30:02,385 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-134563090281383369_1475 src: /192.168.1.156:46296 dest: /192.168.1.156:50010
2017-05-20 20:30:02,387 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-134563090281383369_1475 src: /192.168.1.156:46296 dest: /192.168.1.156:50010 of size 13545
2017-05-20 20:30:02,694 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-20 20:30:12,981 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 20:30:35,286 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3255895951577441180_1476 src: /192.168.1.157:38536 dest: /192.168.1.157:50010
2017-05-20 20:30:35,291 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8551394157999161155_1479 src: /192.168.1.157:38537 dest: /192.168.1.157:50010
2017-05-20 20:30:35,292 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8551394157999161155_1479 src: /192.168.1.157:38537 dest: /192.168.1.157:50010 of size 23481
2017-05-20 20:30:35,404 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5808705391370106812_1479 src: /192.168.1.156:46316 dest: /192.168.1.156:50010
2017-05-20 20:30:36,097 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3255895951577441180_1476 src: /192.168.1.157:38536 dest: /192.168.1.157:50010 of size 31976695
2017-05-20 20:30:36,397 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5808705391370106812_1479 src: /192.168.1.156:46316 dest: /192.168.1.156:50010 of size 31964396
2017-05-20 20:30:38,280 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8240781229683166153_1479 src: /192.168.1.157:38538 dest: /192.168.1.157:50010
2017-05-20 20:30:38,814 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8240781229683166153_1479 src: /192.168.1.157:38538 dest: /192.168.1.157:50010 of size 31980463
2017-05-20 20:30:41,356 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7721851855015491655_1471 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7721851855015491655
2017-05-20 20:30:41,368 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5808705391370106812_1479 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5808705391370106812
2017-05-20 20:30:41,375 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3255895951577441180_1476 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3255895951577441180
2017-05-20 20:30:41,376 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-516189048380153183_1472 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-516189048380153183
2017-05-20 20:30:41,376 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-134563090281383369_1475 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-134563090281383369
2017-05-20 20:30:41,376 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-12490829322730309_1473 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-12490829322730309
2017-05-20 20:30:41,376 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8551394157999161155_1479 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8551394157999161155
2017-05-20 20:30:46,424 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-20 20:30:59,163 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-20 20:30:59,355 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-20 20:30:59,357 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-20 20:30:59,358 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-20 20:30:59,433 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-20 20:30:59,496 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-20 20:30:59,496 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-20 20:30:59,497 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-20 20:30:59,720 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-20 20:30:59,753 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-20 20:30:59,756 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-20 20:30:59,756 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-20 20:30:59,761 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-20 20:30:59,782 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-20 20:30:59,787 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-20 20:30:59,787 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-20 20:30:59,789 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-20 20:30:59,790 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-20 20:30:59,790 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-20 20:30:59,790 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-20 20:30:59,801 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-20 20:30:59,802 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-20 20:30:59,815 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-20 20:31:02,815 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 9 blocks got processed in 12 msecs
2017-05-20 20:31:28,567 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-8240781229683166153_1479
2017-05-20 20:31:35,870 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8240781229683166153_1479 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8240781229683166153
2017-05-20 20:32:08,848 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8318400644660085058_1484 src: /192.168.1.156:46322 dest: /192.168.1.156:50010
2017-05-20 20:32:08,867 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8318400644660085058_1484 src: /192.168.1.156:46322 dest: /192.168.1.156:50010 of size 13545
2017-05-20 20:32:08,943 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4931564700330817557_1480 src: /192.168.1.157:38543 dest: /192.168.1.157:50010
2017-05-20 20:32:08,950 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4931564700330817557_1480 src: /192.168.1.157:38543 dest: /192.168.1.157:50010 of size 91176
2017-05-20 20:32:09,180 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4931564700330817557_1480 to /192.168.1.159
2017-05-20 20:32:11,842 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5461935180584638260_1481 src: /192.168.1.156:46334 dest: /192.168.1.156:50010
2017-05-20 20:32:11,843 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5461935180584638260_1481 src: /192.168.1.156:46334 dest: /192.168.1.156:50010 of size 2165
2017-05-20 20:32:11,845 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5461935180584638260_1481 src: /192.168.1.156:46335 dest: /192.168.1.156:50010
2017-05-20 20:32:11,845 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-5461935180584638260_1481 received exception java.io.IOException: Block blk_-5461935180584638260_1481 is valid, and cannot be written to.
2017-05-20 20:32:11,847 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-5461935180584638260_1481 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:32:14,918 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2461501965220419865_1482 src: /192.168.1.158:56417 dest: /192.168.1.158:50010
2017-05-20 20:32:14,919 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2461501965220419865_1482 src: /192.168.1.158:56417 dest: /192.168.1.158:50010 of size 13560
2017-05-20 20:32:15,526 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-20 20:32:19,527 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-20 20:32:20,061 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-20 20:32:25,475 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-20 20:32:44,960 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1463839635941711106_1485 src: /192.168.1.157:38579 dest: /192.168.1.157:50010
2017-05-20 20:32:45,756 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1463839635941711106_1485 src: /192.168.1.157:38579 dest: /192.168.1.157:50010 of size 31981189
2017-05-20 20:32:47,858 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2607644094451505066_1486 src: /192.168.1.158:56434 dest: /192.168.1.158:50010
2017-05-20 20:32:47,945 INFO org.apache.hadoop.dfs.DataNode: Exception in receiveBlock for block blk_2607644094451505066_1486 org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
2017-05-20 20:32:47,946 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_2607644094451505066_1486 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
2017-05-20 20:32:47,946 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: No space left on device
	at org.apache.hadoop.dfs.DataNode.checkDiskError(DataNode.java:595)
	at org.apache.hadoop.dfs.DataNode.access$1500(DataNode.java:83)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receivePacket(DataNode.java:2645)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.receiveBlock(DataNode.java:2698)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1283)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-20 20:32:53,966 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6220887464534182002_1488 src: /192.168.1.158:56435 dest: /192.168.1.158:50010
2017-05-20 20:32:53,967 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6220887464534182002_1488 src: /192.168.1.158:56435 dest: /192.168.1.158:50010 of size 23481
2017-05-20 20:32:56,898 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8318400644660085058_1484 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8318400644660085058
2017-05-20 20:32:56,900 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5461935180584638260_1481 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5461935180584638260
2017-05-20 20:32:56,900 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4931564700330817557_1480 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4931564700330817557
2017-05-20 20:32:56,900 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2461501965220419865_1482 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2461501965220419865
2017-05-20 20:32:56,911 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1463839635941711106_1485 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1463839635941711106
2017-05-20 20:32:56,911 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6220887464534182002_1488 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6220887464534182002
2017-05-20 20:42:39,304 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 21:42:41,941 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 22:42:44,736 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
2017-05-20 23:42:44,974 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 8 blocks got processed in 3 msecs
