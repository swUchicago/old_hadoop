2017-05-23 00:21:42,555 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-23 01:21:45,418 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-23 02:21:48,299 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 5 msecs
2017-05-23 03:21:48,486 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-23 04:21:51,109 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-23 05:21:53,588 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-23 06:21:56,238 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 5 msecs
2017-05-23 06:48:39,027 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 06:48:49,874 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 06:48:50,096 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 06:48:50,098 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 06:48:50,099 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 06:48:50,169 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 06:48:50,228 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 06:48:50,229 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 06:48:50,229 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 06:48:50,470 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-23 06:48:50,507 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 06:48:50,510 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 06:48:50,511 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 06:48:50,516 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 06:48:50,535 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 06:48:50,541 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 06:48:50,543 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 06:48:50,543 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 06:48:50,544 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 06:48:50,544 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 06:48:50,545 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 06:48:50,548 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 06:48:50,548 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 06:48:50,558 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 06:48:53,557 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 6 msecs
2017-05-23 06:49:50,526 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5439110319587115548_2871 src: /192.168.1.156:37048 dest: /192.168.1.156:50010
2017-05-23 06:49:50,526 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1452946865251104850_2869 src: /192.168.1.157:52543 dest: /192.168.1.157:50010
2017-05-23 06:49:50,548 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5439110319587115548_2871 src: /192.168.1.156:37048 dest: /192.168.1.156:50010 of size 13560
2017-05-23 06:49:50,553 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1452946865251104850_2869 src: /192.168.1.157:52543 dest: /192.168.1.157:50010 of size 91176
2017-05-23 06:49:53,490 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1270093427060408432_2870 src: /192.168.1.156:37052 dest: /192.168.1.156:50010
2017-05-23 06:49:53,491 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1270093427060408432_2870 src: /192.168.1.156:37052 dest: /192.168.1.156:50010 of size 8645
2017-05-23 06:49:53,497 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3267844831052861415_2873 src: /192.168.1.157:52547 dest: /192.168.1.157:50010
2017-05-23 06:49:53,499 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3267844831052861415_2873 src: /192.168.1.157:52547 dest: /192.168.1.157:50010 of size 13545
2017-05-23 06:49:58,431 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 06:50:10,099 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 06:51:20,306 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 06:51:27,070 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 06:51:55,936 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-23 06:52:56,581 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5024273430132712258_2873 src: /192.168.1.156:37166 dest: /192.168.1.156:50010
2017-05-23 06:52:56,582 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_5024273430132712258_2873 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 06:52:56,584 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 06:52:59,787 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5439110319587115548_2871 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5439110319587115548
2017-05-23 06:52:59,788 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1452946865251104850_2869 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1452946865251104850
2017-05-23 06:52:59,788 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1270093427060408432_2870 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1270093427060408432
2017-05-23 06:52:59,789 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3267844831052861415_2873 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3267844831052861415
2017-05-23 06:53:05,551 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 06:53:16,304 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 06:53:16,492 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 06:53:16,494 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 06:53:16,496 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 06:53:16,552 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 06:53:16,600 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 06:53:16,601 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 06:53:16,601 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 06:53:16,827 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 06:53:16,869 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 06:53:16,872 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 06:53:16,872 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-23 06:53:16,877 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 06:53:16,895 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 06:53:16,899 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 06:53:16,900 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 06:53:16,901 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 06:53:16,901 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 06:53:16,902 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 06:53:16,902 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 06:53:16,913 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 06:53:16,914 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 06:53:16,925 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 06:53:19,926 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 12 msecs
2017-05-23 06:54:22,993 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5349233590546343962_2882 src: /192.168.1.158:37146 dest: /192.168.1.158:50010
2017-05-23 06:54:23,008 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5016882560608627141_2878 src: /192.168.1.156:37180 dest: /192.168.1.156:50010
2017-05-23 06:54:23,010 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5349233590546343962_2882 src: /192.168.1.158:37146 dest: /192.168.1.158:50010 of size 13545
2017-05-23 06:54:23,013 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5016882560608627141_2878 src: /192.168.1.156:37180 dest: /192.168.1.156:50010 of size 91176
2017-05-23 06:54:25,979 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1119624077665578340_2880 src: /192.168.1.157:52659 dest: /192.168.1.157:50010
2017-05-23 06:54:25,981 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1119624077665578340_2880 src: /192.168.1.157:52659 dest: /192.168.1.157:50010 of size 13560
2017-05-23 06:54:25,982 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_520215093117850087_2879 src: /192.168.1.157:52660 dest: /192.168.1.157:50010
2017-05-23 06:54:25,982 INFO org.apache.hadoop.dfs.DataNode: Received block blk_520215093117850087_2879 src: /192.168.1.157:52660 dest: /192.168.1.157:50010 of size 8645
2017-05-23 06:54:26,010 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_520215093117850087_2879 src: /192.168.1.156:37181 dest: /192.168.1.156:50010
2017-05-23 06:54:26,010 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_520215093117850087_2879 received exception java.io.IOException: Block blk_520215093117850087_2879 is valid, and cannot be written to.
2017-05-23 06:54:26,012 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1119624077665578340_2880 src: /192.168.1.156:37182 dest: /192.168.1.156:50010
2017-05-23 06:54:26,013 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-1119624077665578340_2880 received exception java.io.IOException: Block blk_-1119624077665578340_2880 is valid, and cannot be written to.
2017-05-23 06:54:26,013 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-1119624077665578340_2880 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 06:54:26,013 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_520215093117850087_2879 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 06:54:28,968 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-1119624077665578340_2880 to 192.168.1.158:50010
2017-05-23 06:54:28,974 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-1119624077665578340_2880 to /192.168.1.158:50010
2017-05-23 06:54:30,002 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 06:54:41,958 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 06:54:48,519 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 06:54:55,322 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 06:55:01,600 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 06:55:08,651 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 06:55:15,315 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 06:55:22,525 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 06:55:28,887 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 06:55:35,758 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 06:55:43,790 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 06:56:12,263 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 06:56:27,430 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-23 06:57:41,043 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_654329668496050693_2882 src: /192.168.1.157:52772 dest: /192.168.1.157:50010
2017-05-23 06:57:41,044 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_654329668496050693_2882 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 06:57:41,044 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 06:57:44,077 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5349233590546343962_2882 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5349233590546343962
2017-05-23 06:57:44,078 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5016882560608627141_2878 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5016882560608627141
2017-05-23 06:57:44,078 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1119624077665578340_2880 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1119624077665578340
2017-05-23 06:57:44,078 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_520215093117850087_2879 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_520215093117850087
2017-05-23 06:57:51,172 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 06:58:01,984 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 06:58:02,172 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 06:58:02,174 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 06:58:02,176 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 06:58:02,245 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 06:58:02,303 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 06:58:02,304 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 06:58:02,304 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 06:58:02,521 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 06:58:02,551 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 06:58:02,553 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 06:58:02,553 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 06:58:02,558 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 06:58:02,574 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 06:58:02,579 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 06:58:02,579 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 06:58:02,581 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 06:58:02,581 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 06:58:02,582 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 06:58:02,582 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 06:58:02,587 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 06:58:02,588 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 06:58:02,596 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 06:58:05,598 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-23 06:59:08,665 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8649324594514892487_2889 src: /192.168.1.156:37301 dest: /192.168.1.156:50010
2017-05-23 06:59:08,671 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9096602717739722798_2887 src: /192.168.1.158:37244 dest: /192.168.1.158:50010
2017-05-23 06:59:08,679 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8649324594514892487_2889 src: /192.168.1.156:37301 dest: /192.168.1.156:50010 of size 13560
2017-05-23 06:59:08,680 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9096602717739722798_2887 src: /192.168.1.158:37244 dest: /192.168.1.158:50010 of size 91176
2017-05-23 06:59:11,651 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_531491655356726158_2888 src: /192.168.1.157:52784 dest: /192.168.1.157:50010
2017-05-23 06:59:11,652 INFO org.apache.hadoop.dfs.DataNode: Received block blk_531491655356726158_2888 src: /192.168.1.157:52784 dest: /192.168.1.157:50010 of size 8645
2017-05-23 06:59:11,656 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4522489192680345831_2891 src: /192.168.1.157:52785 dest: /192.168.1.157:50010
2017-05-23 06:59:11,657 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4522489192680345831_2891 src: /192.168.1.157:52785 dest: /192.168.1.157:50010 of size 13545
2017-05-23 06:59:11,670 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_531491655356726158_2888 src: /192.168.1.156:37303 dest: /192.168.1.156:50010
2017-05-23 06:59:11,671 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_531491655356726158_2888 received exception java.io.IOException: Block blk_531491655356726158_2888 is valid, and cannot be written to.
2017-05-23 06:59:11,673 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_531491655356726158_2888 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 06:59:11,673 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4522489192680345831_2891 src: /192.168.1.156:37302 dest: /192.168.1.156:50010
2017-05-23 06:59:11,673 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4522489192680345831_2891 received exception java.io.IOException: Block blk_4522489192680345831_2891 is valid, and cannot be written to.
2017-05-23 06:59:11,674 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_4522489192680345831_2891 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 06:59:14,668 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4522489192680345831_2891 to 192.168.1.158:50010
2017-05-23 06:59:14,673 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_4522489192680345831_2891 to /192.168.1.158:50010
2017-05-23 06:59:15,636 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 06:59:27,437 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 07:00:01,130 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 07:01:02,044 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 07:02:20,794 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9096602717739722798_2887 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9096602717739722798
2017-05-23 07:02:20,795 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8649324594514892487_2889 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8649324594514892487
2017-05-23 07:02:20,795 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_531491655356726158_2888 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_531491655356726158
2017-05-23 07:02:23,794 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4522489192680345831_2891 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4522489192680345831
2017-05-23 07:02:30,481 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 07:02:41,213 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 07:02:41,412 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 07:02:41,414 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 07:02:41,415 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 07:02:41,481 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 07:02:41,529 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 07:02:41,530 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 07:02:41,530 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 07:02:41,781 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-23 07:02:41,822 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 07:02:41,825 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 07:02:41,825 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-23 07:02:41,830 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 07:02:41,857 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 07:02:41,864 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 07:02:41,864 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 07:02:41,865 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 07:02:41,865 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 07:02:41,865 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 07:02:41,865 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 07:02:41,890 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 07:02:41,890 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 07:02:41,903 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 07:02:44,906 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-23 07:03:41,962 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1945445325374138779_2897 src: /192.168.1.157:52910 dest: /192.168.1.157:50010
2017-05-23 07:03:41,971 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3414579345102274772_2896 src: /192.168.1.156:37424 dest: /192.168.1.156:50010
2017-05-23 07:03:41,987 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1945445325374138779_2897 src: /192.168.1.157:52910 dest: /192.168.1.157:50010 of size 8645
2017-05-23 07:03:41,988 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3414579345102274772_2896 src: /192.168.1.156:37424 dest: /192.168.1.156:50010 of size 91176
2017-05-23 07:03:44,937 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5807834975830019174_2900 src: /192.168.1.157:52914 dest: /192.168.1.157:50010
2017-05-23 07:03:44,938 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5807834975830019174_2900 src: /192.168.1.157:52914 dest: /192.168.1.157:50010 of size 13552
2017-05-23 07:03:47,973 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-535561581788988103_2898 src: /192.168.1.158:37339 dest: /192.168.1.158:50010
2017-05-23 07:03:47,977 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-535561581788988103_2898 src: /192.168.1.158:37339 dest: /192.168.1.158:50010 of size 13567
2017-05-23 07:03:55,320 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 07:04:02,064 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 07:04:09,039 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 07:04:15,608 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 07:04:22,726 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 07:04:29,276 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 07:04:36,113 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 07:04:42,880 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 07:04:49,948 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 07:06:06,752 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-23 07:07:18,019 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4178164140863760284_2900 src: /192.168.1.157:53052 dest: /192.168.1.157:50010
2017-05-23 07:07:18,020 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4178164140863760284_2900 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 07:07:18,022 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 07:07:21,066 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-535561581788988103_2898 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-535561581788988103
2017-05-23 07:07:21,067 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1945445325374138779_2897 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1945445325374138779
2017-05-23 07:07:21,068 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3414579345102274772_2896 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3414579345102274772
2017-05-23 07:07:21,068 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5807834975830019174_2900 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5807834975830019174
2017-05-23 07:07:27,074 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-23 07:07:27,085 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 07:07:37,843 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 07:07:38,034 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 07:07:38,036 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 07:07:38,038 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 07:07:38,107 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 07:07:38,165 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 07:07:38,166 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 07:07:38,166 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 07:07:38,421 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 07:07:38,461 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 07:07:38,468 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 07:07:38,468 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-23 07:07:38,473 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 07:07:38,495 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 07:07:38,499 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 07:07:38,500 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 07:07:38,501 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 07:07:38,501 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 07:07:38,501 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 07:07:38,502 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 07:07:38,535 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 07:07:38,536 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 07:07:38,550 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 07:07:41,547 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 11 msecs
2017-05-23 07:08:44,593 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_9153103050655201805_2905 src: /192.168.1.158:37421 dest: /192.168.1.158:50010
2017-05-23 07:08:44,608 INFO org.apache.hadoop.dfs.DataNode: Received block blk_9153103050655201805_2905 src: /192.168.1.158:37421 dest: /192.168.1.158:50010 of size 91176
2017-05-23 07:08:44,638 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_274388399447489893_2906 src: /192.168.1.158:37422 dest: /192.168.1.158:50010
2017-05-23 07:08:44,639 INFO org.apache.hadoop.dfs.DataNode: Received block blk_274388399447489893_2906 src: /192.168.1.158:37422 dest: /192.168.1.158:50010 of size 8645
2017-05-23 07:08:47,570 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7733363768068126227_2909 src: /192.168.1.157:53067 dest: /192.168.1.157:50010
2017-05-23 07:08:47,571 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7733363768068126227_2909 src: /192.168.1.157:53067 dest: /192.168.1.157:50010 of size 13552
2017-05-23 07:08:47,634 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7733363768068126227_2909 src: /192.168.1.156:37561 dest: /192.168.1.156:50010
2017-05-23 07:08:47,634 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7733363768068126227_2909 received exception java.io.IOException: Block blk_7733363768068126227_2909 is valid, and cannot be written to.
2017-05-23 07:08:47,636 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7024251467325121758_2907 src: /192.168.1.156:37562 dest: /192.168.1.156:50010
2017-05-23 07:08:47,639 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7733363768068126227_2909 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 07:08:47,640 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7024251467325121758_2907 src: /192.168.1.156:37562 dest: /192.168.1.156:50010 of size 13567
2017-05-23 07:08:57,194 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 07:09:04,404 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 07:09:11,634 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 07:09:18,418 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 07:09:25,130 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 07:09:31,795 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 07:09:38,913 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 07:09:45,235 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 07:10:49,045 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 07:10:55,917 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 07:12:29,875 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7024251467325121758_2907 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7024251467325121758
2017-05-23 07:12:29,876 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_274388399447489893_2906 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_274388399447489893
2017-05-23 07:12:29,877 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7733363768068126227_2909 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7733363768068126227
2017-05-23 07:12:29,877 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_9153103050655201805_2905 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_9153103050655201805
2017-05-23 07:12:35,766 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 07:12:46,623 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 07:12:46,822 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 07:12:46,824 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 07:12:46,825 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 07:12:46,888 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 07:12:46,937 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 07:12:46,937 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 07:12:46,938 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 07:12:47,153 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-23 07:12:47,187 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 07:12:47,189 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 07:12:47,189 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 07:12:47,194 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 07:12:47,211 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 07:12:47,216 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 07:12:47,216 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 07:12:47,217 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 07:12:47,218 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 07:12:47,218 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 07:12:47,218 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 07:12:47,242 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 07:12:47,243 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 07:12:47,256 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 07:12:50,258 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-23 07:13:53,311 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_815910623900809391_2914 src: /192.168.1.158:37505 dest: /192.168.1.158:50010
2017-05-23 07:13:53,322 INFO org.apache.hadoop.dfs.DataNode: Received block blk_815910623900809391_2914 src: /192.168.1.158:37505 dest: /192.168.1.158:50010 of size 91176
2017-05-23 07:13:53,352 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5523644391618344345_2915 src: /192.168.1.158:37506 dest: /192.168.1.158:50010
2017-05-23 07:13:53,352 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5523644391618344345_2915 src: /192.168.1.158:37506 dest: /192.168.1.158:50010 of size 8645
2017-05-23 07:13:56,298 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7943408828690257423_2916 src: /192.168.1.157:53210 dest: /192.168.1.157:50010
2017-05-23 07:13:56,299 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7943408828690257423_2916 src: /192.168.1.157:53210 dest: /192.168.1.157:50010 of size 13567
2017-05-23 07:13:56,301 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8944922534933585864_2918 src: /192.168.1.157:53211 dest: /192.168.1.157:50010
2017-05-23 07:13:56,303 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8944922534933585864_2918 src: /192.168.1.157:53211 dest: /192.168.1.157:50010 of size 13552
2017-05-23 07:13:56,349 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8944922534933585864_2918 src: /192.168.1.156:37692 dest: /192.168.1.156:50010
2017-05-23 07:13:56,349 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8944922534933585864_2918 received exception java.io.IOException: Block blk_8944922534933585864_2918 is valid, and cannot be written to.
2017-05-23 07:13:56,351 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8944922534933585864_2918 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 07:13:56,352 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7943408828690257423_2916 src: /192.168.1.156:37693 dest: /192.168.1.156:50010
2017-05-23 07:13:56,353 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7943408828690257423_2916 received exception java.io.IOException: Block blk_-7943408828690257423_2916 is valid, and cannot be written to.
2017-05-23 07:13:56,353 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-7943408828690257423_2916 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 07:14:00,352 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 07:14:12,231 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 07:14:18,775 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 07:14:25,502 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 07:16:06,310 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 07:16:16,911 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-23 07:17:29,441 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7943408828690257423_2916 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7943408828690257423
2017-05-23 07:17:29,441 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_815910623900809391_2914 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_815910623900809391
2017-05-23 07:17:29,442 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5523644391618344345_2915 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5523644391618344345
2017-05-23 07:17:32,379 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5868712083336428138_2918 src: /192.168.1.158:37578 dest: /192.168.1.158:50010
2017-05-23 07:17:32,379 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-5868712083336428138_2918 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 07:17:32,380 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 07:17:35,440 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8944922534933585864_2918 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8944922534933585864
2017-05-23 07:17:42,318 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 07:17:53,143 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 07:17:53,323 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 07:17:53,325 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 07:17:53,326 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 07:17:53,397 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 07:17:53,452 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 07:17:53,453 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 07:17:53,453 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 07:17:53,683 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 07:17:53,719 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 07:17:53,732 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 07:17:53,732 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 07:17:53,738 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 07:17:53,758 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 07:17:53,761 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 07:17:53,762 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 07:17:53,763 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 07:17:53,763 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 07:17:53,763 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 07:17:53,763 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 07:17:53,773 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 07:17:53,773 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 07:17:53,804 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 07:17:56,788 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-23 07:18:53,869 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3065007205374888584_2923 src: /192.168.1.158:37585 dest: /192.168.1.158:50010
2017-05-23 07:18:53,892 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3065007205374888584_2923 src: /192.168.1.158:37585 dest: /192.168.1.158:50010 of size 91176
2017-05-23 07:18:53,907 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7540521870753555000_2925 src: /192.168.1.156:37824 dest: /192.168.1.156:50010
2017-05-23 07:18:53,909 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7540521870753555000_2925 src: /192.168.1.156:37824 dest: /192.168.1.156:50010 of size 13560
2017-05-23 07:18:56,896 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4258204105140300837_2924 src: /192.168.1.156:37829 dest: /192.168.1.156:50010
2017-05-23 07:18:56,896 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4258204105140300837_2924 src: /192.168.1.156:37829 dest: /192.168.1.156:50010 of size 4325
2017-05-23 07:18:59,828 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1679528972220997200_2927 src: /192.168.1.157:53351 dest: /192.168.1.157:50010
2017-05-23 07:18:59,830 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1679528972220997200_2927 src: /192.168.1.157:53351 dest: /192.168.1.157:50010 of size 13545
2017-05-23 07:19:02,594 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 07:19:06,996 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 07:19:18,883 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 07:19:30,724 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 07:19:42,529 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 07:20:02,060 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 07:20:15,249 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 07:20:18,203 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 07:20:33,228 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 07:20:43,955 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 07:21:47,895 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_783736962890350407_2931 src: /192.168.1.157:53450 dest: /192.168.1.157:50010
2017-05-23 07:21:47,896 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_783736962890350407_2931 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 07:21:47,898 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 07:21:50,946 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7540521870753555000_2925 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7540521870753555000
2017-05-23 07:21:50,947 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1679528972220997200_2927 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1679528972220997200
2017-05-23 07:21:50,947 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3065007205374888584_2923 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3065007205374888584
2017-05-23 07:21:50,947 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4258204105140300837_2924 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4258204105140300837
2017-05-23 07:21:57,002 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-23 07:21:57,173 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 07:22:07,940 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 07:22:08,120 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 07:22:08,121 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 07:22:08,123 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 07:22:08,192 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 07:22:08,249 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 07:22:08,250 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 07:22:08,250 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 07:22:08,483 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-23 07:22:08,520 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 07:22:08,522 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 07:22:08,523 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-23 07:22:08,527 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 07:22:08,544 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 07:22:08,550 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 07:22:08,550 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 07:22:08,551 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 07:22:08,552 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 07:22:08,552 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 07:22:08,553 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 07:22:08,569 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 07:22:08,570 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 07:22:08,580 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 07:22:11,585 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-23 07:23:13,998 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 07:23:14,618 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3543433363698490223_2934 src: /192.168.1.157:53463 dest: /192.168.1.157:50010
2017-05-23 07:23:14,630 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3543433363698490223_2934 src: /192.168.1.157:53463 dest: /192.168.1.157:50010 of size 13560
2017-05-23 07:23:14,683 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7697421620853687968_2932 src: /192.168.1.156:37947 dest: /192.168.1.156:50010
2017-05-23 07:23:14,687 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7697421620853687968_2932 src: /192.168.1.156:37947 dest: /192.168.1.156:50010 of size 91176
2017-05-23 07:23:17,622 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7447293840735325134_2936 src: /192.168.1.157:53464 dest: /192.168.1.157:50010
2017-05-23 07:23:17,624 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7447293840735325134_2936 src: /192.168.1.157:53464 dest: /192.168.1.157:50010 of size 13545
2017-05-23 07:23:17,626 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3124839420641621948_2933 src: /192.168.1.157:53465 dest: /192.168.1.157:50010
2017-05-23 07:23:17,627 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3124839420641621948_2933 src: /192.168.1.157:53465 dest: /192.168.1.157:50010 of size 4325
2017-05-23 07:23:17,683 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7447293840735325134_2936 src: /192.168.1.156:37949 dest: /192.168.1.156:50010
2017-05-23 07:23:17,683 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7447293840735325134_2936 received exception java.io.IOException: Block blk_7447293840735325134_2936 is valid, and cannot be written to.
2017-05-23 07:23:17,685 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_7447293840735325134_2936 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 07:23:35,456 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 07:23:47,554 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 07:23:59,030 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 07:24:10,769 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 07:24:22,136 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 07:24:32,790 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 07:24:42,459 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 07:25:59,795 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3124839420641621948_2933 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3124839420641621948
2017-05-23 07:25:59,796 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3543433363698490223_2934 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3543433363698490223
2017-05-23 07:25:59,796 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7697421620853687968_2932 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7697421620853687968
2017-05-23 07:26:02,793 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7447293840735325134_2936 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7447293840735325134
2017-05-23 07:26:07,859 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 07:26:18,690 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 07:26:18,885 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 07:26:18,887 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 07:26:18,889 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 07:26:18,951 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 07:26:18,999 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 07:26:19,000 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 07:26:19,000 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 07:26:19,229 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-23 07:26:19,265 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 07:26:19,270 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 07:26:19,270 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@5876a5
2017-05-23 07:26:19,275 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 07:26:19,294 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 07:26:19,298 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 07:26:19,299 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 07:26:19,299 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 07:26:19,300 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 07:26:19,300 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 07:26:19,300 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 07:26:19,334 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 07:26:19,335 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 07:26:19,350 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 07:26:22,350 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-23 07:27:25,418 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5704748466371054167_2941 src: /192.168.1.158:37759 dest: /192.168.1.158:50010
2017-05-23 07:27:25,434 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6424985975405907703_2945 src: /192.168.1.158:37760 dest: /192.168.1.158:50010
2017-05-23 07:27:25,434 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5704748466371054167_2941 src: /192.168.1.158:37759 dest: /192.168.1.158:50010 of size 91176
2017-05-23 07:27:25,438 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6424985975405907703_2945 src: /192.168.1.158:37760 dest: /192.168.1.158:50010 of size 13545
2017-05-23 07:27:28,405 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4107511556385459680_2942 src: /192.168.1.156:38061 dest: /192.168.1.156:50010
2017-05-23 07:27:28,407 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4107511556385459680_2942 src: /192.168.1.156:38061 dest: /192.168.1.156:50010 of size 4325
2017-05-23 07:27:28,408 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8788488160216982576_2943 src: /192.168.1.157:53571 dest: /192.168.1.157:50010
2017-05-23 07:27:28,408 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4107511556385459680_2942 src: /192.168.1.156:38062 dest: /192.168.1.156:50010
2017-05-23 07:27:28,409 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8788488160216982576_2943 src: /192.168.1.157:53572 dest: /192.168.1.157:50010
2017-05-23 07:27:28,409 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8788488160216982576_2943 received exception java.io.IOException: Block blk_8788488160216982576_2943 is valid, and cannot be written to.
2017-05-23 07:27:28,408 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8788488160216982576_2943 src: /192.168.1.157:53571 dest: /192.168.1.157:50010 of size 13560
2017-05-23 07:27:28,411 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8788488160216982576_2943 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 07:27:28,412 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4107511556385459680_2942 received exception java.io.IOException: Block blk_4107511556385459680_2942 is valid, and cannot be written to.
2017-05-23 07:27:28,412 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_4107511556385459680_2942 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 07:27:31,377 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4107511556385459680_2942 to 192.168.1.158:50010
2017-05-23 07:27:31,380 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_8788488160216982576_2943 to 192.168.1.158:50010
2017-05-23 07:27:31,388 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_8788488160216982576_2943 to /192.168.1.158:50010
2017-05-23 07:27:31,391 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_4107511556385459680_2942 to /192.168.1.158:50010
2017-05-23 07:27:38,471 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 07:27:49,791 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 07:28:01,632 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 07:28:13,375 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 07:28:34,770 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 07:28:38,514 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 07:28:50,322 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 07:29:04,767 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 07:29:07,970 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 07:30:01,473 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4107511556385459680_2942 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4107511556385459680
2017-05-23 07:30:01,473 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5704748466371054167_2941 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5704748466371054167
2017-05-23 07:30:01,474 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8788488160216982576_2943 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8788488160216982576
2017-05-23 07:30:07,474 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6424985975405907703_2945 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6424985975405907703
2017-05-23 07:30:14,458 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 07:30:25,276 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 07:30:25,470 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 07:30:25,472 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 07:30:25,474 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 07:30:25,545 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 07:30:25,610 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 07:30:25,611 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 07:30:25,611 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 07:30:25,854 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 07:30:25,891 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 07:30:25,895 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 07:30:25,895 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-23 07:30:25,900 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 07:30:25,920 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 07:30:25,925 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 07:30:25,926 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 07:30:25,926 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 07:30:25,926 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 07:30:25,927 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 07:30:25,927 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 07:30:25,929 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 07:30:25,930 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 07:30:25,938 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 07:30:28,937 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-23 07:31:25,916 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8272919807438609092_2951 src: /192.168.1.158:37838 dest: /192.168.1.158:50010
2017-05-23 07:31:25,929 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8272919807438609092_2951 src: /192.168.1.158:37838 dest: /192.168.1.158:50010 of size 4325
2017-05-23 07:31:25,983 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4276472943038851754_2950 src: /192.168.1.158:37840 dest: /192.168.1.158:50010
2017-05-23 07:31:25,988 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4276472943038851754_2950 src: /192.168.1.158:37840 dest: /192.168.1.158:50010 of size 91176
2017-05-23 07:31:28,858 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5156023215582086230_2952 src: /192.168.1.157:53679 dest: /192.168.1.157:50010
2017-05-23 07:31:28,860 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5156023215582086230_2952 src: /192.168.1.157:53679 dest: /192.168.1.157:50010 of size 13567
2017-05-23 07:31:28,960 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7384987428884115701_2954 src: /192.168.1.156:38171 dest: /192.168.1.156:50010
2017-05-23 07:31:28,961 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7384987428884115701_2954 src: /192.168.1.156:38171 dest: /192.168.1.156:50010 of size 13552
2017-05-23 07:31:48,944 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 07:32:01,209 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 07:32:14,280 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 07:32:25,051 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 07:32:38,432 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 07:34:19,926 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6292576950976148109_2958 src: /192.168.1.157:53774 dest: /192.168.1.157:50010
2017-05-23 07:34:19,931 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6292576950976148109_2958 src: /192.168.1.157:53774 dest: /192.168.1.157:50010 of size 43172
2017-05-23 07:34:23,130 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8272919807438609092_2951 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8272919807438609092
2017-05-23 07:34:23,130 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5156023215582086230_2952 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5156023215582086230
2017-05-23 07:34:23,131 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4276472943038851754_2950 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4276472943038851754
2017-05-23 07:34:26,138 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6292576950976148109_2958 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6292576950976148109
2017-05-23 07:34:26,139 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7384987428884115701_2954 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7384987428884115701
2017-05-23 07:34:32,070 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 07:34:42,729 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 07:34:42,921 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 07:34:42,923 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 07:34:42,926 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 07:34:42,997 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 07:34:43,056 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 07:34:43,057 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 07:34:43,057 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 07:34:43,296 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@12e8099
2017-05-23 07:34:43,333 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 07:34:43,336 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 07:34:43,336 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 07:34:43,341 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 07:34:43,363 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 07:34:43,369 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 07:34:43,370 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 07:34:43,370 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 07:34:43,370 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 07:34:43,370 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 07:34:43,371 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 07:34:43,385 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 07:34:43,386 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 07:34:43,397 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 07:34:46,401 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-05-23 07:35:49,451 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6954876859511943307_2959 src: /192.168.1.158:37899 dest: /192.168.1.158:50010
2017-05-23 07:35:49,460 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6954876859511943307_2959 src: /192.168.1.158:37899 dest: /192.168.1.158:50010 of size 91176
2017-05-23 07:35:49,525 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7530519820897952360_2961 src: /192.168.1.158:37900 dest: /192.168.1.158:50010
2017-05-23 07:35:49,526 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7530519820897952360_2961 src: /192.168.1.158:37900 dest: /192.168.1.158:50010 of size 13567
2017-05-23 07:35:52,526 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5450038126173437488_2963 src: /192.168.1.156:38283 dest: /192.168.1.156:50010
2017-05-23 07:35:52,528 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5450038126173437488_2963 src: /192.168.1.156:38283 dest: /192.168.1.156:50010 of size 13552
2017-05-23 07:35:55,528 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5430109856497764882_2960 src: /192.168.1.158:37901 dest: /192.168.1.158:50010
2017-05-23 07:35:55,528 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5430109856497764882_2960 src: /192.168.1.158:37901 dest: /192.168.1.158:50010 of size 4325
2017-05-23 07:36:11,991 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 07:36:22,847 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 07:36:34,919 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 07:36:46,594 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 07:37:48,927 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 07:38:58,506 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-736789841188307725_2967 src: /192.168.1.158:37941 dest: /192.168.1.158:50010
2017-05-23 07:38:58,510 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-736789841188307725_2967 src: /192.168.1.158:37941 dest: /192.168.1.158:50010 of size 44902
2017-05-23 07:39:01,586 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7530519820897952360_2961 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7530519820897952360
2017-05-23 07:39:01,588 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6954876859511943307_2959 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6954876859511943307
2017-05-23 07:39:01,589 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5430109856497764882_2960 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5430109856497764882
2017-05-23 07:39:01,589 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-736789841188307725_2967 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-736789841188307725
2017-05-23 07:39:01,589 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5450038126173437488_2963 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5450038126173437488
2017-05-23 07:39:08,616 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 07:39:19,507 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 07:39:19,734 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 07:39:19,737 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 07:39:19,738 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 07:39:19,809 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 07:39:19,866 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 07:39:19,867 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 07:39:19,867 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 07:39:20,103 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-23 07:39:20,139 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 07:39:20,142 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 07:39:20,142 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-23 07:39:20,147 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 07:39:20,168 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 07:39:20,173 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 07:39:20,174 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 07:39:20,174 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 07:39:20,175 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 07:39:20,175 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 07:39:20,175 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 07:39:20,177 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 07:39:20,177 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 07:39:20,186 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 07:39:23,188 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-23 07:40:26,178 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_335411407828917497_2969 src: /192.168.1.158:37953 dest: /192.168.1.158:50010
2017-05-23 07:40:26,195 INFO org.apache.hadoop.dfs.DataNode: Received block blk_335411407828917497_2969 src: /192.168.1.158:37953 dest: /192.168.1.158:50010 of size 4325
2017-05-23 07:40:26,313 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2511109775428572820_2968 src: /192.168.1.156:38407 dest: /192.168.1.156:50010
2017-05-23 07:40:26,320 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2511109775428572820_2968 src: /192.168.1.156:38407 dest: /192.168.1.156:50010 of size 91176
2017-05-23 07:40:29,161 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1568202729912419763_2970 src: /192.168.1.157:53909 dest: /192.168.1.157:50010
2017-05-23 07:40:29,162 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1568202729912419763_2970 src: /192.168.1.157:53910 dest: /192.168.1.157:50010
2017-05-23 07:40:29,163 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1568202729912419763_2970 received exception java.io.IOException: Block blk_1568202729912419763_2970 is valid, and cannot be written to.
2017-05-23 07:40:29,165 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_1568202729912419763_2970 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 07:40:29,172 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1568202729912419763_2970 src: /192.168.1.157:53909 dest: /192.168.1.157:50010 of size 13567
2017-05-23 07:40:29,312 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8770674468543554345_2972 src: /192.168.1.156:38408 dest: /192.168.1.156:50010
2017-05-23 07:40:29,314 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8770674468543554345_2972 src: /192.168.1.156:38408 dest: /192.168.1.156:50010 of size 13552
2017-05-23 07:40:48,377 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 07:41:00,752 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 07:41:12,878 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 07:41:24,638 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 07:42:30,037 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 07:43:23,217 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2094706040500710536_2976 src: /192.168.1.157:54013 dest: /192.168.1.157:50010
2017-05-23 07:43:23,223 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2094706040500710536_2976 src: /192.168.1.157:54013 dest: /192.168.1.157:50010 of size 43990
2017-05-23 07:43:26,393 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8770674468543554345_2972 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8770674468543554345
2017-05-23 07:43:26,395 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2511109775428572820_2968 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2511109775428572820
2017-05-23 07:43:26,395 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_335411407828917497_2969 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_335411407828917497
2017-05-23 07:43:26,396 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1568202729912419763_2970 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1568202729912419763
2017-05-23 07:43:26,396 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2094706040500710536_2976 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2094706040500710536
2017-05-23 07:43:35,060 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 07:43:45,854 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 07:43:46,047 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 07:43:46,048 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 07:43:46,050 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 07:43:46,118 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 07:43:46,175 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 07:43:46,176 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 07:43:46,176 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 07:43:46,413 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-23 07:43:46,450 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 07:43:46,453 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 07:43:46,453 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 07:43:46,458 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 07:43:46,476 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 07:43:46,481 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 07:43:46,481 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 07:43:46,482 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 07:43:46,483 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 07:43:46,484 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 07:43:46,484 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 07:43:46,512 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 07:43:46,512 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 07:43:46,524 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 07:43:49,532 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 20 msecs
2017-05-23 07:44:46,587 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-918114441728292128_2978 src: /192.168.1.157:54024 dest: /192.168.1.157:50010
2017-05-23 07:44:46,613 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-918114441728292128_2978 src: /192.168.1.157:54024 dest: /192.168.1.157:50010 of size 2165
2017-05-23 07:44:46,623 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7614409004511626305_2977 src: /192.168.1.156:38519 dest: /192.168.1.156:50010
2017-05-23 07:44:46,629 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7614409004511626305_2977 src: /192.168.1.156:38519 dest: /192.168.1.156:50010 of size 91176
2017-05-23 07:44:46,864 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 07:44:49,557 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5932902396328950249_2981 src: /192.168.1.157:54029 dest: /192.168.1.157:50010
2017-05-23 07:44:49,558 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5932902396328950249_2981 src: /192.168.1.157:54029 dest: /192.168.1.157:50010 of size 13545
2017-05-23 07:44:49,620 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7363461879477501217_2979 src: /192.168.1.156:38523 dest: /192.168.1.156:50010
2017-05-23 07:44:49,621 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7363461879477501217_2979 src: /192.168.1.156:38523 dest: /192.168.1.156:50010 of size 13560
2017-05-23 07:44:49,623 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7363461879477501217_2979 src: /192.168.1.156:38524 dest: /192.168.1.156:50010
2017-05-23 07:44:49,623 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-7363461879477501217_2979 received exception java.io.IOException: Block blk_-7363461879477501217_2979 is valid, and cannot be written to.
2017-05-23 07:44:49,625 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-7363461879477501217_2979 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 07:44:52,587 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-7363461879477501217_2979 to 192.168.1.158:50010
2017-05-23 07:44:52,593 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-7363461879477501217_2979 to /192.168.1.158:50010
2017-05-23 07:45:06,711 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 07:45:23,016 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 07:45:27,561 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 07:45:44,305 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 07:45:48,399 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 07:46:04,202 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 07:46:10,173 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 07:46:25,915 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 07:46:31,044 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 07:47:34,671 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7614409004511626305_2977 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7614409004511626305
2017-05-23 07:47:34,672 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7363461879477501217_2979 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7363461879477501217
2017-05-23 07:47:34,672 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-918114441728292128_2978 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-918114441728292128
2017-05-23 07:47:37,672 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5932902396328950249_2981 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5932902396328950249
2017-05-23 07:47:42,831 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 07:47:53,688 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 07:47:53,874 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 07:47:53,876 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 07:47:53,877 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 07:47:53,938 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 07:47:53,986 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 07:47:53,986 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 07:47:53,986 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 07:47:54,201 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-23 07:47:54,239 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 07:47:54,252 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 07:47:54,252 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 07:47:54,260 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 07:47:54,278 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 07:47:54,283 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 07:47:54,283 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 07:47:54,285 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 07:47:54,285 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 07:47:54,285 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 07:47:54,285 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 07:47:54,298 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 07:47:54,298 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 07:47:54,312 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 07:47:57,312 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 13 msecs
2017-05-23 07:48:59,760 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 07:49:00,373 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4228742375158528487_2988 src: /192.168.1.157:54109 dest: /192.168.1.157:50010
2017-05-23 07:49:00,384 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4228742375158528487_2988 src: /192.168.1.157:54109 dest: /192.168.1.157:50010 of size 2165
2017-05-23 07:49:00,430 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6143946859410388037_2987 src: /192.168.1.156:38585 dest: /192.168.1.156:50010
2017-05-23 07:49:00,447 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6143946859410388037_2987 src: /192.168.1.156:38585 dest: /192.168.1.156:50010 of size 91176
2017-05-23 07:49:03,418 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_207024857929240187_2989 src: /192.168.1.156:38586 dest: /192.168.1.156:50010
2017-05-23 07:49:03,421 INFO org.apache.hadoop.dfs.DataNode: Received block blk_207024857929240187_2989 src: /192.168.1.156:38586 dest: /192.168.1.156:50010 of size 13560
2017-05-23 07:49:06,421 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7323036788843930177_2991 src: /192.168.1.156:38588 dest: /192.168.1.156:50010
2017-05-23 07:49:06,422 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7323036788843930177_2991 src: /192.168.1.156:38588 dest: /192.168.1.156:50010 of size 13545
2017-05-23 07:49:15,738 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 07:49:20,573 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 07:49:37,259 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 07:49:41,416 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 07:49:57,944 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 07:50:02,233 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 07:50:18,081 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 07:50:23,157 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 07:50:38,810 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 07:50:44,963 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 07:51:00,233 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-23 07:52:12,449 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3670319015049284164_2996 src: /192.168.1.158:38123 dest: /192.168.1.158:50010
2017-05-23 07:52:12,451 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3670319015049284164_2996 src: /192.168.1.158:38123 dest: /192.168.1.158:50010 of size 29267
2017-05-23 07:52:15,501 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6143946859410388037_2987 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6143946859410388037
2017-05-23 07:52:15,503 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_207024857929240187_2989 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_207024857929240187
2017-05-23 07:52:15,503 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4228742375158528487_2988 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4228742375158528487
2017-05-23 07:52:18,505 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3670319015049284164_2996 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3670319015049284164
2017-05-23 07:52:18,505 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7323036788843930177_2991 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7323036788843930177
2017-05-23 07:52:23,593 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 07:52:34,419 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 07:52:34,602 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 07:52:34,605 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 07:52:34,607 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 07:52:34,677 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 07:52:34,733 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 07:52:34,734 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 07:52:34,734 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 07:52:34,978 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-23 07:52:35,017 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 07:52:35,020 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 07:52:35,020 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-23 07:52:35,027 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 07:52:35,050 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 07:52:35,055 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 07:52:35,056 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 07:52:35,057 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 07:52:35,057 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 07:52:35,058 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 07:52:35,058 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 07:52:35,060 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 07:52:35,061 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 07:52:35,068 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 07:52:38,068 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-23 07:53:40,458 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 07:53:41,076 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2771927356595352357_2997 src: /192.168.1.158:38135 dest: /192.168.1.158:50010
2017-05-23 07:53:41,089 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2771927356595352357_2997 src: /192.168.1.158:38135 dest: /192.168.1.158:50010 of size 91176
2017-05-23 07:53:41,156 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3273665318472880426_3001 src: /192.168.1.156:38659 dest: /192.168.1.156:50010
2017-05-23 07:53:41,160 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3273665318472880426_3001 src: /192.168.1.156:38659 dest: /192.168.1.156:50010 of size 13545
2017-05-23 07:53:44,067 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_960185982439895201_2999 src: /192.168.1.157:54199 dest: /192.168.1.157:50010
2017-05-23 07:53:44,069 INFO org.apache.hadoop.dfs.DataNode: Received block blk_960185982439895201_2999 src: /192.168.1.157:54199 dest: /192.168.1.157:50010 of size 13560
2017-05-23 07:53:44,158 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_960185982439895201_2999 src: /192.168.1.156:38660 dest: /192.168.1.156:50010
2017-05-23 07:53:44,159 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_960185982439895201_2999 received exception java.io.IOException: Block blk_960185982439895201_2999 is valid, and cannot be written to.
2017-05-23 07:53:44,160 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_960185982439895201_2999 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 07:53:44,162 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6795647330969258807_2998 src: /192.168.1.156:38661 dest: /192.168.1.156:50010
2017-05-23 07:53:44,164 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6795647330969258807_2998 src: /192.168.1.156:38661 dest: /192.168.1.156:50010 of size 2165
2017-05-23 07:53:47,124 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_960185982439895201_2999 to 192.168.1.158:50010
2017-05-23 07:53:47,129 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_960185982439895201_2999 to /192.168.1.158:50010
2017-05-23 07:54:02,262 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 07:54:24,117 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 07:54:40,770 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 07:54:45,009 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 07:55:01,283 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 07:55:05,810 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 07:55:21,570 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 07:55:27,639 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 07:55:42,939 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 07:55:45,928 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 07:56:50,140 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2121011756371719077_3006 src: /192.168.1.157:54262 dest: /192.168.1.157:50010
2017-05-23 07:56:50,144 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2121011756371719077_3006 src: /192.168.1.157:54262 dest: /192.168.1.157:50010 of size 28905
2017-05-23 07:56:53,204 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3273665318472880426_3001 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3273665318472880426
2017-05-23 07:56:53,204 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_960185982439895201_2999 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_960185982439895201
2017-05-23 07:56:53,205 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2771927356595352357_2997 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2771927356595352357
2017-05-23 07:56:53,205 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6795647330969258807_2998 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6795647330969258807
2017-05-23 07:57:01,157 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 07:57:11,887 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 07:57:12,072 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 07:57:12,073 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 07:57:12,075 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 07:57:12,135 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 07:57:12,183 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 07:57:12,184 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 07:57:12,184 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 07:57:12,401 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 07:57:12,440 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 07:57:12,443 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 07:57:12,443 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-23 07:57:12,448 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 07:57:12,465 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 07:57:12,470 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 07:57:12,471 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 07:57:12,472 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 07:57:12,473 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 07:57:12,473 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 07:57:12,474 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 07:57:12,498 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 07:57:12,499 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 07:57:12,511 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 07:57:12,559 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_2121011756371719077_3006
2017-05-23 07:57:15,514 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 15 msecs
2017-05-23 07:57:48,562 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2121011756371719077_3006 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2121011756371719077
2017-05-23 07:58:12,587 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4417361615664798002_3007 src: /192.168.1.156:38726 dest: /192.168.1.156:50010
2017-05-23 07:58:12,607 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4417361615664798002_3007 src: /192.168.1.156:38726 dest: /192.168.1.156:50010 of size 91176
2017-05-23 07:58:12,636 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6187572441181986476_3011 src: /192.168.1.158:38195 dest: /192.168.1.158:50010
2017-05-23 07:58:12,637 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6187572441181986476_3011 src: /192.168.1.158:38195 dest: /192.168.1.158:50010 of size 13553
2017-05-23 07:58:12,866 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 07:58:15,577 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7849978358534272662_3009 src: /192.168.1.156:38732 dest: /192.168.1.156:50010
2017-05-23 07:58:15,577 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7849978358534272662_3009 src: /192.168.1.156:38732 dest: /192.168.1.156:50010 of size 13568
2017-05-23 07:58:18,545 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3645491722414241846_3008 src: /192.168.1.158:38200 dest: /192.168.1.158:50010
2017-05-23 07:58:18,546 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3645491722414241846_3008 src: /192.168.1.158:38200 dest: /192.168.1.158:50010 of size 2165
2017-05-23 07:58:33,722 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 07:58:49,774 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 07:58:54,586 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 07:59:10,456 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 07:59:15,417 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 07:59:31,057 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 07:59:35,153 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 07:59:50,329 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 07:59:55,357 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 08:00:11,028 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 08:00:15,371 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 08:00:31,020 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-23 08:01:03,691 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7444582492618425368_3015 src: /192.168.1.158:38234 dest: /192.168.1.158:50010
2017-05-23 08:01:03,692 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7444582492618425368_3015 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 08:01:03,694 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 08:01:06,668 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7849978358534272662_3009 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7849978358534272662
2017-05-23 08:01:06,668 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6187572441181986476_3011 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6187572441181986476
2017-05-23 08:01:06,669 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4417361615664798002_3007 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4417361615664798002
2017-05-23 08:01:06,669 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3645491722414241846_3008 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3645491722414241846
2017-05-23 08:01:12,766 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-23 08:01:12,768 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 08:01:23,580 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 08:01:23,780 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 08:01:23,782 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 08:01:23,784 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 08:01:23,852 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 08:01:23,921 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 08:01:23,922 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 08:01:23,922 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 08:01:24,153 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-05-23 08:01:24,185 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 08:01:24,188 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 08:01:24,188 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-23 08:01:24,192 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 08:01:24,209 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 08:01:24,213 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 08:01:24,214 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 08:01:24,215 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 08:01:24,216 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 08:01:24,216 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 08:01:24,216 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 08:01:24,219 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 08:01:24,220 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 08:01:24,231 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 08:01:27,230 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-23 08:02:29,621 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 08:02:30,222 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2691255355059037312_3016 src: /192.168.1.158:38245 dest: /192.168.1.158:50010
2017-05-23 08:02:30,247 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2691255355059037312_3016 src: /192.168.1.158:38245 dest: /192.168.1.158:50010 of size 91176
2017-05-23 08:02:30,277 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4298369759305565128_3017 src: /192.168.1.156:38802 dest: /192.168.1.156:50010
2017-05-23 08:02:30,278 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4298369759305565128_3017 src: /192.168.1.156:38802 dest: /192.168.1.156:50010 of size 2165
2017-05-23 08:02:33,207 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2570330164845505867_3020 src: /192.168.1.157:54355 dest: /192.168.1.157:50010
2017-05-23 08:02:33,208 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2570330164845505867_3020 src: /192.168.1.157:54355 dest: /192.168.1.157:50010 of size 13553
2017-05-23 08:02:33,277 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2570330164845505867_3020 src: /192.168.1.156:38804 dest: /192.168.1.156:50010
2017-05-23 08:02:33,277 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_2570330164845505867_3020 received exception java.io.IOException: Block blk_2570330164845505867_3020 is valid, and cannot be written to.
2017-05-23 08:02:33,279 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_2570330164845505867_3020 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 08:02:36,276 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8749429972540625575_3018 src: /192.168.1.156:38806 dest: /192.168.1.156:50010
2017-05-23 08:02:36,278 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8749429972540625575_3018 src: /192.168.1.156:38806 dest: /192.168.1.156:50010 of size 13568
2017-05-23 08:02:51,437 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 08:03:07,151 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 08:03:11,316 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 08:03:26,708 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 08:05:39,392 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2691255355059037312_3016 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2691255355059037312
2017-05-23 08:05:39,392 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4298369759305565128_3017 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4298369759305565128
2017-05-23 08:05:39,393 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8749429972540625575_3018 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8749429972540625575
2017-05-23 08:05:42,294 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7632760251099415563_3024 src: /192.168.1.158:38273 dest: /192.168.1.158:50010
2017-05-23 08:05:42,296 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7632760251099415563_3024 src: /192.168.1.158:38273 dest: /192.168.1.158:50010 of size 26368
2017-05-23 08:05:45,391 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2570330164845505867_3020 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2570330164845505867
2017-05-23 08:05:50,474 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 08:06:01,282 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 08:06:01,471 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 08:06:01,473 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 08:06:01,475 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 08:06:01,535 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 08:06:01,582 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 08:06:01,583 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 08:06:01,583 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 08:06:01,800 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-23 08:06:01,833 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 08:06:01,834 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 08:06:01,835 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 08:06:01,839 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 08:06:01,855 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 08:06:01,860 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 08:06:01,861 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 08:06:01,862 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 08:06:01,862 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 08:06:01,872 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 08:06:01,872 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 08:06:01,902 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 08:06:01,902 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 08:06:01,915 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 08:06:01,963 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_-7632760251099415563_3024
2017-05-23 08:06:04,915 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 13 msecs
2017-05-23 08:06:37,935 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7632760251099415563_3024 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7632760251099415563
2017-05-23 08:07:07,937 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9101536201038620149_3025 src: /192.168.1.157:54436 dest: /192.168.1.157:50010
2017-05-23 08:07:07,959 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9101536201038620149_3025 src: /192.168.1.157:54436 dest: /192.168.1.157:50010 of size 91176
2017-05-23 08:07:07,979 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2242997469697883794_3027 src: /192.168.1.156:38883 dest: /192.168.1.156:50010
2017-05-23 08:07:07,982 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2242997469697883794_3027 src: /192.168.1.156:38883 dest: /192.168.1.156:50010 of size 13568
2017-05-23 08:07:10,938 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3275415938608952280_3029 src: /192.168.1.157:54437 dest: /192.168.1.157:50010
2017-05-23 08:07:10,949 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3275415938608952280_3029 src: /192.168.1.157:54437 dest: /192.168.1.157:50010 of size 13553
2017-05-23 08:07:10,980 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3275415938608952280_3029 src: /192.168.1.156:38885 dest: /192.168.1.156:50010
2017-05-23 08:07:10,981 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-3275415938608952280_3029 received exception java.io.IOException: Block blk_-3275415938608952280_3029 is valid, and cannot be written to.
2017-05-23 08:07:10,982 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-3275415938608952280_3029 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 08:07:13,938 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-811819020016671277_3026 src: /192.168.1.157:54439 dest: /192.168.1.157:50010
2017-05-23 08:07:13,939 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-811819020016671277_3026 src: /192.168.1.157:54439 dest: /192.168.1.157:50010 of size 2165
2017-05-23 08:07:29,079 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 08:07:46,246 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 08:07:50,899 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 08:08:07,157 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 08:10:26,022 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2312522714187097458_3033 src: /192.168.1.158:38313 dest: /192.168.1.158:50010
2017-05-23 08:10:26,024 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2312522714187097458_3033 src: /192.168.1.158:38313 dest: /192.168.1.158:50010 of size 26368
2017-05-23 08:10:29,040 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9101536201038620149_3025 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9101536201038620149
2017-05-23 08:10:29,040 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3275415938608952280_3029 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3275415938608952280
2017-05-23 08:10:29,041 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2242997469697883794_3027 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2242997469697883794
2017-05-23 08:10:29,041 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-811819020016671277_3026 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-811819020016671277
2017-05-23 08:10:29,041 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2312522714187097458_3033 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2312522714187097458
2017-05-23 08:10:37,839 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 08:10:48,647 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 08:10:48,850 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 08:10:48,852 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 08:10:48,854 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 08:10:48,925 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 08:10:48,981 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 08:10:48,982 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 08:10:48,982 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 08:10:49,217 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-23 08:10:49,253 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 08:10:49,256 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 08:10:49,256 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 08:10:49,261 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 08:10:49,278 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 08:10:49,283 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 08:10:49,283 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 08:10:49,284 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 08:10:49,285 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 08:10:49,285 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 08:10:49,285 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 08:10:49,288 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 08:10:49,289 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 08:10:49,297 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 08:10:52,299 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-23 08:11:49,457 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6484130450185189310_3034 src: /192.168.1.158:38323 dest: /192.168.1.158:50010
2017-05-23 08:11:49,457 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3169214891104056561_3035 src: /192.168.1.158:38324 dest: /192.168.1.158:50010
2017-05-23 08:11:49,471 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6484130450185189310_3034 src: /192.168.1.158:38323 dest: /192.168.1.158:50010 of size 91176
2017-05-23 08:11:49,472 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3169214891104056561_3035 src: /192.168.1.158:38324 dest: /192.168.1.158:50010 of size 8645
2017-05-23 08:11:52,391 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1864221819815374206_3038 src: /192.168.1.157:54521 dest: /192.168.1.157:50010
2017-05-23 08:11:52,398 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1864221819815374206_3038 src: /192.168.1.157:54521 dest: /192.168.1.157:50010 of size 13553
2017-05-23 08:11:52,426 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1864221819815374206_3038 src: /192.168.1.156:38969 dest: /192.168.1.156:50010
2017-05-23 08:11:52,426 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1864221819815374206_3038 received exception java.io.IOException: Block blk_1864221819815374206_3038 is valid, and cannot be written to.
2017-05-23 08:11:52,428 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_1864221819815374206_3038 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 08:11:54,131 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 08:11:55,259 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4988336142857147301_3036 src: /192.168.1.158:38330 dest: /192.168.1.158:50010
2017-05-23 08:11:55,260 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4988336142857147301_3036 src: /192.168.1.158:38330 dest: /192.168.1.158:50010 of size 13568
2017-05-23 08:11:57,522 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 08:12:08,875 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 08:12:12,186 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 08:12:15,160 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 08:12:17,182 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 08:12:19,052 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 08:12:25,736 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 08:12:29,974 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 08:12:45,478 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 08:12:47,322 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 08:14:10,400 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1864221819815374206_3038 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1864221819815374206
2017-05-23 08:14:10,401 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3169214891104056561_3035 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3169214891104056561
2017-05-23 08:14:10,401 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4988336142857147301_3036 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4988336142857147301
2017-05-23 08:14:10,402 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6484130450185189310_3034 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6484130450185189310
2017-05-23 08:14:17,448 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 08:14:28,362 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 08:14:28,560 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 08:14:28,562 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 08:14:28,564 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 08:14:28,627 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 08:14:28,677 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 08:14:28,677 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 08:14:28,678 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 08:14:28,891 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@14a8af0
2017-05-23 08:14:28,921 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 08:14:28,923 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 08:14:28,923 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 08:14:28,929 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 08:14:28,944 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 08:14:28,949 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 08:14:28,950 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 08:14:28,951 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 08:14:28,951 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 08:14:28,952 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 08:14:28,952 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 08:14:28,972 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 08:14:28,972 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 08:14:28,984 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 08:14:31,988 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 16 msecs
2017-05-23 08:15:35,019 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1765779850238119657_3043 src: /192.168.1.157:54628 dest: /192.168.1.157:50010
2017-05-23 08:15:35,041 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1765779850238119657_3043 src: /192.168.1.157:54628 dest: /192.168.1.157:50010 of size 91176
2017-05-23 08:15:35,073 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4687885186101447474_3044 src: /192.168.1.156:39086 dest: /192.168.1.156:50010
2017-05-23 08:15:35,075 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4687885186101447474_3044 src: /192.168.1.156:39086 dest: /192.168.1.156:50010 of size 8645
2017-05-23 08:15:38,015 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-396727214964052089_3045 src: /192.168.1.157:54629 dest: /192.168.1.157:50010
2017-05-23 08:15:38,018 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-396727214964052089_3045 src: /192.168.1.157:54629 dest: /192.168.1.157:50010 of size 13568
2017-05-23 08:15:38,079 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8909355357774174057_3047 src: /192.168.1.156:39087 dest: /192.168.1.156:50010
2017-05-23 08:15:38,080 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8909355357774174057_3047 src: /192.168.1.156:39087 dest: /192.168.1.156:50010 of size 13553
2017-05-23 08:15:38,081 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-396727214964052089_3045 src: /192.168.1.156:39088 dest: /192.168.1.156:50010
2017-05-23 08:15:38,081 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-396727214964052089_3045 received exception java.io.IOException: Block blk_-396727214964052089_3045 is valid, and cannot be written to.
2017-05-23 08:15:38,082 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-396727214964052089_3045 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 08:15:39,610 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 08:15:41,017 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-396727214964052089_3045 to 192.168.1.158:50010
2017-05-23 08:15:41,024 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-396727214964052089_3045 to /192.168.1.158:50010
2017-05-23 08:15:54,590 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 08:15:56,996 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 08:16:03,803 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 08:16:10,677 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 08:16:22,932 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 08:16:29,763 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 08:16:32,172 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 08:17:47,085 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-396727214964052089_3045 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-396727214964052089
2017-05-23 08:17:47,085 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1765779850238119657_3043 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1765779850238119657
2017-05-23 08:17:47,086 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4687885186101447474_3044 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4687885186101447474
2017-05-23 08:17:47,086 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8909355357774174057_3047 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8909355357774174057
2017-05-23 08:17:54,264 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 08:18:05,071 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 08:18:05,254 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 08:18:05,256 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 08:18:05,257 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 08:18:05,321 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 08:18:05,378 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 08:18:05,379 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 08:18:05,379 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 08:18:05,605 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 08:18:05,642 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 08:18:05,645 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 08:18:05,645 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 08:18:05,650 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 08:18:05,667 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 08:18:05,672 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 08:18:05,673 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 08:18:05,674 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 08:18:05,675 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 08:18:05,676 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 08:18:05,676 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 08:18:05,686 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 08:18:05,687 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 08:18:05,697 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 08:18:08,702 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-23 08:19:11,826 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8407637845620813537_3056 src: /192.168.1.158:38502 dest: /192.168.1.158:50010
2017-05-23 08:19:11,838 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8407637845620813537_3056 src: /192.168.1.158:38502 dest: /192.168.1.158:50010 of size 13553
2017-05-23 08:19:11,851 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-591676364744184028_3052 src: /192.168.1.156:39198 dest: /192.168.1.156:50010
2017-05-23 08:19:11,856 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-591676364744184028_3052 src: /192.168.1.156:39198 dest: /192.168.1.156:50010 of size 91176
2017-05-23 08:19:14,805 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4279033309478138107_3053 src: /192.168.1.157:54740 dest: /192.168.1.157:50010
2017-05-23 08:19:14,806 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4279033309478138107_3053 src: /192.168.1.157:54740 dest: /192.168.1.157:50010 of size 8645
2017-05-23 08:19:14,850 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4419287132283731917_3054 src: /192.168.1.156:39199 dest: /192.168.1.156:50010
2017-05-23 08:19:14,851 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4419287132283731917_3054 src: /192.168.1.156:39199 dest: /192.168.1.156:50010 of size 13568
2017-05-23 08:19:24,548 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 08:19:31,494 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 08:19:31,649 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 08:19:37,938 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 08:19:39,058 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 08:19:44,503 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 08:19:46,364 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 08:19:51,102 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 08:19:56,246 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 08:20:07,029 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 08:21:32,855 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6587294480316712554_3056 src: /192.168.1.157:54833 dest: /192.168.1.157:50010
2017-05-23 08:21:32,856 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6587294480316712554_3056 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 08:21:32,858 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 08:21:35,919 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8407637845620813537_3056 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8407637845620813537
2017-05-23 08:21:35,920 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4279033309478138107_3053 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4279033309478138107
2017-05-23 08:21:35,920 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-591676364744184028_3052 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-591676364744184028
2017-05-23 08:21:35,921 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4419287132283731917_3054 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4419287132283731917
2017-05-23 08:21:44,588 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 08:21:55,428 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 08:21:55,617 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 08:21:55,619 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 08:21:55,620 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 08:21:55,693 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 08:21:55,750 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 08:21:55,751 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 08:21:55,751 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 08:21:55,987 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-23 08:21:56,018 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 08:21:56,021 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 08:21:56,021 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 08:21:56,026 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 08:21:56,043 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 08:21:56,048 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 08:21:56,048 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 08:21:56,050 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 08:21:56,050 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 08:21:56,051 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 08:21:56,051 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 08:21:56,054 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 08:21:56,054 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 08:21:56,062 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 08:21:59,062 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-23 08:22:56,127 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5687669678259423573_3061 src: /192.168.1.158:38583 dest: /192.168.1.158:50010
2017-05-23 08:22:56,127 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2055222932800820135_3062 src: /192.168.1.158:38584 dest: /192.168.1.158:50010
2017-05-23 08:22:56,146 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2055222932800820135_3062 src: /192.168.1.158:38584 dest: /192.168.1.158:50010 of size 8645
2017-05-23 08:22:56,146 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5687669678259423573_3061 src: /192.168.1.158:38583 dest: /192.168.1.158:50010 of size 91176
2017-05-23 08:22:56,389 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 08:22:59,059 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5472980363683733449_3065 src: /192.168.1.157:54850 dest: /192.168.1.157:50010
2017-05-23 08:22:59,062 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_888778330386920480_3063 src: /192.168.1.157:54851 dest: /192.168.1.157:50010
2017-05-23 08:22:59,063 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5472980363683733449_3065 src: /192.168.1.157:54850 dest: /192.168.1.157:50010 of size 13553
2017-05-23 08:22:59,064 INFO org.apache.hadoop.dfs.DataNode: Received block blk_888778330386920480_3063 src: /192.168.1.157:54851 dest: /192.168.1.157:50010 of size 13568
2017-05-23 08:22:59,078 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_888778330386920480_3063 src: /192.168.1.156:39308 dest: /192.168.1.156:50010
2017-05-23 08:22:59,078 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_888778330386920480_3063 received exception java.io.IOException: Block blk_888778330386920480_3063 is valid, and cannot be written to.
2017-05-23 08:22:59,079 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_888778330386920480_3063 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 08:23:01,408 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 08:23:09,322 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 08:23:10,355 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 08:23:10,570 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 08:23:17,816 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 08:23:21,116 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 08:23:25,935 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 08:23:29,057 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 08:23:34,532 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 08:23:36,893 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 08:25:17,203 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_888778330386920480_3063 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_888778330386920480
2017-05-23 08:25:17,203 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2055222932800820135_3062 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2055222932800820135
2017-05-23 08:25:17,204 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5472980363683733449_3065 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5472980363683733449
2017-05-23 08:25:17,204 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5687669678259423573_3061 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5687669678259423573
2017-05-23 08:25:23,195 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 08:25:33,920 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 08:25:34,106 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 08:25:34,108 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 08:25:34,110 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 08:25:34,174 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 08:25:34,231 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 08:25:34,231 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 08:25:34,232 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 08:25:34,470 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-23 08:25:34,507 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 08:25:34,510 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 08:25:34,510 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-23 08:25:34,515 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 08:25:34,534 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 08:25:34,540 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 08:25:34,541 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 08:25:34,542 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 08:25:34,543 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 08:25:34,543 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 08:25:34,543 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 08:25:34,553 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 08:25:34,554 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 08:25:34,568 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 08:25:37,570 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 16 msecs
2017-05-23 08:26:40,645 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9074485320230456179_3071 src: /192.168.1.158:38677 dest: /192.168.1.158:50010
2017-05-23 08:26:40,660 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9074485320230456179_3071 src: /192.168.1.158:38677 dest: /192.168.1.158:50010 of size 8645
2017-05-23 08:26:40,681 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5472772282797520916_3070 src: /192.168.1.158:38678 dest: /192.168.1.158:50010
2017-05-23 08:26:40,684 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5472772282797520916_3070 src: /192.168.1.158:38678 dest: /192.168.1.158:50010 of size 91176
2017-05-23 08:26:43,636 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7823587159948509783_3074 src: /192.168.1.157:54953 dest: /192.168.1.157:50010
2017-05-23 08:26:43,637 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7823587159948509783_3074 src: /192.168.1.157:54953 dest: /192.168.1.157:50010 of size 13553
2017-05-23 08:26:43,638 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5584383354929373058_3072 src: /192.168.1.157:54954 dest: /192.168.1.157:50010
2017-05-23 08:26:43,640 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5584383354929373058_3072 src: /192.168.1.157:54954 dest: /192.168.1.157:50010 of size 13568
2017-05-23 08:26:43,673 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5584383354929373058_3072 src: /192.168.1.156:39430 dest: /192.168.1.156:50010
2017-05-23 08:26:43,673 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-5584383354929373058_3072 received exception java.io.IOException: Block blk_-5584383354929373058_3072 is valid, and cannot be written to.
2017-05-23 08:26:43,674 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-5584383354929373058_3072 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 08:26:53,160 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 08:26:55,832 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 08:26:58,129 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 08:27:03,741 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 08:27:05,195 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 08:27:07,662 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 08:27:16,487 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 08:27:17,548 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 08:27:18,562 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 08:28:46,749 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7974698105842196252_3074 src: /192.168.1.156:39524 dest: /192.168.1.156:50010
2017-05-23 08:28:46,750 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_7974698105842196252_3074 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 08:28:46,750 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 08:28:49,661 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9074485320230456179_3071 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9074485320230456179
2017-05-23 08:28:49,662 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5584383354929373058_3072 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5584383354929373058
2017-05-23 08:28:49,662 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5472772282797520916_3070 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5472772282797520916
2017-05-23 08:28:49,663 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7823587159948509783_3074 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7823587159948509783
2017-05-23 08:28:56,837 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 08:29:07,584 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 08:29:07,783 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 08:29:07,785 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 08:29:07,787 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 08:29:07,849 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 08:29:07,898 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 08:29:07,898 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 08:29:07,898 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 08:29:08,112 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-23 08:29:08,148 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 08:29:08,151 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 08:29:08,151 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-23 08:29:08,156 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 08:29:08,173 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 08:29:08,178 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 08:29:08,178 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 08:29:08,180 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 08:29:08,180 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 08:29:08,180 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 08:29:08,181 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 08:29:08,200 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 08:29:08,201 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 08:29:08,213 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 08:29:11,215 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-05-23 08:30:14,320 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1493836426518588378_3081 src: /192.168.1.157:55061 dest: /192.168.1.157:50010
2017-05-23 08:30:14,332 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-564827779892330683_3079 src: /192.168.1.156:39539 dest: /192.168.1.156:50010
2017-05-23 08:30:14,354 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1493836426518588378_3081 src: /192.168.1.157:55061 dest: /192.168.1.157:50010 of size 13568
2017-05-23 08:30:14,366 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-564827779892330683_3079 src: /192.168.1.156:39539 dest: /192.168.1.156:50010 of size 91176
2017-05-23 08:30:17,321 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7120722775972599835_3083 src: /192.168.1.156:39540 dest: /192.168.1.156:50010
2017-05-23 08:30:17,322 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7120722775972599835_3083 src: /192.168.1.156:39540 dest: /192.168.1.156:50010 of size 13553
2017-05-23 08:30:17,324 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6917567405603618338_3080 src: /192.168.1.156:39541 dest: /192.168.1.156:50010
2017-05-23 08:30:17,326 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6917567405603618338_3080 src: /192.168.1.156:39541 dest: /192.168.1.156:50010 of size 8645
2017-05-23 08:30:18,331 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 08:30:19,018 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 08:30:23,695 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 08:30:26,745 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 08:30:30,354 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 08:30:31,797 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 08:30:39,340 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 08:30:47,504 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 08:30:52,758 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 08:30:56,668 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 08:31:03,587 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-23 08:31:04,500 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 08:32:26,422 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6806914382769561438_3083 src: /192.168.1.158:38839 dest: /192.168.1.158:50010
2017-05-23 08:32:26,423 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6806914382769561438_3083 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 08:32:26,424 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 08:32:29,457 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-564827779892330683_3079 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-564827779892330683
2017-05-23 08:32:29,457 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1493836426518588378_3081 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1493836426518588378
2017-05-23 08:32:29,458 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6917567405603618338_3080 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6917567405603618338
2017-05-23 08:32:29,458 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7120722775972599835_3083 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7120722775972599835
2017-05-23 08:34:02,644 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 5 msecs
2017-05-23 09:32:54,542 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 09:33:05,407 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 09:33:05,600 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 09:33:05,602 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 09:33:05,604 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 09:33:05,669 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 09:33:05,717 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 09:33:05,717 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 09:33:05,717 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 09:33:05,936 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-23 09:33:05,977 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 09:33:05,980 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 09:33:05,980 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 09:33:05,985 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 09:33:06,003 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 09:33:06,007 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 09:33:06,008 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 09:33:06,009 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 09:33:06,010 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 09:33:06,010 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 09:33:06,011 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 09:33:06,018 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 09:33:06,018 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 09:33:06,031 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 09:33:09,036 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 18 msecs
2017-05-23 09:34:06,117 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4288311133042763983_3089 src: /192.168.1.158:38847 dest: /192.168.1.158:50010
2017-05-23 09:34:06,130 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4288311133042763983_3089 src: /192.168.1.158:38847 dest: /192.168.1.158:50010 of size 4325
2017-05-23 09:34:06,173 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4613786762779589149_3088 src: /192.168.1.158:38848 dest: /192.168.1.158:50010
2017-05-23 09:34:06,184 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4613786762779589149_3088 src: /192.168.1.158:38848 dest: /192.168.1.158:50010 of size 91176
2017-05-23 09:34:11,647 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 09:34:12,059 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6698133374465086842_3092 src: /192.168.1.157:55184 dest: /192.168.1.157:50010
2017-05-23 09:34:12,060 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6698133374465086842_3092 src: /192.168.1.157:55184 dest: /192.168.1.157:50010 of size 13545
2017-05-23 09:34:12,069 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3506976627891679485_3090 src: /192.168.1.158:38859 dest: /192.168.1.158:50010
2017-05-23 09:34:12,070 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3506976627891679485_3090 src: /192.168.1.158:38859 dest: /192.168.1.158:50010 of size 13560
2017-05-23 09:34:15,373 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 09:34:15,968 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 09:34:19,430 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 09:34:30,528 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 09:34:34,381 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 09:34:34,511 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 09:36:03,146 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3506976627891679485_3090 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3506976627891679485
2017-05-23 09:36:03,146 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4288311133042763983_3089 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4288311133042763983
2017-05-23 09:36:03,147 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4613786762779589149_3088 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4613786762779589149
2017-05-23 09:36:06,156 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6698133374465086842_3092 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6698133374465086842
2017-05-23 09:36:11,253 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 09:36:22,125 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 09:36:22,326 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 09:36:22,328 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 09:36:22,329 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 09:36:22,391 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 09:36:22,440 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 09:36:22,441 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 09:36:22,441 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 09:36:22,651 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 09:36:22,684 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 09:36:22,687 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 09:36:22,688 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-23 09:36:22,692 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 09:36:22,708 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 09:36:22,713 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 09:36:22,714 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 09:36:22,715 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 09:36:22,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 09:36:22,716 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 09:36:22,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 09:36:22,718 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 09:36:22,718 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 09:36:22,726 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 09:36:25,729 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-23 09:37:28,745 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1729492790301756210_3097 src: /192.168.1.157:55272 dest: /192.168.1.157:50010
2017-05-23 09:37:28,761 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1729492790301756210_3097 src: /192.168.1.157:55272 dest: /192.168.1.157:50010 of size 91176
2017-05-23 09:37:28,867 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9090417669123256542_3101 src: /192.168.1.156:39734 dest: /192.168.1.156:50010
2017-05-23 09:37:28,870 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9090417669123256542_3101 src: /192.168.1.156:39734 dest: /192.168.1.156:50010 of size 13545
2017-05-23 09:37:31,743 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4206873054999759036_3099 src: /192.168.1.157:55273 dest: /192.168.1.157:50010
2017-05-23 09:37:31,744 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4206873054999759036_3099 src: /192.168.1.157:55273 dest: /192.168.1.157:50010 of size 13560
2017-05-23 09:37:31,866 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-812885753438837198_3098 src: /192.168.1.156:39735 dest: /192.168.1.156:50010
2017-05-23 09:37:31,867 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-812885753438837198_3098 src: /192.168.1.156:39735 dest: /192.168.1.156:50010 of size 4325
2017-05-23 09:37:37,026 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 09:37:37,576 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 09:37:41,063 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 09:37:42,072 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 09:37:42,289 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 09:37:47,207 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 09:37:54,908 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 09:38:00,019 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 09:39:10,784 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2679266196021007431_3105 src: /192.168.1.157:55347 dest: /192.168.1.157:50010
2017-05-23 09:39:10,785 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2679266196021007431_3105 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 09:39:10,787 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 09:39:13,861 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4206873054999759036_3099 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4206873054999759036
2017-05-23 09:39:13,862 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-812885753438837198_3098 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-812885753438837198
2017-05-23 09:39:13,862 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1729492790301756210_3097 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1729492790301756210
2017-05-23 09:39:16,860 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9090417669123256542_3101 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9090417669123256542
2017-05-23 09:39:21,938 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 09:39:32,811 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 09:39:33,012 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 09:39:33,014 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 09:39:33,015 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 09:39:33,083 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 09:39:33,139 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 09:39:33,140 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 09:39:33,140 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 09:39:33,391 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 09:39:33,431 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 09:39:33,434 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 09:39:33,434 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 09:39:33,439 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 09:39:33,458 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 09:39:33,463 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 09:39:33,464 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 09:39:33,465 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 09:39:33,466 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 09:39:33,466 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 09:39:33,467 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 09:39:33,469 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 09:39:33,469 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 09:39:33,476 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 09:39:36,476 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-23 09:40:39,488 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5155208743880728212_3106 src: /192.168.1.157:55362 dest: /192.168.1.157:50010
2017-05-23 09:40:39,503 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3285809565528364823_3107 src: /192.168.1.156:39816 dest: /192.168.1.156:50010
2017-05-23 09:40:39,505 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5155208743880728212_3106 src: /192.168.1.157:55362 dest: /192.168.1.157:50010 of size 91176
2017-05-23 09:40:39,512 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3285809565528364823_3107 src: /192.168.1.156:39816 dest: /192.168.1.156:50010 of size 4325
2017-05-23 09:40:42,480 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1000661446755133849_3108 src: /192.168.1.157:55363 dest: /192.168.1.157:50010
2017-05-23 09:40:42,481 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1000661446755133849_3108 src: /192.168.1.157:55364 dest: /192.168.1.157:50010
2017-05-23 09:40:42,481 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1000661446755133849_3108 src: /192.168.1.157:55363 dest: /192.168.1.157:50010 of size 13560
2017-05-23 09:40:42,481 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-1000661446755133849_3108 received exception java.io.IOException: Block blk_-1000661446755133849_3108 is valid, and cannot be written to.
2017-05-23 09:40:42,483 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-1000661446755133849_3108 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 09:40:42,507 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4527419371546954510_3110 src: /192.168.1.156:39818 dest: /192.168.1.156:50010
2017-05-23 09:40:42,508 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4527419371546954510_3110 src: /192.168.1.156:39818 dest: /192.168.1.156:50010 of size 13545
2017-05-23 09:40:42,511 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4527419371546954510_3110 src: /192.168.1.156:39817 dest: /192.168.1.156:50010
2017-05-23 09:40:42,511 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_4527419371546954510_3110 received exception java.io.IOException: Block blk_4527419371546954510_3110 is valid, and cannot be written to.
2017-05-23 09:40:42,512 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_4527419371546954510_3110 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 09:40:45,552 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_4527419371546954510_3110 to 192.168.1.158:50010
2017-05-23 09:40:45,555 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_4527419371546954510_3110 to /192.168.1.158:50010
2017-05-23 09:40:47,680 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 09:40:51,659 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 09:40:53,114 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 09:40:57,872 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 09:41:03,877 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 09:41:05,639 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 09:41:18,495 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 09:42:36,547 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2383553945484146328_3114 src: /192.168.1.156:39888 dest: /192.168.1.156:50010
2017-05-23 09:42:36,553 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2383553945484146328_3114 src: /192.168.1.156:39888 dest: /192.168.1.156:50010 of size 46642
2017-05-23 09:42:39,633 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3285809565528364823_3107 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3285809565528364823
2017-05-23 09:42:39,633 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2383553945484146328_3114 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2383553945484146328
2017-05-23 09:42:39,634 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1000661446755133849_3108 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1000661446755133849
2017-05-23 09:42:39,634 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4527419371546954510_3110 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4527419371546954510
2017-05-23 09:42:39,634 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5155208743880728212_3106 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5155208743880728212
2017-05-23 10:19:29,361 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-23 11:19:32,292 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-23 12:19:35,184 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 5 msecs
2017-05-23 12:43:56,820 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 12:44:07,695 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 12:44:07,883 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 12:44:07,885 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 12:44:07,886 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 12:44:07,957 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 12:44:08,015 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 12:44:08,016 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 12:44:08,016 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 12:44:08,253 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 12:44:08,293 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 12:44:08,296 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 12:44:08,296 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-23 12:44:08,301 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 12:44:08,317 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 12:44:08,322 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 12:44:08,323 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 12:44:08,324 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 12:44:08,324 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 12:44:08,324 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 12:44:08,325 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 12:44:08,328 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 12:44:08,328 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 12:44:08,334 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 12:44:11,335 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-23 12:45:08,330 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_946644804722103241_3115 src: /192.168.1.157:55451 dest: /192.168.1.157:50010
2017-05-23 12:45:08,351 INFO org.apache.hadoop.dfs.DataNode: Received block blk_946644804722103241_3115 src: /192.168.1.157:55451 dest: /192.168.1.157:50010 of size 91176
2017-05-23 12:45:08,356 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1171351822669350758_3117 src: /192.168.1.156:39897 dest: /192.168.1.156:50010
2017-05-23 12:45:08,358 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1171351822669350758_3117 src: /192.168.1.156:39897 dest: /192.168.1.156:50010 of size 13560
2017-05-23 12:45:08,640 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 12:45:08,709 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 12:45:13,766 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 12:45:14,243 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5328510961885801576_3119 src: /192.168.1.158:39031 dest: /192.168.1.158:50010
2017-05-23 12:45:14,245 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5328510961885801576_3119 src: /192.168.1.158:39031 dest: /192.168.1.158:50010 of size 13545
2017-05-23 12:45:14,300 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6506518855258594500_3116 src: /192.168.1.157:55466 dest: /192.168.1.157:50010
2017-05-23 12:45:14,301 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6506518855258594500_3116 src: /192.168.1.157:55466 dest: /192.168.1.157:50010 of size 2165
2017-05-23 12:45:26,361 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 12:45:27,290 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 12:45:31,150 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 12:45:33,873 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 12:45:33,955 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 12:46:53,475 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_946644804722103241_3115 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_946644804722103241
2017-05-23 12:46:53,476 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1171351822669350758_3117 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1171351822669350758
2017-05-23 12:46:53,476 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6506518855258594500_3116 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6506518855258594500
2017-05-23 12:46:56,474 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5328510961885801576_3119 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5328510961885801576
2017-05-23 12:47:03,535 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 12:47:14,362 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 12:47:14,559 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 12:47:14,561 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 12:47:14,562 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 12:47:14,620 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 12:47:14,667 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 12:47:14,668 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 12:47:14,668 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 12:47:14,879 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-23 12:47:14,913 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 12:47:14,915 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 12:47:14,915 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-23 12:47:14,920 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 12:47:14,937 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 12:47:14,942 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 12:47:14,943 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 12:47:14,944 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 12:47:14,945 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 12:47:14,945 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 12:47:14,945 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 12:47:14,947 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 12:47:14,947 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 12:47:14,956 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 12:47:17,960 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 9 msecs
2017-05-23 12:48:20,303 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 12:48:20,369 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 12:48:20,992 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1446489486894903947_3126 src: /192.168.1.157:55525 dest: /192.168.1.157:50010
2017-05-23 12:48:21,009 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1446489486894903947_3126 src: /192.168.1.157:55525 dest: /192.168.1.157:50010 of size 13560
2017-05-23 12:48:21,093 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1558624427246158165_3124 src: /192.168.1.158:39066 dest: /192.168.1.158:50010
2017-05-23 12:48:21,104 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1558624427246158165_3124 src: /192.168.1.158:39066 dest: /192.168.1.158:50010 of size 91176
2017-05-23 12:48:25,581 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 12:48:26,973 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3118935254475734585_3125 src: /192.168.1.158:39073 dest: /192.168.1.158:50010
2017-05-23 12:48:26,974 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3118935254475734585_3125 src: /192.168.1.158:39073 dest: /192.168.1.158:50010 of size 2165
2017-05-23 12:48:26,987 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6760825417496185013_3128 src: /192.168.1.157:55534 dest: /192.168.1.157:50010
2017-05-23 12:48:26,988 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6760825417496185013_3128 src: /192.168.1.157:55534 dest: /192.168.1.157:50010 of size 13545
2017-05-23 12:48:38,268 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 12:48:38,359 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 12:48:42,609 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 12:48:45,529 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 12:48:45,567 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 12:50:06,026 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_927108548954251222_3132 src: /192.168.1.157:55580 dest: /192.168.1.157:50010
2017-05-23 12:50:06,031 INFO org.apache.hadoop.dfs.DataNode: Received block blk_927108548954251222_3132 src: /192.168.1.157:55580 dest: /192.168.1.157:50010 of size 27788
2017-05-23 12:50:09,076 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3118935254475734585_3125 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3118935254475734585
2017-05-23 12:50:09,077 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1558624427246158165_3124 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1558624427246158165
2017-05-23 12:50:09,077 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1446489486894903947_3126 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1446489486894903947
2017-05-23 12:50:12,074 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_927108548954251222_3132 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_927108548954251222
2017-05-23 12:50:12,075 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6760825417496185013_3128 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6760825417496185013
2017-05-23 12:50:18,147 WARN org.apache.hadoop.dfs.DataNode: java.io.IOException: Call failed on local exception
	at org.apache.hadoop.ipc.Client.call(Client.java:718)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:216)
	at org.apache.hadoop.dfs.$Proxy4.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.dfs.DataNode.offerService(DataNode.java:655)
	at org.apache.hadoop.dfs.DataNode.run(DataNode.java:2888)
	at java.lang.Thread.run(Thread.java:722)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:225)
	at sun.nio.ch.IOUtil.read(IOUtil.java:198)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:359)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:55)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:150)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:123)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:272)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:235)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:254)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:499)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:441)

2017-05-23 12:50:18,299 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 12:50:29,152 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 12:50:29,348 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 12:50:29,350 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 12:50:29,352 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 12:50:29,422 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 12:50:29,478 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 12:50:29,479 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 12:50:29,479 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 12:50:29,724 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 12:50:29,761 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 12:50:29,764 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 12:50:29,764 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 12:50:29,769 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 12:50:29,788 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 12:50:29,792 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 12:50:29,793 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 12:50:29,794 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 12:50:29,795 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 12:50:29,795 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 12:50:29,795 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 12:50:29,799 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 12:50:29,799 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 12:50:29,808 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 12:50:32,809 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-23 12:51:35,115 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 12:51:35,165 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 12:51:35,729 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2919318585498024224_3133 src: /192.168.1.156:40036 dest: /192.168.1.156:50010
2017-05-23 12:51:35,744 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2919318585498024224_3133 src: /192.168.1.156:40036 dest: /192.168.1.156:50010 of size 91176
2017-05-23 12:51:35,820 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7531863538162328086_3135 src: /192.168.1.157:55596 dest: /192.168.1.157:50010
2017-05-23 12:51:35,825 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7531863538162328086_3135 src: /192.168.1.157:55596 dest: /192.168.1.157:50010 of size 13560
2017-05-23 12:51:38,824 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8566456270867381942_3134 src: /192.168.1.157:55597 dest: /192.168.1.157:50010
2017-05-23 12:51:38,825 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8566456270867381942_3134 src: /192.168.1.157:55598 dest: /192.168.1.157:50010
2017-05-23 12:51:38,825 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8566456270867381942_3134 received exception java.io.IOException: Block blk_8566456270867381942_3134 has already been started (though not completed), and thus cannot be created.
2017-05-23 12:51:38,826 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8566456270867381942_3134 src: /192.168.1.157:55597 dest: /192.168.1.157:50010 of size 2165
2017-05-23 12:51:38,828 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8566456270867381942_3134 has already been started (though not completed), and thus cannot be created.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:919)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 12:51:40,285 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 12:51:41,658 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1111460080420906220_3137 src: /192.168.1.158:39120 dest: /192.168.1.158:50010
2017-05-23 12:51:41,664 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1111460080420906220_3137 src: /192.168.1.158:39120 dest: /192.168.1.158:50010 of size 13545
2017-05-23 12:51:52,949 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 12:51:53,167 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 12:51:57,539 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 12:52:00,236 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 12:52:05,245 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 12:52:16,299 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 12:52:21,180 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 12:53:02,920 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7531863538162328086_3135 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7531863538162328086
2017-05-23 12:53:02,921 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2919318585498024224_3133 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2919318585498024224
2017-05-23 12:53:02,921 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8566456270867381942_3134 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8566456270867381942
2017-05-23 12:53:05,923 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1111460080420906220_3137 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1111460080420906220
2017-05-23 12:53:13,698 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 12:53:24,520 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 12:53:24,734 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 12:53:24,737 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 12:53:24,738 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 12:53:24,805 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 12:53:24,860 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 12:53:24,860 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 12:53:24,861 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 12:53:25,097 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@14a8af0
2017-05-23 12:53:25,136 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 12:53:25,145 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 12:53:25,145 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-23 12:53:25,151 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 12:53:25,168 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 12:53:25,173 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 12:53:25,174 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 12:53:25,188 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 12:53:25,188 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 12:53:25,188 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 12:53:25,189 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 12:53:25,192 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 12:53:25,192 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 12:53:25,200 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 12:53:28,199 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-23 12:54:25,187 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5025264319305335384_3142 src: /192.168.1.158:39156 dest: /192.168.1.158:50010
2017-05-23 12:54:25,188 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2583205534700951830_3144 src: /192.168.1.158:39157 dest: /192.168.1.158:50010
2017-05-23 12:54:25,220 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5025264319305335384_3142 src: /192.168.1.158:39156 dest: /192.168.1.158:50010 of size 91176
2017-05-23 12:54:25,221 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2583205534700951830_3144 src: /192.168.1.158:39157 dest: /192.168.1.158:50010 of size 13560
2017-05-23 12:54:28,122 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6816037503373737458_3146 src: /192.168.1.156:40101 dest: /192.168.1.156:50010
2017-05-23 12:54:28,123 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_6816037503373737458_3146 src: /192.168.1.156:40102 dest: /192.168.1.156:50010
2017-05-23 12:54:28,123 INFO org.apache.hadoop.dfs.DataNode: Received block blk_6816037503373737458_3146 src: /192.168.1.156:40101 dest: /192.168.1.156:50010 of size 13545
2017-05-23 12:54:28,125 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_6816037503373737458_3146 received exception java.io.IOException: Block blk_6816037503373737458_3146 is valid, and cannot be written to.
2017-05-23 12:54:28,132 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_6816037503373737458_3146 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 12:54:31,137 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8865386538756243868_3143 src: /192.168.1.157:55668 dest: /192.168.1.157:50010
2017-05-23 12:54:31,138 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8865386538756243868_3143 src: /192.168.1.157:55668 dest: /192.168.1.157:50010 of size 4325
2017-05-23 12:54:35,030 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 12:54:35,321 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 12:54:40,654 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 12:54:40,783 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 12:54:40,959 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 12:54:41,480 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 12:54:47,176 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 12:54:56,645 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 12:54:56,911 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-23 12:55:02,954 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 12:56:13,176 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3554292340354576464_3150 src: /192.168.1.157:55730 dest: /192.168.1.157:50010
2017-05-23 12:56:13,177 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3554292340354576464_3150 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 12:56:13,177 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 12:56:16,379 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2583205534700951830_3144 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2583205534700951830
2017-05-23 12:56:16,379 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5025264319305335384_3142 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5025264319305335384
2017-05-23 12:56:16,380 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_6816037503373737458_3146 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_6816037503373737458
2017-05-23 12:56:16,380 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8865386538756243868_3143 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8865386538756243868
2017-05-23 12:56:23,452 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 12:56:34,230 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 12:56:34,445 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 12:56:34,447 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 12:56:34,449 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 12:56:34,512 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 12:56:34,560 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 12:56:34,561 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 12:56:34,561 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 12:56:34,774 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-23 12:56:34,807 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 12:56:34,823 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 12:56:34,823 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-23 12:56:34,830 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 12:56:34,848 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 12:56:34,852 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 12:56:34,853 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 12:56:34,854 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 12:56:34,855 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 12:56:34,855 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 12:56:34,855 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 12:56:34,857 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 12:56:34,858 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 12:56:34,865 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 12:56:37,866 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-23 12:57:40,275 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 12:57:40,865 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-374044989188119601_3153 src: /192.168.1.157:55748 dest: /192.168.1.157:50010
2017-05-23 12:57:40,883 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-374044989188119601_3153 src: /192.168.1.157:55748 dest: /192.168.1.157:50010 of size 13560
2017-05-23 12:57:40,906 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1837313616365764439_3151 src: /192.168.1.158:39217 dest: /192.168.1.158:50010
2017-05-23 12:57:40,916 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1837313616365764439_3151 src: /192.168.1.158:39217 dest: /192.168.1.158:50010 of size 91176
2017-05-23 12:57:43,864 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1724841834941669624_3155 src: /192.168.1.157:55749 dest: /192.168.1.157:50010
2017-05-23 12:57:43,865 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1724841834941669624_3155 src: /192.168.1.157:55749 dest: /192.168.1.157:50010 of size 13545
2017-05-23 12:57:45,333 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 12:57:45,425 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 12:57:46,923 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4826486158122730011_3152 src: /192.168.1.158:39224 dest: /192.168.1.158:50010
2017-05-23 12:57:46,925 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4826486158122730011_3152 src: /192.168.1.158:39224 dest: /192.168.1.158:50010 of size 4325
2017-05-23 12:57:55,423 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 12:58:01,656 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 12:58:11,273 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 12:58:11,900 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 12:59:28,933 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6082679771858361255_3159 src: /192.168.1.156:40255 dest: /192.168.1.156:50010
2017-05-23 12:59:28,934 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-6082679771858361255_3159 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 12:59:28,936 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 12:59:31,946 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4826486158122730011_3152 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4826486158122730011
2017-05-23 12:59:31,946 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-374044989188119601_3153 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-374044989188119601
2017-05-23 12:59:31,947 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1724841834941669624_3155 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1724841834941669624
2017-05-23 12:59:31,947 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1837313616365764439_3151 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1837313616365764439
2017-05-23 12:59:38,063 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 12:59:48,934 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 12:59:49,135 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 12:59:49,137 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 12:59:49,139 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 12:59:49,211 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 12:59:49,270 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 12:59:49,271 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 12:59:49,271 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 12:59:49,510 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 12:59:49,548 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 12:59:49,550 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 12:59:49,551 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 12:59:49,555 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 12:59:49,573 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 12:59:49,578 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 12:59:49,578 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 12:59:49,579 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 12:59:49,580 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 12:59:49,580 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 12:59:49,580 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 12:59:49,583 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 12:59:49,583 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 12:59:49,591 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 12:59:52,591 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 7 msecs
2017-05-23 13:00:55,588 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3442509156148853560_3162 src: /192.168.1.156:40269 dest: /192.168.1.156:50010
2017-05-23 13:00:55,602 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3442509156148853560_3162 src: /192.168.1.156:40269 dest: /192.168.1.156:50010 of size 13560
2017-05-23 13:00:55,609 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-7364268627680045897_3160 src: /192.168.1.157:55831 dest: /192.168.1.157:50010
2017-05-23 13:00:55,622 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-7364268627680045897_3160 src: /192.168.1.157:55831 dest: /192.168.1.157:50010 of size 91176
2017-05-23 13:00:58,574 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1204729104645779302_3164 src: /192.168.1.156:40270 dest: /192.168.1.156:50010
2017-05-23 13:00:58,575 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_1204729104645779302_3164 src: /192.168.1.156:40271 dest: /192.168.1.156:50010
2017-05-23 13:00:58,577 INFO org.apache.hadoop.dfs.DataNode: Received block blk_1204729104645779302_3164 src: /192.168.1.156:40270 dest: /192.168.1.156:50010 of size 13545
2017-05-23 13:00:58,577 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_1204729104645779302_3164 received exception java.io.IOException: Block blk_1204729104645779302_3164 is valid, and cannot be written to.
2017-05-23 13:00:58,578 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_1204729104645779302_3164 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 13:00:58,614 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5189446302534594627_3161 src: /192.168.1.157:55833 dest: /192.168.1.157:50010
2017-05-23 13:00:58,615 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5189446302534594627_3161 src: /192.168.1.157:55833 dest: /192.168.1.157:50010 of size 4325
2017-05-23 13:01:01,641 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_1204729104645779302_3164 to 192.168.1.158:50010
2017-05-23 13:01:01,647 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_1204729104645779302_3164 to /192.168.1.158:50010
2017-05-23 13:01:04,495 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 13:01:10,260 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 13:01:10,566 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 13:01:11,455 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 13:01:16,572 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 13:01:24,540 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 13:01:25,152 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 13:01:33,991 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 13:02:46,797 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-7364268627680045897_3160 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-7364268627680045897
2017-05-23 13:02:46,798 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5189446302534594627_3161 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5189446302534594627
2017-05-23 13:02:46,798 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3442509156148853560_3162 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3442509156148853560
2017-05-23 13:02:46,799 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_1204729104645779302_3164 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_1204729104645779302
2017-05-23 13:02:55,365 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 13:03:06,181 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 13:03:06,383 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 13:03:06,385 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 13:03:06,386 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 13:03:06,460 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 13:03:06,520 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 13:03:06,521 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 13:03:06,521 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 13:03:06,730 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-05-23 13:03:06,758 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 13:03:06,760 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 13:03:06,760 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-23 13:03:06,764 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 13:03:06,786 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 13:03:06,792 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 13:03:06,792 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 13:03:06,794 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 13:03:06,795 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 13:03:06,795 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 13:03:06,796 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 13:03:06,798 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 13:03:06,799 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 13:03:06,807 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 13:03:09,810 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-23 13:04:06,917 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8046187868727531892_3169 src: /192.168.1.156:40342 dest: /192.168.1.156:50010
2017-05-23 13:04:06,921 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8165638643410809231_3173 src: /192.168.1.158:39336 dest: /192.168.1.158:50010
2017-05-23 13:04:06,936 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8165638643410809231_3173 src: /192.168.1.158:39336 dest: /192.168.1.158:50010 of size 13545
2017-05-23 13:04:06,940 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8046187868727531892_3169 src: /192.168.1.156:40342 dest: /192.168.1.156:50010 of size 91176
2017-05-23 13:04:07,249 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 13:04:07,290 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 13:04:09,885 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2902437180818518573_3171 src: /192.168.1.157:55922 dest: /192.168.1.157:50010
2017-05-23 13:04:09,888 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2902437180818518573_3171 src: /192.168.1.157:55922 dest: /192.168.1.157:50010 of size 13560
2017-05-23 13:04:09,900 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2902437180818518573_3171 src: /192.168.1.156:40349 dest: /192.168.1.156:50010
2017-05-23 13:04:09,900 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_2902437180818518573_3171 received exception java.io.IOException: Block blk_2902437180818518573_3171 is valid, and cannot be written to.
2017-05-23 13:04:09,901 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_2902437180818518573_3171 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 13:04:09,901 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1394467029420769030_3170 src: /192.168.1.156:40350 dest: /192.168.1.156:50010
2017-05-23 13:04:09,902 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1394467029420769030_3170 src: /192.168.1.156:40350 dest: /192.168.1.156:50010 of size 2165
2017-05-23 13:04:12,436 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 13:04:12,490 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 13:04:27,620 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 13:04:28,410 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 13:04:32,317 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 13:04:32,534 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 13:04:38,273 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 13:04:39,544 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 13:06:15,941 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8046187868727531892_3169 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8046187868727531892
2017-05-23 13:06:15,941 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1394467029420769030_3170 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1394467029420769030
2017-05-23 13:06:15,942 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2902437180818518573_3171 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2902437180818518573
2017-05-23 13:06:18,938 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8165638643410809231_3173 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8165638643410809231
2017-05-23 13:06:24,047 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 13:06:34,703 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 13:06:34,890 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 13:06:34,892 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 13:06:34,894 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 13:06:34,959 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 13:06:35,021 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 13:06:35,022 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 13:06:35,022 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 13:06:35,268 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@d08435
2017-05-23 13:06:35,305 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 13:06:35,308 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 13:06:35,308 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 13:06:35,313 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 13:06:35,335 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 13:06:35,340 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 13:06:35,341 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 13:06:35,341 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 13:06:35,341 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 13:06:35,342 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 13:06:35,342 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 13:06:35,358 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 13:06:35,359 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 13:06:35,373 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 13:06:38,377 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-05-23 13:07:40,940 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 13:07:40,973 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 13:07:41,577 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2431735381961868482_3180 src: /192.168.1.156:40425 dest: /192.168.1.156:50010
2017-05-23 13:07:41,593 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2431735381961868482_3180 src: /192.168.1.156:40425 dest: /192.168.1.156:50010 of size 2165
2017-05-23 13:07:41,618 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_495015642118612209_3179 src: /192.168.1.158:39386 dest: /192.168.1.158:50010
2017-05-23 13:07:41,664 INFO org.apache.hadoop.dfs.DataNode: Received block blk_495015642118612209_3179 src: /192.168.1.158:39386 dest: /192.168.1.158:50010 of size 91176
2017-05-23 13:07:44,572 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8646339162608206025_3183 src: /192.168.1.156:40426 dest: /192.168.1.156:50010
2017-05-23 13:07:44,573 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8646339162608206025_3183 src: /192.168.1.156:40426 dest: /192.168.1.156:50010 of size 13545
2017-05-23 13:07:44,582 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_916211753619068073_3181 src: /192.168.1.156:40427 dest: /192.168.1.156:50010
2017-05-23 13:07:44,582 INFO org.apache.hadoop.dfs.DataNode: Received block blk_916211753619068073_3181 src: /192.168.1.156:40427 dest: /192.168.1.156:50010 of size 13560
2017-05-23 13:07:44,598 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_916211753619068073_3181 src: /192.168.1.157:55991 dest: /192.168.1.157:50010
2017-05-23 13:07:44,598 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_916211753619068073_3181 received exception java.io.IOException: Block blk_916211753619068073_3181 is valid, and cannot be written to.
2017-05-23 13:07:44,599 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_916211753619068073_3181 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 13:07:45,984 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 13:07:46,264 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 13:07:47,426 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_916211753619068073_3181 to 192.168.1.158:50010
2017-05-23 13:07:47,429 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_916211753619068073_3181 to /192.168.1.158:50010
2017-05-23 13:08:01,843 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 13:08:02,622 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 13:08:05,679 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-23 13:08:06,200 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 13:08:07,134 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 13:09:41,626 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1685936182148126638_3188 src: /192.168.1.158:39421 dest: /192.168.1.158:50010
2017-05-23 13:09:41,628 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1685936182148126638_3188 src: /192.168.1.158:39421 dest: /192.168.1.158:50010 of size 30893
2017-05-23 13:09:44,484 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_495015642118612209_3179 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_495015642118612209
2017-05-23 13:09:44,484 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_916211753619068073_3181 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_916211753619068073
2017-05-23 13:09:44,485 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2431735381961868482_3180 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2431735381961868482
2017-05-23 13:09:44,637 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_8646339162608206025_3183
2017-05-23 13:09:47,484 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1685936182148126638_3188 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1685936182148126638
2017-05-23 13:09:47,485 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8646339162608206025_3183 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8646339162608206025
2017-05-23 13:09:52,726 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 13:10:03,574 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 13:10:03,780 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 13:10:03,781 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 13:10:03,783 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 13:10:03,846 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 13:10:03,904 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 13:10:03,905 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 13:10:03,905 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 13:10:04,152 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-23 13:10:04,194 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 13:10:04,197 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 13:10:04,197 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-23 13:10:04,202 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 13:10:04,221 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 13:10:04,226 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 13:10:04,227 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 13:10:04,228 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 13:10:04,229 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 13:10:04,229 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 13:10:04,229 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 13:10:04,231 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 13:10:04,232 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 13:10:04,241 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 13:10:07,249 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 14 msecs
2017-05-23 13:11:09,609 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_4712244505860014697_1489 to /192.168.1.159
2017-05-23 13:11:09,711 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 13:11:10,273 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1147321879393106086_3191 src: /192.168.1.158:39434 dest: /192.168.1.158:50010
2017-05-23 13:11:10,284 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1147321879393106086_3191 src: /192.168.1.158:39434 dest: /192.168.1.158:50010 of size 13560
2017-05-23 13:11:10,326 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2259363823321314226_3189 src: /192.168.1.156:40498 dest: /192.168.1.156:50010
2017-05-23 13:11:10,338 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2259363823321314226_3189 src: /192.168.1.156:40498 dest: /192.168.1.156:50010 of size 91176
2017-05-23 13:11:13,258 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9036597336137267610_3190 src: /192.168.1.157:56062 dest: /192.168.1.157:50010
2017-05-23 13:11:13,258 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-9036597336137267610_3190 src: /192.168.1.157:56062 dest: /192.168.1.157:50010 of size 2165
2017-05-23 13:11:13,326 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-9036597336137267610_3190 src: /192.168.1.156:40499 dest: /192.168.1.156:50010
2017-05-23 13:11:13,327 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-9036597336137267610_3190 received exception java.io.IOException: Block blk_-9036597336137267610_3190 is valid, and cannot be written to.
2017-05-23 13:11:13,329 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-9036597336137267610_3190 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 13:11:13,330 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-315260105144588918_3193 src: /192.168.1.156:40500 dest: /192.168.1.156:50010
2017-05-23 13:11:13,332 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-315260105144588918_3193 src: /192.168.1.156:40500 dest: /192.168.1.156:50010 of size 13545
2017-05-23 13:11:14,756 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 13:11:14,974 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 13:11:30,061 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 13:11:31,560 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 13:11:35,457 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 13:11:39,754 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 13:13:19,306 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-486672273159734788_3197 src: /192.168.1.157:56112 dest: /192.168.1.157:50010
2017-05-23 13:13:19,307 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-486672273159734788_3197 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 13:13:19,307 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 13:13:22,394 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-9036597336137267610_3190 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-9036597336137267610
2017-05-23 13:13:22,394 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1147321879393106086_3191 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1147321879393106086
2017-05-23 13:13:22,395 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-315260105144588918_3193 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-315260105144588918
2017-05-23 13:13:22,395 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2259363823321314226_3189 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2259363823321314226
2017-05-23 13:50:10,469 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 13:50:21,433 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 13:50:21,650 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 13:50:21,652 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 13:50:21,654 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 13:50:21,725 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 13:50:21,783 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 13:50:21,784 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 13:50:21,784 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 13:50:22,014 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 13:50:22,053 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 13:50:22,055 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 13:50:22,056 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 13:50:22,060 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 13:50:22,078 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 13:50:22,083 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 13:50:22,084 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 13:50:22,085 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 13:50:22,085 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 13:50:22,085 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 13:50:22,086 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 13:50:22,089 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 13:50:22,090 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 13:50:22,099 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 13:50:25,098 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-23 13:51:22,091 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6724303720476379295_3198 src: /192.168.1.157:56123 dest: /192.168.1.157:50010
2017-05-23 13:51:22,091 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6702892016771290351_3200 src: /192.168.1.158:39472 dest: /192.168.1.158:50010
2017-05-23 13:51:22,115 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6702892016771290351_3200 src: /192.168.1.158:39472 dest: /192.168.1.158:50010 of size 13560
2017-05-23 13:51:22,116 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6724303720476379295_3198 src: /192.168.1.157:56123 dest: /192.168.1.157:50010 of size 91176
2017-05-23 13:51:22,434 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 13:51:22,499 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 13:51:25,018 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7976001094792957225_3199 src: /192.168.1.156:40575 dest: /192.168.1.156:50010
2017-05-23 13:51:25,026 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7976001094792957225_3199 src: /192.168.1.156:40575 dest: /192.168.1.156:50010 of size 2165
2017-05-23 13:51:25,081 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6849614921200238707_3202 src: /192.168.1.157:56129 dest: /192.168.1.157:50010
2017-05-23 13:51:25,083 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6849614921200238707_3202 src: /192.168.1.157:56129 dest: /192.168.1.157:50010 of size 13545
2017-05-23 13:51:38,908 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 13:51:39,141 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 13:51:47,521 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 13:51:47,620 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 13:52:04,305 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 13:52:08,390 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 13:52:09,373 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5677317980074053770_1489 to /192.168.1.159
2017-05-23 13:52:24,261 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 13:52:25,038 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8304980367755669787_1489 to /192.168.1.159
2017-05-23 13:52:28,442 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 13:52:29,507 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 13:52:44,465 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-23 13:52:45,020 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 13:53:34,222 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6849614921200238707_3202 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6849614921200238707
2017-05-23 13:53:34,223 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6724303720476379295_3198 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6724303720476379295
2017-05-23 13:53:34,224 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6702892016771290351_3200 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6702892016771290351
2017-05-23 13:53:34,224 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7976001094792957225_3199 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7976001094792957225
2017-05-23 13:53:40,321 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 13:53:51,192 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 13:53:51,379 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 13:53:51,381 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 13:53:51,383 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 13:53:51,440 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 13:53:51,487 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 13:53:51,488 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 13:53:51,488 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 13:53:51,704 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@72bcaa
2017-05-23 13:53:51,741 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 13:53:51,744 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 13:53:51,744 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 13:53:51,749 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 13:53:51,769 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 13:53:51,774 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 13:53:51,775 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 13:53:51,775 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 13:53:51,776 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 13:53:51,776 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 13:53:51,776 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 13:53:51,790 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 13:53:51,790 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 13:53:51,803 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 13:53:54,808 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 15 msecs
2017-05-23 13:54:57,289 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8274778013988380753_1489 to /192.168.1.159
2017-05-23 13:54:57,289 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8370710552611077688_1489 to /192.168.1.159
2017-05-23 13:54:57,884 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1154903814587225049_3208 src: /192.168.1.157:56200 dest: /192.168.1.157:50010
2017-05-23 13:54:57,899 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1154903814587225049_3208 src: /192.168.1.157:56200 dest: /192.168.1.157:50010 of size 2165
2017-05-23 13:54:57,999 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4703668165258761292_3207 src: /192.168.1.158:39530 dest: /192.168.1.158:50010
2017-05-23 13:54:58,000 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4703668165258761292_3207 src: /192.168.1.158:39530 dest: /192.168.1.158:50010 of size 91176
2017-05-23 13:55:00,881 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3890150433056914293_3209 src: /192.168.1.157:56201 dest: /192.168.1.157:50010
2017-05-23 13:55:00,883 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3890150433056914293_3209 src: /192.168.1.157:56201 dest: /192.168.1.157:50010 of size 13560
2017-05-23 13:55:00,974 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2258922319258523681_3211 src: /192.168.1.156:40654 dest: /192.168.1.156:50010
2017-05-23 13:55:00,976 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2258922319258523681_3211 src: /192.168.1.156:40654 dest: /192.168.1.156:50010 of size 13545
2017-05-23 13:55:00,980 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2258922319258523681_3211 src: /192.168.1.156:40655 dest: /192.168.1.156:50010
2017-05-23 13:55:00,980 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_-2258922319258523681_3211 received exception java.io.IOException: Block blk_-2258922319258523681_3211 is valid, and cannot be written to.
2017-05-23 13:55:00,982 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_-2258922319258523681_3211 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 13:55:03,858 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Starting thread to transfer block blk_-2258922319258523681_3211 to 192.168.1.158:50010
2017-05-23 13:55:03,860 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):Transmitted block blk_-2258922319258523681_3211 to /192.168.1.158:50010
2017-05-23 13:55:13,960 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 13:55:14,524 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-555447371271609286_1489 to /192.168.1.159
2017-05-23 13:55:22,357 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4162966358646071653_1489 to /192.168.1.159
2017-05-23 13:55:22,414 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 13:55:38,631 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 13:55:39,559 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 13:55:57,390 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 13:55:57,396 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 13:56:13,234 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-23 13:57:03,930 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_7162347535274074735_3216 src: /192.168.1.158:39569 dest: /192.168.1.158:50010
2017-05-23 13:57:03,932 INFO org.apache.hadoop.dfs.DataNode: Received block blk_7162347535274074735_3216 src: /192.168.1.158:39569 dest: /192.168.1.158:50010 of size 29062
2017-05-23 13:57:06,936 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2258922319258523681_3211 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2258922319258523681
2017-05-23 13:57:06,937 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1154903814587225049_3208 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1154903814587225049
2017-05-23 13:57:06,937 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3890150433056914293_3209 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3890150433056914293
2017-05-23 13:57:06,938 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4703668165258761292_3207 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4703668165258761292
2017-05-23 13:57:13,196 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 13:57:24,059 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 13:57:24,263 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 13:57:24,264 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 13:57:24,266 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 13:57:24,336 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 13:57:24,395 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 13:57:24,396 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 13:57:24,396 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 13:57:24,637 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 13:57:24,676 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 13:57:24,680 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 13:57:24,680 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 13:57:24,685 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 13:57:24,708 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 13:57:24,715 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 13:57:24,716 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 13:57:24,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 13:57:24,716 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 13:57:24,716 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 13:57:24,717 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 13:57:24,718 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 13:57:24,719 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 13:57:24,725 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 13:57:24,780 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_7162347535274074735_3216
2017-05-23 13:57:27,726 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 7 msecs
2017-05-23 13:58:00,798 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_7162347535274074735_3216 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_7162347535274074735
2017-05-23 13:58:30,115 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 13:58:30,699 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2408283596318560857_3219 src: /192.168.1.157:56265 dest: /192.168.1.157:50010
2017-05-23 13:58:30,727 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2408283596318560857_3219 src: /192.168.1.157:56265 dest: /192.168.1.157:50010 of size 13560
2017-05-23 13:58:30,819 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-2898714976662854524_3217 src: /192.168.1.158:39584 dest: /192.168.1.158:50010
2017-05-23 13:58:30,824 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-2898714976662854524_3217 src: /192.168.1.158:39584 dest: /192.168.1.158:50010 of size 91176
2017-05-23 13:58:33,818 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4922907006637010368_3218 src: /192.168.1.156:40729 dest: /192.168.1.156:50010
2017-05-23 13:58:33,820 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4922907006637010368_3218 src: /192.168.1.156:40729 dest: /192.168.1.156:50010 of size 2165
2017-05-23 13:58:36,743 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2564087708883365260_3221 src: /192.168.1.158:39587 dest: /192.168.1.158:50010
2017-05-23 13:58:36,746 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2564087708883365260_3221 src: /192.168.1.158:39587 dest: /192.168.1.158:50010 of size 13545
2017-05-23 13:58:45,765 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-3883346775917650024_1489 to /192.168.1.159
2017-05-23 13:58:50,115 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 13:58:51,915 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-82003384437117534_1489 to /192.168.1.159
2017-05-23 13:58:56,996 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6096193995661509431_1489 to /192.168.1.159
2017-05-23 13:59:08,393 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8454386369769578846_1489 to /192.168.1.159
2017-05-23 13:59:12,827 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8936856107480993114_1489 to /192.168.1.159
2017-05-23 13:59:13,606 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-4765115671603473561_1489 to /192.168.1.159
2017-05-23 13:59:27,816 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8873170527515694421_1489 to /192.168.1.159
2017-05-23 13:59:35,643 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6914031266689583089_1489 to /192.168.1.159
2017-05-23 13:59:50,378 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6422910236319924635_1489 to /192.168.1.159
2017-05-23 14:00:15,893 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 28 blocks got processed in 20 msecs
2017-05-23 14:00:39,749 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3352044549350375849_3225 src: /192.168.1.158:39621 dest: /192.168.1.158:50010
2017-05-23 14:00:39,750 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3352044549350375849_3225 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 14:00:39,752 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 14:00:42,916 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2898714976662854524_3217 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2898714976662854524
2017-05-23 14:00:42,917 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-2408283596318560857_3219 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-2408283596318560857
2017-05-23 14:00:42,917 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4922907006637010368_3218 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4922907006637010368
2017-05-23 14:00:45,917 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2564087708883365260_3221 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2564087708883365260
2017-05-23 14:06:25,403 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 14:06:36,304 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 14:06:36,502 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 14:06:36,504 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 14:06:36,505 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 14:06:36,575 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 14:06:36,634 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 14:06:36,635 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 14:06:36,635 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 14:06:36,872 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 14:06:36,916 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 14:06:36,918 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 14:06:36,918 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 14:06:36,924 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 14:06:36,943 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 14:06:36,948 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 14:06:36,949 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 14:06:36,951 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 14:06:36,951 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 14:06:36,952 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 14:06:36,952 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 14:06:36,956 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 14:06:36,956 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 14:06:36,964 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 14:06:39,964 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-23 14:07:37,007 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8716990378626445377_3226 src: /192.168.1.157:56329 dest: /192.168.1.157:50010
2017-05-23 14:07:37,019 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3661862340699266196_3227 src: /192.168.1.156:40790 dest: /192.168.1.156:50010
2017-05-23 14:07:37,050 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8716990378626445377_3226 src: /192.168.1.157:56329 dest: /192.168.1.157:50010 of size 91176
2017-05-23 14:07:37,056 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3661862340699266196_3227 src: /192.168.1.156:40790 dest: /192.168.1.156:50010 of size 1085
2017-05-23 14:07:37,298 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-23 14:07:37,361 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-23 14:07:40,008 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-6709704970165139514_3230 src: /192.168.1.156:40796 dest: /192.168.1.156:50010
2017-05-23 14:07:40,013 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-6709704970165139514_3230 src: /192.168.1.156:40796 dest: /192.168.1.156:50010 of size 13544
2017-05-23 14:07:42,963 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-316559553911310849_3228 src: /192.168.1.158:39638 dest: /192.168.1.158:50010
2017-05-23 14:07:42,964 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-316559553911310849_3228 src: /192.168.1.158:39638 dest: /192.168.1.158:50010 of size 13559
2017-05-23 14:07:54,046 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-23 14:07:56,077 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-8960126721114299935_1001 to /192.168.1.159
2017-05-23 14:09:10,050 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5470871555693996928_3234 src: /192.168.1.158:39652 dest: /192.168.1.158:50010
2017-05-23 14:09:10,051 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5470871555693996928_3234 src: /192.168.1.158:39652 dest: /192.168.1.158:50010 of size 16237
2017-05-23 14:09:13,101 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-6709704970165139514_3230 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-6709704970165139514
2017-05-23 14:09:13,101 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3661862340699266196_3227 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3661862340699266196
2017-05-23 14:09:13,102 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-316559553911310849_3228 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-316559553911310849
2017-05-23 14:09:13,102 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8716990378626445377_3226 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8716990378626445377
2017-05-23 14:09:19,274 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 14:09:30,278 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 14:09:30,492 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 14:09:30,494 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 14:09:30,496 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 14:09:30,560 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 14:09:30,612 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 14:09:30,613 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 14:09:30,613 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 14:09:30,836 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-23 14:09:30,876 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 14:09:30,879 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 14:09:30,880 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 14:09:30,884 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 14:09:30,908 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 14:09:30,916 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 14:09:30,917 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 14:09:30,917 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 14:09:30,918 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 14:09:30,918 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 14:09:30,918 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 14:09:30,921 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 14:09:30,922 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 14:09:30,929 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 14:09:30,974 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_5470871555693996928_3234
2017-05-23 14:09:33,933 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 8 msecs
2017-05-23 14:10:06,966 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5470871555693996928_3234 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5470871555693996928
2017-05-23 14:10:36,279 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-23 14:10:36,904 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3774595138859862449_3235 src: /192.168.1.158:39666 dest: /192.168.1.158:50010
2017-05-23 14:10:36,914 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3774595138859862449_3235 src: /192.168.1.158:39666 dest: /192.168.1.158:50010 of size 91176
2017-05-23 14:10:36,978 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4678925850321584906_3237 src: /192.168.1.156:40841 dest: /192.168.1.156:50010
2017-05-23 14:10:36,980 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4678925850321584906_3237 src: /192.168.1.156:40841 dest: /192.168.1.156:50010 of size 13559
2017-05-23 14:10:39,888 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4903419839044418329_3239 src: /192.168.1.157:56374 dest: /192.168.1.157:50010
2017-05-23 14:10:39,891 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4903419839044418329_3239 src: /192.168.1.157:56374 dest: /192.168.1.157:50010 of size 13544
2017-05-23 14:10:42,949 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_136092768011682429_3236 src: /192.168.1.158:39669 dest: /192.168.1.158:50010
2017-05-23 14:10:42,950 INFO org.apache.hadoop.dfs.DataNode: Received block blk_136092768011682429_3236 src: /192.168.1.158:39669 dest: /192.168.1.158:50010 of size 1085
2017-05-23 14:10:53,047 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-23 14:10:57,269 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-23 14:11:04,025 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-23 14:11:20,869 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-23 14:12:07,025 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3308257920616375146_3243 src: /192.168.1.158:39678 dest: /192.168.1.158:50010
2017-05-23 14:12:07,026 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_3308257920616375146_3243 received exception org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
2017-05-23 14:12:07,028 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException: Insufficient space for an additional block
	at org.apache.hadoop.dfs.FSDataset$FSVolumeSet.getNextVolume(FSDataset.java:476)
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:930)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 14:12:10,012 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4678925850321584906_3237 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4678925850321584906
2017-05-23 14:12:10,013 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3774595138859862449_3235 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3774595138859862449
2017-05-23 14:12:10,013 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_136092768011682429_3236 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_136092768011682429
2017-05-23 14:12:13,018 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4903419839044418329_3239 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4903419839044418329
2017-05-23 14:12:17,971 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 14:12:28,822 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 14:12:29,020 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 14:12:29,022 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 14:12:29,023 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 14:12:29,084 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 14:12:29,134 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 14:12:29,135 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 14:12:29,135 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 14:12:29,359 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@18972cf
2017-05-23 14:12:29,395 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 14:12:29,398 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 14:12:29,398 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-23 14:12:29,403 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 14:12:29,423 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 14:12:29,429 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 14:12:29,430 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 14:12:29,430 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 14:12:29,430 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 14:12:29,431 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 14:12:29,431 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 14:12:29,433 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 14:12:29,434 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 14:12:29,443 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 14:12:32,445 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 8 msecs
2017-05-23 14:13:34,894 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-23 14:13:34,930 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-23 14:13:35,453 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3997848848541946394_3246 src: /192.168.1.158:39692 dest: /192.168.1.158:50010
2017-05-23 14:13:35,467 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3997848848541946394_3246 src: /192.168.1.158:39692 dest: /192.168.1.158:50010 of size 13559
2017-05-23 14:13:35,504 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_3239642703164839461_3244 src: /192.168.1.156:40883 dest: /192.168.1.156:50010
2017-05-23 14:13:35,508 INFO org.apache.hadoop.dfs.DataNode: Received block blk_3239642703164839461_3244 src: /192.168.1.156:40883 dest: /192.168.1.156:50010 of size 91176
2017-05-23 14:13:38,435 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8663367492590211957_3248 src: /192.168.1.157:56411 dest: /192.168.1.157:50010
2017-05-23 14:13:38,437 INFO org.apache.hadoop.dfs.DataNode: Received block blk_8663367492590211957_3248 src: /192.168.1.157:56411 dest: /192.168.1.157:50010 of size 13544
2017-05-23 14:13:38,505 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_8663367492590211957_3248 src: /192.168.1.156:40885 dest: /192.168.1.156:50010
2017-05-23 14:13:38,506 INFO org.apache.hadoop.dfs.DataNode: writeBlock blk_8663367492590211957_3248 received exception java.io.IOException: Block blk_8663367492590211957_3248 is valid, and cannot be written to.
2017-05-23 14:13:38,507 ERROR org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020):DataXceiver: java.io.IOException: Block blk_8663367492590211957_3248 is valid, and cannot be written to.
	at org.apache.hadoop.dfs.FSDataset.writeToBlock(FSDataset.java:892)
	at org.apache.hadoop.dfs.DataNode$BlockReceiver.<init>(DataNode.java:2320)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.writeBlock(DataNode.java:1187)
	at org.apache.hadoop.dfs.DataNode$DataXceiver.run(DataNode.java:1045)
	at java.lang.Thread.run(Thread.java:722)

2017-05-23 14:13:41,443 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5145728734856682670_3245 src: /192.168.1.158:39695 dest: /192.168.1.158:50010
2017-05-23 14:13:41,443 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5145728734856682670_3245 src: /192.168.1.158:39695 dest: /192.168.1.158:50010 of size 1085
2017-05-23 14:13:50,620 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-23 14:13:51,245 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-23 14:15:08,477 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1511227358245202736_3252 src: /192.168.1.158:39713 dest: /192.168.1.158:50010
2017-05-23 14:15:08,479 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1511227358245202736_3252 src: /192.168.1.158:39713 dest: /192.168.1.158:50010 of size 18763
2017-05-23 14:15:11,506 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1511227358245202736_3252 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1511227358245202736
2017-05-23 14:15:11,507 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3239642703164839461_3244 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3239642703164839461
2017-05-23 14:15:11,507 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_3997848848541946394_3246 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_3997848848541946394
2017-05-23 14:15:11,508 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5145728734856682670_3245 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5145728734856682670
2017-05-23 14:15:11,508 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_8663367492590211957_3248 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_8663367492590211957
2017-05-23 14:15:20,459 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 14:15:31,292 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 14:15:31,487 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 14:15:31,489 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 14:15:31,491 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 14:15:31,554 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 14:15:31,609 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 14:15:31,610 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 14:15:31,611 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 14:15:31,844 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-23 14:15:31,880 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 14:15:31,883 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 14:15:31,883 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1d58963
2017-05-23 14:15:31,888 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 14:15:31,906 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 14:15:31,911 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 14:15:31,912 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 14:15:31,913 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 14:15:31,914 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 14:15:31,914 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 14:15:31,914 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 14:15:31,917 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 14:15:31,917 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 14:15:31,924 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 14:15:34,922 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 5 msecs
2017-05-23 14:16:31,974 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8931496523707957400_3257 src: /192.168.1.158:39721 dest: /192.168.1.158:50010
2017-05-23 14:16:31,986 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8931496523707957400_3257 src: /192.168.1.158:39721 dest: /192.168.1.158:50010 of size 13544
2017-05-23 14:16:32,015 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4028168609807977532_3253 src: /192.168.1.156:40923 dest: /192.168.1.156:50010
2017-05-23 14:16:32,021 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4028168609807977532_3253 src: /192.168.1.156:40923 dest: /192.168.1.156:50010 of size 91176
2017-05-23 14:16:32,306 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-23 14:16:32,339 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-23 14:16:34,914 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5113284168763132816_3255 src: /192.168.1.157:56459 dest: /192.168.1.157:50010
2017-05-23 14:16:34,916 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5113284168763132816_3255 src: /192.168.1.157:56459 dest: /192.168.1.157:50010 of size 13559
2017-05-23 14:16:34,998 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4221400218299289261_3254 src: /192.168.1.156:40931 dest: /192.168.1.156:50010
2017-05-23 14:16:35,000 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4221400218299289261_3254 src: /192.168.1.156:40931 dest: /192.168.1.156:50010 of size 1085
2017-05-23 14:16:48,339 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-23 14:16:49,284 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-23 14:16:57,318 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_1989889279775532485_1001 to /192.168.1.159
2017-05-23 14:17:13,746 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_8274412040191428808_1001 to /192.168.1.159
2017-05-23 14:18:04,944 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3267035015444945202_3258 src: /192.168.1.157:56482 dest: /192.168.1.157:50010
2017-05-23 14:18:05,749 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3267035015444945202_3258 src: /192.168.1.157:56482 dest: /192.168.1.157:50010 of size 31981189
2017-05-23 14:18:10,954 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_2468887385454687219_3261 src: /192.168.1.158:39748 dest: /192.168.1.158:50010
2017-05-23 14:18:10,956 INFO org.apache.hadoop.dfs.DataNode: Received block blk_2468887385454687219_3261 src: /192.168.1.158:39748 dest: /192.168.1.158:50010 of size 19296
2017-05-23 14:18:11,038 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_811310828943595628_3261 src: /192.168.1.156:40964 dest: /192.168.1.156:50010
2017-05-23 14:18:12,097 INFO org.apache.hadoop.dfs.DataNode: Received block blk_811310828943595628_3261 src: /192.168.1.156:40964 dest: /192.168.1.156:50010 of size 31976695
2017-05-23 14:18:14,007 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5113284168763132816_3255 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5113284168763132816
2017-05-23 14:18:14,008 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4028168609807977532_3253 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4028168609807977532
2017-05-23 14:18:14,008 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4221400218299289261_3254 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4221400218299289261
2017-05-23 14:18:17,010 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8931496523707957400_3257 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8931496523707957400
2017-05-23 14:18:17,020 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3267035015444945202_3258 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3267035015444945202
2017-05-23 14:18:17,029 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_811310828943595628_3261 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_811310828943595628
2017-05-23 14:18:17,029 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_2468887385454687219_3261 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_2468887385454687219
2017-05-23 14:18:22,204 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 14:18:33,080 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 14:18:33,278 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 14:18:33,280 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 14:18:33,281 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 14:18:33,354 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 14:18:33,412 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 14:18:33,413 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 14:18:33,413 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 14:18:33,663 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@c06d57
2017-05-23 14:18:33,702 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 14:18:33,706 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 14:18:33,706 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@2ee666
2017-05-23 14:18:33,712 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 14:18:33,730 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 14:18:33,735 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 14:18:33,736 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 14:18:33,737 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 14:18:33,738 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 14:18:33,738 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 14:18:33,738 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 14:18:33,741 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 14:18:33,741 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 14:18:33,749 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 14:18:36,750 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 6 msecs
2017-05-23 14:19:39,233 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-23 14:19:39,233 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-23 14:19:39,779 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-5226738620255076463_3262 src: /192.168.1.158:39762 dest: /192.168.1.158:50010
2017-05-23 14:19:39,793 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-5226738620255076463_3262 src: /192.168.1.158:39762 dest: /192.168.1.158:50010 of size 91176
2017-05-23 14:19:39,823 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4714337160106308340_3264 src: /192.168.1.156:40977 dest: /192.168.1.156:50010
2017-05-23 14:19:39,826 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4714337160106308340_3264 src: /192.168.1.156:40977 dest: /192.168.1.156:50010 of size 13559
2017-05-23 14:19:42,751 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-8823724049351000776_3266 src: /192.168.1.157:56503 dest: /192.168.1.157:50010
2017-05-23 14:19:42,751 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-8823724049351000776_3266 src: /192.168.1.157:56503 dest: /192.168.1.157:50010 of size 13544
2017-05-23 14:19:42,753 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5442227028032903868_3263 src: /192.168.1.157:56504 dest: /192.168.1.157:50010
2017-05-23 14:19:42,754 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5442227028032903868_3263 src: /192.168.1.157:56504 dest: /192.168.1.157:50010 of size 1085
2017-05-23 14:19:55,666 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-23 14:19:56,044 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-23 14:20:04,170 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-23 14:21:06,858 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4775863142767846771_3270 src: /192.168.1.158:39779 dest: /192.168.1.158:50010
2017-05-23 14:21:06,860 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4775863142767846771_3270 src: /192.168.1.158:39779 dest: /192.168.1.158:50010 of size 17149
2017-05-23 14:21:09,789 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4330948016167658630_3270 src: /192.168.1.157:56531 dest: /192.168.1.157:50010
2017-05-23 14:21:10,490 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4330948016167658630_3270 src: /192.168.1.157:56531 dest: /192.168.1.157:50010 of size 31964396
2017-05-23 14:21:12,817 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-8823724049351000776_3266 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-8823724049351000776
2017-05-23 14:21:12,817 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-5226738620255076463_3262 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-5226738620255076463
2017-05-23 14:21:12,818 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4775863142767846771_3270 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4775863142767846771
2017-05-23 14:21:12,818 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4714337160106308340_3264 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4714337160106308340
2017-05-23 14:21:12,819 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5442227028032903868_3263 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5442227028032903868
2017-05-23 14:21:18,052 INFO org.apache.hadoop.dfs.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at secondvm5/192.168.1.159
************************************************************/
2017-05-23 14:21:28,891 INFO org.apache.hadoop.dfs.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = secondvm5/192.168.1.159
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 0.18.0
STARTUP_MSG:   build = http://svn.apache.org/repos/asf/hadoop/core/branches/branch-0.18 -r 686010; compiled by 'hadoopqa' on Thu Aug 14 19:48:33 UTC 2008
************************************************************/
2017-05-23 14:21:29,078 INFO org.apache.hadoop.dfs.DataNode: Registered FSDatasetStatusMBean
2017-05-23 14:21:29,080 INFO org.apache.hadoop.dfs.DataNode: Opened info server at 50010
2017-05-23 14:21:29,081 INFO org.apache.hadoop.dfs.DataNode: Balancing bandwith is 1048576 bytes/s
2017-05-23 14:21:29,135 INFO org.mortbay.util.Credential: Checking Resource aliases
2017-05-23 14:21:29,183 INFO org.mortbay.http.HttpServer: Version Jetty/5.1.4
2017-05-23 14:21:29,184 INFO org.mortbay.util.Container: Started HttpContext[/static,/static]
2017-05-23 14:21:29,184 INFO org.mortbay.util.Container: Started HttpContext[/logs,/logs]
2017-05-23 14:21:29,387 INFO org.mortbay.util.Container: Started org.mortbay.jetty.servlet.WebApplicationHandler@197f18a
2017-05-23 14:21:29,417 INFO org.mortbay.util.Container: Started WebApplicationContext[/,/]
2017-05-23 14:21:29,419 INFO org.mortbay.http.SocketListener: Started SocketListener on 0.0.0.0:50075
2017-05-23 14:21:29,419 INFO org.mortbay.util.Container: Started org.mortbay.jetty.Server@1185689
2017-05-23 14:21:29,424 INFO org.apache.hadoop.metrics.jvm.JvmMetrics: Initializing JVM Metrics with processName=DataNode, sessionId=null
2017-05-23 14:21:29,440 INFO org.apache.hadoop.ipc.metrics.RpcMetrics: Initializing RPC Metrics with hostName=DataNode, port=50020
2017-05-23 14:21:29,445 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2017-05-23 14:21:29,446 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2017-05-23 14:21:29,447 INFO org.apache.hadoop.ipc.Server: IPC Server handler 0 on 50020: starting
2017-05-23 14:21:29,448 INFO org.apache.hadoop.ipc.Server: IPC Server handler 1 on 50020: starting
2017-05-23 14:21:29,448 INFO org.apache.hadoop.dfs.DataNode: dnRegistration = DatanodeRegistration(secondvm5:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)
2017-05-23 14:21:29,448 INFO org.apache.hadoop.ipc.Server: IPC Server handler 2 on 50020: starting
2017-05-23 14:21:29,450 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020)In DataNode.run, data = FSDataset{dirpath='/home/ubuntu/old_hadoop_temp/dfs/data/current'}
2017-05-23 14:21:29,450 INFO org.apache.hadoop.dfs.DataNode: using BLOCKREPORT_INTERVAL of 3600000msec Initial delay: 0msec
2017-05-23 14:21:29,457 INFO org.apache.hadoop.dfs.DataNode: Starting Periodic block scanner.
2017-05-23 14:21:32,463 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 8 msecs
2017-05-23 14:21:58,287 INFO org.apache.hadoop.dfs.DataBlockScanner: Verification succeeded for blk_4330948016167658630_3270
2017-05-23 14:22:05,505 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4330948016167658630_3270 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4330948016167658630
2017-05-23 14:22:35,084 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_6828596650668451241_1001 to /192.168.1.159
2017-05-23 14:22:35,102 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-5714383415080207311_1001 to /192.168.1.159
2017-05-23 14:22:35,512 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3728342871020792467_3275 src: /192.168.1.156:41020 dest: /192.168.1.156:50010
2017-05-23 14:22:35,528 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3728342871020792467_3275 src: /192.168.1.156:41020 dest: /192.168.1.156:50010 of size 13544
2017-05-23 14:22:35,591 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_4715534340649059289_3271 src: /192.168.1.157:56546 dest: /192.168.1.157:50010
2017-05-23 14:22:35,601 INFO org.apache.hadoop.dfs.DataNode: Received block blk_4715534340649059289_3271 src: /192.168.1.157:56546 dest: /192.168.1.157:50010 of size 91176
2017-05-23 14:22:38,512 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-3429763027466752315_3272 src: /192.168.1.156:41022 dest: /192.168.1.156:50010
2017-05-23 14:22:38,513 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-3429763027466752315_3272 src: /192.168.1.156:41022 dest: /192.168.1.156:50010 of size 1085
2017-05-23 14:22:41,617 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4221972736090145134_3273 src: /192.168.1.158:39795 dest: /192.168.1.158:50010
2017-05-23 14:22:41,618 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4221972736090145134_3273 src: /192.168.1.158:39795 dest: /192.168.1.158:50010 of size 13559
2017-05-23 14:22:51,735 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_-6261442317249549109_1001 to /192.168.1.159
2017-05-23 14:22:52,053 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_3343421719657974443_1001 to /192.168.1.159
2017-05-23 14:23:00,072 INFO org.apache.hadoop.dfs.DataNode: DatanodeRegistration(192.168.1.159:50010, storageID=DS-2051926727-192.168.1.159-50010-1495296278987, infoPort=50075, ipcPort=50020) Served block blk_5765559863906286956_1001 to /192.168.1.159
2017-05-23 14:24:08,559 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_5022035293455470419_3279 src: /192.168.1.158:39810 dest: /192.168.1.158:50010
2017-05-23 14:24:08,561 INFO org.apache.hadoop.dfs.DataNode: Received block blk_5022035293455470419_3279 src: /192.168.1.158:39810 dest: /192.168.1.158:50010 of size 17149
2017-05-23 14:24:08,621 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-1682858084300506134_3279 src: /192.168.1.157:56578 dest: /192.168.1.157:50010
2017-05-23 14:24:09,161 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-1682858084300506134_3279 src: /192.168.1.157:56578 dest: /192.168.1.157:50010 of size 31976695
2017-05-23 14:24:11,622 INFO org.apache.hadoop.dfs.DataNode: Receiving block blk_-4385352657970579277_3278 src: /192.168.1.157:56579 dest: /192.168.1.157:50010
2017-05-23 14:24:12,181 INFO org.apache.hadoop.dfs.DataNode: Received block blk_-4385352657970579277_3278 src: /192.168.1.157:56579 dest: /192.168.1.157:50010 of size 31964396
2017-05-23 14:24:14,572 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4221972736090145134_3273 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4221972736090145134
2017-05-23 14:24:14,573 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3728342871020792467_3275 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3728342871020792467
2017-05-23 14:24:14,574 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-3429763027466752315_3272 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-3429763027466752315
2017-05-23 14:24:14,582 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-1682858084300506134_3279 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-1682858084300506134
2017-05-23 14:24:14,585 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_4715534340649059289_3271 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_4715534340649059289
2017-05-23 14:24:14,585 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_5022035293455470419_3279 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_5022035293455470419
2017-05-23 14:30:47,858 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 6 msecs
2017-05-23 15:30:50,313 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 25 blocks got processed in 4 msecs
2017-05-23 15:30:53,321 INFO org.apache.hadoop.dfs.DataNode: Deleting block blk_-4385352657970579277_3278 file /home/ubuntu/old_hadoop_temp/dfs/data/current/blk_-4385352657970579277
2017-05-23 16:30:53,141 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-23 17:30:53,146 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-05-23 18:30:55,810 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-23 19:30:58,781 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-23 20:31:01,358 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 5 msecs
2017-05-23 21:31:01,365 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 4 msecs
2017-05-23 22:31:01,410 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
2017-05-23 23:31:02,070 INFO org.apache.hadoop.dfs.DataNode: BlockReport of 24 blocks got processed in 3 msecs
